xla/service/gpu/cudnn_fused_conv_rewriter.cc:79:// nvidia currently recommends that we enable this only on Ampere+, but we've
xla/service/gpu/cudnn_fused_conv_rewriter_test.cc:356:                    "the Nvidia Ampere+ GPUs.";
xla/service/gpu/cudnn_fused_conv_rewriter_test.cc:384:                    "the Nvidia Ampere+ GPUs.";
xla/service/gpu/cudnn_fused_conv_rewriter_test.cc:407:           "the Nvidia Ampere+ GPUs.";
xla/service/gpu/cudnn_fused_conv_rewriter_test.cc:1518:  // elu fusion is only active on Ampere+.
xla/service/gpu/cudnn_fused_conv_rewriter_test.cc:1616:  // relu6 fusion is only enabled on Ampere+.
xla/service/gpu/cudnn_fused_conv_rewriter_test.cc:1704:  // Leaky-relu fusion is only enabled on Ampere+.
xla/service/gpu/ir_emitter_triton_test.cc:2478:    GTEST_SKIP() << "This test is for Ampere+ GPUs.";
xla/service/gpu/tests/gpu_fused_mha_test.cc:447:      GTEST_SKIP() << "Fused MHA is supported with the Nvidia AMPERE+ GPUs and "
xla/service/gpu/tests/gpu_fused_mha_test.cc:476:      GTEST_SKIP() << "Fused MHA is supported with the Nvidia AMPERE+ GPUs and "
xla/service/gpu/tests/gpu_fused_mha_test.cc:504:      GTEST_SKIP() << "Fused MHA is supported with the Nvidia AMPERE+ GPUs and "
xla/service/gpu/tests/gpu_fused_mha_test.cc:534:      GTEST_SKIP() << "Fused MHA is supported with the Nvidia AMPERE+ GPUs and "
xla/service/gpu/tests/gpu_fused_mha_test.cc:565:      GTEST_SKIP() << "Fused MHA is supported with the Nvidia AMPERE+ GPUs and "
xla/service/gpu/tests/gpu_fused_mha_test.cc:595:      GTEST_SKIP() << "Fused MHA is supported with the Nvidia AMPERE+ GPUs and "
xla/service/gpu/tests/gpu_fused_mha_test.cc:625:      GTEST_SKIP() << "Fused MHA is supported with the Nvidia AMPERE+ GPUs and "
xla/service/gpu/tests/gpu_fused_mha_test.cc:653:      GTEST_SKIP() << "Fused MHA is supported with the Nvidia AMPERE+ GPUs and "
xla/service/gpu/tests/gpu_fused_mha_test.cc:677:      GTEST_SKIP() << "Fused MHA is supported with the Nvidia AMPERE+ GPUs and "
xla/service/gpu/tests/gpu_fused_mha_test.cc:705:      GTEST_SKIP() << "Fused MHA is supported with the Nvidia AMPERE+ GPUs and "
xla/service/gpu/tests/gpu_fused_mha_test.cc:1275:      GTEST_SKIP() << "Fused MHA is supported with the Nvidia AMPERE+ GPUs and "
xla/service/gpu/tests/gpu_fused_mha_test.cc:1307:      GTEST_SKIP() << "Fused MHA is supported with the Nvidia AMPERE+ GPUs and "
xla/service/gpu/tests/gpu_fused_mha_test.cc:1336:      GTEST_SKIP() << "Fused MHA is supported with the Nvidia AMPERE+ GPUs and "
xla/service/gpu/tests/gpu_fused_mha_test.cc:1368:      GTEST_SKIP() << "Fused MHA is supported with the Nvidia AMPERE+ GPUs and "
xla/service/gpu/tests/gpu_fused_mha_test.cc:1617:      GTEST_SKIP() << "Fused MHA is supported with the Nvidia AMPERE+ GPUs and "
xla/service/gpu/tests/gpu_fused_mha_test.cc:1647:      GTEST_SKIP() << "Fused MHA is supported with the Nvidia AMPERE+ GPUs and "
xla/service/gpu/tests/gpu_fused_mha_test.cc:1774:      GTEST_SKIP() << "Fused MHA is supported with the Nvidia AMPERE+ GPUs and "
xla/service/gpu/tests/gpu_fused_mha_test.cc:2162:      GTEST_SKIP() << "Fused MHA is supported with the Nvidia AMPERE+ GPUs and "
xla/service/gpu/tests/gpu_fused_mha_test.cc:2191:      GTEST_SKIP() << "Fused MHA is supported with the Nvidia AMPERE+ GPUs and "
xla/xla.proto:543:  // available and recommended for Ampere+ GPUs.
