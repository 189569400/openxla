/* Copyright 2023 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

#include <optional>

#include "xla/hlo/ir/hlo_computation.h"
#include "xla/hlo/ir/hlo_instruction.h"
#include "xla/hlo/ir/hlo_module.h"
#include "xla/hlo/ir/hlo_opcode.h"
#include "xla/service/copy_insertion.h"
#include "xla/service/gpu/buffer_sharing.h"
#include "xla/test.h"
#include "xla/tests/hlo_test_base.h"
#include "xla/service/loop_schedule_linearizer.h"
#include "xla/service/gpu/alias_passthrough_params.h"
#include "xla/service/gpu/test_double_buffer.h"
#include "xla/service/while_loop_trip_count_annotator.h"
#include "xla/service/hlo_cse.h"
#include "xla/service/hlo_dce.h"
#include "xla/service/algebraic_simplifier.h"


namespace xla {
namespace gpu {
namespace {

int64_t CountCopies(const HloComputation& computation) {
  int64_t count = 0;
  for (const auto& instruction : computation.instructions()) {
    if (instruction->opcode() == HloOpcode::kCopy) {
      count++;
    }
  }
  return count;
}

int64_t CountCopies(const HloModule& module) {
  int64_t count = 0;
  for (const auto& computation : module.computations()) {
    count += CountCopies(*computation);
  }
  return count;
}

void ExpectOptionalTrue(std::optional<bool> value) {
  EXPECT_TRUE(value.has_value());
  CHECK(value.has_value());
  EXPECT_TRUE(*value);
}

void ExpectOptionalFalse(std::optional<bool> value) {
  EXPECT_TRUE(value.has_value());
  CHECK(value.has_value());
  EXPECT_FALSE(*value);
}

using GpuCopyInsertionTest = HloTestBase;

// This is some kind of end-to-end test for FusionCanShareBufferHint.
TEST_F(GpuCopyInsertionTest, DUSBitcastNoCopy) {
  const char* const kModuleString = R"(
HloModule bitcast_fusion

fused_computation.549 {
  param_1.8511 = bf16[15,1,2,2048,48,128]{3,5,4,2,1,0} parameter(1)
  bitcast.52601 = bf16[15,1,2,48,128,2048]{5,4,3,2,1,0} bitcast(param_1.8511)
  param_0.6313 = bf16[2,48,128,2048]{3,2,1,0} parameter(0)
  bitcast.52600 = bf16[1,1,2,48,128,2048]{5,4,3,2,1,0} bitcast(param_0.6313)
  param_2.5901 = s32[] parameter(2)
  constant_7564 = s32[] constant(0)
  compare.3477 = pred[] compare(param_2.5901, constant_7564), direction=LT
  constant_11524 = s32[] constant(15)
  add.6580 = s32[] add(param_2.5901, constant_11524)
  select.5360 = s32[] select(compare.3477, add.6580, param_2.5901)
  ROOT dynamic-update-slice.325 = bf16[15,1,2,48,128,2048]{5,4,3,2,1,0} dynamic-update-slice(bitcast.52601, bitcast.52600, select.5360, constant_7564, constant_7564, constant_7564, constant_7564, constant_7564)
}

condition {
  constant_6915 = s32[] constant(15)
  param.218 = (bf16[2,48,128,2048]{3,2,1,0}, bf16[15,1,2,2048,48,128]{3,5,4,2,1,0}, s32[]) parameter(0)
  get-tuple-element.3714 = s32[] get-tuple-element(param.218), index=2
  ROOT compare.1738 = pred[] compare(get-tuple-element.3714, constant_6915), direction=LT
}

body {
  tuple_param = (bf16[2,48,128,2048]{3,2,1,0}, bf16[15,1,2,2048,48,128]{3,5,4,2,1,0}, s32[]) parameter(0)
  param_0 = bf16[2,48,128,2048]{3,2,1,0} get-tuple-element(tuple_param), index=0
  param_1 = bf16[15,1,2,2048,48,128]{3,5,4,2,1,0} get-tuple-element(tuple_param), index=1
  param_2 = s32[] get-tuple-element(tuple_param), index=2
  fusion.549 = bf16[15,1,2,48,128,2048]{5,4,3,2,1,0} fusion(param_0, param_1, param_2), kind=kLoop, calls=fused_computation.549
  bitcast = bf16[15,1,2,2048,48,128]{3,5,4,2,1,0} bitcast(fusion.549)
  constant_one = s32[] constant(1)
  add = s32[] add(param_2, constant_one), control-predecessors={fusion.549}
  ROOT tuple = (bf16[2,48,128,2048]{3,2,1,0}, bf16[15,1,2,2048,48,128]{3,5,4,2,1,0}, s32[]) tuple(param_0, bitcast, add)
}

ENTRY main {
  param_0 = bf16[2,48,128,2048]{3,2,1,0} parameter(0)
  param_1 = bf16[15,1,2,2048,48,128]{3,5,4,2,1,0} parameter(1)
  zero = s32[] constant(0)
  tuple = tuple(param_0, param_1, zero)
  ROOT while = (bf16[2,48,128,2048]{3,2,1,0}, bf16[15,1,2,2048,48,128]{3,5,4,2,1,0}, s32[]) while(tuple), condition=condition, body=body, backend_config="{\"known_trip_count\":{\"n\":\"15\"}}"
}
)";

  TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<xla::HloModule> module,
                          ParseAndReturnVerifiedModule(kModuleString));

  CopyInsertion copy_insertion(FusionCanShareBufferHint,
                               /*use_region_based_live_range_analysis=*/0);
  ASSERT_IS_OK(copy_insertion.Run(module.get(), {"foobar"}).status());
  VLOG(2) << module->ToString();
  // Copy insertion adds two copies inside the entry computation.
  EXPECT_EQ(CountCopies(*module->entry_computation()), 2);
  // We expect that for fusion.549, no further copy needs to be added to the
  // module.
  EXPECT_EQ(CountCopies(*module), 2);
}

using FusionCanShareBufferHintTest = HloTestBase;

TEST_F(FusionCanShareBufferHintTest, BufferCanBeSharedSameShape) {
  const char* const kModuleString = R"(
HloModule fusion

fused_computation {
  param_0.1 = f32[2,3]{1,0} parameter(0)
  neg = f32[2,3]{1,0} negate(param_0.1)
  ROOT mul = f32[2,3]{1,0} multiply(param_0.1, neg)
}

ENTRY main {
  param_0 = f32[2,3]{1,0} parameter(0)
  ROOT fusion = f32[2,3]{1,0} fusion(param_0), kind=kLoop, calls=fused_computation
}
)";

  TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<xla::HloModule> module,
                          ParseAndReturnVerifiedModule(kModuleString));
  HloInstruction* fusion = module->entry_computation()->root_instruction();
  ExpectOptionalTrue(FusionCanShareBufferHint(fusion, fusion->operand(0), {}));
}

TEST_F(FusionCanShareBufferHintTest, BufferCanBeSharedBitcastedShape) {
  const char* const kModuleString = R"(
HloModule fusion

fused_computation {
  param_0.1 = f32[2,3]{1,0} parameter(0)
  neg = f32[2,3]{1,0} negate(param_0.1)
  mul = f32[2,3]{1,0} multiply(param_0.1, neg)
  ROOT bitcast = f32[6]{0} bitcast(mul)
}

ENTRY main {
  param_0 = f32[2,3]{1,0} parameter(0)
  ROOT fusion = f32[6]{0} fusion(param_0), kind=kLoop, calls=fused_computation
}
)";

  TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<xla::HloModule> module,
                          ParseAndReturnVerifiedModule(kModuleString));
  HloInstruction* fusion = module->entry_computation()->root_instruction();
  ExpectOptionalTrue(FusionCanShareBufferHint(fusion, fusion->operand(0), {}));
}

TEST_F(FusionCanShareBufferHintTest,
       BufferCanBeSharedConvertedShapeSameByteWidth) {
  const char* const kModuleString = R"(
HloModule fusion

fused_computation {
  param_0.1 = f32[2,3]{1,0} parameter(0)
  neg = f32[2,3]{1,0} negate(param_0.1)
  mul = f32[2,3]{1,0} multiply(param_0.1, neg)
  ROOT convert = s32[2,3]{1,0} convert(mul)
}

ENTRY main {
  param_0 = f32[2,3]{1,0} parameter(0)
  ROOT fusion = s32[2,3]{1,0} fusion(param_0), kind=kLoop, calls=fused_computation
}
)";

  TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<xla::HloModule> module,
                          ParseAndReturnVerifiedModule(kModuleString));
  HloInstruction* fusion = module->entry_computation()->root_instruction();
  ExpectOptionalTrue(FusionCanShareBufferHint(fusion, fusion->operand(0), {}));
}

TEST_F(FusionCanShareBufferHintTest, BufferCanBeSharedMultiOutputFusion) {
  const char* const kModuleString = R"(
HloModule fusion

fused_computation {
  param_0.1 = f32[2,3]{1,0} parameter(0)
  param_1.1 = f32[2,3]{1,0} parameter(1)
  neg = f32[2,3]{1,0} negate(param_1.1)
  mul = f32[2,3]{1,0} multiply(param_0.1, neg)
  ROOT tuple = (f32[2,3]{1,0}, f32[2,3]{1,0}) tuple(mul, neg)
}

ENTRY main {
  param_0 = f32[2,3]{1,0} parameter(0)
  param_1 = f32[2,3]{1,0} parameter(1)
  ROOT fusion = (f32[2,3]{1,0}, f32[2,3]{1,0}) fusion(param_0, param_1), kind=kLoop, calls=fused_computation
}
)";

  TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<xla::HloModule> module,
                          ParseAndReturnVerifiedModule(kModuleString));
  HloInstruction* fusion = module->entry_computation()->root_instruction();
  ExpectOptionalTrue(FusionCanShareBufferHint(fusion, fusion->operand(0), {0}));
  // The second operand cannot share the buffer with the second fusion output,
  // because the 'neg' op is also used on the path to the first fusion output.
  ExpectOptionalFalse(
      FusionCanShareBufferHint(fusion, fusion->operand(1), {1}));
  // The first operand cannot share the buffer with the second fusion output,
  // because there is no path between them.
  ExpectOptionalFalse(
      FusionCanShareBufferHint(fusion, fusion->operand(0), {1}));
}

TEST_F(FusionCanShareBufferHintTest,
       BufferCannotBeSharedConvertedShapeDifferentByteWidth) {
  const char* const kModuleString = R"(
HloModule fusion

fused_computation {
  param_0.1 = f32[2,3]{1,0} parameter(0)
  neg = f32[2,3]{1,0} negate(param_0.1)
  mul = f32[2,3]{1,0} multiply(param_0.1, neg)
  ROOT convert = f16[2,3]{1,0} convert(mul)
}

ENTRY main {
  param_0 = f32[2,3]{1,0} parameter(0)
  ROOT fusion = f16[2,3]{1,0} fusion(param_0), kind=kLoop, calls=fused_computation
}
)";

  TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<xla::HloModule> module,
                          ParseAndReturnVerifiedModule(kModuleString));
  HloInstruction* fusion = module->entry_computation()->root_instruction();
  ExpectOptionalFalse(FusionCanShareBufferHint(fusion, fusion->operand(0), {}));
}

TEST_F(FusionCanShareBufferHintTest, BufferCannotBeSharedShapeBitcastConvert) {
  const char* const kModuleString = R"(
HloModule fusion

fused_computation {
  param_0.1 = s32[3]{0} parameter(0)
  neg = s32[3]{0} negate(param_0.1)
  mul = s32[3]{0} multiply(param_0.1, neg)
  ROOT bitcast-convert = s16[3,2]{1,0} bitcast-convert(mul)
}

ENTRY main {
  param_0 = s32[3]{0} parameter(0)
  ROOT fusion = s16[3,2]{1,0} fusion(param_0), kind=kLoop, calls=fused_computation
}
)";

  TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<xla::HloModule> module,
                          ParseAndReturnVerifiedModule(kModuleString));
  HloInstruction* fusion = module->entry_computation()->root_instruction();
  ExpectOptionalFalse(FusionCanShareBufferHint(fusion, fusion->operand(0), {}));
}

TEST_F(FusionCanShareBufferHintTest, BufferCannotBeSharedDueToCopy) {
  const char* const kModuleString = R"(
HloModule fusion

fused_computation {
  param_0.1 = s32[2,3]{0,1} parameter(0)
  copy = s32[2,3]{1,0} copy(param_0.1)
  ROOT neg = s32[2,3]{1,0} negate(copy)
}

ENTRY main {
  param_0 = s32[2,3]{0,1} parameter(0)
  ROOT fusion = s32[2,3]{1,0} fusion(param_0), kind=kLoop, calls=fused_computation
}
)";

  TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<xla::HloModule> module,
                          ParseAndReturnVerifiedModule(kModuleString));
  HloInstruction* fusion = module->entry_computation()->root_instruction();
  ExpectOptionalFalse(FusionCanShareBufferHint(fusion, fusion->operand(0), {}));
}

TEST_F(FusionCanShareBufferHintTest, BufferCannotBeSharedDueToTranspose) {
  const char* const kModuleString = R"(
HloModule fusion

fused_computation {
  param_0.1 = s32[2,3]{1,0} parameter(0)
  transpose = s32[3,2]{1,0} transpose(param_0.1), dimensions={1,0}
  ROOT neg = s32[3,2]{1,0} negate(transpose)
}

ENTRY main {
  param_0 = s32[2,3]{1,0} parameter(0)
  ROOT fusion = s32[3,2]{1,0} fusion(param_0), kind=kLoop, calls=fused_computation
}
)";

  TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<xla::HloModule> module,
                          ParseAndReturnVerifiedModule(kModuleString));
  HloInstruction* fusion = module->entry_computation()->root_instruction();
  ExpectOptionalFalse(FusionCanShareBufferHint(fusion, fusion->operand(0), {}));
}

TEST_F(FusionCanShareBufferHintTest,
       BufferCannotBeSharedDueToReduceAndBroadcast) {
  const char* const kModuleString = R"(
HloModule fusion

add {
  lhs = s32[] parameter(0)
  rhs = s32[] parameter(1)
  ROOT add = s32[] add(lhs, rhs)
}

fused_computation {
  param_0.1 = s32[3]{0} parameter(0)
  broadcast = s32[3,2]{1,0} broadcast(param_0.1), dimensions={0}
  zero = s32[] constant(0)
  ROOT reduce = s32[3]{0} reduce(broadcast, zero), to_apply=add, dimensions={1}
}

ENTRY main {
  param_0 = s32[3]{0} parameter(0)
  ROOT fusion = s32[3]{0} fusion(param_0), kind=kInput, calls=fused_computation
}
)";

  TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<xla::HloModule> module,
                          ParseAndReturnVerifiedModule(kModuleString));
  HloInstruction* fusion = module->entry_computation()->root_instruction();
  ExpectOptionalFalse(FusionCanShareBufferHint(fusion, fusion->operand(0), {}));
}

TEST_F(FusionCanShareBufferHintTest,
       BufferCanBeSharedBecauseDUSAndDSAccessSameSlice) {
  const char* const kModuleString = R"(
HloModule fusion

fused_computation {
  param_0.1 = s32[6]{0} parameter(0)
  bitcast = s32[2,3]{1,0} bitcast(param_0.1)
  zero = s32[] constant(0)
  param_1.1 = s32[] parameter(1)
  dynamic-slice = s32[1,2]{1,0} dynamic-slice(bitcast, param_1.1, zero), dynamic_slice_sizes={1,2}
  one = s32[] constant(1)
  broadcast = s32[1,2]{1,0} broadcast(one), dimensions={}
  add = s32[1,2] add(dynamic-slice, broadcast)
  dynamic-update-slice = s32[2,3]{1,0} dynamic-update-slice(bitcast, add, param_1.1, zero)
  ROOT bitcast.1 = s32[6]{0} bitcast(dynamic-update-slice)
}

ENTRY main {
  param_0 = s32[6]{0} parameter(0)
  param_1 = s32[] parameter(1)
  ROOT fusion = s32[6]{0} fusion(param_0, param_1), kind=kInput, calls=fused_computation
}
)";

  TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<xla::HloModule> module,
                          ParseAndReturnVerifiedModule(kModuleString));
  HloInstruction* fusion = module->entry_computation()->root_instruction();
  ExpectOptionalTrue(FusionCanShareBufferHint(fusion, fusion->operand(0), {}));
}

TEST_F(FusionCanShareBufferHintTest,
       BufferCannotBeSharedBecauseDUSAndDSAccessDifferentSliceSizes) {
  const char* const kModuleString = R"(
HloModule fusion

fused_computation {
  param_0.1 = s32[6]{0} parameter(0)
  bitcast = s32[2,3]{1,0} bitcast(param_0.1)
  zero = s32[] constant(0)
  param_1.1 = s32[] parameter(1)
  dynamic-slice = s32[1,2]{1,0} dynamic-slice(bitcast, param_1.1, zero), dynamic_slice_sizes={1,2}
  param_2.1 = s32[1,1]{1,0} parameter(2)
  dynamic-update-slice = s32[2,3]{1,0} dynamic-update-slice(bitcast, param_2.1, param_1.1, zero)
  param_3.1 = s32[2,3]{1,0} parameter(3)
  dynamic-update-slice.1 = s32[2,3]{1,0} dynamic-update-slice(param_3.1, dynamic-slice, param_1.1, zero)
  ROOT tuple = (s32[2,3]{1,0}, s32[2,3]{1,0}) tuple(dynamic-update-slice, dynamic-update-slice.1)
}

ENTRY main {
  param_0 = s32[6]{0} parameter(0)
  param_1 = s32[] parameter(1)
  param_2 = s32[1,1]{1,0} parameter(2)
  param_3 = s32[2,3]{1,0} parameter(3)
  ROOT fusion = (s32[2,3]{1,0}, s32[2,3]{1,0}) fusion(param_0, param_1, param_2, param_3), kind=kInput, calls=fused_computation
}
)";

  TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<xla::HloModule> module,
                          ParseAndReturnVerifiedModule(kModuleString));
  HloInstruction* fusion = module->entry_computation()->root_instruction();
  ExpectOptionalFalse(
      FusionCanShareBufferHint(fusion, fusion->operand(0), {0}));
}

TEST_F(FusionCanShareBufferHintTest,
       BufferCanBeSharedBecauseDUSAndDSAccessSlicesOfSizeOne) {
  const char* const kModuleString = R"(
HloModule fusion

fused_computation {
  param_0.1 = s32[6]{0} parameter(0)
  bitcast = s32[2,3]{1,0} bitcast(param_0.1)
  zero = s32[] constant(0)
  param_1.1 = s32[] parameter(1)
  dynamic-slice = s32[1,1]{1,0} dynamic-slice(bitcast, zero, param_1.1), dynamic_slice_sizes={1,1}
  one = s32[] constant(1)
  bitcasted_one = s32[1,1]{1,0} bitcast(one)
  add = s32[1,1] add(dynamic-slice, bitcasted_one)
  dynamic-update-slice = s32[2,3]{1,0} dynamic-update-slice(bitcast, add, param_1.1, zero)
  ROOT bitcast.1 = s32[6]{0} bitcast(dynamic-update-slice)
}

ENTRY main {
  param_0 = s32[6]{0} parameter(0)
  param_1 = s32[] parameter(1)
  ROOT fusion = s32[6]{0} fusion(param_0, param_1), kind=kInput, calls=fused_computation
}
)";

  TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<xla::HloModule> module,
                          ParseAndReturnVerifiedModule(kModuleString));
  HloInstruction* fusion = module->entry_computation()->root_instruction();
  ExpectOptionalTrue(FusionCanShareBufferHint(fusion, fusion->operand(0), {}));
}

TEST_F(FusionCanShareBufferHintTest,
       BufferCannotBeSharedBecauseDUSAndDSAccessDifferentOperands) {
  const char* const kModuleString = R"(
HloModule fusion

fused_computation {
  param_0.1 = s32[6]{0} parameter(0)
  bitcast = s32[2,3]{1,0} bitcast(param_0.1)
  zero = s32[] constant(0)
  param_1.1 = s32[] parameter(1)
  dynamic-slice = s32[1]{0} dynamic-slice(param_0.1, param_1.1), dynamic_slice_sizes={1}
  one = s32[1]{0} constant({1})
  add = s32[1] add(dynamic-slice, one)
  bitcasted_add = s32[1,1]{1,0} bitcast(add)
  dynamic-update-slice = s32[2,3]{1,0} dynamic-update-slice(bitcast, bitcasted_add, param_1.1, zero)
  ROOT bitcast.1 = s32[6]{0} bitcast(dynamic-update-slice)
}

ENTRY main {
  param_0 = s32[6]{0} parameter(0)
  param_1 = s32[] parameter(1)
  ROOT fusion = s32[6]{0} fusion(param_0, param_1), kind=kInput, calls=fused_computation
}
)";

  TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<xla::HloModule> module,
                          ParseAndReturnVerifiedModule(kModuleString));
  HloInstruction* fusion = module->entry_computation()->root_instruction();
  ExpectOptionalFalse(FusionCanShareBufferHint(fusion, fusion->operand(0), {}));
}

TEST_F(FusionCanShareBufferHintTest,
       BufferCannotBeSharedBecauseDUSAndDSAccessDifferentOverlappingOffsets) {
  const char* const kModuleString = R"(
HloModule fusion

fused_computation {
  param_0.1 = s32[6]{0} parameter(0)
  bitcast = s32[2,3]{1,0} bitcast(param_0.1)
  zero = s32[] constant(0)
  param_1.1 = s32[] parameter(1)
  dynamic-slice = s32[1,2]{1,0} dynamic-slice(bitcast, param_1.1, zero), dynamic_slice_sizes={1,2}
  one = s32[] constant(1)
  broadcast = s32[1,2]{1,0} broadcast(one), dimensions={}
  add = s32[1,2] add(dynamic-slice, broadcast)
  dynamic-update-slice = s32[2,3]{1,0} dynamic-update-slice(bitcast, add, param_1.1, one)
  ROOT bitcast.1 = s32[6]{0} bitcast(dynamic-update-slice)
}

ENTRY main {
  param_0 = s32[6]{0} parameter(0)
  param_1 = s32[] parameter(1)
  ROOT fusion = s32[6]{0} fusion(param_0, param_1), kind=kInput, calls=fused_computation
}
)";

  TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<xla::HloModule> module,
                          ParseAndReturnVerifiedModule(kModuleString));
  HloInstruction* fusion = module->entry_computation()->root_instruction();
  ExpectOptionalFalse(FusionCanShareBufferHint(fusion, fusion->operand(0), {}));
}

class GpuCopyInsertionDoubleBufferingTest : public GpuCopyInsertionTest {
  DebugOptions GetDebugOptionsForTest() override {
    DebugOptions debug_options = HloTestBase::GetDebugOptionsForTest();
    debug_options.set_xla_gpu_enable_while_loop_double_buffering(true);
    return debug_options;
  }
};

TEST_F(GpuCopyInsertionDoubleBufferingTest,
       DoubleBufferShouldNotInsertCopy) {
  const char* const kModuleString = R"(
HloModule all_gather_overlapping
condition {
  input_tuple = (f32[1,128], f32[2,128], s32[]) parameter(0)
  cond = s32[] get-tuple-element(input_tuple), index=2
  trip_count = s32[] constant(10)
  ROOT done = pred[] compare(cond, trip_count), direction=LT
}

body {
 input_tuple = (f32[1,128], f32[2,128], s32[]) parameter(0)
 param_0 = f32[1,128] get-tuple-element(input_tuple), index=0
 param_1 = f32[2,128] get-tuple-element(input_tuple), index=1
 cond = s32[] get-tuple-element(input_tuple), index=2
 c0 = f32[] constant(0)
 splat_c0 = f32[1,128] broadcast(c0), dimensions={}
 add = f32[1,128] add(splat_c0, param_0)
 // Start all-gather communication
 all-gather-start = (f32[1,128], f32[2,128]) all-gather-start(add), channel_id=1337, replica_groups={{0,1}}, dimensions={0}, use_global_device_ids=true
 // Intertwined with the all-gather communication, an operation happens which
 // depends on param_1, but crucially has a different output shape (which
 // excludes reusing param_1's buffer for its output).
 c1_s32 = s32[] constant(1)
 c0_s32 = s32[] constant(0)
 one = s32[] constant(1)
 cond_plus_1 = s32[] add(cond, one)
 dynamic-slice = f32[1,128] dynamic-slice(param_1, c1_s32, c0_s32), dynamic_slice_sizes={1,128}
 // The all-gather communication finishes
 all-gather-done = f32[2,128] all-gather-done(all-gather-start)
 ROOT output_tuple = (f32[1,128], f32[2,128], s32[]) tuple(dynamic-slice, all-gather-done, cond_plus_1)
}

ENTRY main {
 param_0 = f32[1,128] parameter(0)
 param_1 = f32[2,128] parameter(1)
 param_2 = s32[] constant(0)
 tuple = (f32[1,128], f32[2,128], s32[]) tuple(param_0, param_1, param_2)
 ROOT while = (f32[1,128], f32[2,128], s32[]) while(tuple), condition=condition, body=body, backend_config={"known_trip_count":{"n":"10"}}
})";

  TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<xla::HloModule> module,
                          ParseAndReturnVerifiedModule(kModuleString));
  CopyInsertion copy_insertion(GpuCompiler::FusionCanShareBufferHint,
                               /*use_region_based_live_range_analysis=*/-1);
  LoopScheduleLinearizer loop_linear(GpuCompiler::FusionCanShareBufferHint);
  AliasPassthroughParams alias_pass;
  TestDoubleBuffer test_double;
  WhileLoopTripCountAnnotator annotator;
  HloDCE dce;

  ASSERT_IS_OK(test_double.Run(module.get()).status());
  ASSERT_IS_OK(dce.Run(module.get()).status());
  ASSERT_IS_OK(annotator.Run(module.get()).status());
  ASSERT_IS_OK(alias_pass.Run(module.get()).status());

  ASSERT_IS_OK(loop_linear.Run(module.get()).status());

  ASSERT_IS_OK(copy_insertion.Run(module.get()).status());

  LOG(ERROR) << module->ToString();
  // We expect that for the while loop, no further copy needs to be added to the
  // module.
  HloInstruction* while_instruction;
  for(auto instr : module->entry_computation()->instructions()) {
    if(instr->opcode() == HloOpcode::kWhile) {
      while_instruction = instr;
    }
  }
  EXPECT_EQ(CountCopies(*(while_instruction->while_body())), 0);
}

TEST_F(GpuCopyInsertionDoubleBufferingTest,
       DoubleBufferShouldNotInsertCopyOddTripCount) {
  const char* const kModuleString = R"(
HloModule all_gather_overlapping
condition {
  input_tuple = (f32[1,128], f32[2,128], s32[]) parameter(0)
  cond = s32[] get-tuple-element(input_tuple), index=2
  trip_count = s32[] constant(10)
  ROOT done = pred[] compare(cond, trip_count), direction=LT
}

body {
 input_tuple = (f32[1,128], f32[2,128], s32[]) parameter(0)
 param_0 = f32[1,128] get-tuple-element(input_tuple), index=0
 param_1 = f32[2,128] get-tuple-element(input_tuple), index=1
 cond = s32[] get-tuple-element(input_tuple), index=2
 c0 = f32[] constant(0)
 splat_c0 = f32[1,128] broadcast(c0), dimensions={}
 add = f32[1,128] add(splat_c0, param_0)
 // Start all-gather communication
 all-gather-start = (f32[1,128], f32[2,128]) all-gather-start(add), channel_id=1337, replica_groups={{0,1}}, dimensions={0}, use_global_device_ids=true
 // Intertwined with the all-gather communication, an operation happens which
 // depends on param_1, but crucially has a different output shape (which
 // excludes reusing param_1's buffer for its output).
 c1_s32 = s32[] constant(1)
 c0_s32 = s32[] constant(0)
 one = s32[] constant(1)
 cond_plus_1 = s32[] add(cond, one)
 dynamic-slice = f32[1,128] dynamic-slice(param_1, c1_s32, c0_s32), dynamic_slice_sizes={1,128}
 // The all-gather communication finishes
 all-gather-done = f32[2,128] all-gather-done(all-gather-start)
 ROOT output_tuple = (f32[1,128], f32[2,128], s32[]) tuple(dynamic-slice, all-gather-done, cond_plus_1)
}

ENTRY main {
 param_0 = f32[1,128] parameter(0)
 param_1 = f32[2,128] parameter(1)
 param_2 = s32[] constant(0)
 tuple = (f32[1,128], f32[2,128], s32[]) tuple(param_0, param_1, param_2)
 ROOT while = (f32[1,128], f32[2,128], s32[]) while(tuple), condition=condition, body=body, backend_config={"known_trip_count":{"n":"11"}}
})";

  TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<xla::HloModule> module,
                          ParseAndReturnVerifiedModule(kModuleString));
  CopyInsertion copy_insertion(GpuCompiler::FusionCanShareBufferHint,
                               /*use_region_based_live_range_analysis=*/-1);
  LoopScheduleLinearizer loop_linear(GpuCompiler::FusionCanShareBufferHint);
  AliasPassthroughParams alias_pass;
  TestDoubleBuffer test_double;
  WhileLoopTripCountAnnotator annotator;
  HloDCE dce;

  ASSERT_IS_OK(test_double.Run(module.get()).status());
  ASSERT_IS_OK(dce.Run(module.get()).status());
  ASSERT_IS_OK(annotator.Run(module.get()).status());
  ASSERT_IS_OK(alias_pass.Run(module.get()).status());

  ASSERT_IS_OK(loop_linear.Run(module.get()).status());

  ASSERT_IS_OK(copy_insertion.Run(module.get()).status());

  LOG(ERROR) << module->ToString();
  // We expect that for the while loop, no further copy needs to be added to the
  // module.
  HloInstruction* while_instruction;
  for(auto instr : module->entry_computation()->instructions()) {
    if(instr->opcode() == HloOpcode::kWhile) {
      while_instruction = instr;
    }
  }
  EXPECT_EQ(CountCopies(*(while_instruction->while_body())), 0);
}

TEST_F(GpuCopyInsertionDoubleBufferingTest,
       DoubleBufferShouldNotInsertCopyCase2) {
  const char* const kModuleString = R"(
HloModule all_gather_overlapping
condition {
  input_tuple = (f32[1,128], f32[1,128], f32[2,128], s32[]) parameter(0)
  cond = s32[] get-tuple-element(input_tuple), index=3
  trip_count = s32[] constant(10)
  ROOT done = pred[] compare(cond, trip_count), direction=LT
}

body {
 input_tuple = (f32[1,128], f32[1,128], f32[2,128], s32[]) parameter(0)
 param_0 = f32[1,128] get-tuple-element(input_tuple), index=0
 param_1 = f32[2,128] get-tuple-element(input_tuple), index=2
 cond = s32[] get-tuple-element(input_tuple), index=3
 c0 = f32[] constant(0)
 splat_c0 = f32[1,128] broadcast(c0), dimensions={}
 add = f32[1,128] add(splat_c0, param_0)
 // Start all-gather communication
 all-gather-start = (f32[1,128], f32[2,128]) all-gather-start(add), channel_id=1337, replica_groups={{0,1}}, dimensions={0}, use_global_device_ids=true
 // Intertwined with the all-gather communication, an operation happens which
 // depends on param_1, but crucially has a different output shape (which
 // excludes reusing param_1's buffer for its output).
 c1_s32 = s32[] constant(1)
 c0_s32 = s32[] constant(0)
 one = s32[] constant(1)
 cond_plus_1 = s32[] add(cond, one)
 dynamic-slice = f32[1,128] dynamic-slice(param_1, c1_s32, c0_s32), dynamic_slice_sizes={1,128}
 // The all-gather communication finishes
 all-gather-done = f32[2,128] all-gather-done(all-gather-start)
 ROOT output_tuple = (f32[1,128], f32[1,128], f32[2,128], s32[]) tuple(param_0, dynamic-slice, all-gather-done, cond_plus_1)
}

ENTRY main {
 param_0 = f32[1,128] parameter(0)
 param_1 = f32[2,128] parameter(1)
 param_2 = s32[] constant(0)
 tuple = (f32[1,128], f32[1,128], f32[2,128], s32[]) tuple(param_0, param_0, param_1, param_2)
 ROOT while = (f32[1,128], f32[1,128], f32[2,128], s32[]) while(tuple), condition=condition, body=body, backend_config={"known_trip_count":{"n":"10"}}
})";

  TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<xla::HloModule> module,
                          ParseAndReturnVerifiedModule(kModuleString));
  CopyInsertion copy_insertion(GpuCompiler::FusionCanShareBufferHint,
                               /*use_region_based_live_range_analysis=*/-1);
  LoopScheduleLinearizer loop_linear(GpuCompiler::FusionCanShareBufferHint);
  AliasPassthroughParams alias_pass;
  TestDoubleBuffer test_double;
  WhileLoopTripCountAnnotator annotator;
  HloDCE dce;

  ASSERT_IS_OK(test_double.Run(module.get()).status());
  ASSERT_IS_OK(dce.Run(module.get()).status());
    LOG(ERROR) << "after dce " << module->ToString();

  ASSERT_IS_OK(annotator.Run(module.get()).status());
  ASSERT_IS_OK(alias_pass.Run(module.get()).status());

  ASSERT_IS_OK(loop_linear.Run(module.get()).status());
  ASSERT_IS_OK(copy_insertion.Run(module.get()).status());

  LOG(ERROR) << module->ToString();
  // We expect that for the while loop, no further copy needs to be added to the
  // module.
  HloInstruction* while_instruction;
  for(auto instr : module->entry_computation()->instructions()) {
    if(instr->opcode() == HloOpcode::kWhile) {
      while_instruction = instr;
    }
  }
  EXPECT_EQ(CountCopies(*(while_instruction->while_body())), 0);
}

TEST_F(GpuCopyInsertionDoubleBufferingTest,
       DoubleBufferGPT) {
  const char* const kModuleString = R"(
HloModule pjit__wrapped_step_fn, input_output_alias={ {0}: (0, {}, may-alias), {1}: (1, {}, may-alias), {2}: (2, {}, may-alias), {3}: (3, {}, may-alias), {4}: (4, {}, may-alias), {5}: (5, {}, may-alias), {6}: (6, {}, may-alias), {7}: (7, {}, may-alias), {8}: (8, {}, may-alias), {9}: (9, {}, may-alias), {10}: (10, {}, may-alias), {11}: (11, {}, may-alias), {12}: (12, {}, may-alias), {13}: (13, {}, may-alias), {14}: (14, {}, may-alias), {15}: (15, {}, may-alias), {16}: (16, {}, may-alias), {17}: (17, {}, may-alias), {18}: (18, {}, may-alias), {19}: (19, {}, may-alias), {20}: (20, {}, may-alias), {21}: (21, {}, may-alias), {22}: (22, {}, may-alias), {23}: (23, {}, may-alias), {24}: (24, {}, may-alias), {25}: (25, {}, may-alias), {26}: (26, {}, may-alias), {27}: (27, {}, may-alias), {28}: (28, {}, may-alias), {29}: (29, {}, may-alias), {30}: (30, {}, may-alias), {31}: (31, {}, may-alias), {32}: (32, {}, may-alias), {33}: (33, {}, may-alias), {34}: (34, {}, may-alias), {35}: (35, {}, may-alias), {36}: (36, {}, may-alias), {37}: (37, {}, may-alias), {38}: (38, {}, may-alias), {39}: (39, {}, may-alias), {40}: (40, {}, may-alias), {41}: (41, {}, may-alias), {42}: (42, {}, may-alias), {43}: (43, {}, may-alias), {44}: (44, {}, may-alias), {45}: (45, {}, may-alias), {46}: (46, {}, may-alias), {47}: (47, {}, may-alias), {48}: (48, {}, may-alias), {49}: (49, {}, may-alias), {50}: (50, {}, may-alias), {51}: (51, {}, may-alias), {52}: (52, {}, may-alias), {53}: (53, {}, may-alias) }, entry_computation_layout={(u32[], f32[8192]{0}, f32[8192]{0}, f32[32000]{0}, f32[1024,32000]{1,0}, /*index=5*/f32[8,32768]{1,0}, f32[8,1024,32768]{2,1,0}, f32[8,8192]{1,0}, f32[8,32768,1024]{2,1,0}, f32[8,8192]{1,0}, /*index=10*/f32[8,8192]{1,0}, f32[8,8192]{1,0}, f32[8,8192]{1,0}, f32[8,3,1024,128,64]{4,3,2,1,0}, f32[8,64]{1,0}, /*index=15*/f32[8,1024,128,64]{3,2,1,0}, s32[], s32[], s32[], f32[8192]{0}, /*index=20*/f32[8192]{0}, f32[32000]{0}, f32[1024,32000]{1,0}, f32[8192]{0}, f32[8192]{0}, /*index=25*/f32[32000]{0}, f32[1024,32000]{1,0}, s32[], s32[8]{0}, s32[8]{0}, /*index=30*/s32[8]{0}, f32[8,32768]{1,0}, f32[8,1024,32768]{2,1,0}, f32[8,8192]{1,0}, f32[8,32768,1024]{2,1,0}, /*index=35*/f32[8,8192]{1,0}, f32[8,8192]{1,0}, f32[8,8192]{1,0}, f32[8,8192]{1,0}, f32[8,3,1024,128,64]{4,3,2,1,0}, /*index=40*/f32[8,64]{1,0}, f32[8,1024,128,64]{3,2,1,0}, f32[8,32768]{1,0}, f32[8,1024,32768]{2,1,0}, f32[8,8192]{1,0}, /*index=45*/f32[8,32768,1024]{2,1,0}, f32[8,8192]{1,0}, f32[8,8192]{1,0}, f32[8,8192]{1,0}, f32[8,8192]{1,0}, /*index=50*/f32[8,3,1024,128,64]{4,3,2,1,0}, f32[8,64]{1,0}, f32[8,1024,128,64]{3,2,1,0}, s32[8]{0}, s32[2,2048]{1,0}, /*index=55*/s32[2,2048]{1,0}, f32[2,2048]{1,0}, f32[2,2048]{1,0})->(u32[], f32[8192]{0}, f32[8192]{0}, f32[32000]{0}, f32[1024,32000]{1,0}, /*index=5*/f32[8,32768]{1,0}, f32[8,1024,32768]{2,1,0}, f32[8,8192]{1,0}, f32[8,32768,1024]{2,1,0}, f32[8,8192]{1,0}, /*index=10*/f32[8,8192]{1,0}, f32[8,8192]{1,0}, f32[8,8192]{1,0}, f32[8,3,1024,128,64]{4,3,2,1,0}, f32[8,64]{1,0}, /*index=15*/f32[8,1024,128,64]{3,2,1,0}, s32[], s32[], s32[], f32[8192]{0}, /*index=20*/f32[8192]{0}, f32[32000]{0}, f32[1024,32000]{1,0}, f32[8192]{0}, f32[8192]{0}, /*index=25*/f32[32000]{0}, f32[1024,32000]{1,0}, s32[], s32[8]{0}, s32[8]{0}, /*index=30*/s32[8]{0}, f32[8,32768]{1,0}, f32[8,1024,32768]{2,1,0}, f32[8,8192]{1,0}, f32[8,32768,1024]{2,1,0}, /*index=35*/f32[8,8192]{1,0}, f32[8,8192]{1,0}, f32[8,8192]{1,0}, f32[8,8192]{1,0}, f32[8,3,1024,128,64]{4,3,2,1,0}, /*index=40*/f32[8,64]{1,0}, f32[8,1024,128,64]{3,2,1,0}, f32[8,32768]{1,0}, f32[8,1024,32768]{2,1,0}, f32[8,8192]{1,0}, /*index=45*/f32[8,32768,1024]{2,1,0}, f32[8,8192]{1,0}, f32[8,8192]{1,0}, f32[8,8192]{1,0}, f32[8,8192]{1,0}, /*index=50*/f32[8,3,1024,128,64]{4,3,2,1,0}, f32[8,64]{1,0}, f32[8,1024,128,64]{3,2,1,0}, s32[8]{0}, f32[], /*index=55*/f32[], f32[], f32[], f32[], f32[], /*index=60*/f32[], f32[], f32[], f32[], f32[], /*index=65*/f32[], f32[], s32[16,2048]{1,0}, f32[16]{0})}, allow_spmd_sharding_propagation_to_output={false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false}

region_15.791 {
  Arg_0.792 = f32[] parameter(0)
  Arg_1.793 = f32[] parameter(1)
  ROOT add.599 = f32[] add(Arg_0.792, Arg_1.793), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/lm.compute_loss/softmax/reduce_sum[axes=(0, 1, 2)]" source_file="/pax/praxis/praxis/layers/embedding_softmax.py" source_line=331}
}

fused_computation {
  param_0.1124 = f32[8,32768,1024]{1,2,0} parameter(0)
  bitcast.7367 = f32[8,1024,32768]{2,1,0} bitcast(param_0.1124)
  param_1.1569 = s32[] parameter(1)
  constant.1667 = s32[] constant(0)
  compare.669 = pred[] compare(param_1.1569, constant.1667), direction=LT, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/lt" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  constant.2303 = s32[] constant(8)
  add.1133 = s32[] add(param_1.1569, constant.2303), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/add" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  select.967 = s32[] select(compare.669, add.1133, param_1.1569), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/select_n" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  ROOT dynamic-slice.185 = f32[1,1024,32768]{2,1,0} dynamic-slice(bitcast.7367, select.967, constant.1667, constant.1667), dynamic_slice_sizes={1,1024,32768}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/dynamic_slice[slice_sizes=(1, 32768, 8192)]" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
} // fused_computation

fused_computation.1 {
  param_0.1118 = f32[8,3,1024,128,64]{4,3,1,2,0} parameter(0)
  bitcast.7368 = f32[8,1024,3,128,64]{4,3,2,1,0} bitcast(param_0.1118)
  param_1.1563 = s32[] parameter(1)
  constant.1668 = s32[] constant(0)
  compare.663 = pred[] compare(param_1.1563, constant.1668), direction=LT, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/lt" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  constant.2288 = s32[] constant(8)
  add.1127 = s32[] add(param_1.1563, constant.2288), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/add" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  select.960 = s32[] select(compare.663, add.1127, param_1.1563), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/select_n" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  ROOT dynamic-slice.186 = f32[1,1024,3,128,64]{4,3,2,1,0} dynamic-slice(bitcast.7368, select.960, constant.1668, constant.1668, constant.1668, /*index=5*/constant.1668), dynamic_slice_sizes={1,1024,3,128,64}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/dynamic_slice[slice_sizes=(1, 3, 8192, 128, 64)]" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
} // fused_computation.1

fused_computation.3 {
  param_0.6 = f32[8,2,2048,8192]{3,2,1,0} parameter(0)
  param_1.1545 = f32[2,2048,8192]{2,1,0} parameter(1)
  bitcast.7369 = f32[1,2,2048,8192]{3,2,1,0} bitcast(param_1.1545)
  param_2.1110 = s32[] parameter(2)
  constant.1671 = s32[] constant(0)
  compare.651 = pred[] compare(param_2.1110, constant.1671), direction=LT, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/lt" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  constant.2241 = s32[] constant(8)
  add.1114 = s32[] add(param_2.1110, constant.2241), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/add" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  select.948 = s32[] select(compare.651, add.1114, param_2.1110), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/select_n" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  ROOT dynamic-update-slice.92 = f32[8,2,2048,8192]{3,2,1,0} dynamic-update-slice(param_0.6, bitcast.7369, select.948, constant.1671, constant.1671, /*index=5*/constant.1671), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
} // fused_computation.3

fused_computation.4 {
  param_3.816 = f32[4096,8192]{1,0} parameter(3)
  bitcast.7536 = f32[2,2048,8192]{2,1,0} bitcast(param_3.816)
  param_0.845 = f32[4096,8192]{1,0} parameter(0)
  param_1.1239 = f32[8,8192]{1,0} parameter(1)
  param_4.506 = s32[] parameter(4)
  constant.1672 = s32[] constant(0)
  compare.659 = pred[] compare(param_4.506, constant.1672), direction=LT, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/lt" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  constant.2261 = s32[] constant(8)
  add.1123 = s32[] add(param_4.506, constant.2261), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/add" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  select.956 = s32[] select(compare.659, add.1123, param_4.506), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/select_n" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  dynamic-slice.187 = f32[1,8192]{1,0} dynamic-slice(param_1.1239, select.956, constant.1672), dynamic_slice_sizes={1,8192}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/dynamic_slice[slice_sizes=(1, 8192)]" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  bitcast.7371 = f32[8192]{0} bitcast(dynamic-slice.187)
  broadcast.2099 = f32[4096,8192]{1,0} broadcast(bitcast.7371), dimensions={1}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/ff_layer/ffn_layer2/bias/add" source_file="/pax/praxis/praxis/layers/linears.py" source_line=143}
  add.847 = f32[4096,8192]{1,0} add(param_0.845, broadcast.2099), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/ff_layer/ffn_layer2/bias/add" source_file="/pax/praxis/praxis/layers/linears.py" source_line=143}
  bitcast.7370 = f32[2,2048,8192]{2,1,0} bitcast(add.847)
  param_2.1116 = f32[2,2048,1]{1,0,2} parameter(2)
  bitcast.7535 = f32[2,2048]{1,0} bitcast(param_2.1116)
  broadcast.2098 = f32[2,2048,8192]{2,1,0} broadcast(bitcast.7535), dimensions={0,1}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/ff_layer/mul" source_file="/pax/praxis/praxis/layers/transformers.py" source_line=468}
  multiply.1289 = f32[2,2048,8192]{2,1,0} multiply(bitcast.7370, broadcast.2098), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/ff_layer/mul" source_file="/pax/praxis/praxis/layers/transformers.py" source_line=468}
  ROOT add.845 = f32[2,2048,8192]{2,1,0} add(bitcast.7536, multiply.1289), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/ff_layer/add" source_file="/pax/praxis/praxis/layers/transformers.py" source_line=489}
} // fused_computation.4

fused_computation.5 {
  param_0.847 = f32[4096,32768]{1,0} parameter(0)
  param_1.1241 = f32[8,32768]{1,0} parameter(1)
  param_3.808 = s32[] parameter(3)
  constant.1674 = s32[] constant(0)
  compare.649 = pred[] compare(param_3.808, constant.1674), direction=LT, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/lt" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  constant.2234 = s32[] constant(8)
  add.1111 = s32[] add(param_3.808, constant.2234), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/add" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  select.946 = s32[] select(compare.649, add.1111, param_3.808), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/select_n" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  dynamic-slice.188 = f32[1,32768]{1,0} dynamic-slice(param_1.1241, select.946, constant.1674), dynamic_slice_sizes={1,32768}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/dynamic_slice[slice_sizes=(1, 32768)]" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  bitcast.7373 = f32[32768]{0} bitcast(dynamic-slice.188)
  broadcast.2107 = f32[4096,32768]{1,0} broadcast(bitcast.7373), dimensions={1}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/ff_layer/ffn_layer1/bias/add" source_file="/pax/praxis/praxis/layers/linears.py" source_line=143}
  add.850 = f32[4096,32768]{1,0} add(param_0.847, broadcast.2107), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/ff_layer/ffn_layer1/bias/add" source_file="/pax/praxis/praxis/layers/linears.py" source_line=143}
  bitcast.7372 = f32[2,2048,32768]{2,1,0} bitcast(add.850)
  multiply.1296 = f32[2,2048,32768]{2,1,0} multiply(bitcast.7372, bitcast.7372), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/ff_layer/ffn_layer1/activation/mul" source_file="/pax/praxis/praxis/layers/activations.py" source_line=157}
  multiply.1295 = f32[2,2048,32768]{2,1,0} multiply(bitcast.7372, multiply.1296), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/ff_layer/ffn_layer1/activation/mul" source_file="/pax/praxis/praxis/layers/activations.py" source_line=157}
  constant.1646 = f32[] constant(0.044715)
  broadcast.2106 = f32[2,2048,32768]{2,1,0} broadcast(constant.1646), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/ff_layer/ffn_layer1/activation/mul" source_file="/pax/praxis/praxis/layers/activations.py" source_line=157}
  multiply.1294 = f32[2,2048,32768]{2,1,0} multiply(multiply.1295, broadcast.2106), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/ff_layer/ffn_layer1/activation/mul" source_file="/pax/praxis/praxis/layers/activations.py" source_line=157}
  add.849 = f32[2,2048,32768]{2,1,0} add(bitcast.7372, multiply.1294), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/ff_layer/ffn_layer1/activation/add" source_file="/pax/praxis/praxis/layers/activations.py" source_line=157}
  constant.1645 = f32[] constant(0.797884583)
  broadcast.2105 = f32[2,2048,32768]{2,1,0} broadcast(constant.1645), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/ff_layer/ffn_layer1/activation/mul" source_file="/pax/praxis/praxis/layers/activations.py" source_line=157}
  multiply.1293 = f32[2,2048,32768]{2,1,0} multiply(add.849, broadcast.2105), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/ff_layer/ffn_layer1/activation/mul" source_file="/pax/praxis/praxis/layers/activations.py" source_line=157}
  tanh.33 = f32[2,2048,32768]{2,1,0} tanh(multiply.1293), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/ff_layer/ffn_layer1/activation/tanh" source_file="/pax/praxis/praxis/layers/activations.py" source_line=157}
  constant.1673 = f32[] constant(1)
  broadcast.2104 = f32[2,2048,32768]{2,1,0} broadcast(constant.1673), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/ff_layer/ffn_layer1/activation/add" source_file="/pax/praxis/praxis/layers/activations.py" source_line=157}
  add.848 = f32[2,2048,32768]{2,1,0} add(tanh.33, broadcast.2104), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/ff_layer/ffn_layer1/activation/add" source_file="/pax/praxis/praxis/layers/activations.py" source_line=157}
  constant.1644 = f32[] constant(0.5)
  broadcast.2102 = f32[2,2048,32768]{2,1,0} broadcast(constant.1644), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/ff_layer/ffn_layer1/activation/mul" source_file="/pax/praxis/praxis/layers/activations.py" source_line=157}
  multiply.1292 = f32[2,2048,32768]{2,1,0} multiply(add.848, broadcast.2102), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/ff_layer/ffn_layer1/activation/mul" source_file="/pax/praxis/praxis/layers/activations.py" source_line=157}
  multiply.1291 = f32[2,2048,32768]{2,1,0} multiply(bitcast.7372, multiply.1292), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/ff_layer/ffn_layer1/activation/mul" source_file="/pax/praxis/praxis/layers/activations.py" source_line=157}
  param_2.1108 = f32[2,2048,1]{1,0,2} parameter(2)
  bitcast.7537 = f32[2,2048]{1,0} bitcast(param_2.1108)
  broadcast.2100 = f32[2,2048,32768]{2,1,0} broadcast(bitcast.7537), dimensions={0,1}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/ff_layer/mul" source_file="/pax/praxis/praxis/layers/transformers.py" source_line=455}
  ROOT multiply.1290 = f32[2,2048,32768]{2,1,0} multiply(multiply.1291, broadcast.2100), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/ff_layer/mul" source_file="/pax/praxis/praxis/layers/transformers.py" source_line=455}
} // fused_computation.5

fused_computation.6 {
  param_5.385 = f32[4096,8192]{1,0} parameter(5)
  bitcast.7676 = f32[2,2048,8192]{2,1,0} bitcast(param_5.385)
  param_4.512 = f32[2,2048]{1,0} parameter(4)
  constant.1676 = f32[] constant(0.000122070312)
  broadcast.2811 = f32[2,2048]{1,0} broadcast(constant.1676), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/layer_norm/div" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=370}
  multiply.1822 = f32[2,2048]{1,0} multiply(param_4.512, broadcast.2811), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/div" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=370}
  broadcast.2810 = f32[2,2048,8192]{2,1,0} broadcast(multiply.1822), dimensions={0,1}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/sub" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  subtract.356 = f32[2,2048,8192]{2,1,0} subtract(bitcast.7676, broadcast.2810), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/sub" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  param_2.1123 = f32[2,2048]{1,0} parameter(2)
  multiply.1299 = f32[2,2048]{1,0} multiply(param_2.1123, broadcast.2811), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/div" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=371}
  constant.1675 = f32[] constant(1e-06)
  broadcast.2112 = f32[2,2048]{1,0} broadcast(constant.1675), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/layer_norm/add" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  add.854 = f32[2,2048]{1,0} add(multiply.1299, broadcast.2112), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/add" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  rsqrt.34 = f32[2,2048]{1,0} rsqrt(add.854), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/rsqrt" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  broadcast.2110 = f32[2,2048,8192]{2,1,0} broadcast(rsqrt.34), dimensions={0,1}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/mul" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  multiply.1298 = f32[2,2048,8192]{2,1,0} multiply(subtract.356, broadcast.2110), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/mul" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  param_1.1546 = f32[8,8192]{1,0} parameter(1)
  param_3.822 = s32[] parameter(3)
  constant.1678 = s32[] constant(0)
  compare.653 = pred[] compare(param_3.822, constant.1678), direction=LT, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/lt" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  constant.2246 = s32[] constant(8)
  add.1116 = s32[] add(param_3.822, constant.2246), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/add" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  select.950 = s32[] select(compare.653, add.1116, param_3.822), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/select_n" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  dynamic-slice.190 = f32[1,8192]{1,0} dynamic-slice(param_1.1546, select.950, constant.1678), dynamic_slice_sizes={1,8192}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/dynamic_slice[slice_sizes=(1, 8192)]" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  constant.1677 = f32[] constant(1)
  broadcast.2111 = f32[1,8192]{1,0} broadcast(constant.1677), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/layer_norm/add" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=376}
  add.853 = f32[1,8192]{1,0} add(dynamic-slice.190, broadcast.2111), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/add" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=376}
  bitcast.7375 = f32[8192]{0} bitcast(add.853)
  broadcast.2109 = f32[2,2048,8192]{2,1,0} broadcast(bitcast.7375), dimensions={2}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/mul" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=376}
  multiply.1297 = f32[2,2048,8192]{2,1,0} multiply(multiply.1298, broadcast.2109), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/mul" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=376}
  param_0.11 = f32[8,8192]{1,0} parameter(0)
  dynamic-slice.189 = f32[1,8192]{1,0} dynamic-slice(param_0.11, select.950, constant.1678), dynamic_slice_sizes={1,8192}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/dynamic_slice[slice_sizes=(1, 8192)]" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  bitcast.7374 = f32[8192]{0} bitcast(dynamic-slice.189)
  broadcast.2108 = f32[2,2048,8192]{2,1,0} broadcast(bitcast.7374), dimensions={2}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/add" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=378}
  ROOT add.852 = f32[2,2048,8192]{2,1,0} add(multiply.1297, broadcast.2108), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/add" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=378}
} // fused_computation.6

fused_computation.7 {
  param_1.1560 = f32[4096,8192]{1,0} parameter(1)
  bitcast.7674 = f32[2,2048,8192]{2,1,0} bitcast(param_1.1560)
  param_0.1115 = f32[2,2048]{1,0} parameter(0)
  constant.2279 = f32[] constant(0.000122070312)
  broadcast.2807 = f32[2,2048]{1,0} broadcast(constant.2279), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/layer_norm/div" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=370}
  multiply.1818 = f32[2,2048]{1,0} multiply(param_0.1115, broadcast.2807), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/div" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=370}
  broadcast.2806 = f32[2,2048,8192]{2,1,0} broadcast(multiply.1818), dimensions={0,1}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/sub" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  subtract.354 = f32[2,2048,8192]{2,1,0} subtract(bitcast.7674, broadcast.2806), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/sub" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  multiply.1300 = f32[2,2048,8192]{2,1,0} multiply(subtract.354, subtract.354), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/mul" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=371}
  constant.1679 = f32[] constant(0)
  ROOT reduce.313 = f32[2,2048]{1,0} reduce(multiply.1300, constant.1679), dimensions={2}, to_apply=region_15.791, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/reduce_sum[axes=(2,)]" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=371}
} // fused_computation.7

fused_computation.9 {
  param_0.16 = f32[256,64,2048]{2,1,0} parameter(0)
  bitcast.7376 = f32[2,128,64,2048]{3,2,1,0} bitcast(param_0.16)
  ROOT transpose.241 = f32[2,2048,128,64]{3,2,1,0} transpose(bitcast.7376), dimensions={0,3,1,2}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/pv_einsum/BNTS,BSNH->BTNH/transpose[permutation=(0, 3, 1, 2)]" source_file="/pax/praxis/praxis/layers/base_ops.py" source_line=42}
}

fused_computation.10 {
  param_0.17 = f32[2,128,2048,2048]{3,2,1,0} parameter(0)
  param_1.27 = f32[2,128,2048]{2,1,0} parameter(1)
  broadcast.2116 = f32[2,128,2048,2048]{3,2,1,0} broadcast(param_1.27), dimensions={0,1,2}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/div" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=1487}
  ROOT divide.171 = f32[2,128,2048,2048]{3,2,1,0} divide(param_0.17, broadcast.2116), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/div" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=1487}
}

fused_computation.14 {
  param_0.854 = f32[8,64]{1,0} parameter(0)
  param_1.1549 = s32[] parameter(1)
  constant.1684 = s32[] constant(0)
  compare.657 = pred[] compare(param_1.1549, constant.1684), direction=LT, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/lt" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  constant.2256 = s32[] constant(8)
  add.1121 = s32[] add(param_1.1549, constant.2256), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/add" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  select.954 = s32[] select(compare.657, add.1121, param_1.1549), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/select_n" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  dynamic-slice.212 = f32[1,64]{1,0} dynamic-slice(param_0.854, select.954, constant.1684), dynamic_slice_sizes={1,64}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/dynamic_slice[slice_sizes=(1, 64)]" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  abs.20 = f32[1,64]{1,0} abs(dynamic-slice.212), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._scale_query/per_dim_scale/jit(softplus)/jit(logaddexp)/abs" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=403}
  negate.111 = f32[1,64]{1,0} negate(abs.20), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._scale_query/per_dim_scale/jit(softplus)/jit(logaddexp)/neg" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=403}
  exponential.54 = f32[1,64]{1,0} exponential(negate.111), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._scale_query/per_dim_scale/jit(softplus)/jit(logaddexp)/exp" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=403}
  ROOT log-plus-one.20 = f32[1,64]{1,0} log-plus-one(exponential.54), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._scale_query/per_dim_scale/jit(softplus)/jit(logaddexp)/log1p" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=403}
} // fused_computation.14

fused_computation.16 {
  param_4.510 = f32[2,2048,8192]{2,1,0} parameter(4)
  param_5.381 = f32[2,2048]{1,0} parameter(5)
  constant.1686 = f32[] constant(0.000122070312)
  broadcast.2803 = f32[2,2048]{1,0} broadcast(constant.1686), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/layer_norm/div" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=370}
  multiply.1814 = f32[2,2048]{1,0} multiply(param_5.381, broadcast.2803), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/layer_norm/div" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=370}
  broadcast.2802 = f32[2,2048,8192]{2,1,0} broadcast(multiply.1814), dimensions={0,1}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/layer_norm/sub" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  subtract.352 = f32[2,2048,8192]{2,1,0} subtract(param_4.510, broadcast.2802), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/layer_norm/sub" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  param_2.1119 = f32[2,2048]{1,0} parameter(2)
  multiply.1309 = f32[2,2048]{1,0} multiply(param_2.1119, broadcast.2803), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/layer_norm/div" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=371}
  constant.1685 = f32[] constant(1e-06)
  broadcast.2127 = f32[2,2048]{1,0} broadcast(constant.1685), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/layer_norm/add" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  add.859 = f32[2,2048]{1,0} add(multiply.1309, broadcast.2127), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/layer_norm/add" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  rsqrt.35 = f32[2,2048]{1,0} rsqrt(add.859), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/layer_norm/rsqrt" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  broadcast.2126 = f32[2,2048,8192]{2,1,0} broadcast(rsqrt.35), dimensions={0,1}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/layer_norm/mul" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  multiply.1308 = f32[2,2048,8192]{2,1,0} multiply(subtract.352, broadcast.2126), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/layer_norm/mul" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  param_1.1547 = f32[8,8192]{1,0} parameter(1)
  param_3.819 = s32[] parameter(3)
  constant.1688 = s32[] constant(0)
  compare.655 = pred[] compare(param_3.819, constant.1688), direction=LT, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/lt" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  constant.2251 = s32[] constant(8)
  add.1119 = s32[] add(param_3.819, constant.2251), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/add" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  select.952 = s32[] select(compare.655, add.1119, param_3.819), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/select_n" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  dynamic-slice.192 = f32[1,8192]{1,0} dynamic-slice(param_1.1547, select.952, constant.1688), dynamic_slice_sizes={1,8192}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/dynamic_slice[slice_sizes=(1, 8192)]" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  constant.1687 = f32[] constant(1)
  broadcast.2125 = f32[1,8192]{1,0} broadcast(constant.1687), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/layer_norm/add" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=376}
  add.858 = f32[1,8192]{1,0} add(dynamic-slice.192, broadcast.2125), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/layer_norm/add" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=376}
  bitcast.7382 = f32[8192]{0} bitcast(add.858)
  broadcast.2124 = f32[2,2048,8192]{2,1,0} broadcast(bitcast.7382), dimensions={2}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/layer_norm/mul" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=376}
  multiply.1307 = f32[2,2048,8192]{2,1,0} multiply(multiply.1308, broadcast.2124), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/layer_norm/mul" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=376}
  param_0.32 = f32[8,8192]{1,0} parameter(0)
  dynamic-slice.191 = f32[1,8192]{1,0} dynamic-slice(param_0.32, select.952, constant.1688), dynamic_slice_sizes={1,8192}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/dynamic_slice[slice_sizes=(1, 8192)]" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  bitcast.7381 = f32[8192]{0} bitcast(dynamic-slice.191)
  broadcast.2123 = f32[2,2048,8192]{2,1,0} broadcast(bitcast.7381), dimensions={2}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/layer_norm/add" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=378}
  ROOT add.857 = f32[2,2048,8192]{2,1,0} add(multiply.1307, broadcast.2123), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/layer_norm/add" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=378}
} // fused_computation.16

fused_computation.18 {
  param_0.1102 = f32[2,2048,8192]{2,1,0} parameter(0)
  param_1.1553 = f32[2,2048]{1,0} parameter(1)
  constant.2270 = f32[] constant(0.000122070312)
  broadcast.2799 = f32[2,2048]{1,0} broadcast(constant.2270), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/layer_norm/div" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=370}
  multiply.1810 = f32[2,2048]{1,0} multiply(param_1.1553, broadcast.2799), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/layer_norm/div" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=370}
  broadcast.2798 = f32[2,2048,8192]{2,1,0} broadcast(multiply.1810), dimensions={0,1}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/layer_norm/sub" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  subtract.350 = f32[2,2048,8192]{2,1,0} subtract(param_0.1102, broadcast.2798), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/layer_norm/sub" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  multiply.1311 = f32[2,2048,8192]{2,1,0} multiply(subtract.350, subtract.350), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/layer_norm/mul" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=371}
  constant.1689 = f32[] constant(0)
  ROOT reduce.314 = f32[2,2048]{1,0} reduce(multiply.1311, constant.1689), dimensions={2}, to_apply=region_15.791, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/layer_norm/reduce_sum[axes=(2,)]" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=371}
} // fused_computation.18

fused_computation.428 {
  param_0.852 = f32[4096,8192]{1,0} parameter(0)
  bitcast.7539 = f32[2,2048,8192]{2,1,0} bitcast(param_0.852)
  constant.1681 = f32[] constant(0)
  ROOT reduce.398 = f32[2,2048]{1,0} reduce(bitcast.7539, constant.1681), dimensions={2}, to_apply=region_15.791, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/reduce_sum[axes=(2,)]" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=370}
}

fused_computation.452 {
  param_0.1112 = f32[24576,4096]{1,0} parameter(0)
  bitcast.7672 = f32[3,128,64,2,2048]{4,3,2,1,0} bitcast(param_0.1112)
  transpose.288 = f32[3,2,128,64,2048]{4,3,2,1,0} transpose(bitcast.7672), dimensions={0,3,1,2,4}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/self_attention/combined_qkv/einsum/ABD,KDNH->KABNH/dot_general[dimension_numbers=(((1,), (2,)), ((), ())) precision=None preferred_element_type=float32]" source_file="/pax/praxis/praxis/layers/base_ops.py" source_line=42}
  slice.106 = f32[1,2,128,64,2048]{4,3,2,1,0} slice(transpose.288), slice={[1:2], [0:2], [0:128], [0:64], [0:2048]}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/self_attention/combined_qkv/slice[start_indices=(1, 0, 0, 0, 0) limit_indices=(2, 16, 2048, 128, 64) strides=(1, 1, 1, 1, 1)]" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=882}
  slice.105.clone.1 = f32[1,2,128,64,2048]{4,3,2,1,0} slice(transpose.288), slice={[2:3], [0:2], [0:128], [0:64], [0:2048]}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/self_attention/combined_qkv/slice[start_indices=(2, 0, 0, 0, 0) limit_indices=(3, 16, 2048, 128, 64) strides=(1, 1, 1, 1, 1)]" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=882}
  slice.79.clone.1 = f32[1,2,128,64,2048]{4,3,2,1,0} slice(transpose.288), slice={[0:1], [0:2], [0:128], [0:64], [0:2048]}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/self_attention/combined_qkv/slice[start_indices=(0, 0, 0, 0, 0) limit_indices=(1, 16, 2048, 128, 64) strides=(1, 1, 1, 1, 1)]" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=882}
  param_2.2024 = f32[8,64]{1,0} parameter(2)
  param_3.2009 = s32[] parameter(3)
  constant.1683.clone.1 = s32[] constant(0)
  compare.661.clone.1 = pred[] compare(param_3.2009, constant.1683.clone.1), direction=LT, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/lt" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  constant.2266.clone.1 = s32[] constant(8)
  add.1125.clone.1 = s32[] add(param_3.2009, constant.2266.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/add" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  select.958.clone.1 = s32[] select(compare.661.clone.1, add.1125.clone.1, param_3.2009), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/select_n" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  dynamic-slice.211.clone.1 = f32[1,64]{1,0} dynamic-slice(param_2.2024, select.958.clone.1, constant.1683.clone.1), dynamic_slice_sizes={1,64}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/dynamic_slice[slice_sizes=(1, 64)]" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  compare.511.clone.1 = pred[1,64]{1,0} compare(dynamic-slice.211.clone.1, dynamic-slice.211.clone.1), direction=NE, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._scale_query/per_dim_scale/jit(softplus)/jit(logaddexp)/ne" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=403}
  constant.1682.clone.1 = f32[] constant(0)
  broadcast.2122.clone.1 = f32[1,64]{1,0} broadcast(constant.1682.clone.1), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._scale_query/per_dim_scale/jit(softplus)/jit(logaddexp)/max" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=403}
  maximum.53.clone.1 = f32[1,64]{1,0} maximum(dynamic-slice.211.clone.1, broadcast.2122.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._scale_query/per_dim_scale/jit(softplus)/jit(logaddexp)/max" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=403}
  param_1.2248 = f32[1,64]{1,0} parameter(1)
  add.855.clone.1 = f32[1,64]{1,0} add(maximum.53.clone.1, param_1.2248), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._scale_query/per_dim_scale/jit(softplus)/jit(logaddexp)/add" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=403}
  select.754.clone.1 = f32[1,64]{1,0} select(compare.511.clone.1, dynamic-slice.211.clone.1, add.855.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._scale_query/per_dim_scale/jit(softplus)/jit(logaddexp)/select_n" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=403}
  constant.1649.clone.1 = f32[] constant(0.180336878)
  broadcast.2121.clone.1 = f32[1,64]{1,0} broadcast(constant.1649.clone.1), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._scale_query/per_dim_scale/mul" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=403}
  multiply.1306.clone.1 = f32[1,64]{1,0} multiply(select.754.clone.1, broadcast.2121.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._scale_query/per_dim_scale/mul" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=403}
  bitcast.7379.clone.1 = f32[64]{0} bitcast(multiply.1306.clone.1)
  broadcast.2120.clone.1 = f32[1,2,128,64,2048]{4,3,2,1,0} broadcast(bitcast.7379.clone.1), dimensions={3}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._scale_query/per_dim_scale/mul" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=404}
  multiply.1304.clone.1 = f32[1,2,128,64,2048]{4,3,2,1,0} multiply(slice.79.clone.1, broadcast.2120.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._scale_query/per_dim_scale/mul" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=404}
  bitcast.7378.clone.1 = f32[2,128,64,2048]{3,2,1,0} bitcast(multiply.1304.clone.1)
  transpose.242.clone.1 = f32[2,128,2048,64]{3,2,1,0} transpose(bitcast.7378.clone.1), dimensions={0,1,3,2}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._scale_query/per_dim_scale/mul" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=404}
  ROOT tuple.29 = (f32[1,2,128,64,2048]{4,3,2,1,0}, f32[1,2,128,64,2048]{4,3,2,1,0}, f32[2,128,2048,64]{3,2,1,0}) tuple(slice.106, slice.105.clone.1, transpose.242.clone.1)
} // fused_computation.452

fused_computation.453 {
  param_0.1119 = f32[8,1024,128,64]{3,2,1,0} parameter(0)
  param_1.2458 = s32[] parameter(1)
  constant.2294 = s32[] constant(0)
  compare.665 = pred[] compare(param_1.2458, constant.2294), direction=LT, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/lt" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  constant.2293 = s32[] constant(8)
  add.1129 = s32[] add(param_1.2458, constant.2293), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/add" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  select.962 = s32[] select(compare.665, add.1129, param_1.2458), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/select_n" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  ROOT dynamic-slice.223 = f32[1,1024,128,64]{3,2,1,0} dynamic-slice(param_0.1119, select.962, constant.2294, constant.2294, constant.2294), dynamic_slice_sizes={1,1024,128,64}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/dynamic_slice[slice_sizes=(1, 8192, 128, 64)]" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
} // fused_computation.453

fused_computation.454 {
  param_0.1121 = f32[8,1024,32768]{2,1,0} parameter(0)
  param_1.2457 = s32[] parameter(1)
  constant.2299 = s32[] constant(0)
  compare.667 = pred[] compare(param_1.2457, constant.2299), direction=LT, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/lt" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  constant.2298 = s32[] constant(8)
  add.1131 = s32[] add(param_1.2457, constant.2298), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/add" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  select.965 = s32[] select(compare.667, add.1131, param_1.2457), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/select_n" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  ROOT dynamic-slice.224 = f32[1,1024,32768]{2,1,0} dynamic-slice(param_0.1121, select.965, constant.2299, constant.2299), dynamic_slice_sizes={1,1024,32768}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/dynamic_slice[slice_sizes=(1, 8192, 32768)]" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
} // fused_computation.454

fused_computation.471 {
  param_0.1729 = f32[2,128,2048,2048]{3,2,1,0} parameter(0)
  param_1.2459 = f32[2,128,2048]{2,1,0} parameter(1)
  broadcast.2117.clone.1 = f32[2,128,2048,2048]{3,2,1,0} broadcast(param_1.2459), dimensions={0,1,2}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/sub" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=1487}
  subtract.292.clone.1 = f32[2,128,2048,2048]{3,2,1,0} subtract(param_0.1729, broadcast.2117.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/sub" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=1487}
  exponential.53.clone.1 = f32[2,128,2048,2048]{3,2,1,0} exponential(subtract.292.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/exp" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=1487}
  constant.4997 = f32[] constant(0)
  reduce.417 = f32[2,128,2048]{2,1,0} reduce(exponential.53.clone.1, constant.4997), dimensions={3}, to_apply=region_15.791, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/reduce_sum[axes=(3,)]" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=1487}
  ROOT tuple.26 = (f32[2,128,2048]{2,1,0}, f32[2,128,2048,2048]{3,2,1,0}) tuple(reduce.417, exponential.53.clone.1)
} // fused_computation.471

region_35.988 {
  Arg_0.989 = f32[] parameter(0)
  Arg_1.990 = f32[] parameter(1)
  ROOT maximum.31 = f32[] maximum(Arg_0.989, Arg_1.990), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/reduce_max[axes=(3,)]" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=1487}
}

fused_computation.472 {
  param_0.1727 = pred[2,128,2048,2048]{3,2,1,0} parameter(0)
  param_2.2251 = f32[256,2048,2048]{2,1,0} parameter(2)
  bitcast.7377.clone.1 = f32[2,128,2048,2048]{3,2,1,0} bitcast(param_2.2251)
  constant.1648.clone.1 = f32[] constant(0.02)
  broadcast.2119.clone.1 = f32[2,128,2048,2048]{3,2,1,0} broadcast(constant.1648.clone.1), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._cap_logits/div" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=1384}
  multiply.1303.clone.1 = f32[2,128,2048,2048]{3,2,1,0} multiply(bitcast.7377.clone.1, broadcast.2119.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._cap_logits/div" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=1384}
  tanh.34.clone.1 = f32[2,128,2048,2048]{3,2,1,0} tanh(multiply.1303.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._cap_logits/tanh" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=1384}
  constant.1647.clone.1 = f32[] constant(50)
  broadcast.2118.clone.1 = f32[2,128,2048,2048]{3,2,1,0} broadcast(constant.1647.clone.1), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._cap_logits/div" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=1384}
  multiply.1302.clone.1 = f32[2,128,2048,2048]{3,2,1,0} multiply(tanh.34.clone.1, broadcast.2118.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._cap_logits/mul" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=1384}
  param_1.2455 = f32[2,128,2048,2048]{3,2,1,0} parameter(1)
  select.753.clone.1 = f32[2,128,2048,2048]{3,2,1,0} select(param_0.1727, multiply.1302.clone.1, param_1.2455), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/jit(_where)/select_n" source_file="/pax/praxis/praxis/py_utils.py" source_line=743}
  constant.4993 = f32[] constant(-inf)
  reduce.418 = f32[2,128,2048]{2,1,0} reduce(select.753.clone.1, constant.4993), dimensions={3}, to_apply=region_35.988, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/reduce_max[axes=(3,)]" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=1487}
  ROOT tuple.27 = (f32[2,128,2048]{2,1,0}, f32[2,128,2048,2048]{3,2,1,0}) tuple(reduce.418, select.753.clone.1)
} // fused_computation.472

region_0.369.clone_spmd.clone.1 {
  param.64 = (s32[], f32[2,2048,8192]{2,1,0}, f32[8,2,2048,8192]{3,2,1,0}, f32[8,32768]{1,0}, f32[8,1024,32768]{2,1,0}, /*index=5*/f32[8,8192]{1,0}, f32[8,32768,1024]{1,2,0}, f32[8,8192]{1,0}, f32[8,8192]{1,0}, f32[8,8192]{1,0}, /*index=10*/f32[8,8192]{1,0}, f32[8,3,1024,128,64]{4,3,1,2,0}, f32[8,64]{1,0}, f32[8,1024,128,64]{3,2,1,0}, pred[2,128,2048,2048]{3,2,1,0}, /*index=15*/f32[2,128,2048,2048]{3,2,1,0}, f32[2,2048,1]{1,0,2}, f32[3,8192,128,64]{3,2,0,1}, f32[8192,128,64]{2,1,0}, f32[8192,32768]{1,0}, /*index=20*/f32[32768,8192]{0,1}, s32[]) parameter(0)
  get-tuple-element.183 = s32[] get-tuple-element(param.64), index=0
  constant.1451 = s32[] constant(1)
  add.600 = s32[] add(get-tuple-element.183, constant.1451), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/add" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  get-tuple-element.197 = f32[8,8192]{1,0} get-tuple-element(param.64), index=7
  get-tuple-element.196 = f32[8,8192]{1,0} get-tuple-element(param.64), index=8
  get-tuple-element.186 = f32[3,8192,128,64]{3,2,0,1} get-tuple-element(param.64), index=17
  bitcast.525 = f32[24576,8192]{0,1} bitcast(get-tuple-element.186)
  get-tuple-element.189 = f32[8,8192]{1,0} get-tuple-element(param.64), index=9
  get-tuple-element.188 = f32[8,8192]{1,0} get-tuple-element(param.64), index=10
  get-tuple-element.187 = f32[2,2048,8192]{2,1,0} get-tuple-element(param.64), index=1
  constant.1456 = f32[] constant(0)
  reduce.114 = f32[2,2048]{1,0} reduce(get-tuple-element.187, constant.1456), dimensions={2}, to_apply=region_15.791, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/layer_norm/reduce_sum[axes=(2,)]" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=370}
  fusion.18 = f32[2,2048]{1,0} fusion(get-tuple-element.187, reduce.114), kind=kInput, calls=fused_computation.18, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/layer_norm/reduce_sum[axes=(2,)]" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=371}
  fusion.16 = f32[2,2048,8192]{2,1,0} fusion(get-tuple-element.189, get-tuple-element.188, fusion.18, get-tuple-element.183, get-tuple-element.187, /*index=5*/reduce.114), kind=kLoop, calls=fused_computation.16, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/layer_norm/add" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=378}
  bitcast.585 = f32[8192,4096]{0,1} bitcast(fusion.16)
  custom-call.7 = f32[24576,4096]{1,0} custom-call(bitcast.525, bitcast.585), custom_call_target="__cublas$gemm", metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/self_attention/combined_qkv/einsum/ABD,KDNH->KABNH/dot_general[dimension_numbers=(((1,), (2,)), ((), ())) precision=None preferred_element_type=float32]" source_file="/pax/praxis/praxis/layers/base_ops.py" source_line=42}, backend_config={"alpha_real":1,"alpha_imag":0,"beta":0,"dot_dimension_numbers":{"lhs_contracting_dimensions":["1"],"rhs_contracting_dimensions":["0"],"lhs_batch_dimensions":[],"rhs_batch_dimensions":[]},"precision_config":{"operand_precision":["DEFAULT","DEFAULT"]},"epilogue":"DEFAULT"}
  get-tuple-element.191 = f32[8,64]{1,0} get-tuple-element(param.64), index=12
  fusion.14 = f32[1,64]{1,0} fusion(get-tuple-element.191, get-tuple-element.183), kind=kLoop, calls=fused_computation.14, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._scale_query/per_dim_scale/jit(softplus)/jit(logaddexp)/log1p" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=403}
  fusion.452 = (f32[1,2,128,64,2048]{4,3,2,1,0}, f32[1,2,128,64,2048]{4,3,2,1,0}, f32[2,128,2048,64]{3,2,1,0}) fusion(custom-call.7, fusion.14, get-tuple-element.191, get-tuple-element.183), kind=kInput, calls=fused_computation.452, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/self_attention/combined_qkv/slice[start_indices=(1, 0, 0, 0, 0) limit_indices=(2, 16, 2048, 128, 64) strides=(1, 1, 1, 1, 1)]" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=882}
  get-tuple-element.459 = f32[1,2,128,64,2048]{4,3,2,1,0} get-tuple-element(fusion.452), index=1
  bitcast.595 = f32[256,64,2048]{2,1,0} bitcast(get-tuple-element.459)
  get-tuple-element.190 = pred[2,128,2048,2048]{3,2,1,0} get-tuple-element(param.64), index=14
  get-tuple-element.192 = f32[2,128,2048,2048]{3,2,1,0} get-tuple-element(param.64), index=15
  get-tuple-element.460 = f32[2,128,2048,64]{3,2,1,0} get-tuple-element(fusion.452), index=2
  bitcast.634 = f32[256,2048,64]{2,1,0} bitcast(get-tuple-element.460)
  get-tuple-element.458 = f32[1,2,128,64,2048]{4,3,2,1,0} get-tuple-element(fusion.452), index=0
  bitcast.639 = f32[256,64,2048]{2,1,0} bitcast(get-tuple-element.458)
  custom-call.8 = f32[256,2048,2048]{2,1,0} custom-call(bitcast.634, bitcast.639), custom_call_target="__cublas$gemm", metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._atten_logits/qk_einsum/BTNH,BSNH->BNTS/dot_general[dimension_numbers=(((3,), (3,)), ((0, 2), (0, 2))) precision=None preferred_element_type=float32]" source_file="/pax/praxis/praxis/layers/base_ops.py" source_line=42}, backend_config={"alpha_real":1,"alpha_imag":0,"beta":0,"dot_dimension_numbers":{"lhs_contracting_dimensions":["2"],"rhs_contracting_dimensions":["1"],"lhs_batch_dimensions":["0"],"rhs_batch_dimensions":["0"]},"precision_config":{"operand_precision":["DEFAULT","DEFAULT"]},"epilogue":"DEFAULT"}
  fusion.472 = (f32[2,128,2048]{2,1,0}, f32[2,128,2048,2048]{3,2,1,0}) fusion(get-tuple-element.190, get-tuple-element.192, custom-call.8), kind=kInput, calls=fused_computation.472, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/reduce_max[axes=(3,)]" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=1487}
  get-tuple-element.457 = f32[2,128,2048,2048]{3,2,1,0} get-tuple-element(fusion.472), index=1
  get-tuple-element.456 = f32[2,128,2048]{2,1,0} get-tuple-element(fusion.472), index=0
  fusion.471 = (f32[2,128,2048]{2,1,0}, f32[2,128,2048,2048]{3,2,1,0}) fusion(get-tuple-element.457, get-tuple-element.456), kind=kInput, calls=fused_computation.471, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/reduce_sum[axes=(3,)]" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=1487}
  get-tuple-element.455 = f32[2,128,2048,2048]{3,2,1,0} get-tuple-element(fusion.471), index=1
  get-tuple-element.454 = f32[2,128,2048]{2,1,0} get-tuple-element(fusion.471), index=0
  fusion.10 = f32[2,128,2048,2048]{3,2,1,0} fusion(get-tuple-element.455, get-tuple-element.454), kind=kLoop, calls=fused_computation.10, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/div" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=1487}
  bitcast.671 = f32[256,2048,2048]{2,1,0} bitcast(fusion.10)
  custom-call.9 = f32[256,64,2048]{2,1,0} custom-call(bitcast.595, bitcast.671), custom_call_target="__cublas$gemm", metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/pv_einsum/BNTS,BSNH->BTNH/dot_general[dimension_numbers=(((1,), (3,)), ((0, 2), (0, 1))) precision=None preferred_element_type=float32]" source_file="/pax/praxis/praxis/layers/base_ops.py" source_line=42}, backend_config={"alpha_real":1,"alpha_imag":0,"beta":0,"dot_dimension_numbers":{"lhs_contracting_dimensions":["2"],"rhs_contracting_dimensions":["2"],"lhs_batch_dimensions":["0"],"rhs_batch_dimensions":["0"]},"precision_config":{"operand_precision":["DEFAULT","DEFAULT"]},"epilogue":"DEFAULT"}
  fusion.9 = f32[2,2048,128,64]{3,2,1,0} fusion(custom-call.9), kind=kInput, calls=fused_computation.9, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/pv_einsum/BNTS,BSNH->BTNH/transpose[permutation=(0, 3, 1, 2)]" source_file="/pax/praxis/praxis/layers/base_ops.py" source_line=42}
  bitcast.678 = f32[4096,8192]{1,0} bitcast(fusion.9)
  get-tuple-element.195 = f32[8192,128,64]{2,1,0} get-tuple-element(param.64), index=18
  bitcast.682 = f32[8192,8192]{0,1} bitcast(get-tuple-element.195)
  bitcast.686 = f32[4096,8192]{1,0} bitcast(get-tuple-element.187)
  cublas-gemm.1 = f32[4096,8192]{1,0} custom-call(bitcast.678, bitcast.682, bitcast.686), custom_call_target="__cublas$gemm", output_to_operand_aliasing={{}: (2, {})}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/self_attention/post/einsum/ABNH,DNH->ABD/dot_general[dimension_numbers=(((3, 2), (2, 1)), ((), ())) precision=None preferred_element_type=float32]" source_file="/pax/praxis/praxis/layers/base_ops.py" source_line=42}, backend_config={"alpha_real":1,"alpha_imag":0,"beta":1,"dot_dimension_numbers":{"lhs_contracting_dimensions":["1"],"rhs_contracting_dimensions":["0"],"lhs_batch_dimensions":[],"rhs_batch_dimensions":[]},"precision_config":{"operand_precision":["DEFAULT","DEFAULT"]},"epilogue":"DEFAULT"}
  fusion.428 = f32[2,2048]{1,0} fusion(cublas-gemm.1), kind=kInput, calls=fused_computation.428, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/reduce_sum[axes=(2,)]" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=370}
  fusion.7 = f32[2,2048]{1,0} fusion(fusion.428, cublas-gemm.1), kind=kInput, calls=fused_computation.7, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/reduce_sum[axes=(2,)]" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=371}
  fusion.6 = f32[2,2048,8192]{2,1,0} fusion(get-tuple-element.197, get-tuple-element.196, fusion.7, get-tuple-element.183, fusion.428, /*index=5*/cublas-gemm.1), kind=kLoop, calls=fused_computation.6, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/add" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=378}
  bitcast.746 = f32[4096,8192]{1,0} bitcast(fusion.6)
  get-tuple-element.200 = f32[8192,32768]{1,0} get-tuple-element(param.64), index=19
  custom-call.11 = f32[4096,32768]{1,0} custom-call(bitcast.746, get-tuple-element.200), custom_call_target="__cublas$gemm", metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/ff_layer/ffn_layer1/linear/einsum/...y,yz->...z/dot_general[dimension_numbers=(((2,), (0,)), ((), ())) precision=None preferred_element_type=float32]" source_file="/pax/praxis/praxis/layers/base_ops.py" source_line=42}, backend_config={"alpha_real":1,"alpha_imag":0,"beta":0,"dot_dimension_numbers":{"lhs_contracting_dimensions":["1"],"rhs_contracting_dimensions":["0"],"lhs_batch_dimensions":[],"rhs_batch_dimensions":[]},"precision_config":{"operand_precision":["DEFAULT","DEFAULT"]},"epilogue":"DEFAULT"}
  get-tuple-element.201 = f32[8,32768]{1,0} get-tuple-element(param.64), index=3
  get-tuple-element.202 = f32[2,2048,1]{1,0,2} get-tuple-element(param.64), index=16
  fusion.5 = f32[2,2048,32768]{2,1,0} fusion(custom-call.11, get-tuple-element.201, get-tuple-element.202, get-tuple-element.183), kind=kLoop, calls=fused_computation.5, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/ff_layer/mul" source_file="/pax/praxis/praxis/layers/transformers.py" source_line=455}
  bitcast.795 = f32[4096,32768]{1,0} bitcast(fusion.5)
  get-tuple-element.205 = f32[32768,8192]{0,1} get-tuple-element(param.64), index=20
  custom-call.12 = f32[4096,8192]{1,0} custom-call(bitcast.795, get-tuple-element.205), custom_call_target="__cublas$gemm", metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/ff_layer/ffn_layer2/linear/einsum/...y,yz->...z/dot_general[dimension_numbers=(((2,), (0,)), ((), ())) precision=None preferred_element_type=float32]" source_file="/pax/praxis/praxis/layers/base_ops.py" source_line=42}, backend_config={"alpha_real":1,"alpha_imag":0,"beta":0,"dot_dimension_numbers":{"lhs_contracting_dimensions":["1"],"rhs_contracting_dimensions":["0"],"lhs_batch_dimensions":[],"rhs_batch_dimensions":[]},"precision_config":{"operand_precision":["DEFAULT","DEFAULT"]},"epilogue":"DEFAULT"}
  get-tuple-element.206 = f32[8,8192]{1,0} get-tuple-element(param.64), index=5
  fusion.4 = f32[2,2048,8192]{2,1,0} fusion(custom-call.12, get-tuple-element.206, get-tuple-element.202, cublas-gemm.1, get-tuple-element.183), kind=kLoop, calls=fused_computation.4, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/ff_layer/add" source_file="/pax/praxis/praxis/layers/transformers.py" source_line=489}
  get-tuple-element.207 = f32[8,2,2048,8192]{3,2,1,0} get-tuple-element(param.64), index=2
  fusion.3 = f32[8,2,2048,8192]{3,2,1,0} fusion(get-tuple-element.207, get-tuple-element.187, get-tuple-element.183), kind=kLoop, calls=fused_computation.3, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  get-tuple-element.198 = f32[8,1024,32768]{2,1,0} get-tuple-element(param.64), index=4
  get-tuple-element.203 = f32[8,32768,1024]{1,2,0} get-tuple-element(param.64), index=6
  get-tuple-element.184 = f32[8,3,1024,128,64]{4,3,1,2,0} get-tuple-element(param.64), index=11
  get-tuple-element.193 = f32[8,1024,128,64]{3,2,1,0} get-tuple-element(param.64), index=13
  get-tuple-element.182 = s32[] get-tuple-element(param.64), index=21
  fusion.1 = f32[1,1024,3,128,64]{4,3,2,1,0} fusion(get-tuple-element.184, get-tuple-element.182), kind=kLoop, calls=fused_computation.1, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/dynamic_slice[slice_sizes=(1, 3, 8192, 128, 64)]" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  bitcast.850 = f32[3,1024,128,64]{3,2,0,1} bitcast(fusion.1)
  all-gather.20 = f32[3,8192,128,64]{3,2,0,1} all-gather(bitcast.850), channel_id=53, replica_groups={{0,1,2,3,4,5,6,7}}, dimensions={1}, use_global_device_ids=true, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/self_attention/combined_qkv/einsum/ABD,KDNH->KABNH/dot_general[dimension_numbers=(((1,), (2,)), ((), ())) precision=None preferred_element_type=float32]" source_file="/pax/praxis/praxis/layers/base_ops.py" source_line=42}
  fusion.453 = f32[1,1024,128,64]{3,2,1,0} fusion(get-tuple-element.193, get-tuple-element.182), kind=kLoop, calls=fused_computation.453, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/dynamic_slice[slice_sizes=(1, 8192, 128, 64)]" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  bitcast.866 = f32[1024,128,64]{2,1,0} bitcast(fusion.453)
  all-gather.21 = f32[8192,128,64]{2,1,0} all-gather(bitcast.866), channel_id=54, replica_groups={{0,1,2,3,4,5,6,7}}, dimensions={0}, use_global_device_ids=true, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/self_attention/post/einsum/ABNH,DNH->ABD/dot_general[dimension_numbers=(((3, 2), (2, 1)), ((), ())) precision=None preferred_element_type=float32]" source_file="/pax/praxis/praxis/layers/base_ops.py" source_line=42}
  fusion.454 = f32[1,1024,32768]{2,1,0} fusion(get-tuple-element.198, get-tuple-element.182), kind=kLoop, calls=fused_computation.454, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/dynamic_slice[slice_sizes=(1, 8192, 32768)]" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  bitcast.882 = f32[1024,32768]{1,0} bitcast(fusion.454)
  all-gather.22 = f32[8192,32768]{1,0} all-gather(bitcast.882), channel_id=55, replica_groups={{0,1,2,3,4,5,6,7}}, dimensions={0}, use_global_device_ids=true, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/ff_layer/ffn_layer1/linear/einsum/...y,yz->...z/dot_general[dimension_numbers=(((2,), (0,)), ((), ())) precision=None preferred_element_type=float32]" source_file="/pax/praxis/praxis/layers/base_ops.py" source_line=42}
  fusion = f32[1,1024,32768]{2,1,0} fusion(get-tuple-element.203, get-tuple-element.182), kind=kLoop, calls=fused_computation, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/dynamic_slice[slice_sizes=(1, 32768, 8192)]" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  bitcast.898 = f32[32768,1024]{0,1} bitcast(fusion)
  all-gather.23 = f32[32768,8192]{0,1} all-gather(bitcast.898), channel_id=56, replica_groups={{0,1,2,3,4,5,6,7}}, dimensions={1}, use_global_device_ids=true, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/ff_layer/ffn_layer2/linear/einsum/...y,yz->...z/dot_general[dimension_numbers=(((2,), (0,)), ((), ())) precision=None preferred_element_type=float32]" source_file="/pax/praxis/praxis/layers/base_ops.py" source_line=42}
  constant.1619 = s32[] constant(2)
  add.621 = s32[] add(get-tuple-element.183, constant.1619)
  ROOT tuple.15 = (s32[], f32[2,2048,8192]{2,1,0}, f32[8,2,2048,8192]{3,2,1,0}, f32[8,32768]{1,0}, f32[8,1024,32768]{2,1,0}, /*index=5*/f32[8,8192]{1,0}, f32[8,32768,1024]{1,2,0}, f32[8,8192]{1,0}, f32[8,8192]{1,0}, f32[8,8192]{1,0}, /*index=10*/f32[8,8192]{1,0}, f32[8,3,1024,128,64]{4,3,1,2,0}, f32[8,64]{1,0}, f32[8,1024,128,64]{3,2,1,0}, pred[2,128,2048,2048]{3,2,1,0}, /*index=15*/f32[2,128,2048,2048]{3,2,1,0}, f32[2,2048,1]{1,0,2}, f32[3,8192,128,64]{3,2,0,1}, f32[8192,128,64]{2,1,0}, f32[8192,32768]{1,0}, /*index=20*/f32[32768,8192]{0,1}, s32[]) tuple(add.600, fusion.4, fusion.3, get-tuple-element.201, get-tuple-element.198, /*index=5*/get-tuple-element.206, get-tuple-element.203, get-tuple-element.197, get-tuple-element.196, get-tuple-element.189, /*index=10*/get-tuple-element.188, get-tuple-element.184, get-tuple-element.191, get-tuple-element.193, get-tuple-element.190, /*index=15*/get-tuple-element.192, get-tuple-element.202, all-gather.20, all-gather.21, all-gather.22, /*index=20*/all-gather.23, add.621)
} // region_0.369.clone_spmd.clone.1

region_7.609.clone_spmd.clone.1 {
  cond_param = (s32[], f32[2,2048,8192]{2,1,0}, f32[8,2,2048,8192]{3,2,1,0}, f32[8,32768]{1,0}, f32[8,1024,32768]{2,1,0}, /*index=5*/f32[8,8192]{1,0}, f32[8,32768,1024]{1,2,0}, f32[8,8192]{1,0}, f32[8,8192]{1,0}, f32[8,8192]{1,0}, /*index=10*/f32[8,8192]{1,0}, f32[8,3,1024,128,64]{4,3,1,2,0}, f32[8,64]{1,0}, f32[8,1024,128,64]{3,2,1,0}, pred[2,128,2048,2048]{3,2,1,0}, /*index=15*/f32[2,128,2048,2048]{3,2,1,0}, f32[2,2048,1]{1,0,2}, f32[3,8192,128,64]{3,2,0,1}, f32[8192,128,64]{2,1,0}, f32[8192,32768]{1,0}, /*index=20*/f32[32768,8192]{0,1}, s32[]) parameter(0)
  get-tuple-element.208 = s32[] get-tuple-element(cond_param), index=0
  constant.1474 = s32[] constant(7)
  ROOT compare.364 = pred[] compare(get-tuple-element.208, constant.1474), direction=LT
}

fused_computation.21 {
  param_0.1183 = f32[8,32768,1024]{1,2,0} parameter(0)
  bitcast.7383 = f32[8,1024,32768]{2,1,0} bitcast(param_0.1183)
  constant.2399 = s32[] constant(7)
  param_1.1644 = s32[] parameter(1)
  subtract.380 = s32[] subtract(constant.2399, param_1.1644), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  constant.1693 = s32[] constant(0)
  compare.677 = pred[] compare(subtract.380, constant.1693), direction=LT, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/lt" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  constant.2397 = s32[] constant(15)
  subtract.379 = s32[] subtract(constant.2397, param_1.1644), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/add" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  select.981 = s32[] select(compare.677, subtract.379, subtract.380), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/select_n" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  ROOT dynamic-slice.193 = f32[1,1024,32768]{2,1,0} dynamic-slice(bitcast.7383, select.981, constant.1693, constant.1693), dynamic_slice_sizes={1,1024,32768}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/dynamic_slice[slice_sizes=(1, 32768, 8192)]" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
} // fused_computation.21

fused_computation.22 {
  param_0.1181 = f32[8,3,1024,128,64]{4,3,1,2,0} parameter(0)
  bitcast.7384 = f32[8,1024,3,128,64]{4,3,2,1,0} bitcast(param_0.1181)
  constant.2392 = s32[] constant(7)
  param_1.1641 = s32[] parameter(1)
  subtract.376 = s32[] subtract(constant.2392, param_1.1641), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  constant.1694 = s32[] constant(0)
  compare.675 = pred[] compare(subtract.376, constant.1694), direction=LT, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/lt" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  constant.2390 = s32[] constant(15)
  subtract.375 = s32[] subtract(constant.2390, param_1.1641), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/add" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  select.979 = s32[] select(compare.675, subtract.375, subtract.376), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/select_n" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  ROOT dynamic-slice.194 = f32[1,1024,3,128,64]{4,3,2,1,0} dynamic-slice(bitcast.7384, select.979, constant.1694, constant.1694, constant.1694, /*index=5*/constant.1694), dynamic_slice_sizes={1,1024,3,128,64}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/dynamic_slice[slice_sizes=(1, 3, 8192, 128, 64)]" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
} // fused_computation.22

fused_computation.24 {
  param_0.48 = f32[8,1024,128,64]{3,2,1,0} parameter(0)
  param_2.877 = f32[1024,128,64]{2,1,0} parameter(2)
  bitcast.7385 = f32[1,1024,128,64]{3,2,1,0} bitcast(param_2.877)
  param_1.64 = s32[] parameter(1)
  constant.1698 = s32[] constant(0)
  ROOT dynamic-update-slice.93 = f32[8,1024,128,64]{3,2,1,0} dynamic-update-slice(param_0.48, bitcast.7385, param_1.64, constant.1698, constant.1698, /*index=5*/constant.1698)
} // fused_computation.24

fused_computation.25 {
  param_0.49 = f32[8,64]{1,0} parameter(0)
  param_2.1155 = f32[64]{0} parameter(2)
  constant.1699 = f32[] constant(0.180336878)
  broadcast.2133 = f32[64]{0} broadcast(constant.1699), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._scale_query/per_dim_scale/mul" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=403}
  multiply.1317 = f32[64]{0} multiply(param_2.1155, broadcast.2133), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._scale_query/per_dim_scale/mul" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=403}
  param_3.845 = f32[8,64]{1,0} parameter(3)
  param_1.66 = s32[] parameter(1)
  constant.1700 = s32[] constant(0)
  dynamic-slice.213 = f32[1,64]{1,0} dynamic-slice(param_3.845, param_1.66, constant.1700), dynamic_slice_sizes={1,64}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/dynamic_slice[slice_sizes=(1, 64)]" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  bitcast.7541 = f32[64]{0} bitcast(dynamic-slice.213)
  constant.1650 = f32[] constant(inf)
  broadcast.2132 = f32[64]{0} broadcast(constant.1650), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._scale_query/per_dim_scale/jit(softplus)/eq" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=403}
  compare.515 = pred[64]{0} compare(bitcast.7541, broadcast.2132), direction=EQ, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._scale_query/per_dim_scale/jit(softplus)/eq" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=403}
  constant.1701 = f32[] constant(0)
  broadcast.2134 = f32[64]{0} broadcast(constant.1701), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._scale_query/per_dim_scale/jit(softplus)/jit(logaddexp)/max" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=403}
  select.758 = f32[64]{0} select(compare.515, broadcast.2134, bitcast.7541), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._scale_query/per_dim_scale/jit(softplus)/select_n" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=403}
  compare.671 = pred[64]{0} compare(bitcast.7541, bitcast.7541), direction=NE, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._scale_query/per_dim_scale/jit(softplus)/jit(logaddexp)/ne" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=403}
  maximum.75 = f32[64]{0} maximum(bitcast.7541, broadcast.2134), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._scale_query/per_dim_scale/jit(softplus)/jit(logaddexp)/max" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=403}
  abs.26 = f32[64]{0} abs(bitcast.7541), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._scale_query/per_dim_scale/jit(softplus)/jit(logaddexp)/abs" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=403}
  negate.138 = f32[64]{0} negate(abs.26), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._scale_query/per_dim_scale/jit(softplus)/jit(logaddexp)/neg" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=403}
  exponential.72 = f32[64]{0} exponential(negate.138), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._scale_query/per_dim_scale/jit(softplus)/jit(logaddexp)/exp" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=403}
  log-plus-one.26 = f32[64]{0} log-plus-one(exponential.72), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._scale_query/per_dim_scale/jit(softplus)/jit(logaddexp)/log1p" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=403}
  add.1135 = f32[64]{0} add(maximum.75, log-plus-one.26), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._scale_query/per_dim_scale/jit(softplus)/jit(logaddexp)/add" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=403}
  select.969 = f32[64]{0} select(compare.671, bitcast.7541, add.1135), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._scale_query/per_dim_scale/jit(softplus)/jit(logaddexp)/select_n" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=403}
  compare.514 = pred[64]{0} compare(select.969, broadcast.2132), direction=EQ, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._scale_query/per_dim_scale/jit(softplus)/eq" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=403}
  select.757 = f32[64]{0} select(compare.514, broadcast.2134, select.969), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._scale_query/per_dim_scale/jit(softplus)/select_n" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=403}
  subtract.296 = f32[64]{0} subtract(select.758, select.757), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._scale_query/per_dim_scale/jit(softplus)/sub" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=403}
  exponential.55 = f32[64]{0} exponential(subtract.296), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._scale_query/per_dim_scale/jit(softplus)/exp" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=403}
  multiply.1316 = f32[64]{0} multiply(multiply.1317, exponential.55), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._scale_query/per_dim_scale/jit(softplus)/mul" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=403}
  bitcast.7386 = f32[1,64]{1,0} bitcast(multiply.1316)
  ROOT dynamic-update-slice.94 = f32[8,64]{1,0} dynamic-update-slice(param_0.49, bitcast.7386, param_1.66, constant.1700), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
} // fused_computation.25

fused_computation.26 {
  param_1.1253 = f32[3,2,128,64,2048]{4,3,2,1,0} parameter(1)
  slice.92 = f32[1,2,128,64,2048]{4,3,2,1,0} slice(param_1.1253), slice={[0:1], [0:2], [0:128], [0:64], [0:2048]}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/combined_qkv/slice[start_indices=(0, 0, 0, 0, 0) limit_indices=(1, 16, 2048, 128, 64) strides=(1, 1, 1, 1, 1)]" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=882}
  bitcast.7542 = f32[2,128,64,2048]{3,2,1,0} bitcast(slice.92)
  param_0.858 = f32[2,128,64,2048]{3,2,1,0} parameter(0)
  multiply.1318 = f32[2,128,64,2048]{3,2,1,0} multiply(bitcast.7542, param_0.858), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._scale_query/per_dim_scale/mul" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=404}
  bitcast.7387 = f32[256,64,2048]{2,1,0} bitcast(multiply.1318), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._scale_query/per_dim_scale/mul" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=404}
  constant.1702 = f32[] constant(0)
  ROOT reduce.315 = f32[256,64]{1,0} reduce(bitcast.7387, constant.1702), dimensions={2}, to_apply=region_15.791
} // fused_computation.26

fused_computation.27 {
  param_2.881 = f32[8,3,1024,128,64]{4,3,1,2,0} parameter(2)
  bitcast.7389 = f32[8,1024,3,128,64]{4,3,2,1,0} bitcast(param_2.881)
  param_1.1254 = f32[3,128,64,1024]{2,1,0,3} parameter(1)
  bitcast.7388 = f32[1,1024,3,128,64]{4,3,2,1,0} bitcast(param_1.1254)
  param_0.53 = s32[] parameter(0)
  constant.1703 = s32[] constant(0)
  ROOT dynamic-update-slice.95 = f32[8,1024,3,128,64]{4,3,2,1,0} dynamic-update-slice(bitcast.7389, bitcast.7388, param_0.53, constant.1703, constant.1703, /*index=5*/constant.1703, constant.1703)
} // fused_computation.27

fused_computation.28 {
  param_0.54 = f32[8,8192]{1,0} parameter(0)
  param_2.882 = f32[8192]{0} parameter(2)
  bitcast.7390 = f32[1,8192]{1,0} bitcast(param_2.882)
  param_1.74 = s32[] parameter(1)
  constant.1704 = s32[] constant(0)
  ROOT dynamic-update-slice.96 = f32[8,8192]{1,0} dynamic-update-slice(param_0.54, bitcast.7390, param_1.74, constant.1704), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
} // fused_computation.28

fused_computation.29 {
  param_0.859 = f32[2,2048,8192]{2,1,0} parameter(0)
  param_1.1255 = f32[4096,8192]{1,0} parameter(1)
  bitcast.7543 = f32[2,2048,8192]{2,1,0} bitcast(param_1.1255)
  multiply.1319 = f32[2,2048,8192]{2,1,0} multiply(param_0.859, bitcast.7543), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/layer_norm/mul" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=376}
  bitcast.7391 = f32[4096,8192]{1,0} bitcast(multiply.1319), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/layer_norm/mul" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=376}
  constant.1705 = f32[] constant(0)
  reduce.316 = f32[8192]{0} reduce(bitcast.7391, constant.1705), dimensions={0}, to_apply=region_15.791, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/layer_norm/reduce_sum[axes=(0, 1)]" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=376}
  reduce.419 = f32[8192]{0} reduce(param_1.1255, constant.1705), dimensions={0}, to_apply=region_15.791, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/layer_norm/reduce_sum[axes=(0, 1)]" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=378}
  ROOT tuple.33 = (f32[8192]{0}, f32[8192]{0}) tuple(reduce.316, reduce.419)
} // fused_computation.29

fused_computation.30 {
  param_0.57 = f32[8,8192]{1,0} parameter(0)
  param_2.884 = f32[8192]{0} parameter(2)
  bitcast.7392 = f32[1,8192]{1,0} bitcast(param_2.884)
  param_1.79 = s32[] parameter(1)
  constant.1706 = s32[] constant(0)
  ROOT dynamic-update-slice.97 = f32[8,8192]{1,0} dynamic-update-slice(param_0.57, bitcast.7392, param_1.79, constant.1706), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
} // fused_computation.30

fused_computation.31 {
  param_0.58 = f32[8,8192]{1,0} parameter(0)
  param_2.885 = f32[8192]{0} parameter(2)
  bitcast.7393 = f32[1,8192]{1,0} bitcast(param_2.885)
  param_1.81 = s32[] parameter(1)
  constant.1707 = s32[] constant(0)
  ROOT dynamic-update-slice.98 = f32[8,8192]{1,0} dynamic-update-slice(param_0.58, bitcast.7393, param_1.81, constant.1707), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
} // fused_computation.31

fused_computation.32 {
  param_0.860 = f32[2,2048,8192]{2,1,0} parameter(0)
  param_1.1256 = f32[4096,8192]{1,0} parameter(1)
  bitcast.7544 = f32[2,2048,8192]{2,1,0} bitcast(param_1.1256)
  multiply.1320 = f32[2,2048,8192]{2,1,0} multiply(param_0.860, bitcast.7544), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/mul" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=376}
  bitcast.7394 = f32[4096,8192]{1,0} bitcast(multiply.1320), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/mul" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=376}
  constant.1708 = f32[] constant(0)
  reduce.317 = f32[8192]{0} reduce(bitcast.7394, constant.1708), dimensions={0}, to_apply=region_15.791, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/reduce_sum[axes=(0, 1)]" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=376}
  reduce.420 = f32[8192]{0} reduce(param_1.1256, constant.1708), dimensions={0}, to_apply=region_15.791, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/reduce_sum[axes=(0, 1)]" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=378}
  ROOT tuple.39 = (f32[8192]{0}, f32[8192]{0}) tuple(reduce.317, reduce.420)
} // fused_computation.32

fused_computation.33 {
  param_0.61 = f32[8,8192]{1,0} parameter(0)
  param_2.887 = f32[8192]{0} parameter(2)
  bitcast.7395 = f32[1,8192]{1,0} bitcast(param_2.887)
  param_1.86 = s32[] parameter(1)
  constant.1709 = s32[] constant(0)
  ROOT dynamic-update-slice.99 = f32[8,8192]{1,0} dynamic-update-slice(param_0.61, bitcast.7395, param_1.86, constant.1709), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
} // fused_computation.33

fused_computation.34 {
  param_2.888 = f32[8,32768,1024]{1,2,0} parameter(2)
  bitcast.7397 = f32[8,1024,32768]{2,1,0} bitcast(param_2.888)
  param_1.1257 = f32[32768,1024]{0,1} parameter(1)
  bitcast.7396 = f32[1,1024,32768]{2,1,0} bitcast(param_1.1257)
  param_0.63 = s32[] parameter(0)
  constant.1710 = s32[] constant(0)
  ROOT dynamic-update-slice.100 = f32[8,1024,32768]{2,1,0} dynamic-update-slice(bitcast.7397, bitcast.7396, param_0.63, constant.1710, constant.1710)
} // fused_computation.34

fused_computation.35 {
  param_0.64 = f32[8,8192]{1,0} parameter(0)
  param_2.889 = f32[8192]{0} parameter(2)
  bitcast.7398 = f32[1,8192]{1,0} bitcast(param_2.889)
  param_1.91 = s32[] parameter(1)
  constant.1711 = s32[] constant(0)
  ROOT dynamic-update-slice.101 = f32[8,8192]{1,0} dynamic-update-slice(param_0.64, bitcast.7398, param_1.91, constant.1711), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
} // fused_computation.35

fused_computation.36 {
  param_0.65 = f32[8,1024,32768]{2,1,0} parameter(0)
  param_2.890 = f32[1024,32768]{1,0} parameter(2)
  bitcast.7399 = f32[1,1024,32768]{2,1,0} bitcast(param_2.890)
  param_1.93 = s32[] parameter(1)
  constant.1713 = s32[] constant(0)
  ROOT dynamic-update-slice.102 = f32[8,1024,32768]{2,1,0} dynamic-update-slice(param_0.65, bitcast.7399, param_1.93, constant.1713, constant.1713)
} // fused_computation.36

fused_computation.37 {
  param_0.66 = f32[8,32768]{1,0} parameter(0)
  param_2.891 = f32[32768]{0} parameter(2)
  bitcast.7400 = f32[1,32768]{1,0} bitcast(param_2.891)
  param_1.95 = s32[] parameter(1)
  constant.1714 = s32[] constant(0)
  ROOT dynamic-update-slice.103 = f32[8,32768]{1,0} dynamic-update-slice(param_0.66, bitcast.7400, param_1.95, constant.1714), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
} // fused_computation.37

fused_computation.38 {
  param_3.68 = f32[2,2048,8192]{2,1,0} parameter(3)
  param_4.30 = f32[2,2048,8192]{2,1,0} parameter(4)
  add.865 = f32[2,2048,8192]{2,1,0} add(param_3.68, param_4.30), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/layer_norm/add_any" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=371}
  param_2.80 = f32[2,2048,8192]{2,1,0} parameter(2)
  add.864 = f32[2,2048,8192]{2,1,0} add(add.865, param_2.80), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/layer_norm/add_any" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  param_0.69 = f32[2,2048]{1,0} parameter(0)
  param_1.101 = f32[2,2048]{1,0} parameter(1)
  add.863 = f32[2,2048]{1,0} add(param_0.69, param_1.101), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/layer_norm/add_any" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  constant.1716 = f32[] constant(0.000122070312)
  broadcast.2136 = f32[2,2048]{1,0} broadcast(constant.1716), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/layer_norm/div" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=370}
  multiply.1321 = f32[2,2048]{1,0} multiply(add.863, broadcast.2136), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/layer_norm/div" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=370}
  broadcast.2135 = f32[2,2048,8192]{2,1,0} broadcast(multiply.1321), dimensions={0,1}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/layer_norm/broadcast_in_dim[shape=(16, 2048, 8192) broadcast_dimensions=(0, 1)]" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=370}
  ROOT add.861 = f32[2,2048,8192]{2,1,0} add(add.864, broadcast.2135), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/layer_norm/add_any" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=370}
} // fused_computation.38

fused_computation.39 {
  param_2.2028 = f32[4096,8192]{1,0} parameter(2)
  bitcast.7734.clone.1 = f32[2,2048,8192]{2,1,0} bitcast(param_2.2028)
  param_1.2255 = f32[1,8192]{1,0} parameter(1)
  bitcast.7733.clone.1 = f32[8192]{0} bitcast(param_1.2255)
  broadcast.2899.clone.1 = f32[2,2048,8192]{2,1,0} broadcast(bitcast.7733.clone.1), dimensions={2}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/layer_norm/mul" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=376}
  multiply.1861.clone.1 = f32[2,2048,8192]{2,1,0} multiply(bitcast.7734.clone.1, broadcast.2899.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/layer_norm/mul" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=376}
  param_0.1649 = f32[2,2048]{1,0} parameter(0)
  bitcast.7548.clone.1 = f32[1,2,2048]{2,1,0} bitcast(param_0.1649)
  rsqrt.38.clone.1 = f32[1,2,2048]{2,1,0} rsqrt(bitcast.7548.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/layer_norm/rsqrt" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  bitcast.7547.clone.1 = f32[2,2048]{1,0} bitcast(rsqrt.38.clone.1)
  broadcast.2137.clone.1 = f32[2,2048,8192]{2,1,0} broadcast(bitcast.7547.clone.1), dimensions={0,1}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/layer_norm/mul" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  multiply.1322.clone.1 = f32[2,2048,8192]{2,1,0} multiply(multiply.1861.clone.1, broadcast.2137.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/layer_norm/mul" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  negate.112 = f32[2,2048,8192]{2,1,0} negate(multiply.1322.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/layer_norm/neg" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  constant.1717 = f32[] constant(0)
  reduce.318 = f32[2,2048]{1,0} reduce(negate.112, constant.1717), dimensions={2}, to_apply=region_15.791, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/layer_norm/reduce_sum[axes=(2,)]" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  param_4.1751 = f32[8,2,2048,8192]{3,2,1,0} parameter(4)
  param_5.1556 = s32[] parameter(5)
  constant.2314.clone.1 = s32[] constant(0)
  dynamic-slice.228.clone.1 = f32[1,2,2048,8192]{3,2,1,0} dynamic-slice(param_4.1751, param_5.1556, constant.2314.clone.1, constant.2314.clone.1, constant.2314.clone.1), dynamic_slice_sizes={1,2,2048,8192}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/dynamic_slice[slice_sizes=(1, 16, 2048, 8192)]" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  bitcast.7680.clone.1 = f32[2,2048,8192]{2,1,0} bitcast(dynamic-slice.228.clone.1)
  param_3.2021 = f32[2,2048]{1,0} parameter(3)
  constant.2313.clone.1 = f32[] constant(0.000122070312)
  broadcast.2820.clone.1 = f32[2,2048]{1,0} broadcast(constant.2313.clone.1), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/layer_norm/div" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=370}
  multiply.1830.clone.1 = f32[2,2048]{1,0} multiply(param_3.2021, broadcast.2820.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/layer_norm/div" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=370}
  broadcast.2818.clone.1 = f32[2,2048,8192]{2,1,0} broadcast(multiply.1830.clone.1), dimensions={0,1}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/layer_norm/sub" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  subtract.360.clone.1 = f32[2,2048,8192]{2,1,0} subtract(bitcast.7680.clone.1, broadcast.2818.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/layer_norm/sub" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  multiply.1327.clone.1 = f32[2,2048,8192]{2,1,0} multiply(subtract.360.clone.1, multiply.1861.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/layer_norm/mul" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  reduce.320.clone.1 = f32[2,2048]{1,0} reduce(multiply.1327.clone.1, constant.1717), dimensions={2}, to_apply=region_15.791, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/layer_norm/reduce_sum[axes=(2,)]" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  ROOT tuple.32 = (f32[2,2048]{1,0}, f32[2,2048,8192]{2,1,0}, f32[2,2048]{1,0}) tuple(reduce.318, multiply.1322.clone.1, reduce.320.clone.1)
} // fused_computation.39

fused_computation.40 {
  param_3.2017 = f32[8,2,2048,8192]{3,2,1,0} parameter(3)
  param_4.1743 = s32[] parameter(4)
  constant.2324.clone.1 = s32[] constant(0)
  dynamic-slice.232.clone.1 = f32[1,2,2048,8192]{3,2,1,0} dynamic-slice(param_3.2017, param_4.1743, constant.2324.clone.1, constant.2324.clone.1, constant.2324.clone.1), dynamic_slice_sizes={1,2,2048,8192}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/dynamic_slice[slice_sizes=(1, 16, 2048, 8192)]" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  bitcast.7684.clone.1 = f32[2,2048,8192]{2,1,0} bitcast(dynamic-slice.232.clone.1)
  param_2.2038 = f32[2,2048]{1,0} parameter(2)
  constant.2323.clone.1 = f32[] constant(0.000122070312)
  broadcast.2831.clone.1 = f32[2,2048]{1,0} broadcast(constant.2323.clone.1), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/layer_norm/div" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=370}
  multiply.1835.clone.1 = f32[2,2048]{1,0} multiply(param_2.2038, broadcast.2831.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/layer_norm/div" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=370}
  broadcast.2830.clone.1 = f32[2,2048,8192]{2,1,0} broadcast(multiply.1835.clone.1), dimensions={0,1}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/layer_norm/sub" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  subtract.364.clone.1 = f32[2,2048,8192]{2,1,0} subtract(bitcast.7684.clone.1, broadcast.2830.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/layer_norm/sub" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  param_1.2262 = f32[2,2048]{1,0} parameter(1)
  bitcast.7402.clone.1 = f32[1,2,2048]{2,1,0} bitcast(param_1.2262)
  param_0.1651 = f32[2,2048]{1,0} parameter(0)
  bitcast.7549.clone.1 = f32[1,2,2048]{2,1,0} bitcast(param_0.1651)
  rsqrt.39.clone.1 = f32[1,2,2048]{2,1,0} rsqrt(bitcast.7549.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/layer_norm/rsqrt" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  divide.172.clone.1 = f32[1,2,2048]{2,1,0} divide(rsqrt.39.clone.1, bitcast.7549.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/layer_norm/div" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  constant.1719.clone.1 = f32[] constant(-0.5)
  broadcast.2140.clone.1 = f32[1,2,2048]{2,1,0} broadcast(constant.1719.clone.1), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/final_ln/mul" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  multiply.1326.clone.1 = f32[1,2,2048]{2,1,0} multiply(divide.172.clone.1, broadcast.2140.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/layer_norm/mul" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  multiply.1325.clone.1 = f32[1,2,2048]{2,1,0} multiply(bitcast.7402.clone.1, multiply.1326.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/layer_norm/mul" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  constant.1720.clone.1 = f32[] constant(0.000244140625)
  broadcast.2139.clone.1 = f32[1,2,2048]{2,1,0} broadcast(constant.1720.clone.1), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/mul" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=371}
  multiply.1324.clone.1 = f32[1,2,2048]{2,1,0} multiply(multiply.1325.clone.1, broadcast.2139.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/layer_norm/mul" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=371}
  bitcast.7401.clone.1 = f32[2,2048]{1,0} bitcast(multiply.1324.clone.1)
  broadcast.2138.clone.1 = f32[2,2048,8192]{2,1,0} broadcast(bitcast.7401.clone.1), dimensions={0,1}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/layer_norm/mul" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=371}
  multiply.1323.clone.1 = f32[2,2048,8192]{2,1,0} multiply(subtract.364.clone.1, broadcast.2138.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/layer_norm/mul" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=371}
  negate.113 = f32[2,2048,8192]{2,1,0} negate(multiply.1323.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/layer_norm/neg" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=371}
  constant.1718 = f32[] constant(0)
  reduce.319 = f32[2,2048]{1,0} reduce(negate.113, constant.1718), dimensions={2}, to_apply=region_15.791, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/layer_norm/reduce_sum[axes=(2,)]" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=371}
  ROOT tuple.31 = (f32[2,2048]{1,0}, f32[2,2048,8192]{2,1,0}) tuple(reduce.319, multiply.1323.clone.1)
} // fused_computation.40

fused_computation.46 {
  param_0.82 = f32[256,2048,64]{2,1,0} parameter(0)
  bitcast.7407 = f32[2,128,2048,64]{3,2,1,0} bitcast(param_0.82)
  ROOT transpose.245 = f32[2,128,64,2048]{3,2,1,0} transpose(bitcast.7407), dimensions={0,1,3,2}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._atten_logits/qk_einsum/BTNH,BSNH->BNTS/dot_general[dimension_numbers=(((3,), (1,)), ((0, 1), (0, 2))) precision=None preferred_element_type=float32]" source_file="/pax/praxis/praxis/layers/base_ops.py" source_line=42}
}

fused_computation.47 {
  param_0.873 = f32[3,2,128,64,2048]{4,3,2,1,0} parameter(0)
  slice.93 = f32[1,2,128,64,2048]{4,3,2,1,0} slice(param_0.873), slice={[1:2], [0:2], [0:128], [0:64], [0:2048]}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/combined_qkv/slice[start_indices=(1, 0, 0, 0, 0) limit_indices=(2, 16, 2048, 128, 64) strides=(1, 1, 1, 1, 1)]" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=882}
  bitcast.7408 = f32[2,128,64,2048]{3,2,1,0} bitcast(slice.93)
  ROOT transpose.246 = f32[2,128,2048,64]{3,2,1,0} transpose(bitcast.7408), dimensions={0,1,3,2}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._shard_blnh/sharding_constraint[sharding=GSPMDSharding({devices=[8,1,1,1]<=[8]}) resource_env=ResourceEnv(Mesh(device_ids=array([[[0],\n        [1],\n        [2],\n        [3],\n        [4],\n        [5],\n        [6],\n        [7]]]), axis_names=(\'replica\', \'data\', \'mdl\')), ()) unconstrained_dims=set()]" source_file="/pax/praxis/praxis/py_utils.py" source_line=486}
}

fused_computation.48 {
  param_5.282 = pred[1,2,2048,2048]{3,2,1,0} parameter(5)
  bitcast.7553 = pred[2,2048,2048]{2,1,0} bitcast(param_5.282)
  broadcast.2149 = pred[2,128,2048,2048]{3,2,1,0} broadcast(bitcast.7553), dimensions={0,2,3}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/jit(_where)/broadcast_in_dim[shape=(16, 128, 2048, 2048) broadcast_dimensions=(0, 2, 3)]" source_file="/pax/praxis/praxis/py_utils.py" source_line=743}
  param_2.896 = f32[2,128,2048]{2,1,0} parameter(2)
  negate.114 = f32[2,128,2048]{2,1,0} negate(param_2.896), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/neg" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=1487}
  broadcast.2145 = f32[2,128,2048,2048]{3,2,1,0} broadcast(negate.114), dimensions={0,1,2}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/broadcast_in_dim[shape=(16, 128, 2048, 2048) broadcast_dimensions=(0, 1, 2)]" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=1487}
  param_4.403 = f32[256,2048,2048]{2,1,0} parameter(4)
  bitcast.7552 = f32[2,128,2048,2048]{3,2,1,0} bitcast(param_4.403)
  param_3.691 = f32[2,128,2048]{2,1,0} parameter(3)
  broadcast.2146 = f32[2,128,2048,2048]{3,2,1,0} broadcast(param_3.691), dimensions={0,1,2}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/div" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=1487}
  divide.173 = f32[2,128,2048,2048]{3,2,1,0} divide(bitcast.7552, broadcast.2146), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/div" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=1487}
  add.869 = f32[2,128,2048,2048]{3,2,1,0} add(broadcast.2145, divide.173), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/add_any" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=1487}
  param_1.1272 = f32[2,128,2048,2048]{3,2,1,0} parameter(1)
  multiply.1335 = f32[2,128,2048,2048]{3,2,1,0} multiply(add.869, param_1.1272), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/mul" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=1487}
  constant.1726 = f32[] constant(0)
  broadcast.2144 = f32[2,128,2048,2048]{3,2,1,0} broadcast(constant.1726), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/jit(_where)/broadcast_in_dim[shape=(16, 128, 2048, 2048) broadcast_dimensions=()]" source_file="/pax/praxis/praxis/py_utils.py" source_line=743}
  select.759 = f32[2,128,2048,2048]{3,2,1,0} select(broadcast.2149, multiply.1335, broadcast.2144), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/jit(_where)/select_n" source_file="/pax/praxis/praxis/py_utils.py" source_line=743}
  constant.1723 = f32[] constant(50)
  broadcast.2147 = f32[2,128,2048,2048]{3,2,1,0} broadcast(constant.1723), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._cap_logits/div" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=1384}
  multiply.1334 = f32[2,128,2048,2048]{3,2,1,0} multiply(select.759, broadcast.2147), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._cap_logits/mul" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=1384}
  constant.1725 = f32[] constant(1)
  broadcast.2143 = f32[2,128,2048,2048]{3,2,1,0} broadcast(constant.1725), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._cap_logits/sub" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=1384}
  param_0.87 = f32[2,128,2048,2048]{3,2,1,0} parameter(0)
  subtract.297 = f32[2,128,2048,2048]{3,2,1,0} subtract(broadcast.2143, param_0.87), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._cap_logits/sub" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=1384}
  multiply.1332 = f32[2,128,2048,2048]{3,2,1,0} multiply(multiply.1334, subtract.297), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._cap_logits/mul" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=1384}
  multiply.1331 = f32[2,128,2048,2048]{3,2,1,0} multiply(multiply.1332, param_0.87), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._cap_logits/mul" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=1384}
  add.868 = f32[2,128,2048,2048]{3,2,1,0} add(multiply.1332, multiply.1331), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._cap_logits/add_any" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=1384}
  constant.1724 = f32[] constant(0.02)
  broadcast.2148 = f32[2,128,2048,2048]{3,2,1,0} broadcast(constant.1724), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._cap_logits/div" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=1384}
  ROOT multiply.1330 = f32[2,128,2048,2048]{3,2,1,0} multiply(add.868, broadcast.2148), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._cap_logits/div" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=1384}
} // fused_computation.48

fused_computation.49 {
  param_2.898 = f32[256,2048,2048]{2,1,0} parameter(2)
  bitcast.7554 = f32[2,128,2048,2048]{3,2,1,0} bitcast(param_2.898)
  constant.1727 = f32[] constant(1)
  broadcast.2151 = f32[2,128,2048]{2,1,0} broadcast(constant.1727), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/broadcast_in_dim[shape=(16, 128, 2048, 1) broadcast_dimensions=()]" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=1487}
  param_1.1273 = f32[2,128,2048]{2,1,0} parameter(1)
  multiply.1338 = f32[2,128,2048]{2,1,0} multiply(param_1.1273, param_1.1273), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/mul" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=1487}
  divide.174 = f32[2,128,2048]{2,1,0} divide(broadcast.2151, multiply.1338), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/div" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=1487}
  broadcast.2150 = f32[2,128,2048,2048]{3,2,1,0} broadcast(divide.174), dimensions={0,1,2}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/mul" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=1487}
  multiply.1337 = f32[2,128,2048,2048]{3,2,1,0} multiply(bitcast.7554, broadcast.2150), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/mul" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=1487}
  param_0.874 = f32[2,128,2048,2048]{3,2,1,0} parameter(0)
  multiply.1336 = f32[2,128,2048,2048]{3,2,1,0} multiply(multiply.1337, param_0.874), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/mul" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=1487}
  constant.1728 = f32[] constant(0)
  ROOT reduce.321 = f32[2,128,2048]{2,1,0} reduce(multiply.1336, constant.1728), dimensions={3}, to_apply=region_15.791, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/reduce_sum[axes=(3,)]" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=1487}
} // fused_computation.49

fused_computation.50 {
  param_3.96 = f32[2,2048,8192]{2,1,0} parameter(3)
  param_4.52 = f32[2,2048,8192]{2,1,0} parameter(4)
  add.874 = f32[2,2048,8192]{2,1,0} add(param_3.96, param_4.52), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/add_any" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=371}
  param_2.102 = f32[2,2048,8192]{2,1,0} parameter(2)
  add.873 = f32[2,2048,8192]{2,1,0} add(add.874, param_2.102), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/add_any" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  param_0.92 = f32[2,2048]{1,0} parameter(0)
  param_1.135 = f32[2,2048]{1,0} parameter(1)
  add.872 = f32[2,2048]{1,0} add(param_0.92, param_1.135), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/add_any" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  constant.1729 = f32[] constant(0.000122070312)
  broadcast.2153 = f32[2,2048]{1,0} broadcast(constant.1729), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/layer_norm/div" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=370}
  multiply.1339 = f32[2,2048]{1,0} multiply(add.872, broadcast.2153), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/div" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=370}
  broadcast.2152 = f32[2,2048,8192]{2,1,0} broadcast(multiply.1339), dimensions={0,1}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/broadcast_in_dim[shape=(16, 2048, 8192) broadcast_dimensions=(0, 1)]" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=370}
  ROOT add.870 = f32[2,2048,8192]{2,1,0} add(add.873, broadcast.2152), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/add_any" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=370}
} // fused_computation.50

fused_computation.51 {
  param_2.2043 = f32[4096,8192]{1,0} parameter(2)
  bitcast.7710.clone.1 = f32[2,2048,8192]{2,1,0} bitcast(param_2.2043)
  param_1.2270 = f32[1,8192]{1,0} parameter(1)
  bitcast.7709.clone.1 = f32[8192]{0} bitcast(param_1.2270)
  broadcast.2891.clone.1 = f32[2,2048,8192]{2,1,0} broadcast(bitcast.7709.clone.1), dimensions={2}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/mul" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=376}
  multiply.1853.clone.1 = f32[2,2048,8192]{2,1,0} multiply(bitcast.7710.clone.1, broadcast.2891.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/mul" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=376}
  param_0.1653 = f32[2,2048]{1,0} parameter(0)
  bitcast.7558.clone.1 = f32[1,2,2048]{2,1,0} bitcast(param_0.1653)
  rsqrt.40.clone.1 = f32[1,2,2048]{2,1,0} rsqrt(bitcast.7558.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/rsqrt" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  bitcast.7557.clone.1 = f32[2,2048]{1,0} bitcast(rsqrt.40.clone.1)
  broadcast.2154.clone.1 = f32[2,2048,8192]{2,1,0} broadcast(bitcast.7557.clone.1), dimensions={0,1}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/mul" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  multiply.1340.clone.1 = f32[2,2048,8192]{2,1,0} multiply(multiply.1853.clone.1, broadcast.2154.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/mul" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  negate.115 = f32[2,2048,8192]{2,1,0} negate(multiply.1340.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/neg" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  constant.1730 = f32[] constant(0)
  reduce.322 = f32[2,2048]{1,0} reduce(negate.115, constant.1730), dimensions={2}, to_apply=region_15.791, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/reduce_sum[axes=(2,)]" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  param_4.1766 = f32[4096,8192]{1,0} parameter(4)
  bitcast.7694.clone.1 = f32[2,2048,8192]{2,1,0} bitcast(param_4.1766)
  param_3.2032 = f32[2,2048]{1,0} parameter(3)
  constant.2347.clone.1 = f32[] constant(0.000122070312)
  broadcast.2855.clone.1 = f32[2,2048]{1,0} broadcast(constant.2347.clone.1), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/layer_norm/div" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=370}
  multiply.1841.clone.1 = f32[2,2048]{1,0} multiply(param_3.2032, broadcast.2855.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/div" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=370}
  broadcast.2854.clone.1 = f32[2,2048,8192]{2,1,0} broadcast(multiply.1841.clone.1), dimensions={0,1}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/sub" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=371}
  subtract.366.clone.1 = f32[2,2048,8192]{2,1,0} subtract(bitcast.7694.clone.1, broadcast.2854.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/sub" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=371}
  multiply.1345.clone.1 = f32[2,2048,8192]{2,1,0} multiply(subtract.366.clone.1, multiply.1853.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/mul" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  reduce.324.clone.1 = f32[2,2048]{1,0} reduce(multiply.1345.clone.1, constant.1730), dimensions={2}, to_apply=region_15.791, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/reduce_sum[axes=(2,)]" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  ROOT tuple.38 = (f32[2,2048]{1,0}, f32[2,2048,8192]{2,1,0}, f32[2,2048]{1,0}) tuple(reduce.322, multiply.1340.clone.1, reduce.324.clone.1)
} // fused_computation.51

fused_computation.52 {
  param_3.2028 = f32[4096,8192]{1,0} parameter(3)
  bitcast.7696.clone.1 = f32[2,2048,8192]{2,1,0} bitcast(param_3.2028)
  param_2.2053 = f32[2,2048]{1,0} parameter(2)
  constant.2350.clone.1 = f32[] constant(0.000122070312)
  broadcast.2859.clone.1 = f32[2,2048]{1,0} broadcast(constant.2350.clone.1), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/layer_norm/div" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=370}
  multiply.1843.clone.1 = f32[2,2048]{1,0} multiply(param_2.2053, broadcast.2859.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/div" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=370}
  broadcast.2858.clone.1 = f32[2,2048,8192]{2,1,0} broadcast(multiply.1843.clone.1), dimensions={0,1}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/sub" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=371}
  subtract.368.clone.1 = f32[2,2048,8192]{2,1,0} subtract(bitcast.7696.clone.1, broadcast.2858.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/sub" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=371}
  param_1.2277 = f32[2,2048]{1,0} parameter(1)
  bitcast.7410.clone.1 = f32[1,2,2048]{2,1,0} bitcast(param_1.2277)
  param_0.1655 = f32[2,2048]{1,0} parameter(0)
  bitcast.7559.clone.1 = f32[1,2,2048]{2,1,0} bitcast(param_0.1655)
  rsqrt.41.clone.1 = f32[1,2,2048]{2,1,0} rsqrt(bitcast.7559.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/rsqrt" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  divide.175.clone.1 = f32[1,2,2048]{2,1,0} divide(rsqrt.41.clone.1, bitcast.7559.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/div" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  constant.1732.clone.1 = f32[] constant(-0.5)
  broadcast.2157.clone.1 = f32[1,2,2048]{2,1,0} broadcast(constant.1732.clone.1), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/final_ln/mul" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  multiply.1344.clone.1 = f32[1,2,2048]{2,1,0} multiply(divide.175.clone.1, broadcast.2157.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/mul" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  multiply.1343.clone.1 = f32[1,2,2048]{2,1,0} multiply(bitcast.7410.clone.1, multiply.1344.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/mul" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  constant.1733.clone.1 = f32[] constant(0.000244140625)
  broadcast.2156.clone.1 = f32[1,2,2048]{2,1,0} broadcast(constant.1733.clone.1), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/mul" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=371}
  multiply.1342.clone.1 = f32[1,2,2048]{2,1,0} multiply(multiply.1343.clone.1, broadcast.2156.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/mul" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=371}
  bitcast.7409.clone.1 = f32[2,2048]{1,0} bitcast(multiply.1342.clone.1)
  broadcast.2155.clone.1 = f32[2,2048,8192]{2,1,0} broadcast(bitcast.7409.clone.1), dimensions={0,1}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/mul" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=371}
  multiply.1341.clone.1 = f32[2,2048,8192]{2,1,0} multiply(subtract.368.clone.1, broadcast.2155.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/mul" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=371}
  negate.116 = f32[2,2048,8192]{2,1,0} negate(multiply.1341.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/neg" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=371}
  constant.1731 = f32[] constant(0)
  reduce.323 = f32[2,2048]{1,0} reduce(negate.116, constant.1731), dimensions={2}, to_apply=region_15.791, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/reduce_sum[axes=(2,)]" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=371}
  ROOT tuple.37 = (f32[2,2048]{1,0}, f32[2,2048,8192]{2,1,0}) tuple(reduce.323, multiply.1341.clone.1)
} // fused_computation.52

fused_computation.59 {
  param_0.1155 = f32[4096,32768]{1,0} parameter(0)
  param_1.1612 = f32[8,32768]{1,0} parameter(1)
  param_2.1182 = s32[] parameter(2)
  constant.2359 = s32[] constant(0)
  dynamic-slice.238 = f32[1,32768]{1,0} dynamic-slice(param_1.1612, param_2.1182, constant.2359), dynamic_slice_sizes={1,32768}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/dynamic_slice[slice_sizes=(1, 32768)]" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  bitcast.7702 = f32[32768]{0} bitcast(dynamic-slice.238)
  broadcast.2873 = f32[4096,32768]{1,0} broadcast(bitcast.7702), dimensions={1}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/ffn_layer1/bias/add" source_file="/pax/praxis/praxis/layers/linears.py" source_line=143}
  add.1139 = f32[4096,32768]{1,0} add(param_0.1155, broadcast.2873), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/ffn_layer1/bias/add" source_file="/pax/praxis/praxis/layers/linears.py" source_line=143}
  bitcast.7563 = f32[2,2048,32768]{2,1,0} bitcast(add.1139)
  multiply.1800 = f32[2,2048,32768]{2,1,0} multiply(bitcast.7563, bitcast.7563), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/ffn_layer1/activation/mul" source_file="/pax/praxis/praxis/layers/activations.py" source_line=157}
  multiply.1363 = f32[2,2048,32768]{2,1,0} multiply(bitcast.7563, multiply.1800), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/ffn_layer1/activation/mul" source_file="/pax/praxis/praxis/layers/activations.py" source_line=157}
  constant.1654 = f32[] constant(0.044715)
  broadcast.2169 = f32[2,2048,32768]{2,1,0} broadcast(constant.1654), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/ff_layer/ffn_layer1/activation/mul" source_file="/pax/praxis/praxis/layers/activations.py" source_line=157}
  multiply.1362 = f32[2,2048,32768]{2,1,0} multiply(multiply.1363, broadcast.2169), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/ffn_layer1/activation/mul" source_file="/pax/praxis/praxis/layers/activations.py" source_line=157}
  add.880 = f32[2,2048,32768]{2,1,0} add(bitcast.7563, multiply.1362), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/ffn_layer1/activation/add" source_file="/pax/praxis/praxis/layers/activations.py" source_line=157}
  constant.1741 = f32[] constant(0.797884583)
  broadcast.2168 = f32[2,2048,32768]{2,1,0} broadcast(constant.1741), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/ff_layer/ffn_layer1/activation/mul" source_file="/pax/praxis/praxis/layers/activations.py" source_line=157}
  multiply.1360 = f32[2,2048,32768]{2,1,0} multiply(add.880, broadcast.2168), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/ffn_layer1/activation/mul" source_file="/pax/praxis/praxis/layers/activations.py" source_line=157}
  ROOT tanh.35 = f32[2,2048,32768]{2,1,0} tanh(multiply.1360), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/ffn_layer1/activation/tanh" source_file="/pax/praxis/praxis/layers/activations.py" source_line=157}
} // fused_computation.59

fused_computation.61 {
  constant.1738 = f32[] constant(1)
  broadcast.2171 = f32[2,2048]{1,0} broadcast(constant.1738), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/sub.body_fn/sub/x_layers_0/ff_layer/sub" source_file="/pax/praxis/praxis/layers/transformers.py" source_line=455}
  param_0.113 = f32[2,2048]{1,0} parameter(0)
  ROOT subtract.299 = f32[2,2048]{1,0} subtract(broadcast.2171, param_0.113), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/sub" source_file="/pax/praxis/praxis/layers/transformers.py" source_line=468}
}

fused_computation.63 {
  param_5.1577 = f32[4096,8192]{1,0} parameter(5)
  bitcast.7700.clone.1 = f32[2,2048,8192]{2,1,0} bitcast(param_5.1577)
  param_4.1783 = f32[2,2048]{1,0} parameter(4)
  constant.2356.clone.1 = f32[] constant(0.000122070312)
  broadcast.2871.clone.1 = f32[2,2048]{1,0} broadcast(constant.2356.clone.1), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/layer_norm/div" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=370}
  multiply.1847.clone.1 = f32[2,2048]{1,0} multiply(param_4.1783, broadcast.2871.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/div" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=370}
  broadcast.2870.clone.1 = f32[2,2048,8192]{2,1,0} broadcast(multiply.1847.clone.1), dimensions={0,1}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/sub" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=371}
  subtract.372.clone.1 = f32[2,2048,8192]{2,1,0} subtract(bitcast.7700.clone.1, broadcast.2870.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/sub" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=371}
  param_3.2044 = f32[2,2048]{1,0} parameter(3)
  bitcast.7566.clone.1 = f32[1,2,2048]{2,1,0} bitcast(param_3.2044)
  rsqrt.42.clone.1 = f32[1,2,2048]{2,1,0} rsqrt(bitcast.7566.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/rsqrt" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  bitcast.7565.clone.1 = f32[2,2048]{1,0} bitcast(rsqrt.42.clone.1)
  broadcast.2176.clone.1 = f32[2,2048,8192]{2,1,0} broadcast(bitcast.7565.clone.1), dimensions={0,1}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/mul" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  multiply.1367.clone.1 = f32[2,2048,8192]{2,1,0} multiply(subtract.372.clone.1, broadcast.2176.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/mul" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  param_2.2063 = f32[1,8192]{1,0} parameter(2)
  bitcast.7564 = f32[8192]{0} bitcast(param_2.2063)
  broadcast.2174 = f32[2,2048,8192]{2,1,0} broadcast(bitcast.7564), dimensions={2}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/mul" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=376}
  multiply.1366 = f32[2,2048,8192]{2,1,0} multiply(multiply.1367.clone.1, broadcast.2174), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/mul" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=376}
  param_0.116 = f32[8,8192]{1,0} parameter(0)
  param_1.173 = s32[] parameter(1)
  constant.1743 = s32[] constant(0)
  dynamic-slice.196 = f32[1,8192]{1,0} dynamic-slice(param_0.116, param_1.173, constant.1743), dynamic_slice_sizes={1,8192}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/dynamic_slice[slice_sizes=(1, 8192)]" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  bitcast.7413 = f32[8192]{0} bitcast(dynamic-slice.196)
  broadcast.2173 = f32[2,2048,8192]{2,1,0} broadcast(bitcast.7413), dimensions={2}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/add" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=378}
  add.882 = f32[2,2048,8192]{2,1,0} add(multiply.1366, broadcast.2173), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/add" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=378}
  ROOT tuple.43 = (f32[2,2048,8192]{2,1,0}, f32[2,2048,8192]{2,1,0}) tuple(add.882, multiply.1367.clone.1)
} // fused_computation.63

fused_computation.64 {
  param_0.119 = f32[8,8192]{1,0} parameter(0)
  param_1.176 = s32[] parameter(1)
  constant.1745 = s32[] constant(0)
  dynamic-slice.197 = f32[1,8192]{1,0} dynamic-slice(param_0.119, param_1.176, constant.1745), dynamic_slice_sizes={1,8192}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/dynamic_slice[slice_sizes=(1, 8192)]" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  constant.1744 = f32[] constant(1)
  broadcast.2175 = f32[1,8192]{1,0} broadcast(constant.1744), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/layer_norm/add" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=376}
  ROOT add.884 = f32[1,8192]{1,0} add(dynamic-slice.197, broadcast.2175), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/add" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=376}
} // fused_computation.64

fused_computation.66 {
  param_0.123 = f32[2,2048]{1,0} parameter(0)
  constant.1747 = f32[] constant(0.000122070312)
  broadcast.2178 = f32[2,2048]{1,0} broadcast(constant.1747), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/layer_norm/div" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=370}
  multiply.1368 = f32[2,2048]{1,0} multiply(param_0.123, broadcast.2178), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/div" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=371}
  constant.1746 = f32[] constant(1e-06)
  broadcast.2177 = f32[2,2048]{1,0} broadcast(constant.1746), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/layer_norm/add" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  ROOT add.885 = f32[2,2048]{1,0} add(multiply.1368, broadcast.2177), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/add" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
} // fused_computation.66

fused_computation.67 {
  param_1.1604 = f32[4096,8192]{1,0} parameter(1)
  bitcast.7698 = f32[2,2048,8192]{2,1,0} bitcast(param_1.1604)
  param_0.1151 = f32[2,2048]{1,0} parameter(0)
  constant.2353 = f32[] constant(0.000122070312)
  broadcast.2865 = f32[2,2048]{1,0} broadcast(constant.2353), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/layer_norm/div" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=370}
  multiply.1845 = f32[2,2048]{1,0} multiply(param_0.1151, broadcast.2865), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/div" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=370}
  broadcast.2863 = f32[2,2048,8192]{2,1,0} broadcast(multiply.1845), dimensions={0,1}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/sub" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=371}
  subtract.370 = f32[2,2048,8192]{2,1,0} subtract(bitcast.7698, broadcast.2863), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/sub" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=371}
  multiply.1369 = f32[2,2048,8192]{2,1,0} multiply(subtract.370, subtract.370), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/mul" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=371}
  constant.1748 = f32[] constant(0)
  ROOT reduce.325 = f32[2,2048]{1,0} reduce(multiply.1369, constant.1748), dimensions={2}, to_apply=region_15.791, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/reduce_sum[axes=(2,)]" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=371}
} // fused_computation.67

fused_computation.69 {
  param_0.128 = f32[256,64,2048]{2,1,0} parameter(0)
  bitcast.7414 = f32[2,128,64,2048]{3,2,1,0} bitcast(param_0.128)
  ROOT transpose.247 = f32[2,2048,128,64]{3,2,1,0} transpose(bitcast.7414), dimensions={0,3,1,2}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/pv_einsum/BNTS,BSNH->BTNH/transpose[permutation=(0, 3, 1, 2)]" source_file="/pax/praxis/praxis/layers/base_ops.py" source_line=42}
}

fused_computation.70 {
  param_0.129 = f32[2,128,2048,2048]{3,2,1,0} parameter(0)
  param_1.189 = f32[2,128,2048]{2,1,0} parameter(1)
  broadcast.2181 = f32[2,128,2048,2048]{3,2,1,0} broadcast(param_1.189), dimensions={0,1,2}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/div" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=1487}
  ROOT divide.176 = f32[2,128,2048,2048]{3,2,1,0} divide(param_0.129, broadcast.2181), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/div" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=1487}
}

fused_computation.74 {
  param_1.1294 = f32[3,2,128,64,2048]{4,3,2,1,0} parameter(1)
  slice.94 = f32[1,2,128,64,2048]{4,3,2,1,0} slice(param_1.1294), slice={[0:1], [0:2], [0:128], [0:64], [0:2048]}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/combined_qkv/slice[start_indices=(0, 0, 0, 0, 0) limit_indices=(1, 16, 2048, 128, 64) strides=(1, 1, 1, 1, 1)]" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=882}
  bitcast.7570 = f32[2,128,64,2048]{3,2,1,0} bitcast(slice.94)
  param_0.893 = f32[64]{0} parameter(0)
  broadcast.2187 = f32[2,128,64,2048]{3,2,1,0} broadcast(param_0.893), dimensions={2}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._scale_query/per_dim_scale/mul" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=404}
  multiply.1374 = f32[2,128,64,2048]{3,2,1,0} multiply(bitcast.7570, broadcast.2187), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._scale_query/per_dim_scale/mul" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=404}
  ROOT transpose.248 = f32[2,128,2048,64]{3,2,1,0} transpose(multiply.1374), dimensions={0,1,3,2}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._scale_query/per_dim_scale/mul" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=404}
} // fused_computation.74

fused_computation.75 {
  param_0.1139 = f32[8,64]{1,0} parameter(0)
  param_1.1587 = s32[] parameter(1)
  constant.2334 = s32[] constant(0)
  dynamic-slice.236 = f32[1,64]{1,0} dynamic-slice(param_0.1139, param_1.1587, constant.2334), dynamic_slice_sizes={1,64}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/dynamic_slice[slice_sizes=(1, 64)]" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  bitcast.7688 = f32[64]{0} bitcast(dynamic-slice.236)
  compare.673 = pred[64]{0} compare(bitcast.7688, bitcast.7688), direction=NE, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._scale_query/per_dim_scale/jit(softplus)/jit(logaddexp)/ne" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=403}
  constant.2333 = f32[] constant(0)
  broadcast.2838 = f32[64]{0} broadcast(constant.2333), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._scale_query/per_dim_scale/jit(softplus)/jit(logaddexp)/max" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=403}
  maximum.77 = f32[64]{0} maximum(bitcast.7688, broadcast.2838), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._scale_query/per_dim_scale/jit(softplus)/jit(logaddexp)/max" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=403}
  abs.28 = f32[64]{0} abs(bitcast.7688), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._scale_query/per_dim_scale/jit(softplus)/jit(logaddexp)/abs" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=403}
  negate.140 = f32[64]{0} negate(abs.28), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._scale_query/per_dim_scale/jit(softplus)/jit(logaddexp)/neg" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=403}
  exponential.74 = f32[64]{0} exponential(negate.140), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._scale_query/per_dim_scale/jit(softplus)/jit(logaddexp)/exp" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=403}
  log-plus-one.28 = f32[64]{0} log-plus-one(exponential.74), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._scale_query/per_dim_scale/jit(softplus)/jit(logaddexp)/log1p" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=403}
  add.1137 = f32[64]{0} add(maximum.77, log-plus-one.28), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._scale_query/per_dim_scale/jit(softplus)/jit(logaddexp)/add" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=403}
  select.971 = f32[64]{0} select(compare.673, bitcast.7688, add.1137), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._scale_query/per_dim_scale/jit(softplus)/jit(logaddexp)/select_n" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=403}
  constant.1756 = f32[] constant(0.180336878)
  broadcast.2188 = f32[64]{0} broadcast(constant.1756), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._scale_query/per_dim_scale/mul" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=403}
  ROOT multiply.1375 = f32[64]{0} multiply(select.971, broadcast.2188), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._scale_query/per_dim_scale/mul" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=403}
} // fused_computation.75

fused_computation.77 {
  param_0.891 = f32[2,1,2048,2048]{3,2,0,1} parameter(0)
  bitcast.7416 = f32[1,2,2048,2048]{3,2,1,0} bitcast(param_0.891)
  iota.53 = s32[2048,2048]{1,0} iota(), iota_dimension=0, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/broadcast_in_dim[shape=(1, 2048, 2048, 1) broadcast_dimensions=(0, 1, 3)]" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=102}
  iota.52 = s32[2048,2048]{1,0} iota(), iota_dimension=1, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/broadcast_in_dim[shape=(2048, 1, 1, 2048) broadcast_dimensions=(1, 2, 3)]" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=101}
  compare.518 = pred[2048,2048]{1,0} compare(iota.53, iota.52), direction=LT, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/lt" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=103}
  constant.1753 = f32[] constant(-2.38197633e+38)
  broadcast.2193 = f32[2048,2048]{1,0} broadcast(constant.1753), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/mul" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=103}
  constant.1754 = f32[] constant(0)
  broadcast.2192 = f32[2048,2048]{1,0} broadcast(constant.1754), dimensions={}
  select.762 = f32[2048,2048]{1,0} select(compare.518, broadcast.2193, broadcast.2192), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/mul" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=103}
  broadcast.2191 = f32[1,2,2048,2048]{3,2,1,0} broadcast(select.762), dimensions={2,3}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/min" source_file="/pax/praxis/praxis/layers/transformers.py" source_line=128}
  minimum.15 = f32[1,2,2048,2048]{3,2,1,0} minimum(bitcast.7416, broadcast.2191), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/min" source_file="/pax/praxis/praxis/layers/transformers.py" source_line=128}
  constant.1655 = f32[] constant(-1.19098816e+38)
  broadcast.2190 = f32[1,2,2048,2048]{3,2,1,0} broadcast(constant.1655), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/ge" source_file="/pax/praxis/praxis/py_utils.py" source_line=743}
  ROOT compare.517 = pred[1,2,2048,2048]{3,2,1,0} compare(minimum.15, broadcast.2190), direction=GE, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/ge" source_file="/pax/praxis/praxis/py_utils.py" source_line=743}
} // fused_computation.77

fused_computation.78 {
  param_0.146 = f32[24576,4096]{1,0} parameter(0)
  bitcast.7417 = f32[3,128,64,2,2048]{4,3,2,1,0} bitcast(param_0.146)
  ROOT transpose.249 = f32[3,2,128,64,2048]{4,3,2,1,0} transpose(bitcast.7417), dimensions={0,3,1,2,4}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/combined_qkv/einsum/ABD,KDNH->KABNH/dot_general[dimension_numbers=(((1,), (2,)), ((), ())) precision=None preferred_element_type=float32]" source_file="/pax/praxis/praxis/layers/base_ops.py" source_line=42}
}

fused_computation.79 {
  param_5.1582 = f32[8,2,2048,8192]{3,2,1,0} parameter(5)
  param_1.215 = s32[] parameter(1)
  constant.1759 = s32[] constant(0)
  dynamic-slice.226.clone.1 = f32[1,2,2048,8192]{3,2,1,0} dynamic-slice(param_5.1582, param_1.215, constant.1759, constant.1759, constant.1759), dynamic_slice_sizes={1,2,2048,8192}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/dynamic_slice[slice_sizes=(1, 16, 2048, 8192)]" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  bitcast.7678.clone.1 = f32[2,2048,8192]{2,1,0} bitcast(dynamic-slice.226.clone.1)
  param_4.1794 = f32[2,2048]{1,0} parameter(4)
  constant.2308.clone.1 = f32[] constant(0.000122070312)
  broadcast.2815.clone.1 = f32[2,2048]{1,0} broadcast(constant.2308.clone.1), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/layer_norm/div" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=370}
  multiply.1826.clone.1 = f32[2,2048]{1,0} multiply(param_4.1794, broadcast.2815.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/layer_norm/div" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=370}
  broadcast.2814.clone.1 = f32[2,2048,8192]{2,1,0} broadcast(multiply.1826.clone.1), dimensions={0,1}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/layer_norm/sub" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  subtract.358.clone.1 = f32[2,2048,8192]{2,1,0} subtract(bitcast.7678.clone.1, broadcast.2814.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/layer_norm/sub" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  param_3.2052 = f32[2,2048]{1,0} parameter(3)
  bitcast.7574.clone.1 = f32[1,2,2048]{2,1,0} bitcast(param_3.2052)
  rsqrt.43.clone.1 = f32[1,2,2048]{2,1,0} rsqrt(bitcast.7574.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/layer_norm/rsqrt" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  bitcast.7573.clone.1 = f32[2,2048]{1,0} bitcast(rsqrt.43.clone.1)
  broadcast.2197.clone.1 = f32[2,2048,8192]{2,1,0} broadcast(bitcast.7573.clone.1), dimensions={0,1}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/layer_norm/mul" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  multiply.1377.clone.1 = f32[2,2048,8192]{2,1,0} multiply(subtract.358.clone.1, broadcast.2197.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/layer_norm/mul" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  param_2.2071 = f32[1,8192]{1,0} parameter(2)
  bitcast.7572 = f32[8192]{0} bitcast(param_2.2071)
  broadcast.2195 = f32[2,2048,8192]{2,1,0} broadcast(bitcast.7572), dimensions={2}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/layer_norm/mul" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=376}
  multiply.1376 = f32[2,2048,8192]{2,1,0} multiply(multiply.1377.clone.1, broadcast.2195), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/layer_norm/mul" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=376}
  param_0.148 = f32[8,8192]{1,0} parameter(0)
  dynamic-slice.198 = f32[1,8192]{1,0} dynamic-slice(param_0.148, param_1.215, constant.1759), dynamic_slice_sizes={1,8192}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/dynamic_slice[slice_sizes=(1, 8192)]" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  bitcast.7418 = f32[8192]{0} bitcast(dynamic-slice.198)
  broadcast.2194 = f32[2,2048,8192]{2,1,0} broadcast(bitcast.7418), dimensions={2}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/layer_norm/add" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=378}
  add.887 = f32[2,2048,8192]{2,1,0} add(multiply.1376, broadcast.2194), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/layer_norm/add" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=378}
  ROOT tuple.46 = (f32[2,2048,8192]{2,1,0}, f32[2,2048,8192]{2,1,0}) tuple(add.887, multiply.1377.clone.1)
} // fused_computation.79

fused_computation.80 {
  param_0.896 = f32[8,8192]{1,0} parameter(0)
  param_1.1298 = s32[] parameter(1)
  constant.1761 = s32[] constant(0)
  dynamic-slice.199 = f32[1,8192]{1,0} dynamic-slice(param_0.896, param_1.1298, constant.1761), dynamic_slice_sizes={1,8192}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/dynamic_slice[slice_sizes=(1, 8192)]" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  constant.1760 = f32[] constant(1)
  broadcast.2196 = f32[1,8192]{1,0} broadcast(constant.1760), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/layer_norm/add" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=376}
  ROOT add.888 = f32[1,8192]{1,0} add(dynamic-slice.199, broadcast.2196), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/layer_norm/add" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=376}
} // fused_computation.80

fused_computation.82 {
  param_0.897 = f32[2,2048]{1,0} parameter(0)
  constant.1763 = f32[] constant(0.000122070312)
  broadcast.2199 = f32[2,2048]{1,0} broadcast(constant.1763), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/layer_norm/div" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=370}
  multiply.1378 = f32[2,2048]{1,0} multiply(param_0.897, broadcast.2199), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/layer_norm/div" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=371}
  constant.1762 = f32[] constant(1e-06)
  broadcast.2198 = f32[2,2048]{1,0} broadcast(constant.1762), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/layer_norm/add" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  ROOT add.890 = f32[2,2048]{1,0} add(multiply.1378, broadcast.2198), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/layer_norm/add" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
} // fused_computation.82

fused_computation.83 {
  param_1.1581 = f32[8,2,2048,8192]{3,2,1,0} parameter(1)
  param_2.1151 = s32[] parameter(2)
  constant.2319 = s32[] constant(0)
  dynamic-slice.230 = f32[1,2,2048,8192]{3,2,1,0} dynamic-slice(param_1.1581, param_2.1151, constant.2319, constant.2319, constant.2319), dynamic_slice_sizes={1,2,2048,8192}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/dynamic_slice[slice_sizes=(1, 16, 2048, 8192)]" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  bitcast.7682 = f32[2,2048,8192]{2,1,0} bitcast(dynamic-slice.230)
  param_0.1131 = f32[2,2048]{1,0} parameter(0)
  constant.2318 = f32[] constant(0.000122070312)
  broadcast.2827 = f32[2,2048]{1,0} broadcast(constant.2318), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/layer_norm/div" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=370}
  multiply.1833 = f32[2,2048]{1,0} multiply(param_0.1131, broadcast.2827), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/layer_norm/div" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=370}
  broadcast.2825 = f32[2,2048,8192]{2,1,0} broadcast(multiply.1833), dimensions={0,1}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/layer_norm/sub" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  subtract.362 = f32[2,2048,8192]{2,1,0} subtract(bitcast.7682, broadcast.2825), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/layer_norm/sub" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  multiply.1379 = f32[2,2048,8192]{2,1,0} multiply(subtract.362, subtract.362), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/layer_norm/mul" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=371}
  constant.1764 = f32[] constant(0)
  ROOT reduce.326 = f32[2,2048]{1,0} reduce(multiply.1379, constant.1764), dimensions={2}, to_apply=region_15.791, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/layer_norm/reduce_sum[axes=(2,)]" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=371}
} // fused_computation.83

fused_computation.85 {
  constant.1769 = s32[] constant(7)
  param_0.903 = s32[] parameter(0)
  subtract.304 = s32[] subtract(constant.1769, param_0.903), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  constant.1770 = s32[] constant(0)
  compare.519 = pred[] compare(subtract.304, constant.1770), direction=LT, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/lt" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  constant.1771 = s32[] constant(15)
  subtract.303 = s32[] subtract(constant.1771, param_0.903), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/add" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  ROOT select.763 = s32[] select(compare.519, subtract.303, subtract.304), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/select_n" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
} // fused_computation.85

fused_computation.429 {
  param_0.1659 = f32[2,2048,8192]{2,1,0} parameter(0)
  param_1.2285 = f32[2,2048]{1,0} parameter(1)
  broadcast.2170.clone.1 = f32[2,2048,8192]{2,1,0} broadcast(param_1.2285), dimensions={0,1}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/mul" source_file="/pax/praxis/praxis/layers/transformers.py" source_line=468}
  multiply.1364.clone.1 = f32[2,2048,8192]{2,1,0} multiply(param_0.1659, broadcast.2170.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/mul" source_file="/pax/praxis/praxis/layers/transformers.py" source_line=468}
  bitcast.7545 = f32[4096,8192]{1,0} bitcast(multiply.1364.clone.1)
  constant.1712 = f32[] constant(0)
  reduce.399 = f32[8192]{0} reduce(bitcast.7545, constant.1712), dimensions={0}, to_apply=region_15.791, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/ffn_layer2/bias/reduce_sum[axes=(0, 1)]" source_file="/pax/praxis/praxis/layers/linears.py" source_line=143}
  ROOT tuple.41 = (f32[8192]{0}, f32[2,2048,8192]{2,1,0}) tuple(reduce.399, multiply.1364.clone.1)
} // fused_computation.429

fused_computation.430 {
  param_3.2042 = f32[4096,32768]{1,0} parameter(3)
  param_4.1776 = f32[8,32768]{1,0} parameter(4)
  param_5.1573 = s32[] parameter(5)
  constant.2365.clone.1 = s32[] constant(0)
  dynamic-slice.242.clone.1 = f32[1,32768]{1,0} dynamic-slice(param_4.1776, param_5.1573, constant.2365.clone.1), dynamic_slice_sizes={1,32768}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/dynamic_slice[slice_sizes=(1, 32768)]" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  bitcast.7706.clone.1 = f32[32768]{0} bitcast(dynamic-slice.242.clone.1)
  broadcast.2879.clone.1 = f32[4096,32768]{1,0} broadcast(bitcast.7706.clone.1), dimensions={1}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/ffn_layer1/bias/add" source_file="/pax/praxis/praxis/layers/linears.py" source_line=143}
  add.1143.clone.1 = f32[4096,32768]{1,0} add(param_3.2042, broadcast.2879.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/ffn_layer1/bias/add" source_file="/pax/praxis/praxis/layers/linears.py" source_line=143}
  bitcast.7562.clone.1 = f32[2,2048,32768]{2,1,0} bitcast(add.1143.clone.1)
  param_2.2062 = f32[4096,32768]{1,0} parameter(2)
  bitcast.7411.clone.1 = f32[2,2048,32768]{2,1,0} bitcast(param_2.2062)
  param_1.2283 = f32[2,2048]{1,0} parameter(1)
  broadcast.2165.clone.1 = f32[2,2048,32768]{2,1,0} broadcast(param_1.2283), dimensions={0,1}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/mul" source_file="/pax/praxis/praxis/layers/transformers.py" source_line=455}
  multiply.1358.clone.1 = f32[2,2048,32768]{2,1,0} multiply(bitcast.7411.clone.1, broadcast.2165.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/mul" source_file="/pax/praxis/praxis/layers/transformers.py" source_line=455}
  multiply.1357.clone.1 = f32[2,2048,32768]{2,1,0} multiply(bitcast.7562.clone.1, multiply.1358.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/ffn_layer1/activation/mul" source_file="/pax/praxis/praxis/layers/activations.py" source_line=157}
  constant.1735.clone.1 = f32[] constant(0.5)
  broadcast.2164.clone.1 = f32[2,2048,32768]{2,1,0} broadcast(constant.1735.clone.1), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/ff_layer/ffn_layer1/activation/mul" source_file="/pax/praxis/praxis/layers/activations.py" source_line=157}
  multiply.1356.clone.1 = f32[2,2048,32768]{2,1,0} multiply(multiply.1357.clone.1, broadcast.2164.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/ffn_layer1/activation/mul" source_file="/pax/praxis/praxis/layers/activations.py" source_line=157}
  constant.1737.clone.1 = f32[] constant(1)
  broadcast.2163.clone.1 = f32[2,2048,32768]{2,1,0} broadcast(constant.1737.clone.1), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/ff_layer/ffn_layer1/activation/add" source_file="/pax/praxis/praxis/layers/activations.py" source_line=157}
  param_0.1658 = f32[2,2048,32768]{2,1,0} parameter(0)
  subtract.298.clone.1 = f32[2,2048,32768]{2,1,0} subtract(broadcast.2163.clone.1, param_0.1658), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/ffn_layer1/activation/sub" source_file="/pax/praxis/praxis/layers/activations.py" source_line=157}
  multiply.1355.clone.1 = f32[2,2048,32768]{2,1,0} multiply(multiply.1356.clone.1, subtract.298.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/ffn_layer1/activation/mul" source_file="/pax/praxis/praxis/layers/activations.py" source_line=157}
  multiply.1354.clone.1 = f32[2,2048,32768]{2,1,0} multiply(multiply.1355.clone.1, param_0.1658), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/ffn_layer1/activation/mul" source_file="/pax/praxis/praxis/layers/activations.py" source_line=157}
  add.878.clone.1 = f32[2,2048,32768]{2,1,0} add(multiply.1355.clone.1, multiply.1354.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/ffn_layer1/activation/add_any" source_file="/pax/praxis/praxis/layers/activations.py" source_line=157}
  constant.1736.clone.1 = f32[] constant(0.797884583)
  broadcast.2162.clone.1 = f32[2,2048,32768]{2,1,0} broadcast(constant.1736.clone.1), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/ff_layer/ffn_layer1/activation/mul" source_file="/pax/praxis/praxis/layers/activations.py" source_line=157}
  multiply.1353.clone.1 = f32[2,2048,32768]{2,1,0} multiply(add.878.clone.1, broadcast.2162.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/ffn_layer1/activation/mul" source_file="/pax/praxis/praxis/layers/activations.py" source_line=157}
  constant.1653.clone.1 = f32[] constant(0.0356774069)
  broadcast.2161.clone.1 = f32[2,2048,32768]{2,1,0} broadcast(constant.1653.clone.1), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/ffn_layer1/activation/mul" source_file="/pax/praxis/praxis/layers/activations.py" source_line=157}
  multiply.1352.clone.1 = f32[2,2048,32768]{2,1,0} multiply(add.878.clone.1, broadcast.2161.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/ffn_layer1/activation/mul" source_file="/pax/praxis/praxis/layers/activations.py" source_line=157}
  multiply.1799.clone.1 = f32[2,2048,32768]{2,1,0} multiply(bitcast.7562.clone.1, bitcast.7562.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/ffn_layer1/activation/mul" source_file="/pax/praxis/praxis/layers/activations.py" source_line=157}
  constant.1652.clone.1 = f32[] constant(3)
  broadcast.2159.clone.1 = f32[2,2048,32768]{2,1,0} broadcast(constant.1652.clone.1), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/ffn_layer1/activation/mul" source_file="/pax/praxis/praxis/layers/activations.py" source_line=157}
  multiply.1351.clone.1 = f32[2,2048,32768]{2,1,0} multiply(multiply.1799.clone.1, broadcast.2159.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/ffn_layer1/activation/mul" source_file="/pax/praxis/praxis/layers/activations.py" source_line=157}
  multiply.1348.clone.1 = f32[2,2048,32768]{2,1,0} multiply(multiply.1352.clone.1, multiply.1351.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/ffn_layer1/activation/mul" source_file="/pax/praxis/praxis/layers/activations.py" source_line=157}
  add.876.clone.1 = f32[2,2048,32768]{2,1,0} add(multiply.1353.clone.1, multiply.1348.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/ffn_layer1/activation/add_any" source_file="/pax/praxis/praxis/layers/activations.py" source_line=157}
  add.1147.clone.1 = f32[2,2048,32768]{2,1,0} add(param_0.1658, broadcast.2163.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/ffn_layer1/activation/add" source_file="/pax/praxis/praxis/layers/activations.py" source_line=157}
  multiply.1851.clone.1 = f32[2,2048,32768]{2,1,0} multiply(add.1147.clone.1, broadcast.2164.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/ffn_layer1/activation/mul" source_file="/pax/praxis/praxis/layers/activations.py" source_line=157}
  multiply.1347.clone.1 = f32[2,2048,32768]{2,1,0} multiply(multiply.1358.clone.1, multiply.1851.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/ffn_layer1/activation/mul" source_file="/pax/praxis/praxis/layers/activations.py" source_line=157}
  add.875.clone.1 = f32[2,2048,32768]{2,1,0} add(add.876.clone.1, multiply.1347.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/ffn_layer1/activation/add_any" source_file="/pax/praxis/praxis/layers/activations.py" source_line=157}
  bitcast.7546 = f32[4096,32768]{1,0} bitcast(add.875.clone.1)
  constant.1715 = f32[] constant(0)
  reduce.400 = f32[32768]{0} reduce(bitcast.7546, constant.1715), dimensions={0}, to_apply=region_15.791, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/ffn_layer1/bias/reduce_sum[axes=(0, 1)]" source_file="/pax/praxis/praxis/layers/linears.py" source_line=143}
  multiply.1314.clone.1 = f32[2,2048,32768]{2,1,0} multiply(bitcast.7562.clone.1, multiply.1851.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/ffn_layer1/activation/mul" source_file="/pax/praxis/praxis/layers/activations.py" source_line=157}
  multiply.1313.clone.1 = f32[2,2048,32768]{2,1,0} multiply(multiply.1314.clone.1, broadcast.2165.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/mul" source_file="/pax/praxis/praxis/layers/transformers.py" source_line=455}
  ROOT tuple.42 = (f32[32768]{0}, f32[2,2048,32768]{2,1,0}, f32[2,2048,32768]{2,1,0}) tuple(reduce.400, add.875.clone.1, multiply.1313.clone.1)
} // fused_computation.430

fused_computation.432 {
  param_0.878 = f32[4096,8192]{1,0} parameter(0)
  bitcast.7556 = f32[2,2048,128,64]{3,2,1,0} bitcast(param_0.878)
  transpose.278 = f32[2,128,64,2048]{3,2,1,0} transpose(bitcast.7556), dimensions={0,2,3,1}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/pv_einsum/BNTS,BSNH->BTNH/transpose[permutation=(0, 2, 3, 1)]" source_file="/pax/praxis/praxis/layers/base_ops.py" source_line=42}
  transpose.277.clone.1 = f32[2,128,2048,64]{3,2,1,0} transpose(bitcast.7556), dimensions={0,2,1,3}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/post/einsum/ABNH,DNH->ABD/dot_general[dimension_numbers=(((2,), (0,)), ((), ())) precision=None preferred_element_type=float32]" source_file="/pax/praxis/praxis/layers/base_ops.py" source_line=42}
  ROOT tuple.35 = (f32[2,128,64,2048]{3,2,1,0}, f32[2,128,2048,64]{3,2,1,0}) tuple(transpose.278, transpose.277.clone.1)
}

fused_computation.433 {
  param_0.889 = f32[4096,8192]{1,0} parameter(0)
  bitcast.7568 = f32[2,2048,8192]{2,1,0} bitcast(param_0.889)
  constant.1750 = f32[] constant(0)
  ROOT reduce.401 = f32[2,2048]{1,0} reduce(bitcast.7568, constant.1750), dimensions={2}, to_apply=region_15.791, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/reduce_sum[axes=(2,)]" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=370}
}

fused_computation.434 {
  param_0.902 = f32[8,2,2048,8192]{3,2,1,0} parameter(0)
  param_1.1308 = s32[] parameter(1)
  constant.1767 = s32[] constant(0)
  dynamic-slice.216 = f32[1,2,2048,8192]{3,2,1,0} dynamic-slice(param_0.902, param_1.1308, constant.1767, constant.1767, constant.1767), dynamic_slice_sizes={1,2,2048,8192}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/dynamic_slice[slice_sizes=(1, 16, 2048, 8192)]" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  bitcast.7576 = f32[2,2048,8192]{2,1,0} bitcast(dynamic-slice.216)
  constant.1768 = f32[] constant(0)
  ROOT reduce.402 = f32[2,2048]{1,0} reduce(bitcast.7576, constant.1768), dimensions={2}, to_apply=region_15.791, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/layer_norm/reduce_sum[axes=(2,)]" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=370}
} // fused_computation.434

fused_computation.455 {
  param_0.1728 = pred[1,2,2048,2048]{3,2,1,0} parameter(0)
  bitcast.7692 = pred[2,2048,2048]{2,1,0} bitcast(param_0.1728)
  broadcast.2851 = pred[2,128,2048,2048]{3,2,1,0} broadcast(bitcast.7692), dimensions={0,2,3}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/jit(_where)/broadcast_in_dim[shape=(16, 128, 2048, 2048) broadcast_dimensions=(0, 2, 3)]" source_file="/pax/praxis/praxis/py_utils.py" source_line=743}
  param_1.2456 = f32[256,2048,2048]{2,1,0} parameter(1)
  bitcast.7415.clone.1 = f32[2,128,2048,2048]{3,2,1,0} bitcast(param_1.2456)
  constant.1755.clone.1 = f32[] constant(0.02)
  broadcast.2186.clone.1 = f32[2,128,2048,2048]{3,2,1,0} broadcast(constant.1755.clone.1), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._cap_logits/div" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=1384}
  multiply.1373.clone.1 = f32[2,128,2048,2048]{3,2,1,0} multiply(bitcast.7415.clone.1, broadcast.2186.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._cap_logits/div" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=1384}
  tanh.36.clone.1 = f32[2,128,2048,2048]{3,2,1,0} tanh(multiply.1373.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._cap_logits/tanh" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=1384}
  constant.2344 = f32[] constant(50)
  broadcast.2850 = f32[2,128,2048,2048]{3,2,1,0} broadcast(constant.2344), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._cap_logits/div" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=1384}
  multiply.1839 = f32[2,128,2048,2048]{3,2,1,0} multiply(tanh.36.clone.1, broadcast.2850), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._cap_logits/mul" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=1384}
  constant.2343 = f32[] constant(-2.38197633e+38)
  broadcast.2849 = f32[2,128,2048,2048]{3,2,1,0} broadcast(constant.2343), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/jit(_where)/broadcast_in_dim[shape=(16, 128, 2048, 2048) broadcast_dimensions=()]" source_file="/pax/praxis/praxis/py_utils.py" source_line=743}
  select.977 = f32[2,128,2048,2048]{3,2,1,0} select(broadcast.2851, multiply.1839, broadcast.2849), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/jit(_where)/select_n" source_file="/pax/praxis/praxis/py_utils.py" source_line=743}
  constant.4994 = f32[] constant(-inf)
  reduce.413 = f32[2,128,2048]{2,1,0} reduce(select.977, constant.4994), dimensions={3}, to_apply=region_35.988, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/reduce_max[axes=(3,)]" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=1487}
  ROOT tuple.45 = (f32[2,128,2048]{2,1,0}, f32[2,128,2048,2048]{3,2,1,0}) tuple(reduce.413, tanh.36.clone.1)
} // fused_computation.455

fused_computation.457 {
  param_3.896 = f32[256,2048,64]{2,1,0} parameter(3)
  bitcast.7730 = f32[2,128,2048,64]{3,2,1,0} bitcast(param_3.896)
  transpose.294 = f32[2,128,64,2048]{3,2,1,0} transpose(bitcast.7730), dimensions={0,1,3,2}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._atten_logits/qk_einsum/BTNH,BSNH->BNTS/dot_general[dimension_numbers=(((2,), (1,)), ((0, 1), (0, 2))) precision=None preferred_element_type=float32]" source_file="/pax/praxis/praxis/layers/base_ops.py" source_line=42}
  bitcast.7729 = f32[1,2,128,64,2048]{4,3,2,1,0} bitcast(transpose.294)
  constant.2383 = f32[] constant(0)
  pad.65 = f32[3,2,128,64,2048]{4,3,2,1,0} pad(bitcast.7729, constant.2383), padding=1_1x0_0x0_0x0_0x0_0, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/combined_qkv/pad[padding_config=((1, 1, 0), (0, 0, 0), (0, 0, 0), (0, 0, 0), (0, 0, 0))]" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=882}
  param_1.1633 = f32[2,128,64,2048]{3,2,1,0} parameter(1)
  param_2.1205 = f32[64]{0} parameter(2)
  broadcast.2897 = f32[2,128,64,2048]{3,2,1,0} broadcast(param_2.1205), dimensions={2}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._scale_query/per_dim_scale/mul" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=404}
  multiply.1859 = f32[2,128,64,2048]{3,2,1,0} multiply(param_1.1633, broadcast.2897), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._scale_query/per_dim_scale/mul" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=404}
  bitcast.7728 = f32[1,2,128,64,2048]{4,3,2,1,0} bitcast(multiply.1859)
  pad.64 = f32[3,2,128,64,2048]{4,3,2,1,0} pad(bitcast.7728, constant.2383), padding=0_2x0_0x0_0x0_0x0_0, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/combined_qkv/pad[padding_config=((0, 2, 0), (0, 0, 0), (0, 0, 0), (0, 0, 0), (0, 0, 0))]" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=882}
  add.1155 = f32[3,2,128,64,2048]{4,3,2,1,0} add(pad.65, pad.64), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/combined_qkv/add_any" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=882}
  param_0.1175 = f32[256,64,2048]{2,1,0} parameter(0)
  bitcast.7727 = f32[1,2,128,64,2048]{4,3,2,1,0} bitcast(param_0.1175)
  pad.63 = f32[3,2,128,64,2048]{4,3,2,1,0} pad(bitcast.7727, constant.2383), padding=2_0x0_0x0_0x0_0x0_0, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/combined_qkv/pad[padding_config=((2, 0, 0), (0, 0, 0), (0, 0, 0), (0, 0, 0), (0, 0, 0))]" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=882}
  add.1154 = f32[3,2,128,64,2048]{4,3,2,1,0} add(add.1155, pad.63), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/combined_qkv/add_any" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=882}
  transpose.292 = f32[2,2048,3,128,64]{4,3,2,1,0} transpose(add.1154), dimensions={1,4,0,2,3}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/combined_qkv/einsum/ABD,KDNH->KABNH/transpose[permutation=(0, 3, 4, 1, 2)]" source_file="/pax/praxis/praxis/layers/base_ops.py" source_line=42}
  transpose.289.clone.1 = f32[3,128,64,2,2048]{4,3,2,1,0} transpose(add.1154), dimensions={0,2,3,1,4}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/combined_qkv/einsum/ABD,KDNH->KABNH/transpose[permutation=(0, 3, 4, 1, 2)]" source_file="/pax/praxis/praxis/layers/base_ops.py" source_line=42}
  ROOT tuple.34 = (f32[2,2048,3,128,64]{4,3,2,1,0}, f32[3,128,64,2,2048]{4,3,2,1,0}) tuple(transpose.292, transpose.289.clone.1)
} // fused_computation.457

fused_computation.473 {
  param_2.2252 = pred[1,2,2048,2048]{3,2,1,0} parameter(2)
  bitcast.7690.clone.1 = pred[2,2048,2048]{2,1,0} bitcast(param_2.2252)
  broadcast.2845.clone.1 = pred[2,128,2048,2048]{3,2,1,0} broadcast(bitcast.7690.clone.1), dimensions={0,2,3}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/jit(_where)/broadcast_in_dim[shape=(16, 128, 2048, 2048) broadcast_dimensions=(0, 2, 3)]" source_file="/pax/praxis/praxis/py_utils.py" source_line=743}
  param_1.2460 = f32[2,128,2048,2048]{3,2,1,0} parameter(1)
  constant.2339.clone.1 = f32[] constant(50)
  broadcast.2844.clone.1 = f32[2,128,2048,2048]{3,2,1,0} broadcast(constant.2339.clone.1), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._cap_logits/div" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=1384}
  multiply.1837.clone.1 = f32[2,128,2048,2048]{3,2,1,0} multiply(param_1.2460, broadcast.2844.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._cap_logits/mul" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=1384}
  constant.2338.clone.1 = f32[] constant(-2.38197633e+38)
  broadcast.2843.clone.1 = f32[2,128,2048,2048]{3,2,1,0} broadcast(constant.2338.clone.1), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/jit(_where)/broadcast_in_dim[shape=(16, 128, 2048, 2048) broadcast_dimensions=()]" source_file="/pax/praxis/praxis/py_utils.py" source_line=743}
  select.974.clone.1 = f32[2,128,2048,2048]{3,2,1,0} select(broadcast.2845.clone.1, multiply.1837.clone.1, broadcast.2843.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/jit(_where)/select_n" source_file="/pax/praxis/praxis/py_utils.py" source_line=743}
  param_0.1730 = f32[2,128,2048]{2,1,0} parameter(0)
  broadcast.2182.clone.1 = f32[2,128,2048,2048]{3,2,1,0} broadcast(param_0.1730), dimensions={0,1,2}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/sub" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=1487}
  subtract.301.clone.1 = f32[2,128,2048,2048]{3,2,1,0} subtract(select.974.clone.1, broadcast.2182.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/sub" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=1487}
  exponential.56.clone.1 = f32[2,128,2048,2048]{3,2,1,0} exponential(subtract.301.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/exp" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=1487}
  constant.5000 = f32[] constant(0)
  reduce.421 = f32[2,128,2048]{2,1,0} reduce(exponential.56.clone.1, constant.5000), dimensions={3}, to_apply=region_15.791, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/reduce_sum[axes=(3,)]" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=1487}
  ROOT tuple.44 = (f32[2,128,2048]{2,1,0}, f32[2,128,2048,2048]{3,2,1,0}) tuple(reduce.421, exponential.56.clone.1)
} // fused_computation.473

region_32.1118_spmd.1.clone {
  loop_peel_param = (s32[], f32[2,2048,8192]{2,1,0}, f32[8,32768]{1,0}, f32[8,1024,32768]{2,1,0}, f32[8,8192]{1,0}, /*index=5*/f32[8,32768,1024]{1,2,0}, f32[8,8192]{1,0}, f32[8,8192]{1,0}, f32[8,8192]{1,0}, f32[8,8192]{1,0}, /*index=10*/f32[8,3,1024,128,64]{4,3,1,2,0}, f32[8,64]{1,0}, f32[8,1024,128,64]{3,2,1,0}, f32[8,32768]{1,0}, f32[8,1024,32768]{2,1,0}, /*index=15*/f32[8,32768,1024]{1,2,0}, f32[8,8192]{1,0}, f32[8,8192]{1,0}, f32[8,8192]{1,0}, f32[8,8192]{1,0}, /*index=20*/f32[8,3,1024,128,64]{4,3,1,2,0}, f32[8,64]{1,0}, f32[8,1024,128,64]{3,2,1,0}, f32[8,2,2048,8192]{3,2,1,0}, f32[2,1,2048,2048]{3,2,0,1}, /*index=25*/f32[2,2048]{1,0}, f32[3,8192,128,64]{3,2,0,1}, f32[32768,8192]{0,1}, s32[], s32[], /*index=30*/f32[8192,32768]{1,0}, f32[32768,8192]{1,0}, f32[3,128,64,8192]{3,2,1,0}, f32[8192,128,64]{2,1,0}) parameter(0)
  get-tuple-element.327 = s32[] get-tuple-element(loop_peel_param), index=0
  constant.1581 = s32[] constant(1)
  add.622 = s32[] add(get-tuple-element.327, constant.1581), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/add" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  get-tuple-element.332 = f32[8,2,2048,8192]{3,2,1,0} get-tuple-element(loop_peel_param), index=23
  fusion.85 = s32[] fusion(get-tuple-element.327), kind=kLoop, calls=fused_computation.85, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/select_n" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  fusion.434 = f32[2,2048]{1,0} fusion(get-tuple-element.332, fusion.85), kind=kInput, calls=fused_computation.434, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/layer_norm/reduce_sum[axes=(2,)]" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=370}
  fusion.83 = f32[2,2048]{1,0} fusion(fusion.434, get-tuple-element.332, fusion.85), kind=kInput, calls=fused_computation.83, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/layer_norm/reduce_sum[axes=(2,)]" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=371}
  fusion.82 = f32[2,2048]{1,0} fusion(fusion.83), kind=kLoop, calls=fused_computation.82, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/layer_norm/add" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  get-tuple-element.333 = f32[8,8192]{1,0} get-tuple-element(loop_peel_param), index=19
  fusion.80 = f32[1,8192]{1,0} fusion(get-tuple-element.333, fusion.85), kind=kLoop, calls=fused_computation.80, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/layer_norm/add" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=376}
  get-tuple-element.331 = f32[3,8192,128,64]{3,2,0,1} get-tuple-element(loop_peel_param), index=26
  bitcast.1494 = f32[24576,8192]{0,1} bitcast(get-tuple-element.331)
  get-tuple-element.334 = f32[8,8192]{1,0} get-tuple-element(loop_peel_param), index=18
  fusion.79 = (f32[2,2048,8192]{2,1,0}, f32[2,2048,8192]{2,1,0}) fusion(get-tuple-element.334, fusion.85, fusion.80, fusion.82, fusion.434, /*index=5*/get-tuple-element.332), kind=kLoop, calls=fused_computation.79, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/layer_norm/add" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=378}
  get-tuple-element.490 = f32[2,2048,8192]{2,1,0} get-tuple-element(fusion.79), index=0
  bitcast.992 = f32[8192,4096]{0,1} bitcast(get-tuple-element.490)
  custom-call.13 = f32[24576,4096]{1,0} custom-call(bitcast.1494, bitcast.992), custom_call_target="__cublas$gemm", metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/combined_qkv/einsum/ABD,KDNH->KABNH/dot_general[dimension_numbers=(((1,), (2,)), ((), ())) precision=None preferred_element_type=float32]" source_file="/pax/praxis/praxis/layers/base_ops.py" source_line=42}, backend_config={"alpha_real":1,"alpha_imag":0,"beta":0,"dot_dimension_numbers":{"lhs_contracting_dimensions":["1"],"rhs_contracting_dimensions":["0"],"lhs_batch_dimensions":[],"rhs_batch_dimensions":[]},"precision_config":{"operand_precision":["DEFAULT","DEFAULT"]},"epilogue":"DEFAULT"}
  fusion.78 = f32[3,2,128,64,2048]{4,3,2,1,0} fusion(custom-call.13), kind=kLoop, calls=fused_computation.78, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/combined_qkv/einsum/ABD,KDNH->KABNH/dot_general[dimension_numbers=(((1,), (2,)), ((), ())) precision=None preferred_element_type=float32]" source_file="/pax/praxis/praxis/layers/base_ops.py" source_line=42}
  slice.50 = f32[1,2,128,64,2048]{4,3,2,1,0} slice(fusion.78), slice={[2:3], [0:2], [0:128], [0:64], [0:2048]}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/combined_qkv/slice[start_indices=(2, 0, 0, 0, 0) limit_indices=(3, 16, 2048, 128, 64) strides=(1, 1, 1, 1, 1)]" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=882}
  bitcast.1002 = f32[256,64,2048]{2,1,0} bitcast(slice.50)
  get-tuple-element.335 = f32[2,1,2048,2048]{3,2,0,1} get-tuple-element(loop_peel_param), index=24
  fusion.77 = pred[1,2,2048,2048]{3,2,1,0} fusion(get-tuple-element.335), kind=kLoop, calls=fused_computation.77, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/ge" source_file="/pax/praxis/praxis/py_utils.py" source_line=743}
  get-tuple-element.336 = f32[8,64]{1,0} get-tuple-element(loop_peel_param), index=21
  fusion.75 = f32[64]{0} fusion(get-tuple-element.336, fusion.85), kind=kLoop, calls=fused_computation.75, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._scale_query/per_dim_scale/mul" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=403}
  fusion.74 = f32[2,128,2048,64]{3,2,1,0} fusion(fusion.75, fusion.78), kind=kInput, calls=fused_computation.74, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._scale_query/per_dim_scale/mul" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=404}
  bitcast.1062 = f32[256,2048,64]{2,1,0} bitcast(fusion.74)
  slice.52 = f32[1,2,128,64,2048]{4,3,2,1,0} slice(fusion.78), slice={[1:2], [0:2], [0:128], [0:64], [0:2048]}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/combined_qkv/slice[start_indices=(1, 0, 0, 0, 0) limit_indices=(2, 16, 2048, 128, 64) strides=(1, 1, 1, 1, 1)]" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=882}
  bitcast.1067 = f32[256,64,2048]{2,1,0} bitcast(slice.52)
  custom-call.14 = f32[256,2048,2048]{2,1,0} custom-call(bitcast.1062, bitcast.1067), custom_call_target="__cublas$gemm", metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._atten_logits/qk_einsum/BTNH,BSNH->BNTS/dot_general[dimension_numbers=(((3,), (3,)), ((0, 2), (0, 2))) precision=None preferred_element_type=float32]" source_file="/pax/praxis/praxis/layers/base_ops.py" source_line=42}, backend_config={"alpha_real":1,"alpha_imag":0,"beta":0,"dot_dimension_numbers":{"lhs_contracting_dimensions":["2"],"rhs_contracting_dimensions":["1"],"lhs_batch_dimensions":["0"],"rhs_batch_dimensions":["0"]},"precision_config":{"operand_precision":["DEFAULT","DEFAULT"]},"epilogue":"DEFAULT"}
  fusion.455 = (f32[2,128,2048]{2,1,0}, f32[2,128,2048,2048]{3,2,1,0}) fusion(fusion.77, custom-call.14), kind=kInput, calls=fused_computation.455, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/reduce_max[axes=(3,)]" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=1487}
  get-tuple-element.488 = f32[2,128,2048]{2,1,0} get-tuple-element(fusion.455), index=0
  get-tuple-element.489 = f32[2,128,2048,2048]{3,2,1,0} get-tuple-element(fusion.455), index=1
  fusion.473 = (f32[2,128,2048]{2,1,0}, f32[2,128,2048,2048]{3,2,1,0}) fusion(get-tuple-element.488, get-tuple-element.489, fusion.77), kind=kInput, calls=fused_computation.473, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/reduce_sum[axes=(3,)]" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=1487}
  get-tuple-element.487 = f32[2,128,2048,2048]{3,2,1,0} get-tuple-element(fusion.473), index=1
  get-tuple-element.486 = f32[2,128,2048]{2,1,0} get-tuple-element(fusion.473), index=0
  fusion.70 = f32[2,128,2048,2048]{3,2,1,0} fusion(get-tuple-element.487, get-tuple-element.486), kind=kLoop, calls=fused_computation.70, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/div" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=1487}
  bitcast.1100 = f32[256,2048,2048]{2,1,0} bitcast(fusion.70)
  custom-call.15 = f32[256,64,2048]{2,1,0} custom-call(bitcast.1002, bitcast.1100), custom_call_target="__cublas$gemm", metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/pv_einsum/BNTS,BSNH->BTNH/dot_general[dimension_numbers=(((1,), (3,)), ((0, 2), (0, 1))) precision=None preferred_element_type=float32]" source_file="/pax/praxis/praxis/layers/base_ops.py" source_line=42}, backend_config={"alpha_real":1,"alpha_imag":0,"beta":0,"dot_dimension_numbers":{"lhs_contracting_dimensions":["2"],"rhs_contracting_dimensions":["2"],"lhs_batch_dimensions":["0"],"rhs_batch_dimensions":["0"]},"precision_config":{"operand_precision":["DEFAULT","DEFAULT"]},"epilogue":"DEFAULT"}
  fusion.69 = f32[2,2048,128,64]{3,2,1,0} fusion(custom-call.15), kind=kInput, calls=fused_computation.69, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/pv_einsum/BNTS,BSNH->BTNH/transpose[permutation=(0, 3, 1, 2)]" source_file="/pax/praxis/praxis/layers/base_ops.py" source_line=42}
  bitcast.1836 = f32[4096,8192]{1,0} bitcast(fusion.69)
  get-tuple-element.337 = f32[8,1024,128,64]{3,2,1,0} get-tuple-element(loop_peel_param), index=22
  constant.1583 = s32[] constant(0)
  dynamic-slice.162 = f32[1,1024,128,64]{3,2,1,0} dynamic-slice(get-tuple-element.337, fusion.85, constant.1583, constant.1583, constant.1583), dynamic_slice_sizes={1,1024,128,64}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/dynamic_slice[slice_sizes=(1, 8192, 128, 64)]" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  bitcast.1116 = f32[1024,128,64]{2,1,0} bitcast(dynamic-slice.162)
  all-gather.43 = f32[8192,128,64]{2,1,0} all-gather(bitcast.1116), channel_id=64, replica_groups={{0,1,2,3,4,5,6,7}}, dimensions={0}, use_global_device_ids=true, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/post/einsum/ABNH,DNH->ABD/dot_general[dimension_numbers=(((3, 2), (2, 1)), ((), ())) precision=None preferred_element_type=float32]" source_file="/pax/praxis/praxis/layers/base_ops.py" source_line=42}
  bitcast.1120 = f32[8192,8192]{0,1} bitcast(all-gather.43)
  dynamic-slice.158 = f32[1,2,2048,8192]{3,2,1,0} dynamic-slice(get-tuple-element.332, fusion.85, constant.1583, constant.1583, constant.1583), dynamic_slice_sizes={1,2,2048,8192}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/dynamic_slice[slice_sizes=(1, 16, 2048, 8192)]" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  bitcast.1124 = f32[4096,8192]{1,0} bitcast(dynamic-slice.158)
  cublas-gemm.3 = f32[4096,8192]{1,0} custom-call(bitcast.1836, bitcast.1120, bitcast.1124), custom_call_target="__cublas$gemm", output_to_operand_aliasing={{}: (2, {})}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/post/einsum/ABNH,DNH->ABD/dot_general[dimension_numbers=(((3, 2), (2, 1)), ((), ())) precision=None preferred_element_type=float32]" source_file="/pax/praxis/praxis/layers/base_ops.py" source_line=42}, backend_config={"alpha_real":1,"alpha_imag":0,"beta":1,"dot_dimension_numbers":{"lhs_contracting_dimensions":["1"],"rhs_contracting_dimensions":["0"],"lhs_batch_dimensions":[],"rhs_batch_dimensions":[]},"precision_config":{"operand_precision":["DEFAULT","DEFAULT"]},"epilogue":"DEFAULT"}
  fusion.433 = f32[2,2048]{1,0} fusion(cublas-gemm.3), kind=kInput, calls=fused_computation.433, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/reduce_sum[axes=(2,)]" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=370}
  fusion.67 = f32[2,2048]{1,0} fusion(fusion.433, cublas-gemm.3), kind=kInput, calls=fused_computation.67, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/reduce_sum[axes=(2,)]" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=371}
  fusion.66 = f32[2,2048]{1,0} fusion(fusion.67), kind=kLoop, calls=fused_computation.66, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/add" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  get-tuple-element.338 = f32[8,8192]{1,0} get-tuple-element(loop_peel_param), index=17
  fusion.64 = f32[1,8192]{1,0} fusion(get-tuple-element.338, fusion.85), kind=kLoop, calls=fused_computation.64, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/add" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=376}
  get-tuple-element.339 = f32[8,8192]{1,0} get-tuple-element(loop_peel_param), index=16
  fusion.63 = (f32[2,2048,8192]{2,1,0}, f32[2,2048,8192]{2,1,0}) fusion(get-tuple-element.339, fusion.85, fusion.64, fusion.66, fusion.433, /*index=5*/cublas-gemm.3), kind=kLoop, calls=fused_computation.63, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/add" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=378}
  get-tuple-element.484 = f32[2,2048,8192]{2,1,0} get-tuple-element(fusion.63), index=0
  bitcast.1190 = f32[4096,8192]{1,0} bitcast(get-tuple-element.484)
  get-tuple-element.340 = f32[8,1024,32768]{2,1,0} get-tuple-element(loop_peel_param), index=14
  dynamic-slice.165 = f32[1,1024,32768]{2,1,0} dynamic-slice(get-tuple-element.340, fusion.85, constant.1583, constant.1583), dynamic_slice_sizes={1,1024,32768}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/dynamic_slice[slice_sizes=(1, 8192, 32768)]" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  bitcast.1199 = f32[1024,32768]{1,0} bitcast(dynamic-slice.165)
  all-gather.44 = f32[8192,32768]{1,0} all-gather(bitcast.1199), channel_id=65, replica_groups={{0,1,2,3,4,5,6,7}}, dimensions={0}, use_global_device_ids=true, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/ffn_layer1/linear/einsum/...y,yz->...z/dot_general[dimension_numbers=(((2,), (0,)), ((), ())) precision=None preferred_element_type=float32]" source_file="/pax/praxis/praxis/layers/base_ops.py" source_line=42}
  custom-call.17 = f32[4096,32768]{1,0} custom-call(bitcast.1190, all-gather.44), custom_call_target="__cublas$gemm", metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/ffn_layer1/linear/einsum/...y,yz->...z/dot_general[dimension_numbers=(((2,), (0,)), ((), ())) precision=None preferred_element_type=float32]" source_file="/pax/praxis/praxis/layers/base_ops.py" source_line=42}, backend_config={"alpha_real":1,"alpha_imag":0,"beta":0,"dot_dimension_numbers":{"lhs_contracting_dimensions":["1"],"rhs_contracting_dimensions":["0"],"lhs_batch_dimensions":[],"rhs_batch_dimensions":[]},"precision_config":{"operand_precision":["DEFAULT","DEFAULT"]},"epilogue":"DEFAULT"}
  get-tuple-element.341 = f32[8,32768]{1,0} get-tuple-element(loop_peel_param), index=13
  fusion.59 = f32[2,2048,32768]{2,1,0} fusion(custom-call.17, get-tuple-element.341, fusion.85), kind=kLoop, calls=fused_computation.59, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/ffn_layer1/activation/tanh" source_file="/pax/praxis/praxis/layers/activations.py" source_line=157}
  get-tuple-element.342 = f32[2,2048]{1,0} get-tuple-element(loop_peel_param), index=25, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/broadcast_in_dim[shape=(16, 2048, 1) broadcast_dimensions=(0, 1)]" source_file="/pax/praxis/praxis/layers/transformers.py" source_line=428}
  fusion.61 = f32[2,2048]{1,0} fusion(get-tuple-element.342), kind=kLoop, calls=fused_computation.61, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/sub" source_file="/pax/praxis/praxis/layers/transformers.py" source_line=468}
  get-tuple-element.328 = f32[2,2048,8192]{2,1,0} get-tuple-element(loop_peel_param), index=1
  fusion.429 = (f32[8192]{0}, f32[2,2048,8192]{2,1,0}) fusion(get-tuple-element.328, fusion.61), kind=kInput, calls=fused_computation.429, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/ffn_layer2/bias/reduce_sum[axes=(0, 1)]" source_file="/pax/praxis/praxis/layers/linears.py" source_line=143}
  get-tuple-element.482 = f32[2,2048,8192]{2,1,0} get-tuple-element(fusion.429), index=1
  bitcast.1813 = f32[4096,8192]{1,0} bitcast(get-tuple-element.482)
  get-tuple-element.345 = f32[32768,8192]{0,1} get-tuple-element(loop_peel_param), index=27
  custom-call.18 = f32[4096,32768]{1,0} custom-call(bitcast.1813, get-tuple-element.345), custom_call_target="__cublas$gemm", metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/ffn_layer2/linear/einsum/...y,yz->...z/dot_general[dimension_numbers=(((2,), (1,)), ((), ())) precision=None preferred_element_type=float32]" source_file="/pax/praxis/praxis/layers/base_ops.py" source_line=42}, backend_config={"alpha_real":1,"alpha_imag":0,"beta":0,"dot_dimension_numbers":{"lhs_contracting_dimensions":["1"],"rhs_contracting_dimensions":["1"],"lhs_batch_dimensions":[],"rhs_batch_dimensions":[]},"precision_config":{"operand_precision":["DEFAULT","DEFAULT"]},"epilogue":"DEFAULT"}
  fusion.430 = (f32[32768]{0}, f32[2,2048,32768]{2,1,0}, f32[2,2048,32768]{2,1,0}) fusion(fusion.59, fusion.61, custom-call.18, custom-call.17, get-tuple-element.341, /*index=5*/fusion.85), kind=kInput, calls=fused_computation.430, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/ffn_layer1/bias/reduce_sum[axes=(0, 1)]" source_file="/pax/praxis/praxis/layers/linears.py" source_line=143}
  get-tuple-element.480 = f32[2,2048,32768]{2,1,0} get-tuple-element(fusion.430), index=1
  bitcast.1799 = f32[4096,32768]{1,0} bitcast(get-tuple-element.480)
  custom-call.19 = f32[4096,8192]{1,0} custom-call(bitcast.1799, all-gather.44), custom_call_target="__cublas$gemm", metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/ffn_layer1/linear/einsum/...y,yz->...z/dot_general[dimension_numbers=(((2,), (1,)), ((), ())) precision=None preferred_element_type=float32]" source_file="/pax/praxis/praxis/layers/base_ops.py" source_line=42}, backend_config={"alpha_real":1,"alpha_imag":0,"beta":0,"dot_dimension_numbers":{"lhs_contracting_dimensions":["1"],"rhs_contracting_dimensions":["1"],"lhs_batch_dimensions":[],"rhs_batch_dimensions":[]},"precision_config":{"operand_precision":["DEFAULT","DEFAULT"]},"epilogue":"DEFAULT"}
  fusion.51 = (f32[2,2048]{1,0}, f32[2,2048,8192]{2,1,0}, f32[2,2048]{1,0}) fusion(fusion.66, fusion.64, custom-call.19, fusion.433, cublas-gemm.3), kind=kInput, calls=fused_computation.51, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/reduce_sum[axes=(2,)]" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  get-tuple-element.476 = f32[2,2048]{1,0} get-tuple-element(fusion.51), index=2
  fusion.52 = (f32[2,2048]{1,0}, f32[2,2048,8192]{2,1,0}) fusion(fusion.66, get-tuple-element.476, fusion.433, cublas-gemm.3), kind=kInput, calls=fused_computation.52, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/reduce_sum[axes=(2,)]" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=371}
  get-tuple-element.474 = f32[2,2048]{1,0} get-tuple-element(fusion.52), index=0
  get-tuple-element.472 = f32[2,2048]{1,0} get-tuple-element(fusion.51), index=0
  get-tuple-element.473 = f32[2,2048,8192]{2,1,0} get-tuple-element(fusion.51), index=1
  get-tuple-element.475 = f32[2,2048,8192]{2,1,0} get-tuple-element(fusion.52), index=1
  fusion.50 = f32[2,2048,8192]{2,1,0} fusion(get-tuple-element.474, get-tuple-element.472, get-tuple-element.473, get-tuple-element.328, get-tuple-element.475), kind=kLoop, calls=fused_computation.50, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/add_any" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=370}
  bitcast.1359 = f32[4096,8192]{1,0} bitcast(fusion.50)
  bitcast.1363 = f32[8192,8192]{1,0} bitcast(all-gather.43)
  custom-call.20 = f32[4096,8192]{1,0} custom-call(bitcast.1359, bitcast.1363), custom_call_target="__cublas$gemm", metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/post/einsum/ABNH,DNH->ABD/dot_general[dimension_numbers=(((2,), (0,)), ((), ())) precision=None preferred_element_type=float32]" source_file="/pax/praxis/praxis/layers/base_ops.py" source_line=42}, backend_config={"alpha_real":1,"alpha_imag":0,"beta":0,"dot_dimension_numbers":{"lhs_contracting_dimensions":["1"],"rhs_contracting_dimensions":["0"],"lhs_batch_dimensions":[],"rhs_batch_dimensions":[]},"precision_config":{"operand_precision":["DEFAULT","DEFAULT"]},"epilogue":"DEFAULT"}
  fusion.432 = (f32[2,128,64,2048]{3,2,1,0}, f32[2,128,2048,64]{3,2,1,0}) fusion(custom-call.20), kind=kInput, calls=fused_computation.432, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/pv_einsum/BNTS,BSNH->BTNH/transpose[permutation=(0, 2, 3, 1)]" source_file="/pax/praxis/praxis/layers/base_ops.py" source_line=42}
  get-tuple-element.470 = f32[2,128,64,2048]{3,2,1,0} get-tuple-element(fusion.432), index=0
  bitcast.1475 = f32[256,64,2048]{2,1,0} bitcast(get-tuple-element.470)
  custom-call.24 = f32[256,64,2048]{2,1,0} custom-call(bitcast.1475, bitcast.1100), custom_call_target="__cublas$gemm", metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/pv_einsum/BNTS,BSNH->BTNH/dot_general[dimension_numbers=(((3,), (2,)), ((0, 1), (0, 1))) precision=None preferred_element_type=float32]" source_file="/pax/praxis/praxis/layers/base_ops.py" source_line=42}, backend_config={"alpha_real":1,"alpha_imag":0,"beta":0,"dot_dimension_numbers":{"lhs_contracting_dimensions":["2"],"rhs_contracting_dimensions":["1"],"lhs_batch_dimensions":["0"],"rhs_batch_dimensions":["0"]},"precision_config":{"operand_precision":["DEFAULT","DEFAULT"]},"epilogue":"DEFAULT"}
  get-tuple-element.471 = f32[2,128,2048,64]{3,2,1,0} get-tuple-element(fusion.432), index=1
  bitcast.1370 = f32[256,2048,64]{2,1,0} bitcast(get-tuple-element.471)
  custom-call.21 = f32[256,2048,2048]{2,1,0} custom-call(bitcast.1370, bitcast.1002), custom_call_target="__cublas$gemm", metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/pv_einsum/BNTS,BSNH->BTNH/dot_general[dimension_numbers=(((2,), (3,)), ((0, 1), (0, 2))) precision=None preferred_element_type=float32]" source_file="/pax/praxis/praxis/layers/base_ops.py" source_line=42}, backend_config={"alpha_real":1,"alpha_imag":0,"beta":0,"dot_dimension_numbers":{"lhs_contracting_dimensions":["2"],"rhs_contracting_dimensions":["1"],"lhs_batch_dimensions":["0"],"rhs_batch_dimensions":["0"]},"precision_config":{"operand_precision":["DEFAULT","DEFAULT"]},"epilogue":"DEFAULT"}
  fusion.49 = f32[2,128,2048]{2,1,0} fusion(get-tuple-element.487, get-tuple-element.486, custom-call.21), kind=kInput, calls=fused_computation.49, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/reduce_sum[axes=(3,)]" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=1487}
  fusion.48 = f32[2,128,2048,2048]{3,2,1,0} fusion(get-tuple-element.489, get-tuple-element.487, fusion.49, get-tuple-element.486, custom-call.21, /*index=5*/fusion.77), kind=kLoop, calls=fused_computation.48, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._cap_logits/div" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=1384}
  bitcast.1428 = f32[256,2048,2048]{2,1,0} bitcast(fusion.48)
  fusion.47 = f32[2,128,2048,64]{3,2,1,0} fusion(fusion.78), kind=kInput, calls=fused_computation.47, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._shard_blnh/sharding_constraint[sharding=GSPMDSharding({devices=[8,1,1,1]<=[8]}) resource_env=ResourceEnv(Mesh(device_ids=array([[[0],\n        [1],\n        [2],\n        [3],\n        [4],\n        [5],\n        [6],\n        [7]]]), axis_names=(\'replica\', \'data\', \'mdl\')), ()) unconstrained_dims=set()]" source_file="/pax/praxis/praxis/py_utils.py" source_line=486}
  bitcast.1452 = f32[256,2048,64]{2,1,0} bitcast(fusion.47)
  custom-call.23 = f32[256,2048,64]{2,1,0} custom-call(bitcast.1428, bitcast.1452), custom_call_target="__cublas$gemm", metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._atten_logits/qk_einsum/BTNH,BSNH->BNTS/dot_general[dimension_numbers=(((3,), (1,)), ((0, 1), (0, 2))) precision=None preferred_element_type=float32]" source_file="/pax/praxis/praxis/layers/base_ops.py" source_line=42}, backend_config={"alpha_real":1,"alpha_imag":0,"beta":0,"dot_dimension_numbers":{"lhs_contracting_dimensions":["2"],"rhs_contracting_dimensions":["1"],"lhs_batch_dimensions":["0"],"rhs_batch_dimensions":["0"]},"precision_config":{"operand_precision":["DEFAULT","DEFAULT"]},"epilogue":"DEFAULT"}
  fusion.46 = f32[2,128,64,2048]{3,2,1,0} fusion(custom-call.23), kind=kInput, calls=fused_computation.46, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._atten_logits/qk_einsum/BTNH,BSNH->BNTS/dot_general[dimension_numbers=(((3,), (1,)), ((0, 1), (0, 2))) precision=None preferred_element_type=float32]" source_file="/pax/praxis/praxis/layers/base_ops.py" source_line=42}
  custom-call.22 = f32[256,2048,64]{2,1,0} custom-call(bitcast.1428, bitcast.1062), custom_call_target="__cublas$gemm", metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._atten_logits/qk_einsum/BTNH,BSNH->BNTS/dot_general[dimension_numbers=(((2,), (1,)), ((0, 1), (0, 2))) precision=None preferred_element_type=float32]" source_file="/pax/praxis/praxis/layers/base_ops.py" source_line=42}, backend_config={"alpha_real":1,"alpha_imag":0,"beta":0,"dot_dimension_numbers":{"lhs_contracting_dimensions":["1"],"rhs_contracting_dimensions":["1"],"lhs_batch_dimensions":["0"],"rhs_batch_dimensions":["0"]},"precision_config":{"operand_precision":["DEFAULT","DEFAULT"]},"epilogue":"DEFAULT"}
  fusion.457 = (f32[2,2048,3,128,64]{4,3,2,1,0}, f32[3,128,64,2,2048]{4,3,2,1,0}) fusion(custom-call.24, fusion.46, fusion.75, custom-call.22), kind=kLoop, calls=fused_computation.457, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/combined_qkv/einsum/ABD,KDNH->KABNH/transpose[permutation=(0, 3, 4, 1, 2)]" source_file="/pax/praxis/praxis/layers/base_ops.py" source_line=42}
  get-tuple-element.468 = f32[2,2048,3,128,64]{4,3,2,1,0} get-tuple-element(fusion.457), index=0
  bitcast.1492 = f32[4096,24576]{1,0} bitcast(get-tuple-element.468)
  custom-call.25 = f32[4096,8192]{1,0} custom-call(bitcast.1492, bitcast.1494), custom_call_target="__cublas$gemm", metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/combined_qkv/einsum/ABD,KDNH->KABNH/dot_general[dimension_numbers=(((0, 1, 2), (0, 2, 3)), ((), ())) precision=None preferred_element_type=float32]" source_file="/pax/praxis/praxis/layers/base_ops.py" source_line=42}, backend_config={"alpha_real":1,"alpha_imag":0,"beta":0,"dot_dimension_numbers":{"lhs_contracting_dimensions":["1"],"rhs_contracting_dimensions":["0"],"lhs_batch_dimensions":[],"rhs_batch_dimensions":[]},"precision_config":{"operand_precision":["DEFAULT","DEFAULT"]},"epilogue":"DEFAULT"}
  fusion.39 = (f32[2,2048]{1,0}, f32[2,2048,8192]{2,1,0}, f32[2,2048]{1,0}) fusion(fusion.82, fusion.80, custom-call.25, fusion.434, get-tuple-element.332, /*index=5*/fusion.85), kind=kInput, calls=fused_computation.39, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/layer_norm/reduce_sum[axes=(2,)]" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  get-tuple-element.465 = f32[2,2048]{1,0} get-tuple-element(fusion.39), index=2
  fusion.40 = (f32[2,2048]{1,0}, f32[2,2048,8192]{2,1,0}) fusion(fusion.82, get-tuple-element.465, fusion.434, get-tuple-element.332, fusion.85), kind=kInput, calls=fused_computation.40, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/layer_norm/reduce_sum[axes=(2,)]" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=371}
  get-tuple-element.463 = f32[2,2048]{1,0} get-tuple-element(fusion.40), index=0
  get-tuple-element.461 = f32[2,2048]{1,0} get-tuple-element(fusion.39), index=0
  get-tuple-element.462 = f32[2,2048,8192]{2,1,0} get-tuple-element(fusion.39), index=1
  get-tuple-element.464 = f32[2,2048,8192]{2,1,0} get-tuple-element(fusion.40), index=1
  fusion.38 = f32[2,2048,8192]{2,1,0} fusion(get-tuple-element.463, get-tuple-element.461, get-tuple-element.462, fusion.50, get-tuple-element.464), kind=kLoop, calls=fused_computation.38, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/layer_norm/add_any" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=370}
  get-tuple-element.346 = f32[8,32768]{1,0} get-tuple-element(loop_peel_param), index=2
  get-tuple-element.479 = f32[32768]{0} get-tuple-element(fusion.430), index=0
  all-reduce.50 = f32[32768]{0} all-reduce(get-tuple-element.479), channel_id=67, replica_groups={{0}}, to_apply=region_15.791, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/ffn_layer1/bias/reduce_sum[axes=(0, 1)]" source_file="/pax/praxis/praxis/layers/linears.py" source_line=143}
  fusion.37 = f32[8,32768]{1,0} fusion(get-tuple-element.346, fusion.85, all-reduce.50), kind=kLoop, calls=fused_computation.37, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  get-tuple-element.347 = f32[8,1024,32768]{2,1,0} get-tuple-element(loop_peel_param), index=3
  get-tuple-element.357 = s32[] get-tuple-element(loop_peel_param), index=29
  get-tuple-element.360 = f32[8192,32768]{1,0} get-tuple-element(loop_peel_param), index=30
  reduce-scatter.19 = f32[1024,32768]{1,0} reduce-scatter(get-tuple-element.360), channel_id=104, replica_groups={{0}}, dimensions={0}, to_apply=region_15.791
  fusion.36 = f32[8,1024,32768]{2,1,0} fusion(get-tuple-element.347, get-tuple-element.357, reduce-scatter.19), kind=kLoop, calls=fused_computation.36
  get-tuple-element.348 = f32[8,8192]{1,0} get-tuple-element(loop_peel_param), index=4
  get-tuple-element.481 = f32[8192]{0} get-tuple-element(fusion.429), index=0
  all-reduce.51 = f32[8192]{0} all-reduce(get-tuple-element.481), channel_id=69, replica_groups={{0}}, to_apply=region_15.791, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/ffn_layer2/bias/reduce_sum[axes=(0, 1)]" source_file="/pax/praxis/praxis/layers/linears.py" source_line=143}
  fusion.35 = f32[8,8192]{1,0} fusion(get-tuple-element.348, fusion.85, all-reduce.51), kind=kLoop, calls=fused_computation.35, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  get-tuple-element.365 = f32[32768,8192]{1,0} get-tuple-element(loop_peel_param), index=31
  transpose.189 = f32[8192,32768]{1,0} transpose(get-tuple-element.365), dimensions={1,0}
  bitcast.1600 = f32[32768,8192]{0,1} bitcast(transpose.189)
  reduce-scatter.21 = f32[32768,1024]{0,1} reduce-scatter(bitcast.1600), channel_id=106, replica_groups={{0}}, dimensions={1}, to_apply=region_15.791
  get-tuple-element.349 = f32[8,32768,1024]{1,2,0} get-tuple-element(loop_peel_param), index=5
  fusion.34 = f32[8,1024,32768]{2,1,0} fusion(get-tuple-element.357, reduce-scatter.21, get-tuple-element.349), kind=kLoop, calls=fused_computation.34
  bitcast.1608 = f32[8,32768,1024]{1,2,0} bitcast(fusion.34)
  get-tuple-element.350 = f32[8,8192]{1,0} get-tuple-element(loop_peel_param), index=6
  get-tuple-element.485 = f32[2,2048,8192]{2,1,0} get-tuple-element(fusion.63), index=1
  fusion.32 = (f32[8192]{0}, f32[8192]{0}) fusion(get-tuple-element.485, custom-call.19), kind=kInput, calls=fused_computation.32, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/reduce_sum[axes=(0, 1)]" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=376}
  get-tuple-element.478 = f32[8192]{0} get-tuple-element(fusion.32), index=1
  all-reduce.52 = f32[8192]{0} all-reduce(get-tuple-element.478), channel_id=71, replica_groups={{0}}, to_apply=region_15.791, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/reduce_sum[axes=(0, 1)]" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=378}
  fusion.33 = f32[8,8192]{1,0} fusion(get-tuple-element.350, fusion.85, all-reduce.52), kind=kLoop, calls=fused_computation.33, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  get-tuple-element.351 = f32[8,8192]{1,0} get-tuple-element(loop_peel_param), index=7
  get-tuple-element.477 = f32[8192]{0} get-tuple-element(fusion.32), index=0
  all-reduce.53 = f32[8192]{0} all-reduce(get-tuple-element.477), channel_id=72, replica_groups={{0}}, to_apply=region_15.791, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/reduce_sum[axes=(0, 1)]" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=376}
  fusion.31 = f32[8,8192]{1,0} fusion(get-tuple-element.351, fusion.85, all-reduce.53), kind=kLoop, calls=fused_computation.31, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  get-tuple-element.352 = f32[8,8192]{1,0} get-tuple-element(loop_peel_param), index=8
  get-tuple-element.491 = f32[2,2048,8192]{2,1,0} get-tuple-element(fusion.79), index=1
  fusion.29 = (f32[8192]{0}, f32[8192]{0}) fusion(get-tuple-element.491, custom-call.25), kind=kInput, calls=fused_computation.29, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/layer_norm/reduce_sum[axes=(0, 1)]" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=376}
  get-tuple-element.467 = f32[8192]{0} get-tuple-element(fusion.29), index=1
  all-reduce.54 = f32[8192]{0} all-reduce(get-tuple-element.467), channel_id=73, replica_groups={{0}}, to_apply=region_15.791, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/layer_norm/reduce_sum[axes=(0, 1)]" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=378}
  fusion.30 = f32[8,8192]{1,0} fusion(get-tuple-element.352, fusion.85, all-reduce.54), kind=kLoop, calls=fused_computation.30, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  get-tuple-element.353 = f32[8,8192]{1,0} get-tuple-element(loop_peel_param), index=9
  get-tuple-element.466 = f32[8192]{0} get-tuple-element(fusion.29), index=0
  fusion.26 = f32[256,64]{1,0} fusion(fusion.46, fusion.78), kind=kInput, calls=fused_computation.26
  constant.1588 = f32[] constant(0)
  reduce.205 = f32[64]{0} reduce(fusion.26, constant.1588), dimensions={0}, to_apply=region_15.791, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._scale_query/per_dim_scale/reduce_sum[axes=(0, 1, 2)]" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=404}
  all-reduce.57 = (f32[8192]{0}, f32[64]{0}) all-reduce(get-tuple-element.466, reduce.205), channel_id=74, replica_groups={{0}}, to_apply=region_15.791
  get-tuple-element.743 = f32[8192]{0} get-tuple-element(all-reduce.57), index=0, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/layer_norm/reduce_sum[axes=(0, 1)]" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=376}
  fusion.28 = f32[8,8192]{1,0} fusion(get-tuple-element.353, fusion.85, get-tuple-element.743), kind=kLoop, calls=fused_computation.28, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  get-tuple-element.370 = f32[3,128,64,8192]{3,2,1,0} get-tuple-element(loop_peel_param), index=32
  transpose.190 = f32[8192,3,128,64]{3,2,1,0} transpose(get-tuple-element.370), dimensions={3,0,1,2}
  bitcast.1687 = f32[3,128,64,8192]{2,1,0,3} bitcast(transpose.190)
  reduce-scatter.23 = f32[3,128,64,1024]{2,1,0,3} reduce-scatter(bitcast.1687), channel_id=108, replica_groups={{0}}, dimensions={3}, to_apply=region_15.791
  get-tuple-element.354 = f32[8,3,1024,128,64]{4,3,1,2,0} get-tuple-element(loop_peel_param), index=10
  fusion.27 = f32[8,1024,3,128,64]{4,3,2,1,0} fusion(get-tuple-element.357, reduce-scatter.23, get-tuple-element.354), kind=kLoop, calls=fused_computation.27
  bitcast.1695 = f32[8,3,1024,128,64]{4,3,1,2,0} bitcast(fusion.27)
  get-tuple-element.355 = f32[8,64]{1,0} get-tuple-element(loop_peel_param), index=11
  get-tuple-element.744 = f32[64]{0} get-tuple-element(all-reduce.57), index=1, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._scale_query/per_dim_scale/reduce_sum[axes=(0, 1, 2)]" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=404}
  fusion.25 = f32[8,64]{1,0} fusion(get-tuple-element.355, fusion.85, get-tuple-element.744, get-tuple-element.336), kind=kLoop, calls=fused_computation.25, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  get-tuple-element.356 = f32[8,1024,128,64]{3,2,1,0} get-tuple-element(loop_peel_param), index=12
  get-tuple-element.394 = f32[8192,128,64]{2,1,0} get-tuple-element(loop_peel_param), index=33
  reduce-scatter.25 = f32[1024,128,64]{2,1,0} reduce-scatter(get-tuple-element.394), channel_id=110, replica_groups={{0}}, dimensions={0}, to_apply=region_15.791
  fusion.24 = f32[8,1024,128,64]{3,2,1,0} fusion(get-tuple-element.356, get-tuple-element.357, reduce-scatter.25), kind=kLoop, calls=fused_computation.24
  get-tuple-element.343 = f32[8,32768,1024]{1,2,0} get-tuple-element(loop_peel_param), index=15
  get-tuple-element.329 = f32[8,3,1024,128,64]{4,3,1,2,0} get-tuple-element(loop_peel_param), index=20
  get-tuple-element.326 = s32[] get-tuple-element(loop_peel_param), index=28
  fusion.22 = f32[1,1024,3,128,64]{4,3,2,1,0} fusion(get-tuple-element.329, get-tuple-element.326), kind=kLoop, calls=fused_computation.22, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/dynamic_slice[slice_sizes=(1, 3, 8192, 128, 64)]" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  bitcast.1769 = f32[3,1024,128,64]{3,2,0,1} bitcast(fusion.22)
  all-gather.42 = f32[3,8192,128,64]{3,2,0,1} all-gather(bitcast.1769), channel_id=63, replica_groups={{0,1,2,3,4,5,6,7}}, dimensions={1}, use_global_device_ids=true, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/combined_qkv/einsum/ABD,KDNH->KABNH/dot_general[dimension_numbers=(((1,), (2,)), ((), ())) precision=None preferred_element_type=float32]" source_file="/pax/praxis/praxis/layers/base_ops.py" source_line=42}
  fusion.21 = f32[1,1024,32768]{2,1,0} fusion(get-tuple-element.343, get-tuple-element.326), kind=kLoop, calls=fused_computation.21, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/dynamic_slice[slice_sizes=(1, 32768, 8192)]" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  bitcast.1787 = f32[32768,1024]{0,1} bitcast(fusion.21)
  all-gather.45 = f32[32768,8192]{0,1} all-gather(bitcast.1787), channel_id=66, replica_groups={{0,1,2,3,4,5,6,7}}, dimensions={1}, use_global_device_ids=true, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/ffn_layer2/linear/einsum/...y,yz->...z/dot_general[dimension_numbers=(((2,), (1,)), ((), ())) precision=None preferred_element_type=float32]" source_file="/pax/praxis/praxis/layers/base_ops.py" source_line=42}
  constant.1620 = s32[] constant(2)
  add.648 = s32[] add(get-tuple-element.327, constant.1620)
  bitcast.1797 = f32[8192,4096]{0,1} bitcast(get-tuple-element.484)
  custom-call.26 = f32[8192,32768]{1,0} custom-call(bitcast.1797, bitcast.1799), custom_call_target="__cublas$gemm", metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/ffn_layer1/linear/einsum/...y,yz->...z/transpose[permutation=(1, 0)]" source_file="/pax/praxis/praxis/layers/base_ops.py" source_line=42}, backend_config={"alpha_real":1,"alpha_imag":0,"beta":0,"dot_dimension_numbers":{"lhs_contracting_dimensions":["1"],"rhs_contracting_dimensions":["0"],"lhs_batch_dimensions":[],"rhs_batch_dimensions":[]},"precision_config":{"operand_precision":["DEFAULT","DEFAULT"]},"epilogue":"DEFAULT"}
  get-tuple-element.483 = f32[2,2048,32768]{2,1,0} get-tuple-element(fusion.430), index=2
  bitcast.1811 = f32[32768,4096]{0,1} bitcast(get-tuple-element.483)
  custom-call.27 = f32[32768,8192]{1,0} custom-call(bitcast.1811, bitcast.1813), custom_call_target="__cublas$gemm", metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/ffn_layer2/linear/einsum/...y,yz->...z/transpose[permutation=(1, 0)]" source_file="/pax/praxis/praxis/layers/base_ops.py" source_line=42}, backend_config={"alpha_real":1,"alpha_imag":0,"beta":0,"dot_dimension_numbers":{"lhs_contracting_dimensions":["1"],"rhs_contracting_dimensions":["0"],"lhs_batch_dimensions":[],"rhs_batch_dimensions":[]},"precision_config":{"operand_precision":["DEFAULT","DEFAULT"]},"epilogue":"DEFAULT"}
  get-tuple-element.469 = f32[3,128,64,2,2048]{4,3,2,1,0} get-tuple-element(fusion.457), index=1
  bitcast.1822 = f32[24576,4096]{1,0} bitcast(get-tuple-element.469)
  bitcast.1826 = f32[4096,8192]{1,0} bitcast(get-tuple-element.490)
  custom-call.28 = f32[24576,8192]{1,0} custom-call(bitcast.1822, bitcast.1826), custom_call_target="__cublas$gemm", metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/combined_qkv/einsum/ABD,KDNH->KABNH/dot_general[dimension_numbers=(((3, 4), (0, 1)), ((), ())) precision=None preferred_element_type=float32]" source_file="/pax/praxis/praxis/layers/base_ops.py" source_line=42}, backend_config={"alpha_real":1,"alpha_imag":0,"beta":0,"dot_dimension_numbers":{"lhs_contracting_dimensions":["1"],"rhs_contracting_dimensions":["0"],"lhs_batch_dimensions":[],"rhs_batch_dimensions":[]},"precision_config":{"operand_precision":["DEFAULT","DEFAULT"]},"epilogue":"DEFAULT"}
  bitcast.1830 = f32[3,128,64,8192]{3,2,1,0} bitcast(custom-call.28)
  bitcast.1834 = f32[8192,4096]{0,1} bitcast(fusion.50)
  custom-call.29 = f32[8192,8192]{1,0} custom-call(bitcast.1834, bitcast.1836), custom_call_target="__cublas$gemm", metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/post/einsum/ABNH,DNH->ABD/dot_general[dimension_numbers=(((0, 1), (0, 1)), ((), ())) precision=None preferred_element_type=float32]" source_file="/pax/praxis/praxis/layers/base_ops.py" source_line=42}, backend_config={"alpha_real":1,"alpha_imag":0,"beta":0,"dot_dimension_numbers":{"lhs_contracting_dimensions":["1"],"rhs_contracting_dimensions":["0"],"lhs_batch_dimensions":[],"rhs_batch_dimensions":[]},"precision_config":{"operand_precision":["DEFAULT","DEFAULT"]},"epilogue":"DEFAULT"}
  bitcast.1840 = f32[8192,128,64]{2,1,0} bitcast(custom-call.29)
  ROOT tuple.22 = (s32[], f32[2,2048,8192]{2,1,0}, f32[8,32768]{1,0}, f32[8,1024,32768]{2,1,0}, f32[8,8192]{1,0}, /*index=5*/f32[8,32768,1024]{1,2,0}, f32[8,8192]{1,0}, f32[8,8192]{1,0}, f32[8,8192]{1,0}, f32[8,8192]{1,0}, /*index=10*/f32[8,3,1024,128,64]{4,3,1,2,0}, f32[8,64]{1,0}, f32[8,1024,128,64]{3,2,1,0}, f32[8,32768]{1,0}, f32[8,1024,32768]{2,1,0}, /*index=15*/f32[8,32768,1024]{1,2,0}, f32[8,8192]{1,0}, f32[8,8192]{1,0}, f32[8,8192]{1,0}, f32[8,8192]{1,0}, /*index=20*/f32[8,3,1024,128,64]{4,3,1,2,0}, f32[8,64]{1,0}, f32[8,1024,128,64]{3,2,1,0}, f32[8,2,2048,8192]{3,2,1,0}, f32[2,1,2048,2048]{3,2,0,1}, /*index=25*/f32[2,2048]{1,0}, f32[3,8192,128,64]{3,2,0,1}, f32[32768,8192]{0,1}, s32[], s32[], /*index=30*/f32[8192,32768]{1,0}, f32[32768,8192]{1,0}, f32[3,128,64,8192]{3,2,1,0}, f32[8192,128,64]{2,1,0}) tuple(add.622, fusion.38, fusion.37, fusion.36, fusion.35, /*index=5*/bitcast.1608, fusion.33, fusion.31, fusion.30, fusion.28, /*index=10*/bitcast.1695, fusion.25, fusion.24, get-tuple-element.341, get-tuple-element.340, /*index=15*/get-tuple-element.343, get-tuple-element.339, get-tuple-element.338, get-tuple-element.334, get-tuple-element.333, /*index=20*/get-tuple-element.329, get-tuple-element.336, get-tuple-element.337, get-tuple-element.332, get-tuple-element.335, /*index=25*/get-tuple-element.342, all-gather.42, all-gather.45, add.648, fusion.85, /*index=30*/custom-call.26, custom-call.27, bitcast.1830, bitcast.1840)
} // region_32.1118_spmd.1.clone

region_65.1623_spmd.1.clone {
  loop_peel_cond_param = (s32[], f32[2,2048,8192]{2,1,0}, f32[8,32768]{1,0}, f32[8,1024,32768]{2,1,0}, f32[8,8192]{1,0}, /*index=5*/f32[8,32768,1024]{1,2,0}, f32[8,8192]{1,0}, f32[8,8192]{1,0}, f32[8,8192]{1,0}, f32[8,8192]{1,0}, /*index=10*/f32[8,3,1024,128,64]{4,3,1,2,0}, f32[8,64]{1,0}, f32[8,1024,128,64]{3,2,1,0}, f32[8,32768]{1,0}, f32[8,1024,32768]{2,1,0}, /*index=15*/f32[8,32768,1024]{1,2,0}, f32[8,8192]{1,0}, f32[8,8192]{1,0}, f32[8,8192]{1,0}, f32[8,8192]{1,0}, /*index=20*/f32[8,3,1024,128,64]{4,3,1,2,0}, f32[8,64]{1,0}, f32[8,1024,128,64]{3,2,1,0}, f32[8,2,2048,8192]{3,2,1,0}, f32[2,1,2048,2048]{3,2,0,1}, /*index=25*/f32[2,2048]{1,0}, f32[3,8192,128,64]{3,2,0,1}, f32[32768,8192]{0,1}, s32[], s32[], /*index=30*/f32[8192,32768]{1,0}, f32[32768,8192]{1,0}, f32[3,128,64,8192]{3,2,1,0}, f32[8192,128,64]{2,1,0}) parameter(0)
  get-tuple-element.325 = s32[] get-tuple-element(loop_peel_cond_param), index=0
  constant.1580 = s32[] constant(7)
  ROOT compare.373 = pred[] compare(get-tuple-element.325, constant.1580), direction=LT
}

fused_computation.86 {
  param_2.1219 = f32[] parameter(2)
  param_3.907 = f32[] parameter(3)
  compare.681 = pred[] compare(param_2.1219, param_3.907), direction=GT, metadata={op_name="/gt" source_file="/pax/praxis/praxis/layers/embedding_softmax.py" source_line=323}
  compare.680 = pred[] compare(param_2.1219, param_2.1219), direction=NE, metadata={op_name="/ne" source_file="/pax/praxis/praxis/layers/embedding_softmax.py" source_line=323}
  or.5 = pred[] or(compare.681, compare.680), metadata={op_name="/or" source_file="/pax/praxis/praxis/layers/embedding_softmax.py" source_line=323}
  compare.521 = pred[] compare(param_2.1219, param_3.907), direction=EQ, metadata={op_name="/eq" source_file="/pax/praxis/praxis/layers/embedding_softmax.py" source_line=323}
  param_0.161 = s32[] parameter(0)
  param_1.234 = s32[] parameter(1)
  compare.520 = pred[] compare(param_0.161, param_1.234), direction=LT, metadata={op_name="/lt" source_file="/pax/praxis/praxis/layers/embedding_softmax.py" source_line=323}
  and.1 = pred[] and(compare.521, compare.520), metadata={op_name="/and" source_file="/pax/praxis/praxis/layers/embedding_softmax.py" source_line=323}
  or.2 = pred[] or(or.5, and.1), metadata={op_name="/or" source_file="/pax/praxis/praxis/layers/embedding_softmax.py" source_line=323}
  ROOT select.764 = s32[] select(or.2, param_0.161, param_1.234), metadata={op_name="/select_n" source_file="/pax/praxis/praxis/layers/embedding_softmax.py" source_line=323}
} // fused_computation.86

fused_computation.458 {
  param_0.1187 = f32[] parameter(0)
  param_1.1648 = f32[] parameter(1)
  compare.685 = pred[] compare(param_0.1187, param_1.1648), direction=GT, metadata={op_name="/gt" source_file="/pax/praxis/praxis/layers/embedding_softmax.py" source_line=323}
  compare.684 = pred[] compare(param_0.1187, param_0.1187), direction=NE, metadata={op_name="/ne" source_file="/pax/praxis/praxis/layers/embedding_softmax.py" source_line=323}
  or.7 = pred[] or(compare.685, compare.684), metadata={op_name="/or" source_file="/pax/praxis/praxis/layers/embedding_softmax.py" source_line=323}
  ROOT select.982 = f32[] select(or.7, param_0.1187, param_1.1648), metadata={op_name="/select_n" source_file="/pax/praxis/praxis/layers/embedding_softmax.py" source_line=323}
} // fused_computation.458

region_13.759 {
  Arg_0.760 = f32[] parameter(0)
  Arg_2.762 = f32[] parameter(2)
  fusion.458 = f32[] fusion(Arg_0.760, Arg_2.762), kind=kLoop, calls=fused_computation.458, metadata={op_name="/select_n" source_file="/pax/praxis/praxis/layers/embedding_softmax.py" source_line=323}
  Arg_1.761 = s32[] parameter(1)
  Arg_3.763 = s32[] parameter(3)
  fusion.86 = s32[] fusion(Arg_1.761, Arg_3.763, Arg_0.760, Arg_2.762), kind=kLoop, calls=fused_computation.86, metadata={op_name="/select_n" source_file="/pax/praxis/praxis/layers/embedding_softmax.py" source_line=323}
  ROOT tuple.773 = (f32[], s32[]) tuple(fusion.458, fusion.86)
} // region_13.759

fused_computation.88 {
  param_1.2234 = f32[2,2048]{1,0} parameter(1)
  negate.176 = f32[2,2048]{1,0} negate(param_1.2234), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/lm.compute_loss/softmax/neg" source_file="/pax/praxis/praxis/layers/embedding_softmax.py" source_line=317}
  param_0.1640 = f32[2,2048]{1,0} parameter(0)
  multiply.2789 = f32[2,2048]{1,0} multiply(negate.176, param_0.1640), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/lm.compute_loss/softmax/mul" source_file="/pax/praxis/praxis/layers/embedding_softmax.py" source_line=328}
  constant.1772 = f32[] constant(0)
  reduce.327 = f32[2]{0} reduce(multiply.2789, constant.1772), dimensions={1}, to_apply=region_15.791, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/lm.compute_loss/reduce_sum[axes=(1,)]" source_file="/pax/praxis/praxis/layers/transformer_models.py" source_line=612}
  ROOT negate.118 = f32[2]{0} negate(reduce.327), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_loss/neg" source_file="/pax/praxis/praxis/layers/models.py" source_line=170}
} // fused_computation.88

fused_computation.91 {
  param_1.2237 = f32[2,2048]{1,0} parameter(1)
  negate.178 = f32[2,2048]{1,0} negate(param_1.2237), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/lm.compute_loss/softmax/neg" source_file="/pax/praxis/praxis/layers/embedding_softmax.py" source_line=317}
  param_0.1643 = f32[2,2048]{1,0} parameter(0)
  multiply.2791 = f32[2,2048]{1,0} multiply(negate.178, param_0.1643), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/lm.compute_loss/softmax/mul" source_file="/pax/praxis/praxis/layers/embedding_softmax.py" source_line=328}
  bitcast.7420 = f32[4096]{0} bitcast(multiply.2791), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/lm.compute_loss/softmax/mul" source_file="/pax/praxis/praxis/layers/embedding_softmax.py" source_line=328}
  constant.1776 = f32[] constant(0)
  reduce.329 = f32[] reduce(bitcast.7420, constant.1776), dimensions={0}, to_apply=region_15.791, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/lm.compute_loss/softmax/reduce_sum[axes=(0, 1, 2)]" source_file="/pax/praxis/praxis/layers/embedding_softmax.py" source_line=327}
  param_2.2250 = s32[2,2048]{1,0} parameter(2)
  param_3.2220 = s32[2,2048]{1,0} parameter(3)
  compare.524.clone.1 = pred[2,2048]{1,0} compare(param_2.2250, param_3.2220), direction=EQ, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_loss/eq" source_file="/pax/praxis/praxis/layers/models.py" source_line=129}
  broadcast.2202.clone.1 = f32[2,2048]{1,0} broadcast(constant.1776), dimensions={}
  select.765.clone.1 = f32[2,2048]{1,0} select(compare.524.clone.1, param_0.1643, broadcast.2202.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_loss/mul" source_file="/pax/praxis/praxis/layers/models.py" source_line=129}
  bitcast.7419.clone.1 = f32[4096]{0} bitcast(select.765.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_loss/mul" source_file="/pax/praxis/praxis/layers/models.py" source_line=129}
  reduce.328.clone.1 = f32[] reduce(bitcast.7419.clone.1, constant.1776), dimensions={0}, to_apply=region_15.791, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_loss/reduce_sum[axes=(0, 1)]" source_file="/pax/praxis/praxis/layers/models.py" source_line=129}
  ROOT tuple.145 = (f32[], f32[]) tuple(reduce.329, reduce.328.clone.1)
} // fused_computation.91

fused_computation.93 {
  param_1.1695 = s32[2,2048]{1,0} parameter(1)
  broadcast.2903 = s32[2,2048,32000]{2,1,0} broadcast(param_1.1695), dimensions={0,1}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/lm.compute_loss/softmax/jit(_one_hot)/eq" source_file="/pax/praxis/praxis/layers/embedding_softmax.py" source_line=299}
  iota.62 = s32[2,2048,32000]{2,1,0} iota(), iota_dimension=2, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/lm.compute_loss/softmax/jit(_one_hot)/eq" source_file="/pax/praxis/praxis/layers/embedding_softmax.py" source_line=299}
  compare.687 = pred[2,2048,32000]{2,1,0} compare(broadcast.2903, iota.62), direction=EQ, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/lm.compute_loss/softmax/jit(_one_hot)/eq" source_file="/pax/praxis/praxis/layers/embedding_softmax.py" source_line=299}
  param_3.954 = f32[4096,32000]{1,0} parameter(3)
  bitcast.7770 = f32[2,2048,32000]{2,1,0} bitcast(param_3.954)
  constant.2511 = f32[] constant(30)
  broadcast.2981 = f32[2,2048,32000]{2,1,0} broadcast(constant.2511), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/lm.compute_loss/softmax/softmax.get_logits/div" source_file="/pax/praxis/praxis/layers/embedding_softmax.py" source_line=245}
  multiply.1885 = f32[2,2048,32000]{2,1,0} multiply(bitcast.7770, broadcast.2981), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/lm.compute_loss/softmax/softmax.get_logits/mul" source_file="/pax/praxis/praxis/layers/embedding_softmax.py" source_line=245}
  param_2.1275 = f32[2,2048]{1,0} parameter(2)
  broadcast.2980 = f32[2,2048,32000]{2,1,0} broadcast(param_2.1275), dimensions={0,1}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/lm.compute_loss/softmax/jit(log_softmax)/sub" source_file="/pax/praxis/praxis/layers/embedding_softmax.py" source_line=296}
  subtract.390 = f32[2,2048,32000]{2,1,0} subtract(multiply.1885, broadcast.2980), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/lm.compute_loss/softmax/jit(log_softmax)/sub" source_file="/pax/praxis/praxis/layers/embedding_softmax.py" source_line=296}
  param_0.1233 = f32[2,2048]{1,0} parameter(0)
  broadcast.2203 = f32[2,2048,32000]{2,1,0} broadcast(param_0.1233), dimensions={0,1}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/lm.compute_loss/softmax/jit(log_softmax)/sub" source_file="/pax/praxis/praxis/layers/embedding_softmax.py" source_line=296}
  subtract.305 = f32[2,2048,32000]{2,1,0} subtract(subtract.390, broadcast.2203), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/lm.compute_loss/softmax/jit(log_softmax)/sub" source_file="/pax/praxis/praxis/layers/embedding_softmax.py" source_line=296}
  constant.1777 = f32[] constant(0)
  broadcast.2205 = f32[2,2048,32000]{2,1,0} broadcast(constant.1777), dimensions={}
  select.766 = f32[2,2048,32000]{2,1,0} select(compare.687, subtract.305, broadcast.2205), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/lm.compute_loss/softmax/mul" source_file="/pax/praxis/praxis/layers/embedding_softmax.py" source_line=318}
  bitcast.7421 = f32[2,2048,128,250]{3,2,1,0} bitcast(select.766), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/lm.compute_loss/softmax/mul" source_file="/pax/praxis/praxis/layers/embedding_softmax.py" source_line=318}
  reduce.330 = f32[2,2048,128]{2,1,0} reduce(bitcast.7421, constant.1777), dimensions={3}, to_apply=region_15.791, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/lm.compute_loss/softmax/reduce_sum[axes=(2,)]" source_file="/pax/praxis/praxis/layers/embedding_softmax.py" source_line=317}
  constant.2410.clone.1 = f32[] constant(1)
  param_5.1710 = f32[] parameter(5)
  constant.2409.clone.1 = f32[] constant(1e-06)
  add.1157.clone.1 = f32[] add(param_5.1710, constant.2409.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/lm.compute_loss/softmax/add" source_file="/pax/praxis/praxis/layers/embedding_softmax.py" source_line=349}
  divide.229.clone.1 = f32[] divide(constant.2410.clone.1, add.1157.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/lm.compute_loss/softmax/div" source_file="/pax/praxis/praxis/layers/embedding_softmax.py" source_line=349}
  broadcast.2916.clone.1 = f32[2,2048]{1,0} broadcast(divide.229.clone.1), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/lm.compute_loss/softmax/broadcast_in_dim[shape=(16, 2048, 1) broadcast_dimensions=()]" source_file="/pax/praxis/praxis/layers/embedding_softmax.py" source_line=327}
  param_4.1950 = f32[2,2048]{1,0} parameter(4)
  multiply.1865.clone.1 = f32[2,2048]{1,0} multiply(broadcast.2916.clone.1, param_4.1950), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/lm.compute_loss/softmax/mul" source_file="/pax/praxis/praxis/layers/embedding_softmax.py" source_line=328}
  negate.142.clone.1 = f32[2,2048]{1,0} negate(multiply.1865.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/lm.compute_loss/softmax/neg" source_file="/pax/praxis/praxis/layers/embedding_softmax.py" source_line=317}
  broadcast.2915.clone.1 = f32[2,2048,32000]{2,1,0} broadcast(negate.142.clone.1), dimensions={0,1}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/lm.compute_loss/softmax/broadcast_in_dim[shape=(16, 2048, 32000) broadcast_dimensions=(0, 1)]" source_file="/pax/praxis/praxis/layers/embedding_softmax.py" source_line=317}
  select.984.clone.1 = f32[2,2048,32000]{2,1,0} select(compare.687, broadcast.2915.clone.1, broadcast.2205), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/lm.compute_loss/softmax/mul" source_file="/pax/praxis/praxis/layers/embedding_softmax.py" source_line=318}
  negate.135.clone.1 = f32[2,2048,32000]{2,1,0} negate(select.984.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/lm.compute_loss/softmax/jit(log_softmax)/neg" source_file="/pax/praxis/praxis/layers/embedding_softmax.py" source_line=296}
  bitcast.7533.clone.1 = f32[2,2048,128,250]{3,2,1,0} bitcast(negate.135.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/lm.compute_loss/softmax/jit(log_softmax)/neg" source_file="/pax/praxis/praxis/layers/embedding_softmax.py" source_line=296}
  reduce.396.clone.1 = f32[2,2048,128]{2,1,0} reduce(bitcast.7533.clone.1, constant.1777), dimensions={3}, to_apply=region_15.791, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/lm.compute_loss/softmax/jit(log_softmax)/reduce_sum[axes=(2,)]" source_file="/pax/praxis/praxis/layers/embedding_softmax.py" source_line=296}
  ROOT tuple.144 = (f32[2,2048,128]{2,1,0}, f32[2,2048,128]{2,1,0}) tuple(reduce.330, reduce.396.clone.1)
} // fused_computation.93

fused_computation.132 {
  param_0.247 = f32[8,1024,128,64]{3,2,1,0} parameter(0)
  param_4.1689 = f32[] parameter(4)
  is-finite.41 = pred[] is-finite(param_4.1689), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(isfinite)/is_finite" source_file="/pax/paxml/paxml/learners.py" source_line=256}
  broadcast.2249 = pred[8,1024,128,64]{3,2,1,0} broadcast(is-finite.41), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(_where)/broadcast_in_dim[shape=(8, 8192, 128, 64) broadcast_dimensions=()]" source_file="/pax/paxml/paxml/learners.py" source_line=340}
  param_3.1971 = f32[8]{0} parameter(3)
  broadcast.2247 = f32[8,1024,128,64]{3,2,1,0} broadcast(param_3.1971), dimensions={0}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=695}
  param_10.668 = f32[8]{0} parameter(10)
  broadcast.4823 = f32[8,1024,128,64]{3,2,1,0} broadcast(param_10.668), dimensions={0}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=339}
  param_11.623 = f32[8,1024,128,64]{3,2,1,0} parameter(11)
  param_13.325 = f32[1024,128,64]{2,1,0} parameter(13)
  bitcast.8178 = f32[1,1024,128,64]{3,2,1,0} bitcast(param_13.325)
  param_12.531 = s32[] parameter(12)
  constant.4927 = s32[] constant(0)
  dynamic-update-slice.351 = f32[8,1024,128,64]{3,2,1,0} dynamic-update-slice(param_11.623, bitcast.8178, param_12.531, constant.4927, constant.4927, /*index=5*/constant.4927)
  param_9.788 = f32[1024,128,64]{2,1,0} parameter(9)
  bitcast.8164 = f32[1,1024,128,64]{3,2,1,0} bitcast(param_9.788)
  constant.4930 = s32[] constant(7)
  param_8.908 = s32[] parameter(8)
  subtract.1116 = s32[] subtract(constant.4930, param_8.908), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  compare.1854 = pred[] compare(subtract.1116, constant.4927), direction=LT, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/lt" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  constant.4928 = s32[] constant(15)
  subtract.1115 = s32[] subtract(constant.4928, param_8.908), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/add" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  select.2159 = s32[] select(compare.1854, subtract.1115, subtract.1116), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/select_n" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  dynamic-update-slice.337 = f32[8,1024,128,64]{3,2,1,0} dynamic-update-slice(dynamic-update-slice.351, bitcast.8164, select.2159, constant.4927, constant.4927, /*index=5*/constant.4927), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  param_7.851 = f32[] parameter(7)
  broadcast.4822 = f32[8,1024,128,64]{3,2,1,0} broadcast(param_7.851), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/paxml/paxml/learners.py" source_line=266}
  multiply.2759 = f32[8,1024,128,64]{3,2,1,0} multiply(dynamic-update-slice.337, broadcast.4822), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/paxml/paxml/learners.py" source_line=266}
  compare.1853 = pred[8,1024,128,64]{3,2,1,0} compare(multiply.2759, multiply.2759), direction=NE, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/jit(isnan)/ne" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  constant.1786 = f32[] constant(nan)
  broadcast.4821 = f32[8,1024,128,64]{3,2,1,0} broadcast(constant.1786), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/jit(_where)/broadcast_in_dim[shape=(8, 8192, 128, 64) broadcast_dimensions=(1, 2, 3)]" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  select.2158 = f32[8,1024,128,64]{3,2,1,0} select(compare.1853, broadcast.4821, multiply.2759), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/jit(_where)/select_n" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  constant.1787 = f32[] constant(inf)
  broadcast.4820 = f32[8,1024,128,64]{3,2,1,0} broadcast(constant.1787), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/eq" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  compare.1852 = pred[8,1024,128,64]{3,2,1,0} compare(select.2158, broadcast.4820), direction=EQ, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/eq" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  select.2157 = f32[8,1024,128,64]{3,2,1,0} select(compare.1852, broadcast.4821, select.2158), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/jit(_where)/select_n" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  constant.1788 = f32[] constant(-inf)
  broadcast.4819 = f32[8,1024,128,64]{3,2,1,0} broadcast(constant.1788), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/eq" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  compare.1851 = pred[8,1024,128,64]{3,2,1,0} compare(select.2157, broadcast.4819), direction=EQ, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/eq" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  select.2156 = f32[8,1024,128,64]{3,2,1,0} select(compare.1851, broadcast.4821, select.2157), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/jit(_where)/select_n" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  multiply.2758 = f32[8,1024,128,64]{3,2,1,0} multiply(broadcast.4823, select.2156), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=339}
  param_6.1175 = f32[8]{0} parameter(6)
  broadcast.4818 = f32[8,1024,128,64]{3,2,1,0} broadcast(param_6.1175), dimensions={0}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=339}
  param_5.1499 = f32[8,1024,128,64]{3,2,1,0} parameter(5)
  multiply.2757 = f32[8,1024,128,64]{3,2,1,0} multiply(broadcast.4818, param_5.1499), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=339}
  add.1520 = f32[8,1024,128,64]{3,2,1,0} add(multiply.2758, multiply.2757), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/add" source_file="/pax/praxis/praxis/optimizers.py" source_line=339}
  param_1.2219 = f32[8,1024,128,64]{3,2,1,0} parameter(1)
  param_2.1996 = f32[8]{0} parameter(2)
  constant.1656 = f32[] constant(1.49011612e-08)
  broadcast.2246 = f32[8]{0} broadcast(constant.1656), dimensions={}
  multiply.1391 = f32[8]{0} multiply(param_2.1996, broadcast.2246), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/div" source_file="/pax/praxis/praxis/optimizers.py" source_line=2066}
  sqrt.62 = f32[8]{0} sqrt(multiply.1391), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/sqrt" source_file="/pax/praxis/praxis/optimizers.py" source_line=2080}
  compare.527 = pred[8]{0} compare(sqrt.62, sqrt.62), direction=NE, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/jit(isnan)/ne" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  broadcast.2252 = f32[8]{0} broadcast(constant.1786), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/jit(_where)/broadcast_in_dim[shape=(8,) broadcast_dimensions=()]" source_file="/usr/local/lib/python3.10/dist-packages/optax/_src/schedule.py" source_line=399}
  select.810 = f32[8]{0} select(compare.527, broadcast.2252, sqrt.62), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/jit(_where)/select_n" source_file="/usr/local/lib/python3.10/dist-packages/optax/_src/schedule.py" source_line=399}
  broadcast.2251 = f32[8]{0} broadcast(constant.1787), dimensions={}
  compare.526 = pred[8]{0} compare(select.810, broadcast.2251), direction=EQ, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/eq" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  select.809 = f32[8]{0} select(compare.526, broadcast.2252, select.810), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/jit(_where)/select_n" source_file="/usr/local/lib/python3.10/dist-packages/optax/_src/schedule.py" source_line=399}
  broadcast.2250 = f32[8]{0} broadcast(constant.1788), dimensions={}
  compare.525 = pred[8]{0} compare(select.809, broadcast.2250), direction=EQ, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/eq" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  select.808 = f32[8]{0} select(compare.525, broadcast.2252, select.809), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/jit(_where)/select_n" source_file="/usr/local/lib/python3.10/dist-packages/optax/_src/schedule.py" source_line=399}
  constant.1789 = f32[] constant(1)
  broadcast.2253 = f32[8]{0} broadcast(constant.1789), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(_where))/broadcast_in_dim[shape=(8,) broadcast_dimensions=()]" source_file="/pax/praxis/praxis/schedules.py" source_line=105}
  maximum.56 = f32[8]{0} maximum(select.808, broadcast.2253), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/max" source_file="/pax/praxis/praxis/optimizers.py" source_line=346}
  broadcast.2245 = f32[8,1024,128,64]{3,2,1,0} broadcast(maximum.56), dimensions={0}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/div" source_file="/pax/praxis/praxis/optimizers.py" source_line=347}
  multiply.1389 = f32[8,1024,128,64]{3,2,1,0} multiply(param_1.2219, broadcast.2245)
  divide.178 = f32[8,1024,128,64]{3,2,1,0} divide(add.1520, multiply.1389), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/div" source_file="/pax/praxis/praxis/optimizers.py" source_line=347}
  constant.1790 = f32[] constant(0.001)
  broadcast.2244 = f32[8,1024,128,64]{3,2,1,0} broadcast(constant.1790), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=691}
  multiply.1383 = f32[8,1024,128,64]{3,2,1,0} multiply(param_0.247, broadcast.2244), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=691}
  add.901 = f32[8,1024,128,64]{3,2,1,0} add(divide.178, multiply.1383), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/add" source_file="/pax/praxis/praxis/optimizers.py" source_line=691}
  multiply.1382 = f32[8,1024,128,64]{3,2,1,0} multiply(broadcast.2247, add.901), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=695}
  constant.1791 = f32[] constant(0)
  broadcast.2254 = f32[8,1024,128,64]{3,2,1,0} broadcast(constant.1791), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/broadcast_in_dim[shape=(8, 8192, 128, 64) broadcast_dimensions=()]" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  select.807 = f32[8,1024,128,64]{3,2,1,0} select(broadcast.2249, multiply.1382, broadcast.2254), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(_where)/select_n" source_file="/pax/paxml/paxml/learners.py" source_line=340}
  ROOT add.900 = f32[8,1024,128,64]{3,2,1,0} add(param_0.247, select.807), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/add" source_file="/pax/paxml/paxml/learners.py" source_line=408}
} // fused_computation.132

fused_computation.133 {
  param_5.1712 = f32[8]{0} parameter(5)
  broadcast.4847 = f32[8,1024,128,64]{3,2,1,0} broadcast(param_5.1712), dimensions={0}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=339}
  param_10.667 = f32[8,1024,128,64]{3,2,1,0} parameter(10)
  param_12.529 = f32[1024,128,64]{2,1,0} parameter(12)
  bitcast.8176 = f32[1,1024,128,64]{3,2,1,0} bitcast(param_12.529)
  param_11.622 = s32[] parameter(11)
  constant.4957 = s32[] constant(0)
  dynamic-update-slice.349 = f32[8,1024,128,64]{3,2,1,0} dynamic-update-slice(param_10.667, bitcast.8176, param_11.622, constant.4957, constant.4957, /*index=5*/constant.4957)
  param_4.1955 = f32[1024,128,64]{2,1,0} parameter(4)
  bitcast.8168 = f32[1,1024,128,64]{3,2,1,0} bitcast(param_4.1955)
  constant.4960 = s32[] constant(7)
  param_3.2224 = s32[] parameter(3)
  subtract.1124 = s32[] subtract(constant.4960, param_3.2224), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  compare.1872 = pred[] compare(subtract.1124, constant.4957), direction=LT, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/lt" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  constant.4958 = s32[] constant(15)
  subtract.1123 = s32[] subtract(constant.4958, param_3.2224), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/add" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  select.2175 = s32[] select(compare.1872, subtract.1123, subtract.1124), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/select_n" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  dynamic-update-slice.341 = f32[8,1024,128,64]{3,2,1,0} dynamic-update-slice(dynamic-update-slice.349, bitcast.8168, select.2175, constant.4957, constant.4957, /*index=5*/constant.4957), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  param_2.2072 = f32[] parameter(2)
  broadcast.4846 = f32[8,1024,128,64]{3,2,1,0} broadcast(param_2.2072), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/paxml/paxml/learners.py" source_line=266}
  multiply.2771 = f32[8,1024,128,64]{3,2,1,0} multiply(dynamic-update-slice.341, broadcast.4846), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/paxml/paxml/learners.py" source_line=266}
  compare.1871 = pred[8,1024,128,64]{3,2,1,0} compare(multiply.2771, multiply.2771), direction=NE, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/jit(isnan)/ne" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  constant.4956 = f32[] constant(nan)
  broadcast.4845 = f32[8,1024,128,64]{3,2,1,0} broadcast(constant.4956), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/jit(_where)/broadcast_in_dim[shape=(8, 8192, 128, 64) broadcast_dimensions=(1, 2, 3)]" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  select.2174 = f32[8,1024,128,64]{3,2,1,0} select(compare.1871, broadcast.4845, multiply.2771), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/jit(_where)/select_n" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  constant.4955 = f32[] constant(inf)
  broadcast.4844 = f32[8,1024,128,64]{3,2,1,0} broadcast(constant.4955), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/eq" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  compare.1870 = pred[8,1024,128,64]{3,2,1,0} compare(select.2174, broadcast.4844), direction=EQ, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/eq" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  select.2173 = f32[8,1024,128,64]{3,2,1,0} select(compare.1870, broadcast.4845, select.2174), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/jit(_where)/select_n" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  constant.4954 = f32[] constant(-inf)
  broadcast.4843 = f32[8,1024,128,64]{3,2,1,0} broadcast(constant.4954), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/eq" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  compare.1869 = pred[8,1024,128,64]{3,2,1,0} compare(select.2173, broadcast.4843), direction=EQ, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/eq" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  select.2172 = f32[8,1024,128,64]{3,2,1,0} select(compare.1869, broadcast.4845, select.2173), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/jit(_where)/select_n" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  multiply.2770 = f32[8,1024,128,64]{3,2,1,0} multiply(broadcast.4847, select.2172), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=339}
  param_1.2291 = f32[8]{0} parameter(1)
  broadcast.4842 = f32[8,1024,128,64]{3,2,1,0} broadcast(param_1.2291), dimensions={0}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=339}
  param_0.1662 = f32[8,1024,128,64]{3,2,1,0} parameter(0)
  multiply.2769 = f32[8,1024,128,64]{3,2,1,0} multiply(broadcast.4842, param_0.1662), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=339}
  add.1524 = f32[8,1024,128,64]{3,2,1,0} add(multiply.2770, multiply.2769), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/add" source_file="/pax/praxis/praxis/optimizers.py" source_line=339}
  param_9.787 = f32[8]{0} parameter(9)
  broadcast.4871.clone.1 = f32[8,1024,128,64]{3,2,1,0} broadcast(param_9.787), dimensions={0}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=340}
  multiply.2786.clone.1 = f32[8,1024,128,64]{3,2,1,0} multiply(select.2172, select.2172), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=340}
  multiply.2785.clone.1 = f32[8,1024,128,64]{3,2,1,0} multiply(broadcast.4871.clone.1, multiply.2786.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=340}
  param_8.907 = f32[8]{0} parameter(8)
  broadcast.4866.clone.1 = f32[8,1024,128,64]{3,2,1,0} broadcast(param_8.907), dimensions={0}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=340}
  param_7.975 = f32[8,1024,128,64]{3,2,1,0} parameter(7)
  multiply.2784.clone.1 = f32[8,1024,128,64]{3,2,1,0} multiply(broadcast.4866.clone.1, param_7.975), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=340}
  add.1529.clone.1 = f32[8,1024,128,64]{3,2,1,0} add(multiply.2785.clone.1, multiply.2784.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/add" source_file="/pax/praxis/praxis/optimizers.py" source_line=340}
  sqrt.63.clone.1 = f32[8,1024,128,64]{3,2,1,0} sqrt(add.1529.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/sqrt" source_file="/pax/praxis/praxis/optimizers.py" source_line=684}
  constant.1793.clone.1 = f32[] constant(1e-06)
  broadcast.2255.clone.1 = f32[8,1024,128,64]{3,2,1,0} broadcast(constant.1793.clone.1), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/add" source_file="/pax/praxis/praxis/optimizers.py" source_line=684}
  add.902.clone.1 = f32[8,1024,128,64]{3,2,1,0} add(sqrt.63.clone.1, broadcast.2255.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/add" source_file="/pax/praxis/praxis/optimizers.py" source_line=684}
  divide.179 = f32[8,1024,128,64]{3,2,1,0} divide(add.1524, add.902.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/div" source_file="/pax/praxis/praxis/optimizers.py" source_line=684}
  multiply.1392 = f32[8,1024,128,64]{3,2,1,0} multiply(divide.179, divide.179), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=2078}
  bitcast.7422 = f32[8,2048,4096]{2,1,0} bitcast(multiply.1392), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=2078}
  constant.1792 = f32[] constant(0)
  reduce.331 = f32[8,2048]{1,0} reduce(bitcast.7422, constant.1792), dimensions={2}, to_apply=region_15.791, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/reduce_sum[axes=(1, 2, 3)]" source_file="/pax/praxis/praxis/optimizers.py" source_line=2066}
  param_6.1358 = f32[] parameter(6)
  is-finite.15.clone.1 = pred[] is-finite(param_6.1358), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(isfinite)/is_finite" source_file="/pax/paxml/paxml/learners.py" source_line=256}
  broadcast.2219.clone.1 = pred[8,1024,128,64]{3,2,1,0} broadcast(is-finite.15.clone.1), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(_where)/broadcast_in_dim[shape=(8, 8192, 128, 64) broadcast_dimensions=()]" source_file="/pax/paxml/paxml/learners.py" source_line=340}
  select.781.clone.1 = f32[8,1024,128,64]{3,2,1,0} select(broadcast.2219.clone.1, add.1524, param_0.1662), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(_where)/select_n" source_file="/pax/paxml/paxml/learners.py" source_line=340}
  select.768.clone.1 = f32[8,1024,128,64]{3,2,1,0} select(broadcast.2219.clone.1, add.1529.clone.1, param_7.975), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(_where)/select_n" source_file="/pax/paxml/paxml/learners.py" source_line=340}
  ROOT tuple.49 = (f32[8,2048]{1,0}, f32[8,1024,128,64]{3,2,1,0}, f32[8,1024,128,64]{3,2,1,0}, f32[8,1024,128,64]{3,2,1,0}) tuple(reduce.331, select.781.clone.1, add.902.clone.1, select.768.clone.1)
} // fused_computation.133

fused_computation.138 {
  param_0.259 = f32[8,64]{1,0} parameter(0)
  param_3.1955 = f32[] parameter(3)
  is-finite.42 = pred[] is-finite(param_3.1955), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(isfinite)/is_finite" source_file="/pax/paxml/paxml/learners.py" source_line=256}
  broadcast.2269 = pred[8,64]{1,0} broadcast(is-finite.42), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(_where)/broadcast_in_dim[shape=(8, 64) broadcast_dimensions=()]" source_file="/pax/paxml/paxml/learners.py" source_line=340}
  param_2.1990 = f32[8]{0} parameter(2)
  broadcast.2268 = f32[8,64]{1,0} broadcast(param_2.1990), dimensions={0}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=695}
  param_11.477 = f32[8]{0} parameter(11)
  broadcast.4671 = f32[8,64]{1,0} broadcast(param_11.477), dimensions={0}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=339}
  param_7.837 = f32[8,64]{1,0} parameter(7)
  param_10.551 = f32[64]{0} parameter(10)
  constant.4695 = f32[] constant(0.180336878)
  broadcast.4670 = f32[64]{0} broadcast(constant.4695), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._scale_query/per_dim_scale/mul" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=403}
  multiply.2681 = f32[64]{0} multiply(param_10.551, broadcast.4670), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._scale_query/per_dim_scale/mul" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=403}
  param_8.793 = f32[8,64]{1,0} parameter(8)
  constant.4688 = s32[] constant(7)
  param_9.674 = s32[] parameter(9)
  subtract.1044 = s32[] subtract(constant.4688, param_9.674), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  constant.4685 = s32[] constant(0)
  compare.1733 = pred[] compare(subtract.1044, constant.4685), direction=LT, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/lt" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  constant.4686 = s32[] constant(15)
  subtract.1043 = s32[] subtract(constant.4686, param_9.674), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/add" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  select.2036 = s32[] select(compare.1733, subtract.1043, subtract.1044), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/select_n" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  dynamic-slice.287 = f32[1,64]{1,0} dynamic-slice(param_8.793, select.2036, constant.4685), dynamic_slice_sizes={1,64}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/dynamic_slice[slice_sizes=(1, 64)]" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  bitcast.8122 = f32[64]{0} bitcast(dynamic-slice.287)
  constant.1798 = f32[] constant(inf)
  broadcast.4669 = f32[64]{0} broadcast(constant.1798), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._scale_query/per_dim_scale/jit(softplus)/eq" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=403}
  compare.1732 = pred[64]{0} compare(bitcast.8122, broadcast.4669), direction=EQ, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._scale_query/per_dim_scale/jit(softplus)/eq" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=403}
  constant.1802 = f32[] constant(0)
  broadcast.4668 = f32[64]{0} broadcast(constant.1802), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._scale_query/per_dim_scale/jit(softplus)/jit(logaddexp)/max" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=403}
  select.2035 = f32[64]{0} select(compare.1732, broadcast.4668, bitcast.8122), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._scale_query/per_dim_scale/jit(softplus)/select_n" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=403}
  compare.1730 = pred[64]{0} compare(bitcast.8122, bitcast.8122), direction=NE, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._scale_query/per_dim_scale/jit(softplus)/jit(logaddexp)/ne" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=403}
  maximum.95 = f32[64]{0} maximum(bitcast.8122, broadcast.4668), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._scale_query/per_dim_scale/jit(softplus)/jit(logaddexp)/max" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=403}
  abs.46 = f32[64]{0} abs(bitcast.8122), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._scale_query/per_dim_scale/jit(softplus)/jit(logaddexp)/abs" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=403}
  negate.162 = f32[64]{0} negate(abs.46), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._scale_query/per_dim_scale/jit(softplus)/jit(logaddexp)/neg" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=403}
  exponential.102 = f32[64]{0} exponential(negate.162), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._scale_query/per_dim_scale/jit(softplus)/jit(logaddexp)/exp" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=403}
  log-plus-one.46 = f32[64]{0} log-plus-one(exponential.102), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._scale_query/per_dim_scale/jit(softplus)/jit(logaddexp)/log1p" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=403}
  add.1487 = f32[64]{0} add(maximum.95, log-plus-one.46), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._scale_query/per_dim_scale/jit(softplus)/jit(logaddexp)/add" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=403}
  select.2033 = f32[64]{0} select(compare.1730, bitcast.8122, add.1487), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._scale_query/per_dim_scale/jit(softplus)/jit(logaddexp)/select_n" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=403}
  compare.1729 = pred[64]{0} compare(select.2033, broadcast.4669), direction=EQ, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._scale_query/per_dim_scale/jit(softplus)/eq" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=403}
  select.2032 = f32[64]{0} select(compare.1729, broadcast.4668, select.2033), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._scale_query/per_dim_scale/jit(softplus)/select_n" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=403}
  subtract.1040 = f32[64]{0} subtract(select.2035, select.2032), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._scale_query/per_dim_scale/jit(softplus)/sub" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=403}
  exponential.101 = f32[64]{0} exponential(subtract.1040), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._scale_query/per_dim_scale/jit(softplus)/exp" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=403}
  multiply.2680 = f32[64]{0} multiply(multiply.2681, exponential.101), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._scale_query/per_dim_scale/jit(softplus)/mul" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=403}
  bitcast.8120 = f32[1,64]{1,0} bitcast(multiply.2680)
  dynamic-update-slice.319 = f32[8,64]{1,0} dynamic-update-slice(param_7.837, bitcast.8120, select.2036, constant.4685), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  param_6.1160 = f32[] parameter(6)
  broadcast.4666 = f32[8,64]{1,0} broadcast(param_6.1160), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/paxml/paxml/learners.py" source_line=266}
  multiply.2679 = f32[8,64]{1,0} multiply(dynamic-update-slice.319, broadcast.4666), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/paxml/paxml/learners.py" source_line=266}
  compare.1728 = pred[8,64]{1,0} compare(multiply.2679, multiply.2679), direction=NE, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/jit(isnan)/ne" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  constant.1797 = f32[] constant(nan)
  broadcast.4665 = f32[8,64]{1,0} broadcast(constant.1797), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/jit(_where)/broadcast_in_dim[shape=(8, 64) broadcast_dimensions=(1,)]" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  select.2031 = f32[8,64]{1,0} select(compare.1728, broadcast.4665, multiply.2679), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/jit(_where)/select_n" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  broadcast.4664 = f32[8,64]{1,0} broadcast(constant.1798), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/eq" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  compare.1727 = pred[8,64]{1,0} compare(select.2031, broadcast.4664), direction=EQ, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/eq" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  select.2030 = f32[8,64]{1,0} select(compare.1727, broadcast.4665, select.2031), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/jit(_where)/select_n" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  constant.1799 = f32[] constant(-inf)
  broadcast.4663 = f32[8,64]{1,0} broadcast(constant.1799), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/eq" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  compare.1726 = pred[8,64]{1,0} compare(select.2030, broadcast.4663), direction=EQ, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/eq" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  select.2029 = f32[8,64]{1,0} select(compare.1726, broadcast.4665, select.2030), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/jit(_where)/select_n" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  multiply.2678 = f32[8,64]{1,0} multiply(broadcast.4671, select.2029), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=339}
  param_5.1476 = f32[8]{0} parameter(5)
  broadcast.4662 = f32[8,64]{1,0} broadcast(param_5.1476), dimensions={0}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=339}
  param_4.1669 = f32[8,64]{1,0} parameter(4)
  multiply.2677 = f32[8,64]{1,0} multiply(broadcast.4662, param_4.1669), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=339}
  add.1486 = f32[8,64]{1,0} add(multiply.2678, multiply.2677), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/add" source_file="/pax/praxis/praxis/optimizers.py" source_line=339}
  param_14.143 = f32[8]{0} parameter(14)
  broadcast.4795 = f32[8,64]{1,0} broadcast(param_14.143), dimensions={0}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=340}
  multiply.2746 = f32[8,64]{1,0} multiply(select.2029, select.2029), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=340}
  multiply.2745 = f32[8,64]{1,0} multiply(broadcast.4795, multiply.2746), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=340}
  param_13.205 = f32[8]{0} parameter(13)
  broadcast.4786 = f32[8,64]{1,0} broadcast(param_13.205), dimensions={0}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=340}
  param_12.376 = f32[8,64]{1,0} parameter(12)
  multiply.2744 = f32[8,64]{1,0} multiply(broadcast.4786, param_12.376), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=340}
  add.1516 = f32[8,64]{1,0} add(multiply.2745, multiply.2744), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/add" source_file="/pax/praxis/praxis/optimizers.py" source_line=340}
  sqrt.132 = f32[8,64]{1,0} sqrt(add.1516), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/sqrt" source_file="/pax/praxis/praxis/optimizers.py" source_line=684}
  constant.4870 = f32[] constant(1e-06)
  broadcast.4785 = f32[8,64]{1,0} broadcast(constant.4870), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/add" source_file="/pax/praxis/praxis/optimizers.py" source_line=684}
  add.1515 = f32[8,64]{1,0} add(sqrt.132, broadcast.4785), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/add" source_file="/pax/praxis/praxis/optimizers.py" source_line=684}
  param_1.2215 = f32[8]{0} parameter(1)
  constant.1657 = f32[] constant(0.015625)
  broadcast.2267 = f32[8]{0} broadcast(constant.1657), dimensions={}
  multiply.1406 = f32[8]{0} multiply(param_1.2215, broadcast.2267), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/div" source_file="/pax/praxis/praxis/optimizers.py" source_line=2066}
  sqrt.64 = f32[8]{0} sqrt(multiply.1406), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/sqrt" source_file="/pax/praxis/praxis/optimizers.py" source_line=2080}
  compare.533 = pred[8]{0} compare(sqrt.64, sqrt.64), direction=NE, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/jit(isnan)/ne" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  broadcast.2272 = f32[8]{0} broadcast(constant.1797), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/jit(_where)/broadcast_in_dim[shape=(8,) broadcast_dimensions=()]" source_file="/usr/local/lib/python3.10/dist-packages/optax/_src/schedule.py" source_line=399}
  select.817 = f32[8]{0} select(compare.533, broadcast.2272, sqrt.64), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/jit(_where)/select_n" source_file="/usr/local/lib/python3.10/dist-packages/optax/_src/schedule.py" source_line=399}
  broadcast.2271 = f32[8]{0} broadcast(constant.1798), dimensions={}
  compare.532 = pred[8]{0} compare(select.817, broadcast.2271), direction=EQ, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/eq" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  select.816 = f32[8]{0} select(compare.532, broadcast.2272, select.817), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/jit(_where)/select_n" source_file="/usr/local/lib/python3.10/dist-packages/optax/_src/schedule.py" source_line=399}
  broadcast.2270 = f32[8]{0} broadcast(constant.1799), dimensions={}
  compare.531 = pred[8]{0} compare(select.816, broadcast.2270), direction=EQ, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/eq" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  select.815 = f32[8]{0} select(compare.531, broadcast.2272, select.816), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/jit(_where)/select_n" source_file="/usr/local/lib/python3.10/dist-packages/optax/_src/schedule.py" source_line=399}
  constant.1800 = f32[] constant(1)
  broadcast.2273 = f32[8]{0} broadcast(constant.1800), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(_where))/broadcast_in_dim[shape=(8,) broadcast_dimensions=()]" source_file="/pax/praxis/praxis/schedules.py" source_line=105}
  maximum.57 = f32[8]{0} maximum(select.815, broadcast.2273), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/max" source_file="/pax/praxis/praxis/optimizers.py" source_line=346}
  broadcast.2266 = f32[8,64]{1,0} broadcast(maximum.57), dimensions={0}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/div" source_file="/pax/praxis/praxis/optimizers.py" source_line=347}
  multiply.1404 = f32[8,64]{1,0} multiply(add.1515, broadcast.2266)
  divide.180 = f32[8,64]{1,0} divide(add.1486, multiply.1404), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/div" source_file="/pax/praxis/praxis/optimizers.py" source_line=347}
  constant.1801 = f32[] constant(0.001)
  broadcast.2265 = f32[8,64]{1,0} broadcast(constant.1801), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=691}
  multiply.1403 = f32[8,64]{1,0} multiply(param_0.259, broadcast.2265), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=691}
  add.906 = f32[8,64]{1,0} add(divide.180, multiply.1403), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/add" source_file="/pax/praxis/praxis/optimizers.py" source_line=691}
  multiply.1402 = f32[8,64]{1,0} multiply(broadcast.2268, add.906), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=695}
  broadcast.2264 = f32[8,64]{1,0} broadcast(constant.1802), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/broadcast_in_dim[shape=(8, 64) broadcast_dimensions=()]" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  select.814 = f32[8,64]{1,0} select(broadcast.2269, multiply.1402, broadcast.2264), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(_where)/select_n" source_file="/pax/paxml/paxml/learners.py" source_line=340}
  add.905 = f32[8,64]{1,0} add(param_0.259, select.814), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/add" source_file="/pax/paxml/paxml/learners.py" source_line=408}
  select.769.clone.1 = f32[8,64]{1,0} select(broadcast.2269, add.1516, param_12.376), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(_where)/select_n" source_file="/pax/paxml/paxml/learners.py" source_line=340}
  select.782.clone.1 = f32[8,64]{1,0} select(broadcast.2269, add.1486, param_4.1669), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(_where)/select_n" source_file="/pax/paxml/paxml/learners.py" source_line=340}
  ROOT tuple.51 = (f32[8,64]{1,0}, f32[8,64]{1,0}, f32[8,64]{1,0}) tuple(add.905, select.769.clone.1, select.782.clone.1)
} // fused_computation.138

fused_computation.139 {
  param_7.835 = f32[8]{0} parameter(7)
  broadcast.4711 = f32[8,64]{1,0} broadcast(param_7.835), dimensions={0}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=339}
  param_3.1953 = f32[8,64]{1,0} parameter(3)
  param_6.1158 = f32[64]{0} parameter(6)
  constant.4757 = f32[] constant(0.180336878)
  broadcast.4710 = f32[64]{0} broadcast(constant.4757), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._scale_query/per_dim_scale/mul" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=403}
  multiply.2701 = f32[64]{0} multiply(param_6.1158, broadcast.4710), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._scale_query/per_dim_scale/mul" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=403}
  param_4.1667 = f32[8,64]{1,0} parameter(4)
  constant.4750 = s32[] constant(7)
  param_5.1474 = s32[] parameter(5)
  subtract.1064 = s32[] subtract(constant.4750, param_5.1474), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  constant.4747 = s32[] constant(0)
  compare.1765 = pred[] compare(subtract.1064, constant.4747), direction=LT, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/lt" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  constant.4748 = s32[] constant(15)
  subtract.1063 = s32[] subtract(constant.4748, param_5.1474), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/add" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  select.2068 = s32[] select(compare.1765, subtract.1063, subtract.1064), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/select_n" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  dynamic-slice.295 = f32[1,64]{1,0} dynamic-slice(param_4.1667, select.2068, constant.4747), dynamic_slice_sizes={1,64}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/dynamic_slice[slice_sizes=(1, 64)]" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  bitcast.8134 = f32[64]{0} bitcast(dynamic-slice.295)
  constant.4744 = f32[] constant(inf)
  broadcast.4709 = f32[64]{0} broadcast(constant.4744), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._scale_query/per_dim_scale/jit(softplus)/eq" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=403}
  compare.1764 = pred[64]{0} compare(bitcast.8134, broadcast.4709), direction=EQ, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._scale_query/per_dim_scale/jit(softplus)/eq" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=403}
  constant.1803 = f32[] constant(0)
  broadcast.4708 = f32[64]{0} broadcast(constant.1803), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._scale_query/per_dim_scale/jit(softplus)/jit(logaddexp)/max" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=403}
  select.2067 = f32[64]{0} select(compare.1764, broadcast.4708, bitcast.8134), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._scale_query/per_dim_scale/jit(softplus)/select_n" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=403}
  compare.1762 = pred[64]{0} compare(bitcast.8134, bitcast.8134), direction=NE, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._scale_query/per_dim_scale/jit(softplus)/jit(logaddexp)/ne" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=403}
  maximum.99 = f32[64]{0} maximum(bitcast.8134, broadcast.4708), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._scale_query/per_dim_scale/jit(softplus)/jit(logaddexp)/max" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=403}
  abs.50 = f32[64]{0} abs(bitcast.8134), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._scale_query/per_dim_scale/jit(softplus)/jit(logaddexp)/abs" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=403}
  negate.166 = f32[64]{0} negate(abs.50), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._scale_query/per_dim_scale/jit(softplus)/jit(logaddexp)/neg" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=403}
  exponential.110 = f32[64]{0} exponential(negate.166), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._scale_query/per_dim_scale/jit(softplus)/jit(logaddexp)/exp" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=403}
  log-plus-one.50 = f32[64]{0} log-plus-one(exponential.110), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._scale_query/per_dim_scale/jit(softplus)/jit(logaddexp)/log1p" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=403}
  add.1496 = f32[64]{0} add(maximum.99, log-plus-one.50), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._scale_query/per_dim_scale/jit(softplus)/jit(logaddexp)/add" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=403}
  select.2065 = f32[64]{0} select(compare.1762, bitcast.8134, add.1496), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._scale_query/per_dim_scale/jit(softplus)/jit(logaddexp)/select_n" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=403}
  compare.1761 = pred[64]{0} compare(select.2065, broadcast.4709), direction=EQ, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._scale_query/per_dim_scale/jit(softplus)/eq" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=403}
  select.2064 = f32[64]{0} select(compare.1761, broadcast.4708, select.2065), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._scale_query/per_dim_scale/jit(softplus)/select_n" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=403}
  subtract.1060 = f32[64]{0} subtract(select.2067, select.2064), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._scale_query/per_dim_scale/jit(softplus)/sub" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=403}
  exponential.109 = f32[64]{0} exponential(subtract.1060), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._scale_query/per_dim_scale/jit(softplus)/exp" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=403}
  multiply.2700 = f32[64]{0} multiply(multiply.2701, exponential.109), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._scale_query/per_dim_scale/jit(softplus)/mul" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=403}
  bitcast.8132 = f32[1,64]{1,0} bitcast(multiply.2700)
  dynamic-update-slice.323 = f32[8,64]{1,0} dynamic-update-slice(param_3.1953, bitcast.8132, select.2068, constant.4747), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  param_2.1988 = f32[] parameter(2)
  broadcast.4706 = f32[8,64]{1,0} broadcast(param_2.1988), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/paxml/paxml/learners.py" source_line=266}
  multiply.2699 = f32[8,64]{1,0} multiply(dynamic-update-slice.323, broadcast.4706), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/paxml/paxml/learners.py" source_line=266}
  compare.1760 = pred[8,64]{1,0} compare(multiply.2699, multiply.2699), direction=NE, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/jit(isnan)/ne" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  constant.4745 = f32[] constant(nan)
  broadcast.4705 = f32[8,64]{1,0} broadcast(constant.4745), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/jit(_where)/broadcast_in_dim[shape=(8, 64) broadcast_dimensions=(1,)]" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  select.2063 = f32[8,64]{1,0} select(compare.1760, broadcast.4705, multiply.2699), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/jit(_where)/select_n" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  broadcast.4704 = f32[8,64]{1,0} broadcast(constant.4744), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/eq" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  compare.1759 = pred[8,64]{1,0} compare(select.2063, broadcast.4704), direction=EQ, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/eq" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  select.2062 = f32[8,64]{1,0} select(compare.1759, broadcast.4705, select.2063), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/jit(_where)/select_n" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  constant.4743 = f32[] constant(-inf)
  broadcast.4703 = f32[8,64]{1,0} broadcast(constant.4743), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/eq" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  compare.1758 = pred[8,64]{1,0} compare(select.2062, broadcast.4703), direction=EQ, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/eq" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  select.2061 = f32[8,64]{1,0} select(compare.1758, broadcast.4705, select.2062), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/jit(_where)/select_n" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  multiply.2698 = f32[8,64]{1,0} multiply(broadcast.4711, select.2061), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=339}
  param_1.2213 = f32[8]{0} parameter(1)
  broadcast.4702 = f32[8,64]{1,0} broadcast(param_1.2213), dimensions={0}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=339}
  param_0.1624 = f32[8,64]{1,0} parameter(0)
  multiply.2697 = f32[8,64]{1,0} multiply(broadcast.4702, param_0.1624), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=339}
  add.1495 = f32[8,64]{1,0} add(multiply.2698, multiply.2697), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/add" source_file="/pax/praxis/praxis/optimizers.py" source_line=339}
  param_10.550 = f32[8]{0} parameter(10)
  broadcast.4773 = f32[8,64]{1,0} broadcast(param_10.550), dimensions={0}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=340}
  multiply.2734 = f32[8,64]{1,0} multiply(select.2061, select.2061), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=340}
  multiply.2733 = f32[8,64]{1,0} multiply(broadcast.4773, multiply.2734), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=340}
  param_9.673 = f32[8]{0} parameter(9)
  broadcast.4764 = f32[8,64]{1,0} broadcast(param_9.673), dimensions={0}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=340}
  param_8.792 = f32[8,64]{1,0} parameter(8)
  multiply.2732 = f32[8,64]{1,0} multiply(broadcast.4764, param_8.792), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=340}
  add.1510 = f32[8,64]{1,0} add(multiply.2733, multiply.2732), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/add" source_file="/pax/praxis/praxis/optimizers.py" source_line=340}
  sqrt.130 = f32[8,64]{1,0} sqrt(add.1510), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/sqrt" source_file="/pax/praxis/praxis/optimizers.py" source_line=684}
  constant.4837 = f32[] constant(1e-06)
  broadcast.4763 = f32[8,64]{1,0} broadcast(constant.4837), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/add" source_file="/pax/praxis/praxis/optimizers.py" source_line=684}
  add.1509 = f32[8,64]{1,0} add(sqrt.130, broadcast.4763), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/add" source_file="/pax/praxis/praxis/optimizers.py" source_line=684}
  divide.181 = f32[8,64]{1,0} divide(add.1495, add.1509), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/div" source_file="/pax/praxis/praxis/optimizers.py" source_line=684}
  multiply.1407 = f32[8,64]{1,0} multiply(divide.181, divide.181), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=2078}
  ROOT reduce.332 = f32[8]{0} reduce(multiply.1407, constant.1803), dimensions={1}, to_apply=region_15.791, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/reduce_sum[axes=(1,)]" source_file="/pax/praxis/praxis/optimizers.py" source_line=2066}
} // fused_computation.139

fused_computation.144 {
  param_0.271 = f32[8,3,1024,128,64]{4,3,2,1,0} parameter(0)
  param_4.1565 = f32[] parameter(4)
  is-finite.43 = pred[] is-finite(param_4.1565), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(isfinite)/is_finite" source_file="/pax/paxml/paxml/learners.py" source_line=256}
  broadcast.2288 = pred[8,3,1024,128,64]{4,3,2,1,0} broadcast(is-finite.43), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(_where)/broadcast_in_dim[shape=(8, 3, 8192, 128, 64) broadcast_dimensions=()]" source_file="/pax/paxml/paxml/learners.py" source_line=340}
  param_3.1881 = f32[8]{0} parameter(3)
  broadcast.2287 = f32[8,3,1024,128,64]{4,3,2,1,0} broadcast(param_3.1881), dimensions={0}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=695}
  param_10.673 = f32[8]{0} parameter(10)
  broadcast.4571 = f32[8,3,1024,128,64]{4,3,2,1,0} broadcast(param_10.673), dimensions={0}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=339}
  param_11.625 = f32[8,3,1024,128,64]{4,3,2,1,0} parameter(11)
  param_13.328 = f32[3,128,64,1024]{2,1,0,3} parameter(13)
  bitcast.8186 = f32[1,1024,3,128,64]{4,3,2,1,0} bitcast(param_13.328)
  transpose.356 = f32[1,3,1024,128,64]{4,3,2,1,0} transpose(bitcast.8186), dimensions={0,2,1,3,4}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/broadcast_in_dim[shape=(1, 3, 8192, 128, 64) broadcast_dimensions=(1, 2, 3, 4)]" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  param_12.533 = s32[] parameter(12)
  constant.4539 = s32[] constant(0)
  dynamic-update-slice.359 = f32[8,3,1024,128,64]{4,3,2,1,0} dynamic-update-slice(param_11.625, transpose.356, param_12.533, constant.4539, constant.4539, /*index=5*/constant.4539, constant.4539)
  param_9.794 = f32[3,128,64,1024]{2,1,0,3} parameter(9)
  bitcast.8096 = f32[1,1024,3,128,64]{4,3,2,1,0} bitcast(param_9.794)
  transpose.340 = f32[1,3,1024,128,64]{4,3,2,1,0} transpose(bitcast.8096), dimensions={0,2,1,3,4}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/broadcast_in_dim[shape=(1, 3, 8192, 128, 64) broadcast_dimensions=(1, 2, 3, 4)]" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  constant.4542 = s32[] constant(7)
  param_8.912 = s32[] parameter(8)
  subtract.998 = s32[] subtract(constant.4542, param_8.912), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  compare.1653 = pred[] compare(subtract.998, constant.4539), direction=LT, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/lt" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  constant.4540 = s32[] constant(15)
  subtract.997 = s32[] subtract(constant.4540, param_8.912), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/add" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  select.1954 = s32[] select(compare.1653, subtract.997, subtract.998), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/select_n" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  dynamic-update-slice.305 = f32[8,3,1024,128,64]{4,3,2,1,0} dynamic-update-slice(dynamic-update-slice.359, transpose.340, select.1954, constant.4539, constant.4539, /*index=5*/constant.4539, constant.4539), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  param_7.761 = f32[] parameter(7)
  broadcast.4570 = f32[8,3,1024,128,64]{4,3,2,1,0} broadcast(param_7.761), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/paxml/paxml/learners.py" source_line=266}
  multiply.2631 = f32[8,3,1024,128,64]{4,3,2,1,0} multiply(dynamic-update-slice.305, broadcast.4570), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/paxml/paxml/learners.py" source_line=266}
  compare.1651 = pred[8,3,1024,128,64]{4,3,2,1,0} compare(multiply.2631, multiply.2631), direction=NE, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/jit(isnan)/ne" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  constant.1808 = f32[] constant(nan)
  broadcast.4569 = f32[8,3,1024,128,64]{4,3,2,1,0} broadcast(constant.1808), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/jit(_where)/broadcast_in_dim[shape=(8, 3, 8192, 128, 64) broadcast_dimensions=(1, 2, 3, 4)]" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  select.1952 = f32[8,3,1024,128,64]{4,3,2,1,0} select(compare.1651, broadcast.4569, multiply.2631), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/jit(_where)/select_n" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  constant.1809 = f32[] constant(inf)
  broadcast.4568 = f32[8,3,1024,128,64]{4,3,2,1,0} broadcast(constant.1809), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/eq" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  compare.1650 = pred[8,3,1024,128,64]{4,3,2,1,0} compare(select.1952, broadcast.4568), direction=EQ, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/eq" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  select.1951 = f32[8,3,1024,128,64]{4,3,2,1,0} select(compare.1650, broadcast.4569, select.1952), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/jit(_where)/select_n" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  constant.1810 = f32[] constant(-inf)
  broadcast.4567 = f32[8,3,1024,128,64]{4,3,2,1,0} broadcast(constant.1810), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/eq" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  compare.1649 = pred[8,3,1024,128,64]{4,3,2,1,0} compare(select.1951, broadcast.4567), direction=EQ, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/eq" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  select.1950 = f32[8,3,1024,128,64]{4,3,2,1,0} select(compare.1649, broadcast.4569, select.1951), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/jit(_where)/select_n" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  multiply.2630 = f32[8,3,1024,128,64]{4,3,2,1,0} multiply(broadcast.4571, select.1950), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=339}
  param_6.1048 = f32[8]{0} parameter(6)
  broadcast.4566 = f32[8,3,1024,128,64]{4,3,2,1,0} broadcast(param_6.1048), dimensions={0}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=339}
  param_5.1353 = f32[8,3,1024,128,64]{4,3,2,1,0} parameter(5)
  multiply.2629 = f32[8,3,1024,128,64]{4,3,2,1,0} multiply(broadcast.4566, param_5.1353), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=339}
  add.1471 = f32[8,3,1024,128,64]{4,3,2,1,0} add(multiply.2630, multiply.2629), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/add" source_file="/pax/praxis/praxis/optimizers.py" source_line=339}
  param_1.2183 = f32[8,3,1024,128,64]{4,3,2,1,0} parameter(1)
  param_2.1948 = f32[8]{0} parameter(2)
  constant.1658 = f32[] constant(4.96705388e-09)
  broadcast.2286 = f32[8]{0} broadcast(constant.1658), dimensions={}
  multiply.1425 = f32[8]{0} multiply(param_2.1948, broadcast.2286), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/div" source_file="/pax/praxis/praxis/optimizers.py" source_line=2064}
  sqrt.66 = f32[8]{0} sqrt(multiply.1425), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/sqrt" source_file="/pax/praxis/praxis/optimizers.py" source_line=2080}
  compare.539 = pred[8]{0} compare(sqrt.66, sqrt.66), direction=NE, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/jit(isnan)/ne" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  broadcast.2291 = f32[8]{0} broadcast(constant.1808), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/jit(_where)/broadcast_in_dim[shape=(8,) broadcast_dimensions=()]" source_file="/usr/local/lib/python3.10/dist-packages/optax/_src/schedule.py" source_line=399}
  select.824 = f32[8]{0} select(compare.539, broadcast.2291, sqrt.66), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/jit(_where)/select_n" source_file="/usr/local/lib/python3.10/dist-packages/optax/_src/schedule.py" source_line=399}
  broadcast.2290 = f32[8]{0} broadcast(constant.1809), dimensions={}
  compare.538 = pred[8]{0} compare(select.824, broadcast.2290), direction=EQ, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/eq" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  select.823 = f32[8]{0} select(compare.538, broadcast.2291, select.824), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/jit(_where)/select_n" source_file="/usr/local/lib/python3.10/dist-packages/optax/_src/schedule.py" source_line=399}
  broadcast.2289 = f32[8]{0} broadcast(constant.1810), dimensions={}
  compare.537 = pred[8]{0} compare(select.823, broadcast.2289), direction=EQ, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/eq" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  select.822 = f32[8]{0} select(compare.537, broadcast.2291, select.823), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/jit(_where)/select_n" source_file="/usr/local/lib/python3.10/dist-packages/optax/_src/schedule.py" source_line=399}
  constant.1811 = f32[] constant(1)
  broadcast.2292 = f32[8]{0} broadcast(constant.1811), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(_where))/broadcast_in_dim[shape=(8,) broadcast_dimensions=()]" source_file="/pax/praxis/praxis/schedules.py" source_line=105}
  maximum.58 = f32[8]{0} maximum(select.822, broadcast.2292), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/max" source_file="/pax/praxis/praxis/optimizers.py" source_line=346}
  broadcast.2285 = f32[8,3,1024,128,64]{4,3,2,1,0} broadcast(maximum.58), dimensions={0}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/div" source_file="/pax/praxis/praxis/optimizers.py" source_line=347}
  multiply.1421 = f32[8,3,1024,128,64]{4,3,2,1,0} multiply(param_1.2183, broadcast.2285)
  divide.182 = f32[8,3,1024,128,64]{4,3,2,1,0} divide(add.1471, multiply.1421), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/div" source_file="/pax/praxis/praxis/optimizers.py" source_line=347}
  constant.1812 = f32[] constant(0.001)
  broadcast.2284 = f32[8,3,1024,128,64]{4,3,2,1,0} broadcast(constant.1812), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=691}
  multiply.1415 = f32[8,3,1024,128,64]{4,3,2,1,0} multiply(param_0.271, broadcast.2284), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=691}
  add.912 = f32[8,3,1024,128,64]{4,3,2,1,0} add(divide.182, multiply.1415), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/add" source_file="/pax/praxis/praxis/optimizers.py" source_line=691}
  multiply.1414 = f32[8,3,1024,128,64]{4,3,2,1,0} multiply(broadcast.2287, add.912), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=695}
  constant.1813 = f32[] constant(0)
  broadcast.2283 = f32[8,3,1024,128,64]{4,3,2,1,0} broadcast(constant.1813), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/broadcast_in_dim[shape=(8, 3, 8192, 128, 64) broadcast_dimensions=()]" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  select.821 = f32[8,3,1024,128,64]{4,3,2,1,0} select(broadcast.2288, multiply.1414, broadcast.2283), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(_where)/select_n" source_file="/pax/paxml/paxml/learners.py" source_line=340}
  ROOT add.910 = f32[8,3,1024,128,64]{4,3,2,1,0} add(param_0.271, select.821), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/add" source_file="/pax/paxml/paxml/learners.py" source_line=408}
} // fused_computation.144

fused_computation.145 {
  param_6.1359 = f32[8]{0} parameter(6)
  broadcast.4595 = f32[8,3,1024,128,64]{4,3,2,1,0} broadcast(param_6.1359), dimensions={0}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=339}
  param_8.909 = f32[8,3,1024,128,64]{4,3,2,1,0} parameter(8)
  param_10.671 = f32[3,128,64,1024]{2,1,0,3} parameter(10)
  bitcast.8182 = f32[1,1024,3,128,64]{4,3,2,1,0} bitcast(param_10.671)
  transpose.352 = f32[1,3,1024,128,64]{4,3,2,1,0} transpose(bitcast.8182), dimensions={0,2,1,3,4}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/broadcast_in_dim[shape=(1, 3, 8192, 128, 64) broadcast_dimensions=(1, 2, 3, 4)]" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  param_9.790 = s32[] parameter(9)
  constant.4569 = s32[] constant(0)
  dynamic-update-slice.355 = f32[8,3,1024,128,64]{4,3,2,1,0} dynamic-update-slice(param_8.909, transpose.352, param_9.790, constant.4569, constant.4569, /*index=5*/constant.4569, constant.4569)
  param_5.1714 = f32[3,128,64,1024]{2,1,0,3} parameter(5)
  bitcast.8100 = f32[1,1024,3,128,64]{4,3,2,1,0} bitcast(param_5.1714)
  transpose.344 = f32[1,3,1024,128,64]{4,3,2,1,0} transpose(bitcast.8100), dimensions={0,2,1,3,4}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/broadcast_in_dim[shape=(1, 3, 8192, 128, 64) broadcast_dimensions=(1, 2, 3, 4)]" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  constant.4572 = s32[] constant(7)
  param_4.1959 = s32[] parameter(4)
  subtract.1006 = s32[] subtract(constant.4572, param_4.1959), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  compare.1669 = pred[] compare(subtract.1006, constant.4569), direction=LT, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/lt" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  constant.4570 = s32[] constant(15)
  subtract.1005 = s32[] subtract(constant.4570, param_4.1959), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/add" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  select.1972 = s32[] select(compare.1669, subtract.1005, subtract.1006), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/select_n" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  dynamic-update-slice.309 = f32[8,3,1024,128,64]{4,3,2,1,0} dynamic-update-slice(dynamic-update-slice.355, transpose.344, select.1972, constant.4569, constant.4569, /*index=5*/constant.4569, constant.4569), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  param_3.1892 = f32[] parameter(3)
  broadcast.4594 = f32[8,3,1024,128,64]{4,3,2,1,0} broadcast(param_3.1892), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/paxml/paxml/learners.py" source_line=266}
  multiply.2643 = f32[8,3,1024,128,64]{4,3,2,1,0} multiply(dynamic-update-slice.309, broadcast.4594), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/paxml/paxml/learners.py" source_line=266}
  compare.1668 = pred[8,3,1024,128,64]{4,3,2,1,0} compare(multiply.2643, multiply.2643), direction=NE, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/jit(isnan)/ne" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  constant.4568 = f32[] constant(nan)
  broadcast.4593 = f32[8,3,1024,128,64]{4,3,2,1,0} broadcast(constant.4568), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/jit(_where)/broadcast_in_dim[shape=(8, 3, 8192, 128, 64) broadcast_dimensions=(1, 2, 3, 4)]" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  select.1971 = f32[8,3,1024,128,64]{4,3,2,1,0} select(compare.1668, broadcast.4593, multiply.2643), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/jit(_where)/select_n" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  constant.4567 = f32[] constant(inf)
  broadcast.4592 = f32[8,3,1024,128,64]{4,3,2,1,0} broadcast(constant.4567), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/eq" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  compare.1667 = pred[8,3,1024,128,64]{4,3,2,1,0} compare(select.1971, broadcast.4592), direction=EQ, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/eq" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  select.1970 = f32[8,3,1024,128,64]{4,3,2,1,0} select(compare.1667, broadcast.4593, select.1971), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/jit(_where)/select_n" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  constant.4566 = f32[] constant(-inf)
  broadcast.4591 = f32[8,3,1024,128,64]{4,3,2,1,0} broadcast(constant.4566), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/eq" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  compare.1666 = pred[8,3,1024,128,64]{4,3,2,1,0} compare(select.1970, broadcast.4591), direction=EQ, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/eq" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  select.1969 = f32[8,3,1024,128,64]{4,3,2,1,0} select(compare.1666, broadcast.4593, select.1970), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/jit(_where)/select_n" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  multiply.2642 = f32[8,3,1024,128,64]{4,3,2,1,0} multiply(broadcast.4595, select.1969), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=339}
  param_2.1956 = f32[8]{0} parameter(2)
  broadcast.4590 = f32[8,3,1024,128,64]{4,3,2,1,0} broadcast(param_2.1956), dimensions={0}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=339}
  param_1.2188 = f32[8,3,1024,128,64]{4,3,2,1,0} parameter(1)
  multiply.2641 = f32[8,3,1024,128,64]{4,3,2,1,0} multiply(broadcast.4590, param_1.2188), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=339}
  add.1475 = f32[8,3,1024,128,64]{4,3,2,1,0} add(multiply.2642, multiply.2641), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/add" source_file="/pax/praxis/praxis/optimizers.py" source_line=339}
  param_0.1605 = f32[8,3,1024,128,64]{4,3,2,1,0} parameter(0)
  divide.183 = f32[8,3,1024,128,64]{4,3,2,1,0} divide(add.1475, param_0.1605), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/div" source_file="/pax/praxis/praxis/optimizers.py" source_line=684}
  multiply.1427 = f32[8,3,1024,128,64]{4,3,2,1,0} multiply(divide.183, divide.183), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=2078}
  bitcast.7423 = f32[8,4096,6144]{2,1,0} bitcast(multiply.1427), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=2078}
  constant.1814 = f32[] constant(0)
  reduce.333 = f32[8,4096]{1,0} reduce(bitcast.7423, constant.1814), dimensions={2}, to_apply=region_15.791, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/reduce_sum[axes=(1, 2, 3)]" source_file="/pax/praxis/praxis/optimizers.py" source_line=2063}
  param_7.976 = f32[] parameter(7)
  is-finite.17.clone.1 = pred[] is-finite(param_7.976), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(isfinite)/is_finite" source_file="/pax/paxml/paxml/learners.py" source_line=256}
  broadcast.2221.clone.1 = pred[8,3,1024,128,64]{4,3,2,1,0} broadcast(is-finite.17.clone.1), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(_where)/broadcast_in_dim[shape=(8, 3, 8192, 128, 64) broadcast_dimensions=()]" source_file="/pax/paxml/paxml/learners.py" source_line=340}
  select.783.clone.1 = f32[8,3,1024,128,64]{4,3,2,1,0} select(broadcast.2221.clone.1, add.1475, param_1.2188), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(_where)/select_n" source_file="/pax/paxml/paxml/learners.py" source_line=340}
  ROOT tuple.52 = (f32[8,4096]{1,0}, f32[8,3,1024,128,64]{4,3,2,1,0}) tuple(reduce.333, select.783.clone.1)
} // fused_computation.145

fused_computation.146 {
  param_5.1715 = f32[8]{0} parameter(5)
  broadcast.4619 = f32[8,3,1024,128,64]{4,3,2,1,0} broadcast(param_5.1715), dimensions={0}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=340}
  param_7.977 = f32[8,3,1024,128,64]{4,3,2,1,0} parameter(7)
  param_9.793 = f32[3,128,64,1024]{2,1,0,3} parameter(9)
  bitcast.8184 = f32[1,1024,3,128,64]{4,3,2,1,0} bitcast(param_9.793)
  transpose.354 = f32[1,3,1024,128,64]{4,3,2,1,0} transpose(bitcast.8184), dimensions={0,2,1,3,4}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/broadcast_in_dim[shape=(1, 3, 8192, 128, 64) broadcast_dimensions=(1, 2, 3, 4)]" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  param_8.911 = s32[] parameter(8)
  constant.4599 = s32[] constant(0)
  dynamic-update-slice.357 = f32[8,3,1024,128,64]{4,3,2,1,0} dynamic-update-slice(param_7.977, transpose.354, param_8.911, constant.4599, constant.4599, /*index=5*/constant.4599, constant.4599)
  param_4.1960 = f32[3,128,64,1024]{2,1,0,3} parameter(4)
  bitcast.8104 = f32[1,1024,3,128,64]{4,3,2,1,0} bitcast(param_4.1960)
  transpose.348 = f32[1,3,1024,128,64]{4,3,2,1,0} transpose(bitcast.8104), dimensions={0,2,1,3,4}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/broadcast_in_dim[shape=(1, 3, 8192, 128, 64) broadcast_dimensions=(1, 2, 3, 4)]" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  constant.4602 = s32[] constant(7)
  param_3.2227 = s32[] parameter(3)
  subtract.1014 = s32[] subtract(constant.4602, param_3.2227), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  compare.1685 = pred[] compare(subtract.1014, constant.4599), direction=LT, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/lt" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  constant.4600 = s32[] constant(15)
  subtract.1013 = s32[] subtract(constant.4600, param_3.2227), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/add" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  select.1988 = s32[] select(compare.1685, subtract.1013, subtract.1014), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/select_n" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  dynamic-update-slice.313 = f32[8,3,1024,128,64]{4,3,2,1,0} dynamic-update-slice(dynamic-update-slice.357, transpose.348, select.1988, constant.4599, constant.4599, /*index=5*/constant.4599, constant.4599), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  param_2.1964 = f32[] parameter(2)
  broadcast.4618 = f32[8,3,1024,128,64]{4,3,2,1,0} broadcast(param_2.1964), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/paxml/paxml/learners.py" source_line=266}
  multiply.2659 = f32[8,3,1024,128,64]{4,3,2,1,0} multiply(dynamic-update-slice.313, broadcast.4618), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/paxml/paxml/learners.py" source_line=266}
  compare.1684 = pred[8,3,1024,128,64]{4,3,2,1,0} compare(multiply.2659, multiply.2659), direction=NE, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/jit(isnan)/ne" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  constant.4598 = f32[] constant(nan)
  broadcast.4617 = f32[8,3,1024,128,64]{4,3,2,1,0} broadcast(constant.4598), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/jit(_where)/broadcast_in_dim[shape=(8, 3, 8192, 128, 64) broadcast_dimensions=(1, 2, 3, 4)]" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  select.1987 = f32[8,3,1024,128,64]{4,3,2,1,0} select(compare.1684, broadcast.4617, multiply.2659), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/jit(_where)/select_n" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  constant.4597 = f32[] constant(inf)
  broadcast.4616 = f32[8,3,1024,128,64]{4,3,2,1,0} broadcast(constant.4597), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/eq" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  compare.1683 = pred[8,3,1024,128,64]{4,3,2,1,0} compare(select.1987, broadcast.4616), direction=EQ, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/eq" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  select.1986 = f32[8,3,1024,128,64]{4,3,2,1,0} select(compare.1683, broadcast.4617, select.1987), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/jit(_where)/select_n" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  constant.4596 = f32[] constant(-inf)
  broadcast.4615 = f32[8,3,1024,128,64]{4,3,2,1,0} broadcast(constant.4596), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/eq" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  compare.1682 = pred[8,3,1024,128,64]{4,3,2,1,0} compare(select.1986, broadcast.4615), direction=EQ, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/eq" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  select.1985 = f32[8,3,1024,128,64]{4,3,2,1,0} select(compare.1682, broadcast.4617, select.1986), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/jit(_where)/select_n" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  multiply.2658 = f32[8,3,1024,128,64]{4,3,2,1,0} multiply(select.1985, select.1985), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=340}
  multiply.2657 = f32[8,3,1024,128,64]{4,3,2,1,0} multiply(broadcast.4619, multiply.2658), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=340}
  param_1.2195 = f32[8]{0} parameter(1)
  broadcast.4614 = f32[8,3,1024,128,64]{4,3,2,1,0} broadcast(param_1.2195), dimensions={0}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=340}
  param_0.1610 = f32[8,3,1024,128,64]{4,3,2,1,0} parameter(0)
  multiply.2656 = f32[8,3,1024,128,64]{4,3,2,1,0} multiply(broadcast.4614, param_0.1610), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=340}
  add.1479 = f32[8,3,1024,128,64]{4,3,2,1,0} add(multiply.2657, multiply.2656), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/add" source_file="/pax/praxis/praxis/optimizers.py" source_line=340}
  sqrt.67 = f32[8,3,1024,128,64]{4,3,2,1,0} sqrt(add.1479), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/sqrt" source_file="/pax/praxis/praxis/optimizers.py" source_line=684}
  constant.1815 = f32[] constant(1e-06)
  broadcast.2293 = f32[8,3,1024,128,64]{4,3,2,1,0} broadcast(constant.1815), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/add" source_file="/pax/praxis/praxis/optimizers.py" source_line=684}
  add.913 = f32[8,3,1024,128,64]{4,3,2,1,0} add(sqrt.67, broadcast.2293), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/add" source_file="/pax/praxis/praxis/optimizers.py" source_line=684}
  param_6.1360 = f32[] parameter(6)
  is-finite.6.clone.1 = pred[] is-finite(param_6.1360), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(isfinite)/is_finite" source_file="/pax/paxml/paxml/learners.py" source_line=256}
  broadcast.2210.clone.1 = pred[8,3,1024,128,64]{4,3,2,1,0} broadcast(is-finite.6.clone.1), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(_where)/broadcast_in_dim[shape=(8, 3, 8192, 128, 64) broadcast_dimensions=()]" source_file="/pax/paxml/paxml/learners.py" source_line=340}
  select.770.clone.1 = f32[8,3,1024,128,64]{4,3,2,1,0} select(broadcast.2210.clone.1, add.1479, param_0.1610), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(_where)/select_n" source_file="/pax/paxml/paxml/learners.py" source_line=340}
  ROOT tuple.53 = (f32[8,3,1024,128,64]{4,3,2,1,0}, f32[8,3,1024,128,64]{4,3,2,1,0}) tuple(add.913, select.770.clone.1)
} // fused_computation.146

fused_computation.169 {
  param_6.843 = f32[8]{0} parameter(6)
  broadcast.4143 = f32[8,8192]{1,0} broadcast(param_6.843), dimensions={0}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=339}
  param_3.1722 = f32[8,8192]{1,0} parameter(3)
  param_5.1112 = f32[8192]{0} parameter(5)
  bitcast.8028 = f32[1,8192]{1,0} bitcast(param_5.1112)
  constant.4016 = s32[] constant(7)
  param_4.1354 = s32[] parameter(4)
  subtract.860 = s32[] subtract(constant.4016, param_4.1354), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  constant.4013 = s32[] constant(0)
  compare.1369 = pred[] compare(subtract.860, constant.4013), direction=LT, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/lt" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  constant.4014 = s32[] constant(15)
  subtract.859 = s32[] subtract(constant.4014, param_4.1354), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/add" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  select.1672 = s32[] select(compare.1369, subtract.859, subtract.860), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/select_n" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  dynamic-update-slice.237 = f32[8,8192]{1,0} dynamic-update-slice(param_3.1722, bitcast.8028, select.1672, constant.4013), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  param_2.1862 = f32[] parameter(2)
  broadcast.4142 = f32[8,8192]{1,0} broadcast(param_2.1862), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/paxml/paxml/learners.py" source_line=266}
  multiply.2427 = f32[8,8192]{1,0} multiply(dynamic-update-slice.237, broadcast.4142), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/paxml/paxml/learners.py" source_line=266}
  compare.1368 = pred[8,8192]{1,0} compare(multiply.2427, multiply.2427), direction=NE, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/jit(isnan)/ne" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  constant.4012 = f32[] constant(nan)
  broadcast.4141 = f32[8,8192]{1,0} broadcast(constant.4012), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/jit(_where)/broadcast_in_dim[shape=(8, 8192) broadcast_dimensions=(1,)]" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  select.1671 = f32[8,8192]{1,0} select(compare.1368, broadcast.4141, multiply.2427), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/jit(_where)/select_n" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  constant.4011 = f32[] constant(inf)
  broadcast.4140 = f32[8,8192]{1,0} broadcast(constant.4011), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/eq" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  compare.1367 = pred[8,8192]{1,0} compare(select.1671, broadcast.4140), direction=EQ, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/eq" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  select.1670 = f32[8,8192]{1,0} select(compare.1367, broadcast.4141, select.1671), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/jit(_where)/select_n" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  constant.4010 = f32[] constant(-inf)
  broadcast.4139 = f32[8,8192]{1,0} broadcast(constant.4010), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/eq" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  compare.1366 = pred[8,8192]{1,0} compare(select.1670, broadcast.4139), direction=EQ, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/eq" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  select.1669 = f32[8,8192]{1,0} select(compare.1366, broadcast.4141, select.1670), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/jit(_where)/select_n" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  multiply.2426 = f32[8,8192]{1,0} multiply(broadcast.4143, select.1669), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=339}
  param_1.2111 = f32[8]{0} parameter(1)
  broadcast.4137 = f32[8,8192]{1,0} broadcast(param_1.2111), dimensions={0}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=339}
  param_0.1552 = f32[8,8192]{1,0} parameter(0)
  multiply.2425 = f32[8,8192]{1,0} multiply(broadcast.4137, param_0.1552), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=339}
  add.1396 = f32[8,8192]{1,0} add(multiply.2426, multiply.2425), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/add" source_file="/pax/praxis/praxis/optimizers.py" source_line=339}
  param_9.478 = f32[8]{0} parameter(9)
  broadcast.4185 = f32[8,8192]{1,0} broadcast(param_9.478), dimensions={0}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=340}
  multiply.2450 = f32[8,8192]{1,0} multiply(select.1669, select.1669), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=340}
  multiply.2449 = f32[8,8192]{1,0} multiply(broadcast.4185, multiply.2450), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=340}
  param_8.561 = f32[8]{0} parameter(8)
  broadcast.4179 = f32[8,8192]{1,0} broadcast(param_8.561), dimensions={0}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=340}
  param_7.620 = f32[8,8192]{1,0} parameter(7)
  multiply.2448 = f32[8,8192]{1,0} multiply(broadcast.4179, param_7.620), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=340}
  add.1404 = f32[8,8192]{1,0} add(multiply.2449, multiply.2448), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/add" source_file="/pax/praxis/praxis/optimizers.py" source_line=340}
  sqrt.114 = f32[8,8192]{1,0} sqrt(add.1404), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/sqrt" source_file="/pax/praxis/praxis/optimizers.py" source_line=684}
  constant.4056 = f32[] constant(1e-06)
  broadcast.4178 = f32[8,8192]{1,0} broadcast(constant.4056), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/add" source_file="/pax/praxis/praxis/optimizers.py" source_line=684}
  add.1403 = f32[8,8192]{1,0} add(sqrt.114, broadcast.4178), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/add" source_file="/pax/praxis/praxis/optimizers.py" source_line=684}
  divide.191 = f32[8,8192]{1,0} divide(add.1396, add.1403), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/div" source_file="/pax/praxis/praxis/optimizers.py" source_line=684}
  multiply.1477 = f32[8,8192]{1,0} multiply(divide.191, divide.191), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=2078}
  constant.1864 = f32[] constant(0)
  reduce.337 = f32[8]{0} reduce(multiply.1477, constant.1864), dimensions={1}, to_apply=region_15.791, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/reduce_sum[axes=(1,)]" source_file="/pax/praxis/praxis/optimizers.py" source_line=2066}
  param_12.473 = f32[8,8192]{1,0} parameter(12)
  param_13.284 = f32[8192]{0} parameter(13)
  bitcast.8064.clone.1 = f32[1,8192]{1,0} bitcast(param_13.284)
  dynamic-update-slice.273.clone.1 = f32[8,8192]{1,0} dynamic-update-slice(param_12.473, bitcast.8064.clone.1, select.1672, constant.4013), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  multiply.2535.clone.1 = f32[8,8192]{1,0} multiply(dynamic-update-slice.273.clone.1, broadcast.4142), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/paxml/paxml/learners.py" source_line=266}
  compare.1512.clone.1 = pred[8,8192]{1,0} compare(multiply.2535.clone.1, multiply.2535.clone.1), direction=NE, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/jit(isnan)/ne" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  select.1815.clone.1 = f32[8,8192]{1,0} select(compare.1512.clone.1, broadcast.4141, multiply.2535.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/jit(_where)/select_n" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  compare.1511.clone.1 = pred[8,8192]{1,0} compare(select.1815.clone.1, broadcast.4140), direction=EQ, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/eq" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  select.1814.clone.1 = f32[8,8192]{1,0} select(compare.1511.clone.1, broadcast.4141, select.1815.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/jit(_where)/select_n" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  compare.1510.clone.1 = pred[8,8192]{1,0} compare(select.1814.clone.1, broadcast.4139), direction=EQ, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/eq" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  select.1813.clone.1 = f32[8,8192]{1,0} select(compare.1510.clone.1, broadcast.4141, select.1814.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/jit(_where)/select_n" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  multiply.2534.clone.1 = f32[8,8192]{1,0} multiply(broadcast.4143, select.1813.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=339}
  param_11.579 = f32[8,8192]{1,0} parameter(11)
  multiply.2533.clone.1 = f32[8,8192]{1,0} multiply(broadcast.4137, param_11.579), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=339}
  add.1435.clone.1 = f32[8,8192]{1,0} add(multiply.2534.clone.1, multiply.2533.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/add" source_file="/pax/praxis/praxis/optimizers.py" source_line=339}
  multiply.2558.clone.1 = f32[8,8192]{1,0} multiply(select.1813.clone.1, select.1813.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=340}
  multiply.2557.clone.1 = f32[8,8192]{1,0} multiply(broadcast.4185, multiply.2558.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=340}
  param_10.637 = f32[8,8192]{1,0} parameter(10)
  multiply.2556.clone.1 = f32[8,8192]{1,0} multiply(broadcast.4179, param_10.637), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=340}
  add.1443.clone.1 = f32[8,8192]{1,0} add(multiply.2557.clone.1, multiply.2556.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/add" source_file="/pax/praxis/praxis/optimizers.py" source_line=340}
  sqrt.122.clone.1 = f32[8,8192]{1,0} sqrt(add.1443.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/sqrt" source_file="/pax/praxis/praxis/optimizers.py" source_line=684}
  add.1442.clone.1 = f32[8,8192]{1,0} add(sqrt.122.clone.1, broadcast.4178), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/add" source_file="/pax/praxis/praxis/optimizers.py" source_line=684}
  divide.187.clone.1 = f32[8,8192]{1,0} divide(add.1435.clone.1, add.1442.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/div" source_file="/pax/praxis/praxis/optimizers.py" source_line=684}
  multiply.1454.clone.1 = f32[8,8192]{1,0} multiply(divide.187.clone.1, divide.187.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=2078}
  reduce.335.clone.1 = f32[8]{0} reduce(multiply.1454.clone.1, constant.1864), dimensions={1}, to_apply=region_15.791, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/reduce_sum[axes=(1,)]" source_file="/pax/praxis/praxis/optimizers.py" source_line=2066}
  param_16.268 = f32[8,8192]{1,0} parameter(16)
  param_17.247 = f32[8192]{0} parameter(17)
  bitcast.8082.clone.1 = f32[1,8192]{1,0} bitcast(param_17.247)
  dynamic-update-slice.291.clone.1 = f32[8,8192]{1,0} dynamic-update-slice(param_16.268, bitcast.8082.clone.1, select.1672, constant.4013), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  multiply.2589.clone.1 = f32[8,8192]{1,0} multiply(dynamic-update-slice.291.clone.1, broadcast.4142), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/paxml/paxml/learners.py" source_line=266}
  compare.1589.clone.1 = pred[8,8192]{1,0} compare(multiply.2589.clone.1, multiply.2589.clone.1), direction=NE, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/jit(isnan)/ne" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  select.1893.clone.1 = f32[8,8192]{1,0} select(compare.1589.clone.1, broadcast.4141, multiply.2589.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/jit(_where)/select_n" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  compare.1588.clone.1 = pred[8,8192]{1,0} compare(select.1893.clone.1, broadcast.4140), direction=EQ, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/eq" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  select.1892.clone.1 = f32[8,8192]{1,0} select(compare.1588.clone.1, broadcast.4141, select.1893.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/jit(_where)/select_n" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  compare.1586.clone.1 = pred[8,8192]{1,0} compare(select.1892.clone.1, broadcast.4139), direction=EQ, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/eq" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  select.1890.clone.1 = f32[8,8192]{1,0} select(compare.1586.clone.1, broadcast.4141, select.1892.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/jit(_where)/select_n" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  multiply.2588.clone.1 = f32[8,8192]{1,0} multiply(broadcast.4143, select.1890.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=339}
  param_15.239 = f32[8,8192]{1,0} parameter(15)
  multiply.2587.clone.1 = f32[8,8192]{1,0} multiply(broadcast.4137, param_15.239), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=339}
  add.1453.clone.1 = f32[8,8192]{1,0} add(multiply.2588.clone.1, multiply.2587.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/add" source_file="/pax/praxis/praxis/optimizers.py" source_line=339}
  multiply.2612.clone.1 = f32[8,8192]{1,0} multiply(select.1890.clone.1, select.1890.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=340}
  multiply.2611.clone.1 = f32[8,8192]{1,0} multiply(broadcast.4185, multiply.2612.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=340}
  param_14.229 = f32[8,8192]{1,0} parameter(14)
  multiply.2610.clone.1 = f32[8,8192]{1,0} multiply(broadcast.4179, param_14.229), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=340}
  add.1462.clone.1 = f32[8,8192]{1,0} add(multiply.2611.clone.1, multiply.2610.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/add" source_file="/pax/praxis/praxis/optimizers.py" source_line=340}
  sqrt.126.clone.1 = f32[8,8192]{1,0} sqrt(add.1462.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/sqrt" source_file="/pax/praxis/praxis/optimizers.py" source_line=684}
  add.1461.clone.1 = f32[8,8192]{1,0} add(sqrt.126.clone.1, broadcast.4178), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/add" source_file="/pax/praxis/praxis/optimizers.py" source_line=684}
  divide.185.clone.1 = f32[8,8192]{1,0} divide(add.1453.clone.1, add.1461.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/div" source_file="/pax/praxis/praxis/optimizers.py" source_line=684}
  multiply.1439.clone.1 = f32[8,8192]{1,0} multiply(divide.185.clone.1, divide.185.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=2078}
  reduce.334.clone.1 = f32[8]{0} reduce(multiply.1439.clone.1, constant.1864), dimensions={1}, to_apply=region_15.791, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/reduce_sum[axes=(1,)]" source_file="/pax/praxis/praxis/optimizers.py" source_line=2066}
  param_20.101 = f32[8,8192]{1,0} parameter(20)
  param_21.92 = f32[8192]{0} parameter(21)
  bitcast.7996.clone.1 = f32[1,8192]{1,0} bitcast(param_21.92)
  dynamic-update-slice.205.clone.1 = f32[8,8192]{1,0} dynamic-update-slice(param_20.101, bitcast.7996.clone.1, select.1672, constant.4013), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  multiply.2327.clone.1 = f32[8,8192]{1,0} multiply(dynamic-update-slice.205.clone.1, broadcast.4142), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/paxml/paxml/learners.py" source_line=266}
  compare.1238.clone.1 = pred[8,8192]{1,0} compare(multiply.2327.clone.1, multiply.2327.clone.1), direction=NE, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/jit(isnan)/ne" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  select.1532.clone.1 = f32[8,8192]{1,0} select(compare.1238.clone.1, broadcast.4141, multiply.2327.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/jit(_where)/select_n" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  compare.1237.clone.1 = pred[8,8192]{1,0} compare(select.1532.clone.1, broadcast.4140), direction=EQ, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/eq" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  select.1531.clone.1 = f32[8,8192]{1,0} select(compare.1237.clone.1, broadcast.4141, select.1532.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/jit(_where)/select_n" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  compare.1236.clone.1 = pred[8,8192]{1,0} compare(select.1531.clone.1, broadcast.4139), direction=EQ, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/eq" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  select.1530.clone.1 = f32[8,8192]{1,0} select(compare.1236.clone.1, broadcast.4141, select.1531.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/jit(_where)/select_n" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  multiply.2326.clone.1 = f32[8,8192]{1,0} multiply(broadcast.4143, select.1530.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=339}
  param_19.128 = f32[8,8192]{1,0} parameter(19)
  multiply.2325.clone.1 = f32[8,8192]{1,0} multiply(broadcast.4137, param_19.128), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=339}
  add.1363.clone.1 = f32[8,8192]{1,0} add(multiply.2326.clone.1, multiply.2325.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/add" source_file="/pax/praxis/praxis/optimizers.py" source_line=339}
  multiply.2351.clone.1 = f32[8,8192]{1,0} multiply(select.1530.clone.1, select.1530.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=340}
  multiply.2350.clone.1 = f32[8,8192]{1,0} multiply(broadcast.4185, multiply.2351.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=340}
  param_18.215 = f32[8,8192]{1,0} parameter(18)
  multiply.2349.clone.1 = f32[8,8192]{1,0} multiply(broadcast.4179, param_18.215), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=340}
  add.1372.clone.1 = f32[8,8192]{1,0} add(multiply.2350.clone.1, multiply.2349.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/add" source_file="/pax/praxis/praxis/optimizers.py" source_line=340}
  sqrt.110.clone.1 = f32[8,8192]{1,0} sqrt(add.1372.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/sqrt" source_file="/pax/praxis/praxis/optimizers.py" source_line=684}
  add.1371.clone.1 = f32[8,8192]{1,0} add(sqrt.110.clone.1, broadcast.4178), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/add" source_file="/pax/praxis/praxis/optimizers.py" source_line=684}
  divide.195.clone.1 = f32[8,8192]{1,0} divide(add.1363.clone.1, add.1371.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/div" source_file="/pax/praxis/praxis/optimizers.py" source_line=684}
  multiply.1505.clone.1 = f32[8,8192]{1,0} multiply(divide.195.clone.1, divide.195.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=2078}
  reduce.339.clone.1 = f32[8]{0} reduce(multiply.1505.clone.1, constant.1864), dimensions={1}, to_apply=region_15.791, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/reduce_sum[axes=(1,)]" source_file="/pax/praxis/praxis/optimizers.py" source_line=2066}
  param_24.62 = f32[8,8192]{1,0} parameter(24)
  param_25.55 = f32[8192]{0} parameter(25)
  bitcast.8046.clone.1 = f32[1,8192]{1,0} bitcast(param_25.55)
  dynamic-update-slice.255.clone.1 = f32[8,8192]{1,0} dynamic-update-slice(param_24.62, bitcast.8046.clone.1, select.1672, constant.4013), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  multiply.2481.clone.1 = f32[8,8192]{1,0} multiply(dynamic-update-slice.255.clone.1, broadcast.4142), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/paxml/paxml/learners.py" source_line=266}
  compare.1440.clone.1 = pred[8,8192]{1,0} compare(multiply.2481.clone.1, multiply.2481.clone.1), direction=NE, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/jit(isnan)/ne" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  select.1743.clone.1 = f32[8,8192]{1,0} select(compare.1440.clone.1, broadcast.4141, multiply.2481.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/jit(_where)/select_n" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  compare.1439.clone.1 = pred[8,8192]{1,0} compare(select.1743.clone.1, broadcast.4140), direction=EQ, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/eq" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  select.1742.clone.1 = f32[8,8192]{1,0} select(compare.1439.clone.1, broadcast.4141, select.1743.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/jit(_where)/select_n" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  compare.1438.clone.1 = pred[8,8192]{1,0} compare(select.1742.clone.1, broadcast.4139), direction=EQ, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/eq" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  select.1741.clone.1 = f32[8,8192]{1,0} select(compare.1438.clone.1, broadcast.4141, select.1742.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/jit(_where)/select_n" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  multiply.2480.clone.1 = f32[8,8192]{1,0} multiply(broadcast.4143, select.1741.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=339}
  param_23.73 = f32[8,8192]{1,0} parameter(23)
  multiply.2479.clone.1 = f32[8,8192]{1,0} multiply(broadcast.4137, param_23.73), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=339}
  add.1414.clone.1 = f32[8,8192]{1,0} add(multiply.2480.clone.1, multiply.2479.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/add" source_file="/pax/praxis/praxis/optimizers.py" source_line=339}
  multiply.2504.clone.1 = f32[8,8192]{1,0} multiply(select.1741.clone.1, select.1741.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=340}
  multiply.2503.clone.1 = f32[8,8192]{1,0} multiply(broadcast.4185, multiply.2504.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=340}
  param_22.70 = f32[8,8192]{1,0} parameter(22)
  multiply.2502.clone.1 = f32[8,8192]{1,0} multiply(broadcast.4179, param_22.70), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=340}
  add.1423.clone.1 = f32[8,8192]{1,0} add(multiply.2503.clone.1, multiply.2502.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/add" source_file="/pax/praxis/praxis/optimizers.py" source_line=340}
  sqrt.118.clone.1 = f32[8,8192]{1,0} sqrt(add.1423.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/sqrt" source_file="/pax/praxis/praxis/optimizers.py" source_line=684}
  add.1422.clone.1 = f32[8,8192]{1,0} add(sqrt.118.clone.1, broadcast.4178), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/add" source_file="/pax/praxis/praxis/optimizers.py" source_line=684}
  divide.189.clone.1 = f32[8,8192]{1,0} divide(add.1414.clone.1, add.1422.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/div" source_file="/pax/praxis/praxis/optimizers.py" source_line=684}
  multiply.1466.clone.1 = f32[8,8192]{1,0} multiply(divide.189.clone.1, divide.189.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=2078}
  reduce.336.clone.1 = f32[8]{0} reduce(multiply.1466.clone.1, constant.1864), dimensions={1}, to_apply=region_15.791, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/reduce_sum[axes=(1,)]" source_file="/pax/praxis/praxis/optimizers.py" source_line=2066}
  ROOT tuple.79 = (f32[8]{0}, f32[8]{0}, f32[8]{0}, f32[8]{0}, f32[8]{0}) tuple(reduce.337, reduce.335.clone.1, reduce.334.clone.1, reduce.339.clone.1, reduce.336.clone.1)
} // fused_computation.169

fused_computation.175 {
  param_6.1361 = f32[8]{0} parameter(6)
  broadcast.4055 = f32[8,32768,1024]{2,1,0} broadcast(param_6.1361), dimensions={0}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=339}
  param_8.913 = f32[8,32768,1024]{2,1,0} parameter(8)
  param_10.676 = f32[32768,1024]{0,1} parameter(10)
  bitcast.8190 = f32[1,1024,32768]{2,1,0} bitcast(param_10.676)
  transpose.360 = f32[1,32768,1024]{2,1,0} transpose(bitcast.8190), dimensions={0,2,1}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/broadcast_in_dim[shape=(1, 32768, 8192) broadcast_dimensions=(1, 2)]" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  param_9.796 = s32[] parameter(9)
  constant.3908 = s32[] constant(0)
  dynamic-update-slice.363 = f32[8,32768,1024]{2,1,0} dynamic-update-slice(param_8.913, transpose.360, param_9.796, constant.3908, constant.3908)
  param_5.1717 = f32[32768,1024]{0,1} parameter(5)
  bitcast.8014 = f32[1,1024,32768]{2,1,0} bitcast(param_5.1717)
  transpose.330 = f32[1,32768,1024]{2,1,0} transpose(bitcast.8014), dimensions={0,2,1}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/broadcast_in_dim[shape=(1, 32768, 8192) broadcast_dimensions=(1, 2)]" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  constant.3911 = s32[] constant(7)
  param_4.1964 = s32[] parameter(4)
  subtract.832 = s32[] subtract(constant.3911, param_4.1964), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  compare.1312 = pred[] compare(subtract.832, constant.3908), direction=LT, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/lt" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  constant.3909 = s32[] constant(15)
  subtract.831 = s32[] subtract(constant.3909, param_4.1964), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/add" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  select.1615 = s32[] select(compare.1312, subtract.831, subtract.832), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/select_n" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  dynamic-update-slice.223 = f32[8,32768,1024]{2,1,0} dynamic-update-slice(dynamic-update-slice.363, transpose.330, select.1615, constant.3908, constant.3908), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  param_3.1661 = f32[] parameter(3)
  broadcast.4053 = f32[8,32768,1024]{2,1,0} broadcast(param_3.1661), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/paxml/paxml/learners.py" source_line=266}
  multiply.2389 = f32[8,32768,1024]{2,1,0} multiply(dynamic-update-slice.223, broadcast.4053), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/paxml/paxml/learners.py" source_line=266}
  compare.1311 = pred[8,32768,1024]{2,1,0} compare(multiply.2389, multiply.2389), direction=NE, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/jit(isnan)/ne" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  constant.3907 = f32[] constant(nan)
  broadcast.4052 = f32[8,32768,1024]{2,1,0} broadcast(constant.3907), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/jit(_where)/broadcast_in_dim[shape=(8, 32768, 8192) broadcast_dimensions=(1, 2)]" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  select.1613 = f32[8,32768,1024]{2,1,0} select(compare.1311, broadcast.4052, multiply.2389), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/jit(_where)/select_n" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  constant.3906 = f32[] constant(inf)
  broadcast.4051 = f32[8,32768,1024]{2,1,0} broadcast(constant.3906), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/eq" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  compare.1310 = pred[8,32768,1024]{2,1,0} compare(select.1613, broadcast.4051), direction=EQ, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/eq" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  select.1612 = f32[8,32768,1024]{2,1,0} select(compare.1310, broadcast.4052, select.1613), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/jit(_where)/select_n" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  constant.3905 = f32[] constant(-inf)
  broadcast.4050 = f32[8,32768,1024]{2,1,0} broadcast(constant.3905), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/eq" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  compare.1309 = pred[8,32768,1024]{2,1,0} compare(select.1612, broadcast.4050), direction=EQ, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/eq" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  select.1611 = f32[8,32768,1024]{2,1,0} select(compare.1309, broadcast.4052, select.1612), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/jit(_where)/select_n" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  multiply.2388 = f32[8,32768,1024]{2,1,0} multiply(broadcast.4055, select.1611), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=339}
  param_2.1830 = f32[8]{0} parameter(2)
  broadcast.4049 = f32[8,32768,1024]{2,1,0} broadcast(param_2.1830), dimensions={0}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=339}
  param_1.2084 = f32[8,32768,1024]{2,1,0} parameter(1)
  multiply.2386 = f32[8,32768,1024]{2,1,0} multiply(broadcast.4049, param_1.2084), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=339}
  add.1384 = f32[8,32768,1024]{2,1,0} add(multiply.2388, multiply.2386), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/add" source_file="/pax/praxis/praxis/optimizers.py" source_line=339}
  param_0.1533 = f32[8,32768,1024]{2,1,0} parameter(0)
  divide.193 = f32[8,32768,1024]{2,1,0} divide(add.1384, param_0.1533), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/div" source_file="/pax/praxis/praxis/optimizers.py" source_line=684}
  multiply.1490 = f32[8,32768,1024]{2,1,0} multiply(divide.193, divide.193), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=2078}
  bitcast.7424 = f32[8,4096,8192]{2,1,0} bitcast(multiply.1490), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=2078}
  constant.1876 = f32[] constant(0)
  reduce.338 = f32[8,4096]{1,0} reduce(bitcast.7424, constant.1876), dimensions={2}, to_apply=region_15.791, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/reduce_sum[axes=(1,)]" source_file="/pax/praxis/praxis/optimizers.py" source_line=2063}
  param_7.978 = f32[] parameter(7)
  is-finite.22.clone.1 = pred[] is-finite(param_7.978), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(isfinite)/is_finite" source_file="/pax/paxml/paxml/learners.py" source_line=256}
  broadcast.2226.clone.1 = pred[8,32768,1024]{2,1,0} broadcast(is-finite.22.clone.1), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(_where)/broadcast_in_dim[shape=(8, 32768, 8192) broadcast_dimensions=()]" source_file="/pax/paxml/paxml/learners.py" source_line=340}
  select.788.clone.1 = f32[8,32768,1024]{2,1,0} select(broadcast.2226.clone.1, add.1384, param_1.2084), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(_where)/select_n" source_file="/pax/paxml/paxml/learners.py" source_line=340}
  ROOT tuple.62 = (f32[8,4096]{1,0}, f32[8,32768,1024]{2,1,0}) tuple(reduce.338, select.788.clone.1)
} // fused_computation.175

fused_computation.180 {
  param_0.355 = f32[8,8192]{1,0} parameter(0)
  param_3.1634 = f32[] parameter(3)
  is-finite.49 = pred[] is-finite(param_3.1634), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(isfinite)/is_finite" source_file="/pax/paxml/paxml/learners.py" source_line=256}
  broadcast.2409 = pred[8,8192]{1,0} broadcast(is-finite.49), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(_where)/broadcast_in_dim[shape=(8, 8192) broadcast_dimensions=()]" source_file="/pax/paxml/paxml/learners.py" source_line=340}
  param_2.1816 = f32[8]{0} parameter(2)
  broadcast.2408 = f32[8,8192]{1,0} broadcast(param_2.1816), dimensions={0}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=695}
  param_10.359 = f32[8]{0} parameter(10)
  broadcast.3898 = f32[8,8192]{1,0} broadcast(param_10.359), dimensions={0}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=339}
  param_7.539 = f32[8,8192]{1,0} parameter(7)
  param_9.424 = f32[8192]{0} parameter(9)
  bitcast.7992 = f32[1,8192]{1,0} bitcast(param_9.424)
  constant.3736 = s32[] constant(7)
  param_8.485 = s32[] parameter(8)
  subtract.788 = s32[] subtract(constant.3736, param_8.485), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  constant.3733 = s32[] constant(0)
  compare.1219 = pred[] compare(subtract.788, constant.3733), direction=LT, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/lt" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  constant.3734 = s32[] constant(15)
  subtract.787 = s32[] subtract(constant.3734, param_8.485), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/add" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  select.1517 = s32[] select(compare.1219, subtract.787, subtract.788), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/select_n" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  dynamic-update-slice.201 = f32[8,8192]{1,0} dynamic-update-slice(param_7.539, bitcast.7992, select.1517, constant.3733), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  param_6.722 = f32[] parameter(6)
  broadcast.3897 = f32[8,8192]{1,0} broadcast(param_6.722), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/paxml/paxml/learners.py" source_line=266}
  multiply.2315 = f32[8,8192]{1,0} multiply(dynamic-update-slice.201, broadcast.3897), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/paxml/paxml/learners.py" source_line=266}
  compare.1218 = pred[8,8192]{1,0} compare(multiply.2315, multiply.2315), direction=NE, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/jit(isnan)/ne" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  constant.1882 = f32[] constant(nan)
  broadcast.3896 = f32[8,8192]{1,0} broadcast(constant.1882), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/jit(_where)/broadcast_in_dim[shape=(8, 8192) broadcast_dimensions=(1,)]" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  select.1516 = f32[8,8192]{1,0} select(compare.1218, broadcast.3896, multiply.2315), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/jit(_where)/select_n" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  constant.1883 = f32[] constant(inf)
  broadcast.3895 = f32[8,8192]{1,0} broadcast(constant.1883), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/eq" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  compare.1217 = pred[8,8192]{1,0} compare(select.1516, broadcast.3895), direction=EQ, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/eq" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  select.1515 = f32[8,8192]{1,0} select(compare.1217, broadcast.3896, select.1516), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/jit(_where)/select_n" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  constant.1884 = f32[] constant(-inf)
  broadcast.3894 = f32[8,8192]{1,0} broadcast(constant.1884), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/eq" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  compare.1216 = pred[8,8192]{1,0} compare(select.1515, broadcast.3894), direction=EQ, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/eq" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  select.1514 = f32[8,8192]{1,0} select(compare.1216, broadcast.3896, select.1515), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/jit(_where)/select_n" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  multiply.2314 = f32[8,8192]{1,0} multiply(broadcast.3898, select.1514), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=339}
  param_5.974 = f32[8]{0} parameter(5)
  broadcast.3893 = f32[8,8192]{1,0} broadcast(param_5.974), dimensions={0}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=339}
  param_4.1234 = f32[8,8192]{1,0} parameter(4)
  multiply.2313 = f32[8,8192]{1,0} multiply(broadcast.3893, param_4.1234), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=339}
  add.1359 = f32[8,8192]{1,0} add(multiply.2314, multiply.2313), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/add" source_file="/pax/praxis/praxis/optimizers.py" source_line=339}
  param_13.71 = f32[8]{0} parameter(13)
  broadcast.3979 = f32[8,8192]{1,0} broadcast(param_13.71), dimensions={0}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=340}
  multiply.2360 = f32[8,8192]{1,0} multiply(select.1514, select.1514), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=340}
  multiply.2359 = f32[8,8192]{1,0} multiply(broadcast.3979, multiply.2360), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=340}
  param_12.199 = f32[8]{0} parameter(12)
  broadcast.3973 = f32[8,8192]{1,0} broadcast(param_12.199), dimensions={0}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=340}
  param_11.303 = f32[8,8192]{1,0} parameter(11)
  multiply.2358 = f32[8,8192]{1,0} multiply(broadcast.3973, param_11.303), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=340}
  add.1377 = f32[8,8192]{1,0} add(multiply.2359, multiply.2358), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/add" source_file="/pax/praxis/praxis/optimizers.py" source_line=340}
  sqrt.112 = f32[8,8192]{1,0} sqrt(add.1377), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/sqrt" source_file="/pax/praxis/praxis/optimizers.py" source_line=684}
  constant.3827 = f32[] constant(1e-06)
  broadcast.3972 = f32[8,8192]{1,0} broadcast(constant.3827), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/add" source_file="/pax/praxis/praxis/optimizers.py" source_line=684}
  add.1375 = f32[8,8192]{1,0} add(sqrt.112, broadcast.3972), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/add" source_file="/pax/praxis/praxis/optimizers.py" source_line=684}
  param_1.2075 = f32[8]{0} parameter(1)
  constant.1881 = f32[] constant(0.000122070312)
  broadcast.2407 = f32[8]{0} broadcast(constant.1881), dimensions={}
  multiply.1504 = f32[8]{0} multiply(param_1.2075, broadcast.2407), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/div" source_file="/pax/praxis/praxis/optimizers.py" source_line=2066}
  sqrt.78 = f32[8]{0} sqrt(multiply.1504), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/sqrt" source_file="/pax/praxis/praxis/optimizers.py" source_line=2080}
  compare.575 = pred[8]{0} compare(sqrt.78, sqrt.78), direction=NE, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/jit(isnan)/ne" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  broadcast.2413 = f32[8]{0} broadcast(constant.1882), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/jit(_where)/broadcast_in_dim[shape=(8,) broadcast_dimensions=()]" source_file="/usr/local/lib/python3.10/dist-packages/optax/_src/schedule.py" source_line=399}
  select.866 = f32[8]{0} select(compare.575, broadcast.2413, sqrt.78), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/jit(_where)/select_n" source_file="/usr/local/lib/python3.10/dist-packages/optax/_src/schedule.py" source_line=399}
  broadcast.2412 = f32[8]{0} broadcast(constant.1883), dimensions={}
  compare.574 = pred[8]{0} compare(select.866, broadcast.2412), direction=EQ, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/eq" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  select.865 = f32[8]{0} select(compare.574, broadcast.2413, select.866), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/jit(_where)/select_n" source_file="/usr/local/lib/python3.10/dist-packages/optax/_src/schedule.py" source_line=399}
  broadcast.2410 = f32[8]{0} broadcast(constant.1884), dimensions={}
  compare.573 = pred[8]{0} compare(select.865, broadcast.2410), direction=EQ, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/eq" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  select.864 = f32[8]{0} select(compare.573, broadcast.2413, select.865), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/jit(_where)/select_n" source_file="/usr/local/lib/python3.10/dist-packages/optax/_src/schedule.py" source_line=399}
  constant.1885 = f32[] constant(1)
  broadcast.2414 = f32[8]{0} broadcast(constant.1885), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(_where))/broadcast_in_dim[shape=(8,) broadcast_dimensions=()]" source_file="/pax/praxis/praxis/schedules.py" source_line=105}
  maximum.64 = f32[8]{0} maximum(select.864, broadcast.2414), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/max" source_file="/pax/praxis/praxis/optimizers.py" source_line=346}
  broadcast.2406 = f32[8,8192]{1,0} broadcast(maximum.64), dimensions={0}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/div" source_file="/pax/praxis/praxis/optimizers.py" source_line=347}
  multiply.1503 = f32[8,8192]{1,0} multiply(add.1375, broadcast.2406)
  divide.194 = f32[8,8192]{1,0} divide(add.1359, multiply.1503), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/div" source_file="/pax/praxis/praxis/optimizers.py" source_line=347}
  constant.1886 = f32[] constant(0.001)
  broadcast.2404 = f32[8,8192]{1,0} broadcast(constant.1886), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=691}
  multiply.1502 = f32[8,8192]{1,0} multiply(param_0.355, broadcast.2404), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=691}
  add.950 = f32[8,8192]{1,0} add(divide.194, multiply.1502), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/add" source_file="/pax/praxis/praxis/optimizers.py" source_line=691}
  multiply.1501 = f32[8,8192]{1,0} multiply(broadcast.2408, add.950), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=695}
  constant.1887 = f32[] constant(0)
  broadcast.2403 = f32[8,8192]{1,0} broadcast(constant.1887), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/broadcast_in_dim[shape=(8, 8192) broadcast_dimensions=()]" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  select.863 = f32[8,8192]{1,0} select(broadcast.2409, multiply.1501, broadcast.2403), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(_where)/select_n" source_file="/pax/paxml/paxml/learners.py" source_line=340}
  add.949 = f32[8,8192]{1,0} add(param_0.355, select.863), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/add" source_file="/pax/paxml/paxml/learners.py" source_line=408}
  select.778.clone.1 = f32[8,8192]{1,0} select(broadcast.2409, add.1377, param_11.303), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(_where)/select_n" source_file="/pax/paxml/paxml/learners.py" source_line=340}
  select.789.clone.1 = f32[8,8192]{1,0} select(broadcast.2409, add.1359, param_4.1234), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(_where)/select_n" source_file="/pax/paxml/paxml/learners.py" source_line=340}
  param_18.170 = f32[8,8192]{1,0} parameter(18)
  param_15.183 = f32[8,8192]{1,0} parameter(15)
  param_16.212 = f32[8192]{0} parameter(16)
  bitcast.8078.clone.1 = f32[1,8192]{1,0} bitcast(param_16.212)
  dynamic-update-slice.287.clone.1 = f32[8,8192]{1,0} dynamic-update-slice(param_15.183, bitcast.8078.clone.1, select.1517, constant.3733), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  multiply.2577.clone.1 = f32[8,8192]{1,0} multiply(dynamic-update-slice.287.clone.1, broadcast.3897), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/paxml/paxml/learners.py" source_line=266}
  compare.1569.clone.1 = pred[8,8192]{1,0} compare(multiply.2577.clone.1, multiply.2577.clone.1), direction=NE, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/jit(isnan)/ne" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  select.1874.clone.1 = f32[8,8192]{1,0} select(compare.1569.clone.1, broadcast.3896, multiply.2577.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/jit(_where)/select_n" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  compare.1568.clone.1 = pred[8,8192]{1,0} compare(select.1874.clone.1, broadcast.3895), direction=EQ, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/eq" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  select.1873.clone.1 = f32[8,8192]{1,0} select(compare.1568.clone.1, broadcast.3896, select.1874.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/jit(_where)/select_n" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  compare.1566.clone.1 = pred[8,8192]{1,0} compare(select.1873.clone.1, broadcast.3894), direction=EQ, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/eq" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  select.1872.clone.1 = f32[8,8192]{1,0} select(compare.1566.clone.1, broadcast.3896, select.1873.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/jit(_where)/select_n" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  multiply.2576.clone.1 = f32[8,8192]{1,0} multiply(broadcast.3898, select.1872.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=339}
  param_14.200 = f32[8,8192]{1,0} parameter(14)
  multiply.2575.clone.1 = f32[8,8192]{1,0} multiply(broadcast.3893, param_14.200), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=339}
  add.1449.clone.1 = f32[8,8192]{1,0} add(multiply.2576.clone.1, multiply.2575.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/add" source_file="/pax/praxis/praxis/optimizers.py" source_line=339}
  multiply.2620.clone.1 = f32[8,8192]{1,0} multiply(select.1872.clone.1, select.1872.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=340}
  multiply.2619.clone.1 = f32[8,8192]{1,0} multiply(broadcast.3979, multiply.2620.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=340}
  param_17.185 = f32[8,8192]{1,0} parameter(17)
  multiply.2618.clone.1 = f32[8,8192]{1,0} multiply(broadcast.3973, param_17.185), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=340}
  add.1468.clone.1 = f32[8,8192]{1,0} add(multiply.2619.clone.1, multiply.2618.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/add" source_file="/pax/praxis/praxis/optimizers.py" source_line=340}
  sqrt.128.clone.1 = f32[8,8192]{1,0} sqrt(add.1468.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/sqrt" source_file="/pax/praxis/praxis/optimizers.py" source_line=684}
  add.1467.clone.1 = f32[8,8192]{1,0} add(sqrt.128.clone.1, broadcast.3972), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/add" source_file="/pax/praxis/praxis/optimizers.py" source_line=684}
  param_19.85 = f32[8]{0} parameter(19)
  multiply.1437.clone.1 = f32[8]{0} multiply(param_19.85, broadcast.2407), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/div" source_file="/pax/praxis/praxis/optimizers.py" source_line=2066}
  sqrt.68.clone.1 = f32[8]{0} sqrt(multiply.1437.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/sqrt" source_file="/pax/praxis/praxis/optimizers.py" source_line=2080}
  compare.545.clone.1 = pred[8]{0} compare(sqrt.68.clone.1, sqrt.68.clone.1), direction=NE, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/jit(isnan)/ne" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  select.831.clone.1 = f32[8]{0} select(compare.545.clone.1, broadcast.2413, sqrt.68.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/jit(_where)/select_n" source_file="/usr/local/lib/python3.10/dist-packages/optax/_src/schedule.py" source_line=399}
  compare.544.clone.1 = pred[8]{0} compare(select.831.clone.1, broadcast.2412), direction=EQ, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/eq" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  select.830.clone.1 = f32[8]{0} select(compare.544.clone.1, broadcast.2413, select.831.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/jit(_where)/select_n" source_file="/usr/local/lib/python3.10/dist-packages/optax/_src/schedule.py" source_line=399}
  compare.543.clone.1 = pred[8]{0} compare(select.830.clone.1, broadcast.2410), direction=EQ, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/eq" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  select.829.clone.1 = f32[8]{0} select(compare.543.clone.1, broadcast.2413, select.830.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/jit(_where)/select_n" source_file="/usr/local/lib/python3.10/dist-packages/optax/_src/schedule.py" source_line=399}
  maximum.59.clone.1 = f32[8]{0} maximum(select.829.clone.1, broadcast.2414), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/max" source_file="/pax/praxis/praxis/optimizers.py" source_line=346}
  broadcast.2303.clone.1 = f32[8,8192]{1,0} broadcast(maximum.59.clone.1), dimensions={0}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/div" source_file="/pax/praxis/praxis/optimizers.py" source_line=347}
  multiply.1436.clone.1 = f32[8,8192]{1,0} multiply(add.1467.clone.1, broadcast.2303.clone.1)
  divide.184.clone.1 = f32[8,8192]{1,0} divide(add.1449.clone.1, multiply.1436.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/div" source_file="/pax/praxis/praxis/optimizers.py" source_line=347}
  multiply.1435.clone.1 = f32[8,8192]{1,0} multiply(param_18.170, broadcast.2404), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=691}
  add.917.clone.1 = f32[8,8192]{1,0} add(divide.184.clone.1, multiply.1435.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/add" source_file="/pax/praxis/praxis/optimizers.py" source_line=691}
  multiply.1434.clone.1 = f32[8,8192]{1,0} multiply(broadcast.2408, add.917.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=695}
  select.828.clone.1 = f32[8,8192]{1,0} select(broadcast.2409, multiply.1434.clone.1, broadcast.2403), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(_where)/select_n" source_file="/pax/paxml/paxml/learners.py" source_line=340}
  add.916.clone.1 = f32[8,8192]{1,0} add(param_18.170, select.828.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/add" source_file="/pax/paxml/paxml/learners.py" source_line=408}
  select.773.clone.1.clone.1 = f32[8,8192]{1,0} select(broadcast.2409, add.1468.clone.1, param_17.185), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(_where)/select_n" source_file="/pax/paxml/paxml/learners.py" source_line=340}
  select.784.clone.1.clone.1 = f32[8,8192]{1,0} select(broadcast.2409, add.1449.clone.1, param_14.200), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(_where)/select_n" source_file="/pax/paxml/paxml/learners.py" source_line=340}
  param_24.44 = f32[8,8192]{1,0} parameter(24)
  param_21.60 = f32[8,8192]{1,0} parameter(21)
  param_22.43 = f32[8192]{0} parameter(22)
  bitcast.8060.clone.1 = f32[1,8192]{1,0} bitcast(param_22.43)
  dynamic-update-slice.269.clone.1 = f32[8,8192]{1,0} dynamic-update-slice(param_21.60, bitcast.8060.clone.1, select.1517, constant.3733), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  multiply.2523.clone.1 = f32[8,8192]{1,0} multiply(dynamic-update-slice.269.clone.1, broadcast.3897), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/paxml/paxml/learners.py" source_line=266}
  compare.1496.clone.1 = pred[8,8192]{1,0} compare(multiply.2523.clone.1, multiply.2523.clone.1), direction=NE, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/jit(isnan)/ne" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  select.1799.clone.1 = f32[8,8192]{1,0} select(compare.1496.clone.1, broadcast.3896, multiply.2523.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/jit(_where)/select_n" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  compare.1495.clone.1 = pred[8,8192]{1,0} compare(select.1799.clone.1, broadcast.3895), direction=EQ, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/eq" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  select.1798.clone.1 = f32[8,8192]{1,0} select(compare.1495.clone.1, broadcast.3896, select.1799.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/jit(_where)/select_n" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  compare.1494.clone.1 = pred[8,8192]{1,0} compare(select.1798.clone.1, broadcast.3894), direction=EQ, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/eq" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  select.1797.clone.1 = f32[8,8192]{1,0} select(compare.1494.clone.1, broadcast.3896, select.1798.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/jit(_where)/select_n" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  multiply.2522.clone.1 = f32[8,8192]{1,0} multiply(broadcast.3898, select.1797.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=339}
  param_20.65 = f32[8,8192]{1,0} parameter(20)
  multiply.2521.clone.1 = f32[8,8192]{1,0} multiply(broadcast.3893, param_20.65), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=339}
  add.1431.clone.1 = f32[8,8192]{1,0} add(multiply.2522.clone.1, multiply.2521.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/add" source_file="/pax/praxis/praxis/optimizers.py" source_line=339}
  multiply.2566.clone.1 = f32[8,8192]{1,0} multiply(select.1797.clone.1, select.1797.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=340}
  multiply.2565.clone.1 = f32[8,8192]{1,0} multiply(broadcast.3979, multiply.2566.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=340}
  param_23.47 = f32[8,8192]{1,0} parameter(23)
  multiply.2564.clone.1 = f32[8,8192]{1,0} multiply(broadcast.3973, param_23.47), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=340}
  add.1447.clone.1 = f32[8,8192]{1,0} add(multiply.2565.clone.1, multiply.2564.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/add" source_file="/pax/praxis/praxis/optimizers.py" source_line=340}
  sqrt.124.clone.1 = f32[8,8192]{1,0} sqrt(add.1447.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/sqrt" source_file="/pax/praxis/praxis/optimizers.py" source_line=684}
  add.1446.clone.1 = f32[8,8192]{1,0} add(sqrt.124.clone.1, broadcast.3972), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/add" source_file="/pax/praxis/praxis/optimizers.py" source_line=684}
  param_25.39 = f32[8]{0} parameter(25)
  multiply.1452.clone.1 = f32[8]{0} multiply(param_25.39, broadcast.2407), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/div" source_file="/pax/praxis/praxis/optimizers.py" source_line=2066}
  sqrt.70.clone.1 = f32[8]{0} sqrt(multiply.1452.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/sqrt" source_file="/pax/praxis/praxis/optimizers.py" source_line=2080}
  compare.551.clone.1 = pred[8]{0} compare(sqrt.70.clone.1, sqrt.70.clone.1), direction=NE, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/jit(isnan)/ne" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  select.838.clone.1 = f32[8]{0} select(compare.551.clone.1, broadcast.2413, sqrt.70.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/jit(_where)/select_n" source_file="/usr/local/lib/python3.10/dist-packages/optax/_src/schedule.py" source_line=399}
  compare.550.clone.1 = pred[8]{0} compare(select.838.clone.1, broadcast.2412), direction=EQ, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/eq" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  select.837.clone.1 = f32[8]{0} select(compare.550.clone.1, broadcast.2413, select.838.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/jit(_where)/select_n" source_file="/usr/local/lib/python3.10/dist-packages/optax/_src/schedule.py" source_line=399}
  compare.549.clone.1 = pred[8]{0} compare(select.837.clone.1, broadcast.2410), direction=EQ, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/eq" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  select.836.clone.1 = f32[8]{0} select(compare.549.clone.1, broadcast.2413, select.837.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/jit(_where)/select_n" source_file="/usr/local/lib/python3.10/dist-packages/optax/_src/schedule.py" source_line=399}
  maximum.60.clone.1 = f32[8]{0} maximum(select.836.clone.1, broadcast.2414), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/max" source_file="/pax/praxis/praxis/optimizers.py" source_line=346}
  broadcast.2322.clone.1 = f32[8,8192]{1,0} broadcast(maximum.60.clone.1), dimensions={0}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/div" source_file="/pax/praxis/praxis/optimizers.py" source_line=347}
  multiply.1451.clone.1 = f32[8,8192]{1,0} multiply(add.1446.clone.1, broadcast.2322.clone.1)
  divide.186.clone.1 = f32[8,8192]{1,0} divide(add.1431.clone.1, multiply.1451.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/div" source_file="/pax/praxis/praxis/optimizers.py" source_line=347}
  multiply.1450.clone.1 = f32[8,8192]{1,0} multiply(param_24.44, broadcast.2404), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=691}
  add.923.clone.1 = f32[8,8192]{1,0} add(divide.186.clone.1, multiply.1450.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/add" source_file="/pax/praxis/praxis/optimizers.py" source_line=691}
  multiply.1448.clone.1 = f32[8,8192]{1,0} multiply(broadcast.2408, add.923.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=695}
  select.835.clone.1 = f32[8,8192]{1,0} select(broadcast.2409, multiply.1448.clone.1, broadcast.2403), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(_where)/select_n" source_file="/pax/paxml/paxml/learners.py" source_line=340}
  add.922.clone.1 = f32[8,8192]{1,0} add(param_24.44, select.835.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/add" source_file="/pax/paxml/paxml/learners.py" source_line=408}
  select.774.clone.1.clone.1 = f32[8,8192]{1,0} select(broadcast.2409, add.1447.clone.1, param_23.47), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(_where)/select_n" source_file="/pax/paxml/paxml/learners.py" source_line=340}
  select.785.clone.1.clone.1 = f32[8,8192]{1,0} select(broadcast.2409, add.1431.clone.1, param_20.65), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(_where)/select_n" source_file="/pax/paxml/paxml/learners.py" source_line=340}
  param_30.28 = f32[8,8192]{1,0} parameter(30)
  param_27.59 = f32[8,8192]{1,0} parameter(27)
  param_28.30 = f32[8192]{0} parameter(28)
  bitcast.8042.clone.1 = f32[1,8192]{1,0} bitcast(param_28.30)
  dynamic-update-slice.251.clone.1 = f32[8,8192]{1,0} dynamic-update-slice(param_27.59, bitcast.8042.clone.1, select.1517, constant.3733), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  multiply.2469.clone.1 = f32[8,8192]{1,0} multiply(dynamic-update-slice.251.clone.1, broadcast.3897), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/paxml/paxml/learners.py" source_line=266}
  compare.1424.clone.1 = pred[8,8192]{1,0} compare(multiply.2469.clone.1, multiply.2469.clone.1), direction=NE, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/jit(isnan)/ne" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  select.1727.clone.1 = f32[8,8192]{1,0} select(compare.1424.clone.1, broadcast.3896, multiply.2469.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/jit(_where)/select_n" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  compare.1423.clone.1 = pred[8,8192]{1,0} compare(select.1727.clone.1, broadcast.3895), direction=EQ, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/eq" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  select.1726.clone.1 = f32[8,8192]{1,0} select(compare.1423.clone.1, broadcast.3896, select.1727.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/jit(_where)/select_n" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  compare.1422.clone.1 = pred[8,8192]{1,0} compare(select.1726.clone.1, broadcast.3894), direction=EQ, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/eq" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  select.1725.clone.1 = f32[8,8192]{1,0} select(compare.1422.clone.1, broadcast.3896, select.1726.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/jit(_where)/select_n" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  multiply.2468.clone.1 = f32[8,8192]{1,0} multiply(broadcast.3898, select.1725.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=339}
  param_26.44 = f32[8,8192]{1,0} parameter(26)
  multiply.2467.clone.1 = f32[8,8192]{1,0} multiply(broadcast.3893, param_26.44), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=339}
  add.1410.clone.1 = f32[8,8192]{1,0} add(multiply.2468.clone.1, multiply.2467.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/add" source_file="/pax/praxis/praxis/optimizers.py" source_line=339}
  multiply.2512.clone.1 = f32[8,8192]{1,0} multiply(select.1725.clone.1, select.1725.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=340}
  multiply.2511.clone.1 = f32[8,8192]{1,0} multiply(broadcast.3979, multiply.2512.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=340}
  param_29.31 = f32[8,8192]{1,0} parameter(29)
  multiply.2510.clone.1 = f32[8,8192]{1,0} multiply(broadcast.3973, param_29.31), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=340}
  add.1429.clone.1 = f32[8,8192]{1,0} add(multiply.2511.clone.1, multiply.2510.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/add" source_file="/pax/praxis/praxis/optimizers.py" source_line=340}
  sqrt.120.clone.1 = f32[8,8192]{1,0} sqrt(add.1429.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/sqrt" source_file="/pax/praxis/praxis/optimizers.py" source_line=684}
  add.1428.clone.1 = f32[8,8192]{1,0} add(sqrt.120.clone.1, broadcast.3972), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/add" source_file="/pax/praxis/praxis/optimizers.py" source_line=684}
  param_31.37 = f32[8]{0} parameter(31)
  multiply.1465.clone.1 = f32[8]{0} multiply(param_31.37, broadcast.2407), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/div" source_file="/pax/praxis/praxis/optimizers.py" source_line=2066}
  sqrt.72.clone.1 = f32[8]{0} sqrt(multiply.1465.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/sqrt" source_file="/pax/praxis/praxis/optimizers.py" source_line=2080}
  compare.557.clone.1 = pred[8]{0} compare(sqrt.72.clone.1, sqrt.72.clone.1), direction=NE, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/jit(isnan)/ne" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  select.845.clone.1 = f32[8]{0} select(compare.557.clone.1, broadcast.2413, sqrt.72.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/jit(_where)/select_n" source_file="/usr/local/lib/python3.10/dist-packages/optax/_src/schedule.py" source_line=399}
  compare.556.clone.1 = pred[8]{0} compare(select.845.clone.1, broadcast.2412), direction=EQ, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/eq" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  select.844.clone.1 = f32[8]{0} select(compare.556.clone.1, broadcast.2413, select.845.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/jit(_where)/select_n" source_file="/usr/local/lib/python3.10/dist-packages/optax/_src/schedule.py" source_line=399}
  compare.555.clone.1 = pred[8]{0} compare(select.844.clone.1, broadcast.2410), direction=EQ, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/eq" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  select.843.clone.1 = f32[8]{0} select(compare.555.clone.1, broadcast.2413, select.844.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/jit(_where)/select_n" source_file="/usr/local/lib/python3.10/dist-packages/optax/_src/schedule.py" source_line=399}
  maximum.61.clone.1 = f32[8]{0} maximum(select.843.clone.1, broadcast.2414), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/max" source_file="/pax/praxis/praxis/optimizers.py" source_line=346}
  broadcast.2341.clone.1 = f32[8,8192]{1,0} broadcast(maximum.61.clone.1), dimensions={0}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/div" source_file="/pax/praxis/praxis/optimizers.py" source_line=347}
  multiply.1464.clone.1 = f32[8,8192]{1,0} multiply(add.1428.clone.1, broadcast.2341.clone.1)
  divide.188.clone.1 = f32[8,8192]{1,0} divide(add.1410.clone.1, multiply.1464.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/div" source_file="/pax/praxis/praxis/optimizers.py" source_line=347}
  multiply.1463.clone.1 = f32[8,8192]{1,0} multiply(param_30.28, broadcast.2404), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=691}
  add.931.clone.1 = f32[8,8192]{1,0} add(divide.188.clone.1, multiply.1463.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/add" source_file="/pax/praxis/praxis/optimizers.py" source_line=691}
  multiply.1462.clone.1 = f32[8,8192]{1,0} multiply(broadcast.2408, add.931.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=695}
  select.842.clone.1 = f32[8,8192]{1,0} select(broadcast.2409, multiply.1462.clone.1, broadcast.2403), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(_where)/select_n" source_file="/pax/paxml/paxml/learners.py" source_line=340}
  add.928.clone.1 = f32[8,8192]{1,0} add(param_30.28, select.842.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/add" source_file="/pax/paxml/paxml/learners.py" source_line=408}
  select.775.clone.1.clone.1 = f32[8,8192]{1,0} select(broadcast.2409, add.1429.clone.1, param_29.31), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(_where)/select_n" source_file="/pax/paxml/paxml/learners.py" source_line=340}
  select.786.clone.1.clone.1 = f32[8,8192]{1,0} select(broadcast.2409, add.1410.clone.1, param_26.44), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(_where)/select_n" source_file="/pax/paxml/paxml/learners.py" source_line=340}
  param_36.28 = f32[8,8192]{1,0} parameter(36)
  param_33.51 = f32[8,8192]{1,0} parameter(33)
  param_34.30 = f32[8192]{0} parameter(34)
  bitcast.8024.clone.1 = f32[1,8192]{1,0} bitcast(param_34.30)
  dynamic-update-slice.233.clone.1 = f32[8,8192]{1,0} dynamic-update-slice(param_33.51, bitcast.8024.clone.1, select.1517, constant.3733), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  multiply.2415.clone.1 = f32[8,8192]{1,0} multiply(dynamic-update-slice.233.clone.1, broadcast.3897), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/paxml/paxml/learners.py" source_line=266}
  compare.1352.clone.1 = pred[8,8192]{1,0} compare(multiply.2415.clone.1, multiply.2415.clone.1), direction=NE, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/jit(isnan)/ne" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  select.1655.clone.1 = f32[8,8192]{1,0} select(compare.1352.clone.1, broadcast.3896, multiply.2415.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/jit(_where)/select_n" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  compare.1351.clone.1 = pred[8,8192]{1,0} compare(select.1655.clone.1, broadcast.3895), direction=EQ, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/eq" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  select.1654.clone.1 = f32[8,8192]{1,0} select(compare.1351.clone.1, broadcast.3896, select.1655.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/jit(_where)/select_n" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  compare.1350.clone.1 = pred[8,8192]{1,0} compare(select.1654.clone.1, broadcast.3894), direction=EQ, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/eq" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  select.1653.clone.1 = f32[8,8192]{1,0} select(compare.1350.clone.1, broadcast.3896, select.1654.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/jit(_where)/select_n" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  multiply.2414.clone.1 = f32[8,8192]{1,0} multiply(broadcast.3898, select.1653.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=339}
  param_32.40 = f32[8,8192]{1,0} parameter(32)
  multiply.2413.clone.1 = f32[8,8192]{1,0} multiply(broadcast.3893, param_32.40), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=339}
  add.1391.clone.1 = f32[8,8192]{1,0} add(multiply.2414.clone.1, multiply.2413.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/add" source_file="/pax/praxis/praxis/optimizers.py" source_line=339}
  multiply.2458.clone.1 = f32[8,8192]{1,0} multiply(select.1653.clone.1, select.1653.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=340}
  multiply.2457.clone.1 = f32[8,8192]{1,0} multiply(broadcast.3979, multiply.2458.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=340}
  param_35.31 = f32[8,8192]{1,0} parameter(35)
  multiply.2456.clone.1 = f32[8,8192]{1,0} multiply(broadcast.3973, param_35.31), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=340}
  add.1408.clone.1 = f32[8,8192]{1,0} add(multiply.2457.clone.1, multiply.2456.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/add" source_file="/pax/praxis/praxis/optimizers.py" source_line=340}
  sqrt.116.clone.1 = f32[8,8192]{1,0} sqrt(add.1408.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/sqrt" source_file="/pax/praxis/praxis/optimizers.py" source_line=684}
  add.1407.clone.1 = f32[8,8192]{1,0} add(sqrt.116.clone.1, broadcast.3972), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/add" source_file="/pax/praxis/praxis/optimizers.py" source_line=684}
  param_37.37 = f32[8]{0} parameter(37)
  multiply.1476.clone.1 = f32[8]{0} multiply(param_37.37, broadcast.2407), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/div" source_file="/pax/praxis/praxis/optimizers.py" source_line=2066}
  sqrt.74.clone.1 = f32[8]{0} sqrt(multiply.1476.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/sqrt" source_file="/pax/praxis/praxis/optimizers.py" source_line=2080}
  compare.563.clone.1 = pred[8]{0} compare(sqrt.74.clone.1, sqrt.74.clone.1), direction=NE, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/jit(isnan)/ne" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  select.852.clone.1 = f32[8]{0} select(compare.563.clone.1, broadcast.2413, sqrt.74.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/jit(_where)/select_n" source_file="/usr/local/lib/python3.10/dist-packages/optax/_src/schedule.py" source_line=399}
  compare.562.clone.1 = pred[8]{0} compare(select.852.clone.1, broadcast.2412), direction=EQ, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/eq" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  select.851.clone.1 = f32[8]{0} select(compare.562.clone.1, broadcast.2413, select.852.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/jit(_where)/select_n" source_file="/usr/local/lib/python3.10/dist-packages/optax/_src/schedule.py" source_line=399}
  compare.561.clone.1 = pred[8]{0} compare(select.851.clone.1, broadcast.2410), direction=EQ, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/eq" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  select.850.clone.1 = f32[8]{0} select(compare.561.clone.1, broadcast.2413, select.851.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/jit(_where)/select_n" source_file="/usr/local/lib/python3.10/dist-packages/optax/_src/schedule.py" source_line=399}
  maximum.62.clone.1 = f32[8]{0} maximum(select.850.clone.1, broadcast.2414), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/max" source_file="/pax/praxis/praxis/optimizers.py" source_line=346}
  broadcast.2360.clone.1 = f32[8,8192]{1,0} broadcast(maximum.62.clone.1), dimensions={0}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/div" source_file="/pax/praxis/praxis/optimizers.py" source_line=347}
  multiply.1475.clone.1 = f32[8,8192]{1,0} multiply(add.1407.clone.1, broadcast.2360.clone.1)
  divide.190.clone.1 = f32[8,8192]{1,0} divide(add.1391.clone.1, multiply.1475.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/div" source_file="/pax/praxis/praxis/optimizers.py" source_line=347}
  multiply.1474.clone.1 = f32[8,8192]{1,0} multiply(param_36.28, broadcast.2404), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=691}
  add.937.clone.1 = f32[8,8192]{1,0} add(divide.190.clone.1, multiply.1474.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/add" source_file="/pax/praxis/praxis/optimizers.py" source_line=691}
  multiply.1473.clone.1 = f32[8,8192]{1,0} multiply(broadcast.2408, add.937.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=695}
  select.849.clone.1 = f32[8,8192]{1,0} select(broadcast.2409, multiply.1473.clone.1, broadcast.2403), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(_where)/select_n" source_file="/pax/paxml/paxml/learners.py" source_line=340}
  add.936.clone.1 = f32[8,8192]{1,0} add(param_36.28, select.849.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/add" source_file="/pax/paxml/paxml/learners.py" source_line=408}
  select.776.clone.1.clone.1 = f32[8,8192]{1,0} select(broadcast.2409, add.1408.clone.1, param_35.31), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(_where)/select_n" source_file="/pax/paxml/paxml/learners.py" source_line=340}
  select.787.clone.1.clone.1 = f32[8,8192]{1,0} select(broadcast.2409, add.1391.clone.1, param_32.40), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(_where)/select_n" source_file="/pax/paxml/paxml/learners.py" source_line=340}
  ROOT tuple.72 = (f32[8,8192]{1,0}, f32[8,8192]{1,0}, f32[8,8192]{1,0}, f32[8,8192]{1,0}, f32[8,8192]{1,0}, /*index=5*/f32[8,8192]{1,0}, f32[8,8192]{1,0}, f32[8,8192]{1,0}, f32[8,8192]{1,0}, f32[8,8192]{1,0}, /*index=10*/f32[8,8192]{1,0}, f32[8,8192]{1,0}, f32[8,8192]{1,0}, f32[8,8192]{1,0}, f32[8,8192]{1,0}) tuple(add.949, select.778.clone.1, select.789.clone.1, add.916.clone.1, select.773.clone.1.clone.1, /*index=5*/select.784.clone.1.clone.1, add.922.clone.1, select.774.clone.1.clone.1, select.785.clone.1.clone.1, add.928.clone.1, /*index=10*/select.775.clone.1.clone.1, select.786.clone.1.clone.1, add.936.clone.1, select.776.clone.1.clone.1, select.787.clone.1.clone.1)
} // fused_computation.180

fused_computation.186 {
  param_0.367 = f32[8,1024,32768]{2,1,0} parameter(0)
  param_4.1132 = f32[] parameter(4)
  is-finite.50 = pred[] is-finite(param_4.1132), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(isfinite)/is_finite" source_file="/pax/paxml/paxml/learners.py" source_line=256}
  broadcast.2430 = pred[8,1024,32768]{2,1,0} broadcast(is-finite.50), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(_where)/broadcast_in_dim[shape=(8, 8192, 32768) broadcast_dimensions=()]" source_file="/pax/paxml/paxml/learners.py" source_line=340}
  param_3.1560 = f32[8]{0} parameter(3)
  broadcast.2429 = f32[8,1024,32768]{2,1,0} broadcast(param_3.1560), dimensions={0}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=695}
  param_11.282 = f32[8]{0} parameter(11)
  broadcast.3810 = f32[8,1024,32768]{2,1,0} broadcast(param_11.282), dimensions={0}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=339}
  param_8.424 = f32[8,1024,32768]{2,1,0} parameter(8)
  param_10.333 = f32[1024,32768]{1,0} parameter(10)
  bitcast.7978 = f32[1,1024,32768]{2,1,0} bitcast(param_10.333)
  constant.3627 = s32[] constant(7)
  param_9.381 = s32[] parameter(9)
  subtract.760 = s32[] subtract(constant.3627, param_9.381), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  constant.3624 = s32[] constant(0)
  compare.1156 = pred[] compare(subtract.760, constant.3624), direction=LT, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/lt" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  constant.3625 = s32[] constant(15)
  subtract.759 = s32[] subtract(constant.3625, param_9.381), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/add" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  select.1461 = s32[] select(compare.1156, subtract.759, subtract.760), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/select_n" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  dynamic-update-slice.187 = f32[8,1024,32768]{2,1,0} dynamic-update-slice(param_8.424, bitcast.7978, select.1461, constant.3624, constant.3624), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  param_7.474 = f32[] parameter(7)
  broadcast.3808 = f32[8,1024,32768]{2,1,0} broadcast(param_7.474), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/paxml/paxml/learners.py" source_line=266}
  multiply.2273 = f32[8,1024,32768]{2,1,0} multiply(dynamic-update-slice.187, broadcast.3808), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/paxml/paxml/learners.py" source_line=266}
  compare.1155 = pred[8,1024,32768]{2,1,0} compare(multiply.2273, multiply.2273), direction=NE, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/jit(isnan)/ne" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  constant.1894 = f32[] constant(nan)
  broadcast.3807 = f32[8,1024,32768]{2,1,0} broadcast(constant.1894), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/jit(_where)/broadcast_in_dim[shape=(8, 8192, 32768) broadcast_dimensions=(1, 2)]" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  select.1460 = f32[8,1024,32768]{2,1,0} select(compare.1155, broadcast.3807, multiply.2273), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/jit(_where)/select_n" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  constant.1895 = f32[] constant(inf)
  broadcast.3806 = f32[8,1024,32768]{2,1,0} broadcast(constant.1895), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/eq" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  compare.1154 = pred[8,1024,32768]{2,1,0} compare(select.1460, broadcast.3806), direction=EQ, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/eq" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  select.1459 = f32[8,1024,32768]{2,1,0} select(compare.1154, broadcast.3807, select.1460), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/jit(_where)/select_n" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  constant.1896 = f32[] constant(-inf)
  broadcast.3805 = f32[8,1024,32768]{2,1,0} broadcast(constant.1896), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/eq" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  compare.1153 = pred[8,1024,32768]{2,1,0} compare(select.1459, broadcast.3805), direction=EQ, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/eq" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  select.1458 = f32[8,1024,32768]{2,1,0} select(compare.1153, broadcast.3807, select.1459), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/jit(_where)/select_n" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  multiply.2272 = f32[8,1024,32768]{2,1,0} multiply(broadcast.3810, select.1458), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=339}
  param_6.617 = f32[8]{0} parameter(6)
  broadcast.3804 = f32[8,1024,32768]{2,1,0} broadcast(param_6.617), dimensions={0}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=339}
  param_5.857 = f32[8,1024,32768]{2,1,0} parameter(5)
  multiply.2271 = f32[8,1024,32768]{2,1,0} multiply(broadcast.3804, param_5.857), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=339}
  add.1348 = f32[8,1024,32768]{2,1,0} add(multiply.2272, multiply.2271), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/add" source_file="/pax/praxis/praxis/optimizers.py" source_line=339}
  param_1.2043 = f32[8,1024,32768]{2,1,0} parameter(1)
  param_2.1774 = f32[8]{0} parameter(2)
  constant.1893 = f32[] constant(3.7252903e-09)
  broadcast.2428 = f32[8]{0} broadcast(constant.1893), dimensions={}
  multiply.1518 = f32[8]{0} multiply(param_2.1774, broadcast.2428), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/div" source_file="/pax/praxis/praxis/optimizers.py" source_line=2064}
  sqrt.80 = f32[8]{0} sqrt(multiply.1518), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/sqrt" source_file="/pax/praxis/praxis/optimizers.py" source_line=2080}
  compare.581 = pred[8]{0} compare(sqrt.80, sqrt.80), direction=NE, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/jit(isnan)/ne" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  broadcast.2433 = f32[8]{0} broadcast(constant.1894), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/jit(_where)/broadcast_in_dim[shape=(8,) broadcast_dimensions=()]" source_file="/usr/local/lib/python3.10/dist-packages/optax/_src/schedule.py" source_line=399}
  select.873 = f32[8]{0} select(compare.581, broadcast.2433, sqrt.80), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/jit(_where)/select_n" source_file="/usr/local/lib/python3.10/dist-packages/optax/_src/schedule.py" source_line=399}
  broadcast.2432 = f32[8]{0} broadcast(constant.1895), dimensions={}
  compare.580 = pred[8]{0} compare(select.873, broadcast.2432), direction=EQ, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/eq" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  select.872 = f32[8]{0} select(compare.580, broadcast.2433, select.873), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/jit(_where)/select_n" source_file="/usr/local/lib/python3.10/dist-packages/optax/_src/schedule.py" source_line=399}
  broadcast.2431 = f32[8]{0} broadcast(constant.1896), dimensions={}
  compare.579 = pred[8]{0} compare(select.872, broadcast.2431), direction=EQ, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/eq" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  select.871 = f32[8]{0} select(compare.579, broadcast.2433, select.872), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/jit(_where)/select_n" source_file="/usr/local/lib/python3.10/dist-packages/optax/_src/schedule.py" source_line=399}
  constant.1898 = f32[] constant(1)
  broadcast.2434 = f32[8]{0} broadcast(constant.1898), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(_where))/broadcast_in_dim[shape=(8,) broadcast_dimensions=()]" source_file="/pax/praxis/praxis/schedules.py" source_line=105}
  maximum.65 = f32[8]{0} maximum(select.871, broadcast.2434), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/max" source_file="/pax/praxis/praxis/optimizers.py" source_line=346}
  broadcast.2427 = f32[8,1024,32768]{2,1,0} broadcast(maximum.65), dimensions={0}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/div" source_file="/pax/praxis/praxis/optimizers.py" source_line=347}
  multiply.1517 = f32[8,1024,32768]{2,1,0} multiply(param_1.2043, broadcast.2427)
  divide.196 = f32[8,1024,32768]{2,1,0} divide(add.1348, multiply.1517), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/div" source_file="/pax/praxis/praxis/optimizers.py" source_line=347}
  constant.1900 = f32[] constant(0.001)
  broadcast.2426 = f32[8,1024,32768]{2,1,0} broadcast(constant.1900), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=691}
  multiply.1516 = f32[8,1024,32768]{2,1,0} multiply(param_0.367, broadcast.2426), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=691}
  add.955 = f32[8,1024,32768]{2,1,0} add(divide.196, multiply.1516), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/add" source_file="/pax/praxis/praxis/optimizers.py" source_line=691}
  multiply.1514 = f32[8,1024,32768]{2,1,0} multiply(broadcast.2429, add.955), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=695}
  constant.1901 = f32[] constant(0)
  broadcast.2435 = f32[8,1024,32768]{2,1,0} broadcast(constant.1901), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/broadcast_in_dim[shape=(8, 8192, 32768) broadcast_dimensions=()]" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  select.870 = f32[8,1024,32768]{2,1,0} select(broadcast.2430, multiply.1514, broadcast.2435), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(_where)/select_n" source_file="/pax/paxml/paxml/learners.py" source_line=340}
  add.954 = f32[8,1024,32768]{2,1,0} add(param_0.367, select.870), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/add" source_file="/pax/paxml/paxml/learners.py" source_line=408}
  param_12.458 = f32[8,32768,1024]{2,1,0} parameter(12)
  broadcast.2387.clone.1 = pred[8,32768,1024]{2,1,0} broadcast(is-finite.50), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(_where)/broadcast_in_dim[shape=(8, 32768, 8192) broadcast_dimensions=()]" source_file="/pax/paxml/paxml/learners.py" source_line=340}
  broadcast.2385.clone.1 = f32[8,32768,1024]{2,1,0} broadcast(param_3.1560), dimensions={0}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=695}
  broadcast.4018.clone.1 = f32[8,32768,1024]{2,1,0} broadcast(param_11.282), dimensions={0}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=339}
  param_17.259 = f32[8,32768,1024]{2,1,0} parameter(17)
  param_19.133 = f32[32768,1024]{0,1} parameter(19)
  bitcast.8194 = f32[1,1024,32768]{2,1,0} bitcast(param_19.133)
  transpose.364 = f32[1,32768,1024]{2,1,0} transpose(bitcast.8194), dimensions={0,2,1}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/broadcast_in_dim[shape=(1, 32768, 8192) broadcast_dimensions=(1, 2)]" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  param_18.228 = s32[] parameter(18)
  dynamic-update-slice.367 = f32[8,32768,1024]{2,1,0} dynamic-update-slice(param_17.259, transpose.364, param_18.228, constant.3624, constant.3624)
  param_16.279 = f32[32768,1024]{0,1} parameter(16)
  bitcast.8010.clone.1 = f32[1,1024,32768]{2,1,0} bitcast(param_16.279)
  transpose.326.clone.1 = f32[1,32768,1024]{2,1,0} transpose(bitcast.8010.clone.1), dimensions={0,2,1}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/broadcast_in_dim[shape=(1, 32768, 8192) broadcast_dimensions=(1, 2)]" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  dynamic-update-slice.219.clone.1 = f32[8,32768,1024]{2,1,0} dynamic-update-slice(dynamic-update-slice.367, transpose.326.clone.1, select.1461, constant.3624, constant.3624), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  broadcast.4017.clone.1 = f32[8,32768,1024]{2,1,0} broadcast(param_7.474), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/paxml/paxml/learners.py" source_line=266}
  multiply.2371.clone.1 = f32[8,32768,1024]{2,1,0} multiply(dynamic-update-slice.219.clone.1, broadcast.4017.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/paxml/paxml/learners.py" source_line=266}
  compare.1295.clone.1 = pred[8,32768,1024]{2,1,0} compare(multiply.2371.clone.1, multiply.2371.clone.1), direction=NE, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/jit(isnan)/ne" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  broadcast.4015.clone.1 = f32[8,32768,1024]{2,1,0} broadcast(constant.1894), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/jit(_where)/broadcast_in_dim[shape=(8, 32768, 8192) broadcast_dimensions=(1, 2)]" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  select.1593.clone.1 = f32[8,32768,1024]{2,1,0} select(compare.1295.clone.1, broadcast.4015.clone.1, multiply.2371.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/jit(_where)/select_n" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  broadcast.4013.clone.1 = f32[8,32768,1024]{2,1,0} broadcast(constant.1895), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/eq" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  compare.1294.clone.1 = pred[8,32768,1024]{2,1,0} compare(select.1593.clone.1, broadcast.4013.clone.1), direction=EQ, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/eq" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  select.1592.clone.1 = f32[8,32768,1024]{2,1,0} select(compare.1294.clone.1, broadcast.4015.clone.1, select.1593.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/jit(_where)/select_n" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  broadcast.4012.clone.1 = f32[8,32768,1024]{2,1,0} broadcast(constant.1896), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/eq" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  compare.1293.clone.1 = pred[8,32768,1024]{2,1,0} compare(select.1592.clone.1, broadcast.4012.clone.1), direction=EQ, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/eq" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  select.1591.clone.1 = f32[8,32768,1024]{2,1,0} select(compare.1293.clone.1, broadcast.4015.clone.1, select.1592.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/jit(_where)/select_n" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  multiply.2370.clone.1 = f32[8,32768,1024]{2,1,0} multiply(broadcast.4018.clone.1, select.1591.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=339}
  broadcast.4010.clone.1 = f32[8,32768,1024]{2,1,0} broadcast(param_6.617), dimensions={0}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=339}
  param_15.191 = f32[8,32768,1024]{2,1,0} parameter(15)
  multiply.2369.clone.1 = f32[8,32768,1024]{2,1,0} multiply(broadcast.4010.clone.1, param_15.191), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=339}
  add.1379.clone.1 = f32[8,32768,1024]{2,1,0} add(multiply.2370.clone.1, multiply.2369.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/add" source_file="/pax/praxis/praxis/optimizers.py" source_line=339}
  param_13.266 = f32[8,32768,1024]{2,1,0} parameter(13)
  param_14.204 = f32[8]{0} parameter(14)
  multiply.1489.clone.1 = f32[8]{0} multiply(param_14.204, broadcast.2428), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/div" source_file="/pax/praxis/praxis/optimizers.py" source_line=2064}
  sqrt.76.clone.1 = f32[8]{0} sqrt(multiply.1489.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/sqrt" source_file="/pax/praxis/praxis/optimizers.py" source_line=2080}
  compare.569.clone.1 = pred[8]{0} compare(sqrt.76.clone.1, sqrt.76.clone.1), direction=NE, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/jit(isnan)/ne" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  select.859.clone.1 = f32[8]{0} select(compare.569.clone.1, broadcast.2433, sqrt.76.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/jit(_where)/select_n" source_file="/usr/local/lib/python3.10/dist-packages/optax/_src/schedule.py" source_line=399}
  compare.568.clone.1 = pred[8]{0} compare(select.859.clone.1, broadcast.2432), direction=EQ, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/eq" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  select.858.clone.1 = f32[8]{0} select(compare.568.clone.1, broadcast.2433, select.859.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/jit(_where)/select_n" source_file="/usr/local/lib/python3.10/dist-packages/optax/_src/schedule.py" source_line=399}
  compare.567.clone.1 = pred[8]{0} compare(select.858.clone.1, broadcast.2431), direction=EQ, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/eq" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  select.857.clone.1 = f32[8]{0} select(compare.567.clone.1, broadcast.2433, select.858.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/jit(_where)/select_n" source_file="/usr/local/lib/python3.10/dist-packages/optax/_src/schedule.py" source_line=399}
  maximum.63.clone.1 = f32[8]{0} maximum(select.857.clone.1, broadcast.2434), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/max" source_file="/pax/praxis/praxis/optimizers.py" source_line=346}
  broadcast.2383.clone.1 = f32[8,32768,1024]{2,1,0} broadcast(maximum.63.clone.1), dimensions={0}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/div" source_file="/pax/praxis/praxis/optimizers.py" source_line=347}
  multiply.1488.clone.1 = f32[8,32768,1024]{2,1,0} multiply(param_13.266, broadcast.2383.clone.1)
  divide.192.clone.1 = f32[8,32768,1024]{2,1,0} divide(add.1379.clone.1, multiply.1488.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/div" source_file="/pax/praxis/praxis/optimizers.py" source_line=347}
  broadcast.2381.clone.1 = f32[8,32768,1024]{2,1,0} broadcast(constant.1900), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=691}
  multiply.1487.clone.1 = f32[8,32768,1024]{2,1,0} multiply(param_12.458, broadcast.2381.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=691}
  add.944.clone.1 = f32[8,32768,1024]{2,1,0} add(divide.192.clone.1, multiply.1487.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/add" source_file="/pax/praxis/praxis/optimizers.py" source_line=691}
  multiply.1486.clone.1 = f32[8,32768,1024]{2,1,0} multiply(broadcast.2385.clone.1, add.944.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=695}
  broadcast.2379.clone.1 = f32[8,32768,1024]{2,1,0} broadcast(constant.1901), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/broadcast_in_dim[shape=(8, 32768, 8192) broadcast_dimensions=()]" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  select.856.clone.1 = f32[8,32768,1024]{2,1,0} select(broadcast.2387.clone.1, multiply.1486.clone.1, broadcast.2379.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(_where)/select_n" source_file="/pax/paxml/paxml/learners.py" source_line=340}
  add.942.clone.1 = f32[8,32768,1024]{2,1,0} add(param_12.458, select.856.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/add" source_file="/pax/paxml/paxml/learners.py" source_line=408}
  ROOT tuple.73 = (f32[8,1024,32768]{2,1,0}, f32[8,32768,1024]{2,1,0}) tuple(add.954, add.942.clone.1)
} // fused_computation.186

fused_computation.187 {
  param_6.1249 = f32[8]{0} parameter(6)
  broadcast.3839 = f32[8,1024,32768]{2,1,0} broadcast(param_6.1249), dimensions={0}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=339}
  param_3.2054 = f32[8,1024,32768]{2,1,0} parameter(3)
  param_5.1584 = f32[1024,32768]{1,0} parameter(5)
  bitcast.7982 = f32[1,1024,32768]{2,1,0} bitcast(param_5.1584)
  constant.3657 = s32[] constant(7)
  param_4.1796 = s32[] parameter(4)
  subtract.768 = s32[] subtract(constant.3657, param_4.1796), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  constant.3654 = s32[] constant(0)
  compare.1172 = pred[] compare(subtract.768, constant.3654), direction=LT, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/lt" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  constant.3655 = s32[] constant(15)
  subtract.767 = s32[] subtract(constant.3655, param_4.1796), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/add" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  select.1477 = s32[] select(compare.1172, subtract.767, subtract.768), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/select_n" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  dynamic-update-slice.191 = f32[8,1024,32768]{2,1,0} dynamic-update-slice(param_3.2054, bitcast.7982, select.1477, constant.3654, constant.3654), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  param_2.2073 = f32[] parameter(2)
  broadcast.3837 = f32[8,1024,32768]{2,1,0} broadcast(param_2.2073), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/paxml/paxml/learners.py" source_line=266}
  multiply.2285 = f32[8,1024,32768]{2,1,0} multiply(dynamic-update-slice.191, broadcast.3837), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/paxml/paxml/learners.py" source_line=266}
  compare.1171 = pred[8,1024,32768]{2,1,0} compare(multiply.2285, multiply.2285), direction=NE, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/jit(isnan)/ne" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  constant.3653 = f32[] constant(nan)
  broadcast.3835 = f32[8,1024,32768]{2,1,0} broadcast(constant.3653), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/jit(_where)/broadcast_in_dim[shape=(8, 8192, 32768) broadcast_dimensions=(1, 2)]" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  select.1476 = f32[8,1024,32768]{2,1,0} select(compare.1171, broadcast.3835, multiply.2285), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/jit(_where)/select_n" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  constant.3652 = f32[] constant(inf)
  broadcast.3834 = f32[8,1024,32768]{2,1,0} broadcast(constant.3652), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/eq" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  compare.1170 = pred[8,1024,32768]{2,1,0} compare(select.1476, broadcast.3834), direction=EQ, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/eq" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  select.1475 = f32[8,1024,32768]{2,1,0} select(compare.1170, broadcast.3835, select.1476), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/jit(_where)/select_n" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  constant.3651 = f32[] constant(-inf)
  broadcast.3833 = f32[8,1024,32768]{2,1,0} broadcast(constant.3651), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/eq" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  compare.1169 = pred[8,1024,32768]{2,1,0} compare(select.1475, broadcast.3833), direction=EQ, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/eq" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  select.1474 = f32[8,1024,32768]{2,1,0} select(compare.1169, broadcast.3835, select.1475), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/jit(_where)/select_n" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  multiply.2284 = f32[8,1024,32768]{2,1,0} multiply(broadcast.3839, select.1474), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=339}
  param_1.2292 = f32[8]{0} parameter(1)
  broadcast.3832 = f32[8,1024,32768]{2,1,0} broadcast(param_1.2292), dimensions={0}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=339}
  param_0.1663 = f32[8,1024,32768]{2,1,0} parameter(0)
  multiply.2283 = f32[8,1024,32768]{2,1,0} multiply(broadcast.3832, param_0.1663), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=339}
  add.1352 = f32[8,1024,32768]{2,1,0} add(multiply.2284, multiply.2283), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/add" source_file="/pax/praxis/praxis/optimizers.py" source_line=339}
  param_10.633 = f32[8]{0} parameter(10)
  broadcast.3865.clone.1 = f32[8,1024,32768]{2,1,0} broadcast(param_10.633), dimensions={0}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=340}
  multiply.2302.clone.1 = f32[8,1024,32768]{2,1,0} multiply(select.1474, select.1474), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=340}
  multiply.2300.clone.1 = f32[8,1024,32768]{2,1,0} multiply(broadcast.3865.clone.1, multiply.2302.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=340}
  param_9.745 = f32[8]{0} parameter(9)
  broadcast.3859.clone.1 = f32[8,1024,32768]{2,1,0} broadcast(param_9.745), dimensions={0}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=340}
  param_8.856 = f32[8,1024,32768]{2,1,0} parameter(8)
  multiply.2298.clone.1 = f32[8,1024,32768]{2,1,0} multiply(broadcast.3859.clone.1, param_8.856), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=340}
  add.1356.clone.1 = f32[8,1024,32768]{2,1,0} add(multiply.2300.clone.1, multiply.2298.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/add" source_file="/pax/praxis/praxis/optimizers.py" source_line=340}
  sqrt.81.clone.1 = f32[8,1024,32768]{2,1,0} sqrt(add.1356.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/sqrt" source_file="/pax/praxis/praxis/optimizers.py" source_line=684}
  constant.1903.clone.1 = f32[] constant(1e-06)
  broadcast.2437.clone.1 = f32[8,1024,32768]{2,1,0} broadcast(constant.1903.clone.1), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/add" source_file="/pax/praxis/praxis/optimizers.py" source_line=684}
  add.956.clone.1 = f32[8,1024,32768]{2,1,0} add(sqrt.81.clone.1, broadcast.2437.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/add" source_file="/pax/praxis/praxis/optimizers.py" source_line=684}
  divide.197 = f32[8,1024,32768]{2,1,0} divide(add.1352, add.956.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/div" source_file="/pax/praxis/praxis/optimizers.py" source_line=684}
  multiply.1519 = f32[8,1024,32768]{2,1,0} multiply(divide.197, divide.197), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=2078}
  bitcast.7425 = f32[8,4096,8192]{2,1,0} bitcast(multiply.1519), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=2078}
  constant.1902 = f32[] constant(0)
  reduce.340 = f32[8,4096]{1,0} reduce(bitcast.7425, constant.1902), dimensions={2}, to_apply=region_15.791, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/reduce_sum[axes=(1,)]" source_file="/pax/praxis/praxis/optimizers.py" source_line=2063}
  param_7.893 = f32[] parameter(7)
  is-finite.24.clone.1 = pred[] is-finite(param_7.893), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(isfinite)/is_finite" source_file="/pax/paxml/paxml/learners.py" source_line=256}
  broadcast.2228.clone.1 = pred[8,1024,32768]{2,1,0} broadcast(is-finite.24.clone.1), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(_where)/broadcast_in_dim[shape=(8, 8192, 32768) broadcast_dimensions=()]" source_file="/pax/paxml/paxml/learners.py" source_line=340}
  select.790.clone.1 = f32[8,1024,32768]{2,1,0} select(broadcast.2228.clone.1, add.1352, param_0.1663), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(_where)/select_n" source_file="/pax/paxml/paxml/learners.py" source_line=340}
  select.779.clone.1 = f32[8,1024,32768]{2,1,0} select(broadcast.2228.clone.1, add.1356.clone.1, param_8.856), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(_where)/select_n" source_file="/pax/paxml/paxml/learners.py" source_line=340}
  broadcast.4083.clone.1 = f32[8,32768,1024]{2,1,0} broadcast(param_10.633), dimensions={0}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=340}
  param_13.329 = f32[8,32768,1024]{2,1,0} parameter(13)
  param_15.245 = f32[32768,1024]{0,1} parameter(15)
  bitcast.8192 = f32[1,1024,32768]{2,1,0} bitcast(param_15.245)
  transpose.362 = f32[1,32768,1024]{2,1,0} transpose(bitcast.8192), dimensions={0,2,1}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/broadcast_in_dim[shape=(1, 32768, 8192) broadcast_dimensions=(1, 2)]" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  param_14.284 = s32[] parameter(14)
  dynamic-update-slice.365 = f32[8,32768,1024]{2,1,0} dynamic-update-slice(param_13.329, transpose.362, param_14.284, constant.3654, constant.3654)
  param_12.534 = f32[32768,1024]{0,1} parameter(12)
  bitcast.8018.clone.1 = f32[1,1024,32768]{2,1,0} bitcast(param_12.534)
  transpose.334.clone.1 = f32[1,32768,1024]{2,1,0} transpose(bitcast.8018.clone.1), dimensions={0,2,1}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/broadcast_in_dim[shape=(1, 32768, 8192) broadcast_dimensions=(1, 2)]" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  dynamic-update-slice.227.clone.1 = f32[8,32768,1024]{2,1,0} dynamic-update-slice(dynamic-update-slice.365, transpose.334.clone.1, select.1477, constant.3654, constant.3654), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  broadcast.4081.clone.1 = f32[8,32768,1024]{2,1,0} broadcast(param_2.2073), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/paxml/paxml/learners.py" source_line=266}
  multiply.2405.clone.1 = f32[8,32768,1024]{2,1,0} multiply(dynamic-update-slice.227.clone.1, broadcast.4081.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/paxml/paxml/learners.py" source_line=266}
  compare.1328.clone.1 = pred[8,32768,1024]{2,1,0} compare(multiply.2405.clone.1, multiply.2405.clone.1), direction=NE, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/jit(isnan)/ne" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  broadcast.4080.clone.1 = f32[8,32768,1024]{2,1,0} broadcast(constant.3653), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/jit(_where)/broadcast_in_dim[shape=(8, 32768, 8192) broadcast_dimensions=(1, 2)]" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  select.1631.clone.1 = f32[8,32768,1024]{2,1,0} select(compare.1328.clone.1, broadcast.4080.clone.1, multiply.2405.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/jit(_where)/select_n" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  broadcast.4079.clone.1 = f32[8,32768,1024]{2,1,0} broadcast(constant.3652), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/eq" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  compare.1327.clone.1 = pred[8,32768,1024]{2,1,0} compare(select.1631.clone.1, broadcast.4079.clone.1), direction=EQ, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/eq" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  select.1630.clone.1 = f32[8,32768,1024]{2,1,0} select(compare.1327.clone.1, broadcast.4080.clone.1, select.1631.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/jit(_where)/select_n" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  broadcast.4078.clone.1 = f32[8,32768,1024]{2,1,0} broadcast(constant.3651), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/eq" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  compare.1326.clone.1 = pred[8,32768,1024]{2,1,0} compare(select.1630.clone.1, broadcast.4078.clone.1), direction=EQ, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/eq" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  select.1629.clone.1 = f32[8,32768,1024]{2,1,0} select(compare.1326.clone.1, broadcast.4080.clone.1, select.1630.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/jit(_where)/select_n" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  multiply.2404.clone.1 = f32[8,32768,1024]{2,1,0} multiply(select.1629.clone.1, select.1629.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=340}
  multiply.2403.clone.1 = f32[8,32768,1024]{2,1,0} multiply(broadcast.4083.clone.1, multiply.2404.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=340}
  broadcast.4077.clone.1 = f32[8,32768,1024]{2,1,0} broadcast(param_9.745), dimensions={0}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=340}
  param_11.571 = f32[8,32768,1024]{2,1,0} parameter(11)
  multiply.2402.clone.1 = f32[8,32768,1024]{2,1,0} multiply(broadcast.4077.clone.1, param_11.571), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=340}
  add.1388.clone.1 = f32[8,32768,1024]{2,1,0} add(multiply.2403.clone.1, multiply.2402.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/add" source_file="/pax/praxis/praxis/optimizers.py" source_line=340}
  sqrt.77.clone.1 = f32[8,32768,1024]{2,1,0} sqrt(add.1388.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/sqrt" source_file="/pax/praxis/praxis/optimizers.py" source_line=684}
  broadcast.2393.clone.1 = f32[8,32768,1024]{2,1,0} broadcast(constant.1903.clone.1), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/add" source_file="/pax/praxis/praxis/optimizers.py" source_line=684}
  add.945.clone.1 = f32[8,32768,1024]{2,1,0} add(sqrt.77.clone.1, broadcast.2393.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/add" source_file="/pax/praxis/praxis/optimizers.py" source_line=684}
  broadcast.2215.clone.1.clone.1 = pred[8,32768,1024]{2,1,0} broadcast(is-finite.24.clone.1), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(_where)/broadcast_in_dim[shape=(8, 32768, 8192) broadcast_dimensions=()]" source_file="/pax/paxml/paxml/learners.py" source_line=340}
  select.777.clone.1.clone.1 = f32[8,32768,1024]{2,1,0} select(broadcast.2215.clone.1.clone.1, add.1388.clone.1, param_11.571), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(_where)/select_n" source_file="/pax/paxml/paxml/learners.py" source_line=340}
  ROOT tuple.74 = (f32[8,4096]{1,0}, f32[8,1024,32768]{2,1,0}, f32[8,1024,32768]{2,1,0}, f32[8,1024,32768]{2,1,0}, f32[8,32768,1024]{2,1,0}, /*index=5*/f32[8,32768,1024]{2,1,0}) tuple(reduce.340, select.790.clone.1, add.956.clone.1, select.779.clone.1, add.945.clone.1, /*index=5*/select.777.clone.1.clone.1)
} // fused_computation.187

fused_computation.192 {
  param_0.379 = f32[8,32768]{1,0} parameter(0)
  param_3.1544 = f32[] parameter(3)
  is-finite.51 = pred[] is-finite(param_3.1544), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(isfinite)/is_finite" source_file="/pax/paxml/paxml/learners.py" source_line=256}
  broadcast.2459 = pred[8,32768]{1,0} broadcast(is-finite.51), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(_where)/broadcast_in_dim[shape=(8, 32768) broadcast_dimensions=()]" source_file="/pax/paxml/paxml/learners.py" source_line=340}
  param_2.1768 = f32[8]{0} parameter(2)
  broadcast.2455 = f32[8,32768]{1,0} broadcast(param_2.1768), dimensions={0}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=695}
  param_10.322 = f32[8]{0} parameter(10)
  broadcast.3690 = f32[8,32768]{1,0} broadcast(param_10.322), dimensions={0}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=339}
  param_7.460 = f32[8,32768]{1,0} parameter(7)
  param_9.369 = f32[32768]{0} parameter(9)
  bitcast.7960 = f32[1,32768]{1,0} bitcast(param_9.369)
  constant.3482 = s32[] constant(7)
  param_8.408 = s32[] parameter(8)
  subtract.722 = s32[] subtract(constant.3482, param_8.408), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  constant.3479 = s32[] constant(0)
  compare.1084 = pred[] compare(subtract.722, constant.3479), direction=LT, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/lt" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  constant.3480 = s32[] constant(15)
  subtract.721 = s32[] subtract(constant.3480, param_8.408), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/add" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  select.1389 = s32[] select(compare.1084, subtract.721, subtract.722), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/select_n" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  dynamic-update-slice.169 = f32[8,32768]{1,0} dynamic-update-slice(param_7.460, bitcast.7960, select.1389, constant.3479), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  param_6.602 = f32[] parameter(6)
  broadcast.3689 = f32[8,32768]{1,0} broadcast(param_6.602), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/paxml/paxml/learners.py" source_line=266}
  multiply.2218 = f32[8,32768]{1,0} multiply(dynamic-update-slice.169, broadcast.3689), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/paxml/paxml/learners.py" source_line=266}
  compare.1083 = pred[8,32768]{1,0} compare(multiply.2218, multiply.2218), direction=NE, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/jit(isnan)/ne" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  constant.1907 = f32[] constant(nan)
  broadcast.3688 = f32[8,32768]{1,0} broadcast(constant.1907), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/jit(_where)/broadcast_in_dim[shape=(8, 32768) broadcast_dimensions=(1,)]" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  select.1388 = f32[8,32768]{1,0} select(compare.1083, broadcast.3688, multiply.2218), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/jit(_where)/select_n" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  constant.1908 = f32[] constant(inf)
  broadcast.3687 = f32[8,32768]{1,0} broadcast(constant.1908), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/eq" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  compare.1082 = pred[8,32768]{1,0} compare(select.1388, broadcast.3687), direction=EQ, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/eq" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  select.1387 = f32[8,32768]{1,0} select(compare.1082, broadcast.3688, select.1388), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/jit(_where)/select_n" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  constant.1909 = f32[] constant(-inf)
  broadcast.3686 = f32[8,32768]{1,0} broadcast(constant.1909), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/eq" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  compare.1081 = pred[8,32768]{1,0} compare(select.1387, broadcast.3686), direction=EQ, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/eq" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  select.1386 = f32[8,32768]{1,0} select(compare.1081, broadcast.3688, select.1387), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/jit(_where)/select_n" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  multiply.2217 = f32[8,32768]{1,0} multiply(broadcast.3690, select.1386), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=339}
  param_5.834 = f32[8]{0} parameter(5)
  broadcast.3685 = f32[8,32768]{1,0} broadcast(param_5.834), dimensions={0}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=339}
  param_4.1112 = f32[8,32768]{1,0} parameter(4)
  multiply.2216 = f32[8,32768]{1,0} multiply(broadcast.3685, param_4.1112), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=339}
  add.1329 = f32[8,32768]{1,0} add(multiply.2217, multiply.2216), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/add" source_file="/pax/praxis/praxis/optimizers.py" source_line=339}
  param_13.57 = f32[8]{0} parameter(13)
  broadcast.3778 = f32[8,32768]{1,0} broadcast(param_13.57), dimensions={0}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=340}
  multiply.2262 = f32[8,32768]{1,0} multiply(select.1386, select.1386), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=340}
  multiply.2261 = f32[8,32768]{1,0} multiply(broadcast.3778, multiply.2262), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=340}
  param_12.171 = f32[8]{0} parameter(12)
  broadcast.3772 = f32[8,32768]{1,0} broadcast(param_12.171), dimensions={0}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=340}
  param_11.276 = f32[8,32768]{1,0} parameter(11)
  multiply.2260 = f32[8,32768]{1,0} multiply(broadcast.3772, param_11.276), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=340}
  add.1346 = f32[8,32768]{1,0} add(multiply.2261, multiply.2260), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/add" source_file="/pax/praxis/praxis/optimizers.py" source_line=340}
  sqrt.108 = f32[8,32768]{1,0} sqrt(add.1346), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/sqrt" source_file="/pax/praxis/praxis/optimizers.py" source_line=684}
  constant.3573 = f32[] constant(1e-06)
  broadcast.3770 = f32[8,32768]{1,0} broadcast(constant.3573), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/add" source_file="/pax/praxis/praxis/optimizers.py" source_line=684}
  add.1345 = f32[8,32768]{1,0} add(sqrt.108, broadcast.3770), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/add" source_file="/pax/praxis/praxis/optimizers.py" source_line=684}
  param_1.2039 = f32[8]{0} parameter(1)
  constant.1659 = f32[] constant(3.05175781e-05)
  broadcast.2454 = f32[8]{0} broadcast(constant.1659), dimensions={}
  multiply.1529 = f32[8]{0} multiply(param_1.2039, broadcast.2454), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/div" source_file="/pax/praxis/praxis/optimizers.py" source_line=2066}
  sqrt.82 = f32[8]{0} sqrt(multiply.1529), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/sqrt" source_file="/pax/praxis/praxis/optimizers.py" source_line=2080}
  compare.587 = pred[8]{0} compare(sqrt.82, sqrt.82), direction=NE, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/jit(isnan)/ne" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  broadcast.2453 = f32[8]{0} broadcast(constant.1907), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/jit(_where)/broadcast_in_dim[shape=(8,) broadcast_dimensions=()]" source_file="/usr/local/lib/python3.10/dist-packages/optax/_src/schedule.py" source_line=399}
  select.880 = f32[8]{0} select(compare.587, broadcast.2453, sqrt.82), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/jit(_where)/select_n" source_file="/usr/local/lib/python3.10/dist-packages/optax/_src/schedule.py" source_line=399}
  broadcast.2452 = f32[8]{0} broadcast(constant.1908), dimensions={}
  compare.586 = pred[8]{0} compare(select.880, broadcast.2452), direction=EQ, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/eq" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  select.879 = f32[8]{0} select(compare.586, broadcast.2453, select.880), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/jit(_where)/select_n" source_file="/usr/local/lib/python3.10/dist-packages/optax/_src/schedule.py" source_line=399}
  broadcast.2451 = f32[8]{0} broadcast(constant.1909), dimensions={}
  compare.585 = pred[8]{0} compare(select.879, broadcast.2451), direction=EQ, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/eq" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  select.878 = f32[8]{0} select(compare.585, broadcast.2453, select.879), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/jit(_where)/select_n" source_file="/usr/local/lib/python3.10/dist-packages/optax/_src/schedule.py" source_line=399}
  constant.1910 = f32[] constant(1)
  broadcast.2457 = f32[8]{0} broadcast(constant.1910), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(_where))/broadcast_in_dim[shape=(8,) broadcast_dimensions=()]" source_file="/pax/praxis/praxis/schedules.py" source_line=105}
  maximum.66 = f32[8]{0} maximum(select.878, broadcast.2457), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/max" source_file="/pax/praxis/praxis/optimizers.py" source_line=346}
  broadcast.2450 = f32[8,32768]{1,0} broadcast(maximum.66), dimensions={0}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/div" source_file="/pax/praxis/praxis/optimizers.py" source_line=347}
  multiply.1528 = f32[8,32768]{1,0} multiply(add.1345, broadcast.2450)
  divide.198 = f32[8,32768]{1,0} divide(add.1329, multiply.1528), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/div" source_file="/pax/praxis/praxis/optimizers.py" source_line=347}
  constant.1911 = f32[] constant(0.001)
  broadcast.2449 = f32[8,32768]{1,0} broadcast(constant.1911), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=691}
  multiply.1527 = f32[8,32768]{1,0} multiply(param_0.379, broadcast.2449), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=691}
  add.961 = f32[8,32768]{1,0} add(divide.198, multiply.1527), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/add" source_file="/pax/praxis/praxis/optimizers.py" source_line=691}
  multiply.1526 = f32[8,32768]{1,0} multiply(broadcast.2455, add.961), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=695}
  constant.1912 = f32[] constant(0)
  broadcast.2447 = f32[8,32768]{1,0} broadcast(constant.1912), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/broadcast_in_dim[shape=(8, 32768) broadcast_dimensions=()]" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  select.877 = f32[8,32768]{1,0} select(broadcast.2459, multiply.1526, broadcast.2447), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(_where)/select_n" source_file="/pax/paxml/paxml/learners.py" source_line=340}
  add.960 = f32[8,32768]{1,0} add(param_0.379, select.877), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/add" source_file="/pax/paxml/paxml/learners.py" source_line=408}
  select.780.clone.1 = f32[8,32768]{1,0} select(broadcast.2459, add.1346, param_11.276), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(_where)/select_n" source_file="/pax/paxml/paxml/learners.py" source_line=340}
  select.791.clone.1 = f32[8,32768]{1,0} select(broadcast.2459, add.1329, param_4.1112), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(_where)/select_n" source_file="/pax/paxml/paxml/learners.py" source_line=340}
  ROOT tuple.81 = (f32[8,32768]{1,0}, f32[8,32768]{1,0}, f32[8,32768]{1,0}) tuple(add.960, select.780.clone.1, select.791.clone.1)
} // fused_computation.192

fused_computation.193 {
  param_6.600 = f32[8]{0} parameter(6)
  broadcast.3719 = f32[8,32768]{1,0} broadcast(param_6.600), dimensions={0}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=339}
  param_3.1542 = f32[8,32768]{1,0} parameter(3)
  param_5.832 = f32[32768]{0} parameter(5)
  bitcast.7964 = f32[1,32768]{1,0} bitcast(param_5.832)
  constant.3514 = s32[] constant(7)
  param_4.1110 = s32[] parameter(4)
  subtract.731 = s32[] subtract(constant.3514, param_4.1110), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  constant.3511 = s32[] constant(0)
  compare.1100 = pred[] compare(subtract.731, constant.3511), direction=LT, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/lt" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  constant.3512 = s32[] constant(15)
  subtract.730 = s32[] subtract(constant.3512, param_4.1110), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/add" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  select.1405 = s32[] select(compare.1100, subtract.730, subtract.731), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/select_n" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  dynamic-update-slice.173 = f32[8,32768]{1,0} dynamic-update-slice(param_3.1542, bitcast.7964, select.1405, constant.3511), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  param_2.1766 = f32[] parameter(2)
  broadcast.3718 = f32[8,32768]{1,0} broadcast(param_2.1766), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/paxml/paxml/learners.py" source_line=266}
  multiply.2230 = f32[8,32768]{1,0} multiply(dynamic-update-slice.173, broadcast.3718), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/paxml/paxml/learners.py" source_line=266}
  compare.1099 = pred[8,32768]{1,0} compare(multiply.2230, multiply.2230), direction=NE, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/jit(isnan)/ne" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  constant.3510 = f32[] constant(nan)
  broadcast.3717 = f32[8,32768]{1,0} broadcast(constant.3510), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/jit(_where)/broadcast_in_dim[shape=(8, 32768) broadcast_dimensions=(1,)]" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  select.1404 = f32[8,32768]{1,0} select(compare.1099, broadcast.3717, multiply.2230), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/jit(_where)/select_n" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  constant.3509 = f32[] constant(inf)
  broadcast.3715 = f32[8,32768]{1,0} broadcast(constant.3509), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/eq" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  compare.1098 = pred[8,32768]{1,0} compare(select.1404, broadcast.3715), direction=EQ, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/eq" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  select.1403 = f32[8,32768]{1,0} select(compare.1098, broadcast.3717, select.1404), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/jit(_where)/select_n" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  constant.3508 = f32[] constant(-inf)
  broadcast.3713 = f32[8,32768]{1,0} broadcast(constant.3508), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/eq" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  compare.1097 = pred[8,32768]{1,0} compare(select.1403, broadcast.3713), direction=EQ, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/eq" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  select.1402 = f32[8,32768]{1,0} select(compare.1097, broadcast.3717, select.1403), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(nan_to_num))/jit(_where)/select_n" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  multiply.2229 = f32[8,32768]{1,0} multiply(broadcast.3719, select.1402), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=339}
  param_1.2037 = f32[8]{0} parameter(1)
  broadcast.3712 = f32[8,32768]{1,0} broadcast(param_1.2037), dimensions={0}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=339}
  param_0.1498 = f32[8,32768]{1,0} parameter(0)
  multiply.2228 = f32[8,32768]{1,0} multiply(broadcast.3712, param_0.1498), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=339}
  add.1333 = f32[8,32768]{1,0} add(multiply.2229, multiply.2228), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/add" source_file="/pax/praxis/praxis/optimizers.py" source_line=339}
  param_9.368 = f32[8]{0} parameter(9)
  broadcast.3761 = f32[8,32768]{1,0} broadcast(param_9.368), dimensions={0}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=340}
  multiply.2254 = f32[8,32768]{1,0} multiply(select.1402, select.1402), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=340}
  multiply.2253 = f32[8,32768]{1,0} multiply(broadcast.3761, multiply.2254), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=340}
  param_8.407 = f32[8]{0} parameter(8)
  broadcast.3755 = f32[8,32768]{1,0} broadcast(param_8.407), dimensions={0}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=340}
  param_7.459 = f32[8,32768]{1,0} parameter(7)
  multiply.2252 = f32[8,32768]{1,0} multiply(broadcast.3755, param_7.459), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=340}
  add.1342 = f32[8,32768]{1,0} add(multiply.2253, multiply.2252), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/add" source_file="/pax/praxis/praxis/optimizers.py" source_line=340}
  sqrt.106 = f32[8,32768]{1,0} sqrt(add.1342), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/sqrt" source_file="/pax/praxis/praxis/optimizers.py" source_line=684}
  constant.3554 = f32[] constant(1e-06)
  broadcast.3754 = f32[8,32768]{1,0} broadcast(constant.3554), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/add" source_file="/pax/praxis/praxis/optimizers.py" source_line=684}
  add.1341 = f32[8,32768]{1,0} add(sqrt.106, broadcast.3754), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/add" source_file="/pax/praxis/praxis/optimizers.py" source_line=684}
  divide.199 = f32[8,32768]{1,0} divide(add.1333, add.1341), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/div" source_file="/pax/praxis/praxis/optimizers.py" source_line=684}
  multiply.1530 = f32[8,32768]{1,0} multiply(divide.199, divide.199), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=2078}
  bitcast.7426 = f32[8,128,256]{2,1,0} bitcast(multiply.1530), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=2078}
  constant.1925 = f32[] constant(0)
  ROOT reduce.341 = f32[8,128]{1,0} reduce(bitcast.7426, constant.1925), dimensions={2}, to_apply=region_15.791, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/reduce_sum[axes=(1,)]" source_file="/pax/praxis/praxis/optimizers.py" source_line=2066}
} // fused_computation.193

fused_computation.200 {
  constant.1930 = f32[] constant(1)
  broadcast.2472 = f32[8]{0} broadcast(constant.1930), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(_where))/broadcast_in_dim[shape=(8,) broadcast_dimensions=()]" source_file="/pax/praxis/praxis/schedules.py" source_line=105}
  constant.1935.clone.1 = f32[] constant(0.9)
  broadcast.2474.clone.1 = f32[8]{0} broadcast(constant.1935.clone.1), dimensions={}
  param_0.1669 = s32[8]{0} parameter(0)
  convert.92.clone.1 = f32[8]{0} convert(param_0.1669), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/convert_element_type[new_dtype=float32 weak_type=False]" source_file="/pax/praxis/praxis/schedules.py" source_line=96}
  power.71.clone.1 = f32[8]{0} power(broadcast.2474.clone.1, convert.92.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/pow" source_file="/pax/praxis/praxis/optimizers.py" source_line=331}
  subtract.311.clone.1 = f32[8]{0} subtract(broadcast.2472, power.71.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/sub" source_file="/pax/praxis/praxis/optimizers.py" source_line=331}
  multiply.1541.clone.1 = f32[8]{0} multiply(subtract.311.clone.1, broadcast.2474.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=331}
  add.1327.clone.1 = f32[8]{0} add(convert.92.clone.1, broadcast.2472), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/add" source_file="/pax/praxis/praxis/optimizers.py" source_line=330}
  power.70.clone.1 = f32[8]{0} power(broadcast.2474.clone.1, add.1327.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/pow" source_file="/pax/praxis/praxis/optimizers.py" source_line=331}
  subtract.310.clone.1 = f32[8]{0} subtract(broadcast.2472, power.70.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/sub" source_file="/pax/praxis/praxis/optimizers.py" source_line=331}
  divide.201.clone.1 = f32[8]{0} divide(multiply.1541.clone.1, subtract.310.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/div" source_file="/pax/praxis/praxis/optimizers.py" source_line=331}
  subtract.309 = f32[8]{0} subtract(broadcast.2472, divide.201.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/sub" source_file="/pax/praxis/praxis/optimizers.py" source_line=339}
  constant.1928.clone.1.clone.1 = f32[] constant(0.99)
  broadcast.2464.clone.1.clone.1 = f32[8]{0} broadcast(constant.1928.clone.1.clone.1), dimensions={}
  power.69.clone.1.clone.1 = f32[8]{0} power(broadcast.2464.clone.1.clone.1, convert.92.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/pow" source_file="/pax/praxis/praxis/optimizers.py" source_line=331}
  subtract.308.clone.1.clone.1 = f32[8]{0} subtract(broadcast.2472, power.69.clone.1.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/sub" source_file="/pax/praxis/praxis/optimizers.py" source_line=331}
  multiply.1535.clone.1.clone.1 = f32[8]{0} multiply(subtract.308.clone.1.clone.1, broadcast.2464.clone.1.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=331}
  power.68.clone.1.clone.1 = f32[8]{0} power(broadcast.2464.clone.1.clone.1, add.1327.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/pow" source_file="/pax/praxis/praxis/optimizers.py" source_line=331}
  subtract.307.clone.1.clone.1 = f32[8]{0} subtract(broadcast.2472, power.68.clone.1.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/sub" source_file="/pax/praxis/praxis/optimizers.py" source_line=331}
  divide.200.clone.1.clone.1 = f32[8]{0} divide(multiply.1535.clone.1.clone.1, subtract.307.clone.1.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/div" source_file="/pax/praxis/praxis/optimizers.py" source_line=331}
  subtract.306.clone.1 = f32[8]{0} subtract(broadcast.2472, divide.200.clone.1.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/sub" source_file="/pax/praxis/praxis/optimizers.py" source_line=340}
  param_1.2309 = f32[] parameter(1)
  is-finite.26.clone.1 = pred[] is-finite(param_1.2309), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(isfinite)/is_finite" source_file="/pax/paxml/paxml/learners.py" source_line=256}
  broadcast.2231.clone.1 = pred[8]{0} broadcast(is-finite.26.clone.1), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(_where)/broadcast_in_dim[shape=(8,) broadcast_dimensions=()]" source_file="/pax/paxml/paxml/learners.py" source_line=349}
  constant.1779.clone.1 = s32[] constant(1)
  broadcast.2230.clone.1 = s32[8]{0} broadcast(constant.1779.clone.1), dimensions={}
  add.892.clone.1 = s32[8]{0} add(param_0.1669, broadcast.2230.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/add" source_file="/pax/praxis/praxis/optimizers.py" source_line=697}
  select.792.clone.1 = s32[8]{0} select(broadcast.2231.clone.1, add.892.clone.1, param_0.1669), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(_where)/select_n" source_file="/pax/paxml/paxml/learners.py" source_line=349}
  constant.1913.clone.1 = s32[] constant(4001)
  broadcast.2490.clone.1 = s32[8]{0} broadcast(constant.1913.clone.1), dimensions={}
  compare.598.clone.1 = pred[8]{0} compare(param_0.1669, broadcast.2490.clone.1), direction=LT, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/lt" source_file="/usr/local/lib/python3.10/dist-packages/optax/_src/schedule.py" source_line=399}
  constant.1914.clone.1 = s32[] constant(4000)
  broadcast.2489.clone.1 = s32[8]{0} broadcast(constant.1914.clone.1), dimensions={}
  compare.597.clone.1 = pred[8]{0} compare(param_0.1669, broadcast.2489.clone.1), direction=LT, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/lt" source_file="/usr/local/lib/python3.10/dist-packages/optax/_src/schedule.py" source_line=399}
  constant.1924.clone.1 = f32[] constant(0)
  broadcast.2488.clone.1 = f32[8]{0} broadcast(constant.1924.clone.1), dimensions={}
  compare.596.clone.1 = pred[8]{0} compare(convert.92.clone.1, broadcast.2488.clone.1), direction=LT, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/lt" source_file="/pax/praxis/praxis/schedules.py" source_line=105}
  constant.1915.clone.1 = f32[] constant(4000)
  broadcast.2487.clone.1 = f32[8]{0} broadcast(constant.1915.clone.1), dimensions={}
  compare.595.clone.1 = pred[8]{0} compare(convert.92.clone.1, broadcast.2487.clone.1), direction=GE, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/ge" source_file="/pax/praxis/praxis/schedules.py" source_line=105}
  constant.1916.clone.1 = f32[] constant(0.00025)
  broadcast.2484.clone.1 = f32[8]{0} broadcast(constant.1916.clone.1), dimensions={}
  multiply.1547.clone.1 = f32[8]{0} multiply(convert.92.clone.1, broadcast.2484.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/div" source_file="/pax/praxis/praxis/schedules.py" source_line=99}
  select.891.clone.1 = f32[8]{0} select(compare.595.clone.1, broadcast.2472, multiply.1547.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(_where))/select_n" source_file="/pax/praxis/praxis/schedules.py" source_line=105}
  select.890.clone.1 = f32[8]{0} select(compare.596.clone.1, broadcast.2488.clone.1, select.891.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(_where))/select_n" source_file="/pax/praxis/praxis/schedules.py" source_line=105}
  constant.1917.clone.1 = s32[] constant(-4000)
  broadcast.2483.clone.1 = s32[8]{0} broadcast(constant.1917.clone.1), dimensions={}
  add.969.clone.1 = s32[8]{0} add(param_0.1669, broadcast.2483.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/sub" source_file="/usr/local/lib/python3.10/dist-packages/optax/_src/schedule.py" source_line=399}
  convert.84.clone.1 = f32[8]{0} convert(add.969.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/convert_element_type[new_dtype=float32 weak_type=False]" source_file="/pax/praxis/praxis/schedules.py" source_line=96}
  compare.594.clone.1 = pred[8]{0} compare(convert.84.clone.1, broadcast.2488.clone.1), direction=LT, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/lt" source_file="/pax/praxis/praxis/schedules.py" source_line=105}
  compare.593.clone.1 = pred[8]{0} compare(convert.84.clone.1, broadcast.2472), direction=GE, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/ge" source_file="/pax/praxis/praxis/schedules.py" source_line=105}
  multiply.1545.clone.1 = f32[8]{0} multiply(convert.84.clone.1, broadcast.2488.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/schedules.py" source_line=104}
  add.968.clone.1 = f32[8]{0} add(multiply.1545.clone.1, broadcast.2472), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/add" source_file="/pax/praxis/praxis/schedules.py" source_line=104}
  select.889.clone.1 = f32[8]{0} select(compare.593.clone.1, broadcast.2472, add.968.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(_where))/select_n" source_file="/pax/praxis/praxis/schedules.py" source_line=105}
  select.888.clone.1 = f32[8]{0} select(compare.594.clone.1, broadcast.2472, select.889.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(_where))/select_n" source_file="/pax/praxis/praxis/schedules.py" source_line=105}
  select.887.clone.1 = f32[8]{0} select(compare.597.clone.1, select.890.clone.1, select.888.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(_where))/select_n" source_file="/usr/local/lib/python3.10/dist-packages/optax/_src/schedule.py" source_line=399}
  constant.1918.clone.1 = s32[] constant(-4001)
  broadcast.2482.clone.1 = s32[8]{0} broadcast(constant.1918.clone.1), dimensions={}
  add.967.clone.1 = s32[8]{0} add(param_0.1669, broadcast.2482.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/sub" source_file="/usr/local/lib/python3.10/dist-packages/optax/_src/schedule.py" source_line=399}
  convert.83.clone.1 = f32[8]{0} convert(add.967.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/convert_element_type[new_dtype=float32 weak_type=False]" source_file="/pax/praxis/praxis/schedules.py" source_line=96}
  compare.592.clone.1 = pred[8]{0} compare(convert.83.clone.1, broadcast.2488.clone.1), direction=LT, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/lt" source_file="/pax/praxis/praxis/schedules.py" source_line=105}
  constant.1919.clone.1 = f32[] constant(295999)
  broadcast.2481.clone.1 = f32[8]{0} broadcast(constant.1919.clone.1), dimensions={}
  compare.591.clone.1 = pred[8]{0} compare(convert.83.clone.1, broadcast.2481.clone.1), direction=GE, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/ge" source_file="/pax/praxis/praxis/schedules.py" source_line=105}
  constant.1921.clone.1 = f32[] constant(-2.30258512)
  broadcast.2480.clone.1 = f32[8]{0} broadcast(constant.1921.clone.1), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(_where))/broadcast_in_dim[shape=(8,) broadcast_dimensions=()]" source_file="/pax/praxis/praxis/schedules.py" source_line=105}
  constant.1920.clone.1 = f32[] constant(-7.77903e-06)
  broadcast.2478.clone.1 = f32[8]{0} broadcast(constant.1920.clone.1), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/schedules.py" source_line=104}
  multiply.1544.clone.1 = f32[8]{0} multiply(convert.83.clone.1, broadcast.2478.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/schedules.py" source_line=104}
  select.886.clone.1 = f32[8]{0} select(compare.591.clone.1, broadcast.2480.clone.1, multiply.1544.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(_where))/select_n" source_file="/pax/praxis/praxis/schedules.py" source_line=105}
  select.885.clone.1 = f32[8]{0} select(compare.592.clone.1, broadcast.2488.clone.1, select.886.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(_where))/select_n" source_file="/pax/praxis/praxis/schedules.py" source_line=105}
  exponential.58.clone.1 = f32[8]{0} exponential(select.885.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/exp" source_file="/pax/praxis/praxis/schedules.py" source_line=145}
  select.884.clone.1 = f32[8]{0} select(compare.598.clone.1, select.887.clone.1, exponential.58.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/vmap(jit(_where))/select_n" source_file="/usr/local/lib/python3.10/dist-packages/optax/_src/schedule.py" source_line=399}
  constant.1922.clone.1 = f32[] constant(-0.00016)
  broadcast.2477.clone.1 = f32[8]{0} broadcast(constant.1922.clone.1), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=693}
  multiply.1543.clone.1 = f32[8]{0} multiply(select.884.clone.1, broadcast.2477.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=693}
  ROOT tuple.85 = (f32[8]{0}, f32[8]{0}, f32[8]{0}, f32[8]{0}, s32[8]{0}, /*index=5*/f32[8]{0}) tuple(subtract.309, divide.201.clone.1, subtract.306.clone.1, divide.200.clone.1.clone.1, select.792.clone.1, /*index=5*/multiply.1543.clone.1)
} // fused_computation.200

fused_computation.204 {
  param_0.404 = f32[1024,32000]{1,0} parameter(0)
  param_4.1017 = f32[] parameter(4)
  is-finite.52 = pred[] is-finite(param_4.1017), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(isfinite)/is_finite" source_file="/pax/paxml/paxml/learners.py" source_line=256}
  broadcast.2497 = pred[1024,32000]{1,0} broadcast(is-finite.52), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(_where)/broadcast_in_dim[shape=(8192, 32000) broadcast_dimensions=()]" source_file="/pax/paxml/paxml/learners.py" source_line=340}
  param_3.1471 = f32[] parameter(3)
  broadcast.2496 = f32[1024,32000]{1,0} broadcast(param_3.1471), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=695}
  constant.1942 = f32[] constant(1)
  param_6.516 = f32[] parameter(6)
  subtract.701 = f32[] subtract(constant.1942, param_6.516), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/sub" source_file="/pax/praxis/praxis/optimizers.py" source_line=339}
  broadcast.3598 = f32[1024,32000]{1,0} broadcast(subtract.701), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=339}
  param_7.418 = f32[1024,32000]{1,0} parameter(7)
  param_8.366 = f32[] parameter(8)
  broadcast.3597 = f32[1024,32000]{1,0} broadcast(param_8.366), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/paxml/paxml/learners.py" source_line=266}
  multiply.2179 = f32[1024,32000]{1,0} multiply(param_7.418, broadcast.3597), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/paxml/paxml/learners.py" source_line=266}
  compare.1036 = pred[1024,32000]{1,0} compare(multiply.2179, multiply.2179), direction=NE, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(nan_to_num)/jit(isnan)/ne" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  constant.1939 = f32[] constant(nan)
  broadcast.3595 = f32[1024,32000]{1,0} broadcast(constant.1939), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(nan_to_num)/jit(_where)/broadcast_in_dim[shape=(8192, 32000) broadcast_dimensions=()]" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  select.1341 = f32[1024,32000]{1,0} select(compare.1036, broadcast.3595, multiply.2179), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(nan_to_num)/jit(_where)/select_n" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  constant.1940 = f32[] constant(inf)
  broadcast.3594 = f32[1024,32000]{1,0} broadcast(constant.1940), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(nan_to_num)/eq" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  compare.1035 = pred[1024,32000]{1,0} compare(select.1341, broadcast.3594), direction=EQ, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(nan_to_num)/eq" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  select.1340 = f32[1024,32000]{1,0} select(compare.1035, broadcast.3595, select.1341), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(nan_to_num)/jit(_where)/select_n" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  constant.1941 = f32[] constant(-inf)
  broadcast.3593 = f32[1024,32000]{1,0} broadcast(constant.1941), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(nan_to_num)/eq" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  compare.1034 = pred[1024,32000]{1,0} compare(select.1340, broadcast.3593), direction=EQ, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(nan_to_num)/eq" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  select.1339 = f32[1024,32000]{1,0} select(compare.1034, broadcast.3595, select.1340), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(nan_to_num)/jit(_where)/select_n" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  multiply.2178 = f32[1024,32000]{1,0} multiply(broadcast.3598, select.1339), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=339}
  broadcast.3592 = f32[1024,32000]{1,0} broadcast(param_6.516), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=339}
  param_5.724 = f32[1024,32000]{1,0} parameter(5)
  multiply.2177 = f32[1024,32000]{1,0} multiply(broadcast.3592, param_5.724), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=339}
  add.1315 = f32[1024,32000]{1,0} add(multiply.2178, multiply.2177), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/add" source_file="/pax/praxis/praxis/optimizers.py" source_line=339}
  param_1.2005 = f32[1024,32000]{1,0} parameter(1)
  param_2.1722 = f32[] parameter(2)
  constant.1660 = f32[] constant(3.81469745e-09)
  multiply.1551 = f32[] multiply(param_2.1722, constant.1660), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/div" source_file="/pax/praxis/praxis/optimizers.py" source_line=2064}
  sqrt.84 = f32[] sqrt(multiply.1551), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/sqrt" source_file="/pax/praxis/praxis/optimizers.py" source_line=2080}
  compare.601 = pred[] compare(sqrt.84, sqrt.84), direction=NE, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(nan_to_num)/jit(isnan)/ne" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  select.895 = f32[] select(compare.601, constant.1939, sqrt.84), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(nan_to_num)/jit(_where)/select_n" source_file="/usr/local/lib/python3.10/dist-packages/optax/_src/schedule.py" source_line=399}
  compare.600 = pred[] compare(select.895, constant.1940), direction=EQ, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(nan_to_num)/eq" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  select.894 = f32[] select(compare.600, constant.1939, select.895), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(nan_to_num)/jit(_where)/select_n" source_file="/usr/local/lib/python3.10/dist-packages/optax/_src/schedule.py" source_line=399}
  compare.599 = pred[] compare(select.894, constant.1941), direction=EQ, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(nan_to_num)/eq" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  select.893 = f32[] select(compare.599, constant.1939, select.894), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(nan_to_num)/jit(_where)/select_n" source_file="/usr/local/lib/python3.10/dist-packages/optax/_src/schedule.py" source_line=399}
  maximum.67 = f32[] maximum(select.893, constant.1942), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/max" source_file="/pax/praxis/praxis/optimizers.py" source_line=346}
  broadcast.2494 = f32[1024,32000]{1,0} broadcast(maximum.67), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/div" source_file="/pax/praxis/praxis/optimizers.py" source_line=347}
  multiply.1550 = f32[1024,32000]{1,0} multiply(param_1.2005, broadcast.2494)
  divide.202 = f32[1024,32000]{1,0} divide(add.1315, multiply.1550), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/div" source_file="/pax/praxis/praxis/optimizers.py" source_line=347}
  constant.1943 = f32[] constant(0.001)
  broadcast.2492 = f32[1024,32000]{1,0} broadcast(constant.1943), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=691}
  multiply.1549 = f32[1024,32000]{1,0} multiply(param_0.404, broadcast.2492), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=691}
  add.971 = f32[1024,32000]{1,0} add(divide.202, multiply.1549), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/add" source_file="/pax/praxis/praxis/optimizers.py" source_line=691}
  multiply.1548 = f32[1024,32000]{1,0} multiply(broadcast.2496, add.971), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=695}
  constant.1944 = f32[] constant(0)
  broadcast.2491 = f32[1024,32000]{1,0} broadcast(constant.1944), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/broadcast_in_dim[shape=(8192, 32000) broadcast_dimensions=()]" source_file="/pax/paxml/paxml/learners.py" source_line=340}
  select.892 = f32[1024,32000]{1,0} select(broadcast.2497, multiply.1548, broadcast.2491), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(_where)/select_n" source_file="/pax/paxml/paxml/learners.py" source_line=340}
  ROOT add.970 = f32[1024,32000]{1,0} add(param_0.404, select.892), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/add" source_file="/pax/paxml/paxml/learners.py" source_line=408}
} // fused_computation.204

fused_computation.205 {
  constant.3411 = f32[] constant(1)
  param_1.2310 = f32[] parameter(1)
  subtract.706 = f32[] subtract(constant.3411, param_1.2310), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/sub" source_file="/pax/praxis/praxis/optimizers.py" source_line=339}
  broadcast.3627 = f32[1024,32000]{1,0} broadcast(subtract.706), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=339}
  param_2.2096 = f32[1024,32000]{1,0} parameter(2)
  param_3.2074 = f32[] parameter(3)
  broadcast.3626 = f32[1024,32000]{1,0} broadcast(param_3.2074), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/paxml/paxml/learners.py" source_line=266}
  multiply.2191 = f32[1024,32000]{1,0} multiply(param_2.2096, broadcast.3626), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/paxml/paxml/learners.py" source_line=266}
  compare.1048 = pred[1024,32000]{1,0} compare(multiply.2191, multiply.2191), direction=NE, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(nan_to_num)/jit(isnan)/ne" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  constant.3410 = f32[] constant(nan)
  broadcast.3624 = f32[1024,32000]{1,0} broadcast(constant.3410), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(nan_to_num)/jit(_where)/broadcast_in_dim[shape=(8192, 32000) broadcast_dimensions=()]" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  select.1353 = f32[1024,32000]{1,0} select(compare.1048, broadcast.3624, multiply.2191), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(nan_to_num)/jit(_where)/select_n" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  constant.3409 = f32[] constant(inf)
  broadcast.3622 = f32[1024,32000]{1,0} broadcast(constant.3409), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(nan_to_num)/eq" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  compare.1047 = pred[1024,32000]{1,0} compare(select.1353, broadcast.3622), direction=EQ, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(nan_to_num)/eq" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  select.1352 = f32[1024,32000]{1,0} select(compare.1047, broadcast.3624, select.1353), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(nan_to_num)/jit(_where)/select_n" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  constant.3408 = f32[] constant(-inf)
  broadcast.3621 = f32[1024,32000]{1,0} broadcast(constant.3408), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(nan_to_num)/eq" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  compare.1046 = pred[1024,32000]{1,0} compare(select.1352, broadcast.3621), direction=EQ, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(nan_to_num)/eq" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  select.1351 = f32[1024,32000]{1,0} select(compare.1046, broadcast.3624, select.1352), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(nan_to_num)/jit(_where)/select_n" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  multiply.2190 = f32[1024,32000]{1,0} multiply(broadcast.3627, select.1351), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=339}
  broadcast.3620 = f32[1024,32000]{1,0} broadcast(param_1.2310), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=339}
  param_0.1670 = f32[1024,32000]{1,0} parameter(0)
  multiply.2189 = f32[1024,32000]{1,0} multiply(broadcast.3620, param_0.1670), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=339}
  add.1319 = f32[1024,32000]{1,0} add(multiply.2190, multiply.2189), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/add" source_file="/pax/praxis/praxis/optimizers.py" source_line=339}
  param_6.1269 = f32[] parameter(6)
  subtract.710.clone.1 = f32[] subtract(constant.3411, param_6.1269), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/sub" source_file="/pax/praxis/praxis/optimizers.py" source_line=340}
  broadcast.3653.clone.1 = f32[1024,32000]{1,0} broadcast(subtract.710.clone.1), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=340}
  multiply.2207.clone.1 = f32[1024,32000]{1,0} multiply(select.1351, select.1351), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=340}
  multiply.2205.clone.1 = f32[1024,32000]{1,0} multiply(broadcast.3653.clone.1, multiply.2207.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=340}
  broadcast.3647.clone.1 = f32[1024,32000]{1,0} broadcast(param_6.1269), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=340}
  param_5.1605 = f32[1024,32000]{1,0} parameter(5)
  multiply.2204.clone.1 = f32[1024,32000]{1,0} multiply(broadcast.3647.clone.1, param_5.1605), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=340}
  add.1323.clone.1 = f32[1024,32000]{1,0} add(multiply.2205.clone.1, multiply.2204.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/add" source_file="/pax/praxis/praxis/optimizers.py" source_line=340}
  sqrt.85.clone.1 = f32[1024,32000]{1,0} sqrt(add.1323.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/sqrt" source_file="/pax/praxis/praxis/optimizers.py" source_line=684}
  constant.1946.clone.1 = f32[] constant(1e-06)
  broadcast.2498.clone.1 = f32[1024,32000]{1,0} broadcast(constant.1946.clone.1), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/add" source_file="/pax/praxis/praxis/optimizers.py" source_line=684}
  add.972.clone.1 = f32[1024,32000]{1,0} add(sqrt.85.clone.1, broadcast.2498.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/add" source_file="/pax/praxis/praxis/optimizers.py" source_line=684}
  divide.203 = f32[1024,32000]{1,0} divide(add.1319, add.972.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/div" source_file="/pax/praxis/praxis/optimizers.py" source_line=684}
  multiply.1552 = f32[1024,32000]{1,0} multiply(divide.203, divide.203), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=2078}
  bitcast.7427 = f32[4096,8000]{1,0} bitcast(multiply.1552), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=2078}
  constant.1945 = f32[] constant(0)
  reduce.342 = f32[4096]{0} reduce(bitcast.7427, constant.1945), dimensions={1}, to_apply=region_15.791, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/reduce_sum[axes=(0,)]" source_file="/pax/praxis/praxis/optimizers.py" source_line=2063}
  param_4.1806 = f32[] parameter(4)
  is-finite.34.clone.1 = pred[] is-finite(param_4.1806), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(isfinite)/is_finite" source_file="/pax/paxml/paxml/learners.py" source_line=256}
  broadcast.2240.clone.1 = pred[1024,32000]{1,0} broadcast(is-finite.34.clone.1), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(_where)/broadcast_in_dim[shape=(8192, 32000) broadcast_dimensions=()]" source_file="/pax/paxml/paxml/learners.py" source_line=340}
  select.800.clone.1 = f32[1024,32000]{1,0} select(broadcast.2240.clone.1, add.1319, param_0.1670), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(_where)/select_n" source_file="/pax/paxml/paxml/learners.py" source_line=340}
  select.796.clone.1 = f32[1024,32000]{1,0} select(broadcast.2240.clone.1, add.1323.clone.1, param_5.1605), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(_where)/select_n" source_file="/pax/paxml/paxml/learners.py" source_line=340}
  ROOT tuple.88 = (f32[4096]{0}, f32[1024,32000]{1,0}, f32[1024,32000]{1,0}, f32[1024,32000]{1,0}) tuple(reduce.342, select.800.clone.1, add.972.clone.1, select.796.clone.1)
} // fused_computation.205

fused_computation.210 {
  param_0.416 = f32[32000]{0} parameter(0)
  param_3.1453 = f32[] parameter(3)
  is-finite.53 = pred[] is-finite(param_3.1453), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(isfinite)/is_finite" source_file="/pax/paxml/paxml/learners.py" source_line=256}
  broadcast.2512 = pred[32000]{0} broadcast(is-finite.53), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(_where)/broadcast_in_dim[shape=(32000,) broadcast_dimensions=()]" source_file="/pax/paxml/paxml/learners.py" source_line=340}
  param_2.1710 = f32[] parameter(2)
  broadcast.2511 = f32[32000]{0} broadcast(param_2.1710), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=695}
  constant.1955 = f32[] constant(1)
  param_5.722 = f32[] parameter(5)
  subtract.687 = f32[] subtract(constant.1955, param_5.722), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/sub" source_file="/pax/praxis/praxis/optimizers.py" source_line=339}
  broadcast.3478 = f32[32000]{0} broadcast(subtract.687), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=339}
  param_6.512 = f32[32000]{0} parameter(6)
  param_7.414 = f32[] parameter(7)
  broadcast.3477 = f32[32000]{0} broadcast(param_7.414), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/paxml/paxml/learners.py" source_line=266}
  multiply.2124 = f32[32000]{0} multiply(param_6.512, broadcast.3477), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/paxml/paxml/learners.py" source_line=266}
  compare.982 = pred[32000]{0} compare(multiply.2124, multiply.2124), direction=NE, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(nan_to_num)/jit(isnan)/ne" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  constant.1952 = f32[] constant(nan)
  broadcast.3476 = f32[32000]{0} broadcast(constant.1952), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(nan_to_num)/jit(_where)/broadcast_in_dim[shape=(32000,) broadcast_dimensions=()]" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  select.1287 = f32[32000]{0} select(compare.982, broadcast.3476, multiply.2124), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(nan_to_num)/jit(_where)/select_n" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  constant.1953 = f32[] constant(inf)
  broadcast.3475 = f32[32000]{0} broadcast(constant.1953), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(nan_to_num)/eq" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  compare.981 = pred[32000]{0} compare(select.1287, broadcast.3475), direction=EQ, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(nan_to_num)/eq" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  select.1286 = f32[32000]{0} select(compare.981, broadcast.3476, select.1287), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(nan_to_num)/jit(_where)/select_n" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  constant.1954 = f32[] constant(-inf)
  broadcast.3474 = f32[32000]{0} broadcast(constant.1954), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(nan_to_num)/eq" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  compare.980 = pred[32000]{0} compare(select.1286, broadcast.3474), direction=EQ, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(nan_to_num)/eq" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  select.1285 = f32[32000]{0} select(compare.980, broadcast.3476, select.1286), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(nan_to_num)/jit(_where)/select_n" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  multiply.2123 = f32[32000]{0} multiply(broadcast.3478, select.1285), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=339}
  broadcast.3473 = f32[32000]{0} broadcast(param_5.722), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=339}
  param_4.1000 = f32[32000]{0} parameter(4)
  multiply.2122 = f32[32000]{0} multiply(broadcast.3473, param_4.1000), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=339}
  add.1297 = f32[32000]{0} add(multiply.2123, multiply.2122), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/add" source_file="/pax/praxis/praxis/optimizers.py" source_line=339}
  param_9.329 = f32[] parameter(9)
  subtract.699 = f32[] subtract(constant.1955, param_9.329), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/sub" source_file="/pax/praxis/praxis/optimizers.py" source_line=340}
  broadcast.3566 = f32[32000]{0} broadcast(subtract.699), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=340}
  multiply.2168 = f32[32000]{0} multiply(select.1285, select.1285), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=340}
  multiply.2167 = f32[32000]{0} multiply(broadcast.3566, multiply.2168), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=340}
  broadcast.3561 = f32[32000]{0} broadcast(param_9.329), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=340}
  param_8.359 = f32[32000]{0} parameter(8)
  multiply.2166 = f32[32000]{0} multiply(broadcast.3561, param_8.359), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=340}
  add.1313 = f32[32000]{0} add(multiply.2167, multiply.2166), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/add" source_file="/pax/praxis/praxis/optimizers.py" source_line=340}
  sqrt.104 = f32[32000]{0} sqrt(add.1313), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/sqrt" source_file="/pax/praxis/praxis/optimizers.py" source_line=684}
  constant.3364 = f32[] constant(1e-06)
  broadcast.3559 = f32[32000]{0} broadcast(constant.3364), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/add" source_file="/pax/praxis/praxis/optimizers.py" source_line=684}
  add.1312 = f32[32000]{0} add(sqrt.104, broadcast.3559), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/add" source_file="/pax/praxis/praxis/optimizers.py" source_line=684}
  param_1.2001 = f32[] parameter(1)
  constant.1661 = f32[] constant(3.125e-05)
  multiply.1563 = f32[] multiply(param_1.2001, constant.1661), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/div" source_file="/pax/praxis/praxis/optimizers.py" source_line=2066}
  sqrt.86 = f32[] sqrt(multiply.1563), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/sqrt" source_file="/pax/praxis/praxis/optimizers.py" source_line=2080}
  compare.608 = pred[] compare(sqrt.86, sqrt.86), direction=NE, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(nan_to_num)/jit(isnan)/ne" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  select.902 = f32[] select(compare.608, constant.1952, sqrt.86), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(nan_to_num)/jit(_where)/select_n" source_file="/usr/local/lib/python3.10/dist-packages/optax/_src/schedule.py" source_line=399}
  compare.607 = pred[] compare(select.902, constant.1953), direction=EQ, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(nan_to_num)/eq" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  select.901 = f32[] select(compare.607, constant.1952, select.902), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(nan_to_num)/jit(_where)/select_n" source_file="/usr/local/lib/python3.10/dist-packages/optax/_src/schedule.py" source_line=399}
  compare.606 = pred[] compare(select.901, constant.1954), direction=EQ, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(nan_to_num)/eq" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  select.900 = f32[] select(compare.606, constant.1952, select.901), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(nan_to_num)/jit(_where)/select_n" source_file="/usr/local/lib/python3.10/dist-packages/optax/_src/schedule.py" source_line=399}
  maximum.68 = f32[] maximum(select.900, constant.1955), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/max" source_file="/pax/praxis/praxis/optimizers.py" source_line=346}
  broadcast.2509 = f32[32000]{0} broadcast(maximum.68), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/div" source_file="/pax/praxis/praxis/optimizers.py" source_line=347}
  multiply.1562 = f32[32000]{0} multiply(add.1312, broadcast.2509)
  divide.204 = f32[32000]{0} divide(add.1297, multiply.1562), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/div" source_file="/pax/praxis/praxis/optimizers.py" source_line=347}
  constant.1956 = f32[] constant(0.001)
  broadcast.2508 = f32[32000]{0} broadcast(constant.1956), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=691}
  multiply.1561 = f32[32000]{0} multiply(param_0.416, broadcast.2508), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=691}
  add.976 = f32[32000]{0} add(divide.204, multiply.1561), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/add" source_file="/pax/praxis/praxis/optimizers.py" source_line=691}
  multiply.1560 = f32[32000]{0} multiply(broadcast.2511, add.976), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=695}
  constant.1957 = f32[] constant(0)
  broadcast.2507 = f32[32000]{0} broadcast(constant.1957), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/broadcast_in_dim[shape=(32000,) broadcast_dimensions=()]" source_file="/pax/paxml/paxml/learners.py" source_line=340}
  select.899 = f32[32000]{0} select(broadcast.2512, multiply.1560, broadcast.2507), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(_where)/select_n" source_file="/pax/paxml/paxml/learners.py" source_line=340}
  add.975 = f32[32000]{0} add(param_0.416, select.899), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/add" source_file="/pax/paxml/paxml/learners.py" source_line=408}
  select.797.clone.1 = f32[32000]{0} select(broadcast.2512, add.1313, param_8.359), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(_where)/select_n" source_file="/pax/paxml/paxml/learners.py" source_line=340}
  select.801.clone.1 = f32[32000]{0} select(broadcast.2512, add.1297, param_4.1000), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(_where)/select_n" source_file="/pax/paxml/paxml/learners.py" source_line=340}
  ROOT tuple.90 = (f32[32000]{0}, f32[32000]{0}, f32[32000]{0}) tuple(add.975, select.797.clone.1, select.801.clone.1)
} // fused_computation.210

fused_computation.211 {
  constant.3326 = f32[] constant(1)
  param_1.1999 = f32[] parameter(1)
  subtract.691 = f32[] subtract(constant.3326, param_1.1999), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/sub" source_file="/pax/praxis/praxis/optimizers.py" source_line=339}
  broadcast.3505 = f32[32000]{0} broadcast(subtract.691), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=339}
  param_2.1708 = f32[32000]{0} parameter(2)
  param_3.1451 = f32[] parameter(3)
  broadcast.3504 = f32[32000]{0} broadcast(param_3.1451), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/paxml/paxml/learners.py" source_line=266}
  multiply.2136 = f32[32000]{0} multiply(param_2.1708, broadcast.3504), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/paxml/paxml/learners.py" source_line=266}
  compare.994 = pred[32000]{0} compare(multiply.2136, multiply.2136), direction=NE, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(nan_to_num)/jit(isnan)/ne" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  constant.3325 = f32[] constant(nan)
  broadcast.3503 = f32[32000]{0} broadcast(constant.3325), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(nan_to_num)/jit(_where)/broadcast_in_dim[shape=(32000,) broadcast_dimensions=()]" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  select.1299 = f32[32000]{0} select(compare.994, broadcast.3503, multiply.2136), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(nan_to_num)/jit(_where)/select_n" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  constant.3324 = f32[] constant(inf)
  broadcast.3502 = f32[32000]{0} broadcast(constant.3324), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(nan_to_num)/eq" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  compare.993 = pred[32000]{0} compare(select.1299, broadcast.3502), direction=EQ, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(nan_to_num)/eq" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  select.1298 = f32[32000]{0} select(compare.993, broadcast.3503, select.1299), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(nan_to_num)/jit(_where)/select_n" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  constant.3323 = f32[] constant(-inf)
  broadcast.3501 = f32[32000]{0} broadcast(constant.3323), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(nan_to_num)/eq" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  compare.992 = pred[32000]{0} compare(select.1298, broadcast.3501), direction=EQ, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(nan_to_num)/eq" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  select.1297 = f32[32000]{0} select(compare.992, broadcast.3503, select.1298), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(nan_to_num)/jit(_where)/select_n" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  multiply.2135 = f32[32000]{0} multiply(broadcast.3505, select.1297), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=339}
  broadcast.3500 = f32[32000]{0} broadcast(param_1.1999), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=339}
  param_0.1467 = f32[32000]{0} parameter(0)
  multiply.2134 = f32[32000]{0} multiply(broadcast.3500, param_0.1467), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=339}
  add.1301 = f32[32000]{0} add(multiply.2135, multiply.2134), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/add" source_file="/pax/praxis/praxis/optimizers.py" source_line=339}
  param_5.721 = f32[] parameter(5)
  subtract.697 = f32[] subtract(constant.3326, param_5.721), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/sub" source_file="/pax/praxis/praxis/optimizers.py" source_line=340}
  broadcast.3549 = f32[32000]{0} broadcast(subtract.697), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=340}
  multiply.2159 = f32[32000]{0} multiply(select.1297, select.1297), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=340}
  multiply.2158 = f32[32000]{0} multiply(broadcast.3549, multiply.2159), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=340}
  broadcast.3543 = f32[32000]{0} broadcast(param_5.721), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=340}
  param_4.999 = f32[32000]{0} parameter(4)
  multiply.2157 = f32[32000]{0} multiply(broadcast.3543, param_4.999), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=340}
  add.1309 = f32[32000]{0} add(multiply.2158, multiply.2157), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/add" source_file="/pax/praxis/praxis/optimizers.py" source_line=340}
  sqrt.102 = f32[32000]{0} sqrt(add.1309), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/sqrt" source_file="/pax/praxis/praxis/optimizers.py" source_line=684}
  constant.3353 = f32[] constant(1e-06)
  broadcast.3542 = f32[32000]{0} broadcast(constant.3353), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/add" source_file="/pax/praxis/praxis/optimizers.py" source_line=684}
  add.1308 = f32[32000]{0} add(sqrt.102, broadcast.3542), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/add" source_file="/pax/praxis/praxis/optimizers.py" source_line=684}
  divide.205 = f32[32000]{0} divide(add.1301, add.1308), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/div" source_file="/pax/praxis/praxis/optimizers.py" source_line=684}
  multiply.1564 = f32[32000]{0} multiply(divide.205, divide.205), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=2078}
  bitcast.7428 = f32[128,250]{1,0} bitcast(multiply.1564), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=2078}
  constant.1958 = f32[] constant(0)
  ROOT reduce.343 = f32[128]{0} reduce(bitcast.7428, constant.1958), dimensions={1}, to_apply=region_15.791, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/reduce_sum[axes=(0,)]" source_file="/pax/praxis/praxis/optimizers.py" source_line=2066}
} // fused_computation.211

fused_computation.217 {
  constant.3245 = f32[] constant(1)
  param_1.1979 = f32[] parameter(1)
  subtract.677 = f32[] subtract(constant.3245, param_1.1979), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/sub" source_file="/pax/praxis/praxis/optimizers.py" source_line=339}
  broadcast.3386 = f32[8192]{0} broadcast(subtract.677), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=339}
  param_2.1676 = f32[8192]{0} parameter(2)
  param_3.1403 = f32[] parameter(3)
  broadcast.3385 = f32[8192]{0} broadcast(param_3.1403), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/paxml/paxml/learners.py" source_line=266}
  multiply.2074 = f32[8192]{0} multiply(param_2.1676, broadcast.3385), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/paxml/paxml/learners.py" source_line=266}
  compare.937 = pred[8192]{0} compare(multiply.2074, multiply.2074), direction=NE, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(nan_to_num)/jit(isnan)/ne" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  constant.3244 = f32[] constant(nan)
  broadcast.3384 = f32[8192]{0} broadcast(constant.3244), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(nan_to_num)/jit(_where)/broadcast_in_dim[shape=(8192,) broadcast_dimensions=()]" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  select.1245 = f32[8192]{0} select(compare.937, broadcast.3384, multiply.2074), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(nan_to_num)/jit(_where)/select_n" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  constant.3243 = f32[] constant(inf)
  broadcast.3382 = f32[8192]{0} broadcast(constant.3243), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(nan_to_num)/eq" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  compare.936 = pred[8192]{0} compare(select.1245, broadcast.3382), direction=EQ, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(nan_to_num)/eq" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  select.1244 = f32[8192]{0} select(compare.936, broadcast.3384, select.1245), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(nan_to_num)/jit(_where)/select_n" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  constant.3242 = f32[] constant(-inf)
  broadcast.3381 = f32[8192]{0} broadcast(constant.3242), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(nan_to_num)/eq" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  compare.935 = pred[8192]{0} compare(select.1244, broadcast.3381), direction=EQ, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(nan_to_num)/eq" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  select.1243 = f32[8192]{0} select(compare.935, broadcast.3384, select.1244), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(nan_to_num)/jit(_where)/select_n" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  multiply.2072 = f32[8192]{0} multiply(broadcast.3386, select.1243), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=339}
  broadcast.3380 = f32[8192]{0} broadcast(param_1.1979), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=339}
  param_0.1452 = f32[8192]{0} parameter(0)
  multiply.2070 = f32[8192]{0} multiply(broadcast.3380, param_0.1452), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=339}
  add.1282 = f32[8192]{0} add(multiply.2072, multiply.2070), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/add" source_file="/pax/praxis/praxis/optimizers.py" source_line=339}
  param_5.674 = f32[] parameter(5)
  subtract.683 = f32[] subtract(constant.3245, param_5.674), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/sub" source_file="/pax/praxis/praxis/optimizers.py" source_line=340}
  broadcast.3430 = f32[8192]{0} broadcast(subtract.683), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=340}
  multiply.2103 = f32[8192]{0} multiply(select.1243, select.1243), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=340}
  multiply.2101 = f32[8192]{0} multiply(broadcast.3430, multiply.2103), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=340}
  broadcast.3424 = f32[8192]{0} broadcast(param_5.674), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=340}
  param_4.945 = f32[8192]{0} parameter(4)
  multiply.2099 = f32[8192]{0} multiply(broadcast.3424, param_4.945), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=340}
  add.1291 = f32[8192]{0} add(multiply.2101, multiply.2099), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/add" source_file="/pax/praxis/praxis/optimizers.py" source_line=340}
  sqrt.98 = f32[8192]{0} sqrt(add.1291), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/sqrt" source_file="/pax/praxis/praxis/optimizers.py" source_line=684}
  constant.3270 = f32[] constant(1e-06)
  broadcast.3423 = f32[8192]{0} broadcast(constant.3270), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/add" source_file="/pax/praxis/praxis/optimizers.py" source_line=684}
  add.1289 = f32[8192]{0} add(sqrt.98, broadcast.3423), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/add" source_file="/pax/praxis/praxis/optimizers.py" source_line=684}
  divide.207 = f32[8192]{0} divide(add.1282, add.1289), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/div" source_file="/pax/praxis/praxis/optimizers.py" source_line=684}
  multiply.1575 = f32[8192]{0} multiply(divide.207, divide.207), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=2078}
  constant.1974 = f32[] constant(0)
  reduce.344 = f32[] reduce(multiply.1575, constant.1974), dimensions={0}, to_apply=region_15.791, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/reduce_sum[axes=(0,)]" source_file="/pax/praxis/praxis/optimizers.py" source_line=2066}
  param_8.932 = f32[8192]{0} parameter(8)
  multiply.2001.clone.1 = f32[8192]{0} multiply(param_8.932, broadcast.3385), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/paxml/paxml/learners.py" source_line=266}
  compare.883.clone.1 = pred[8192]{0} compare(multiply.2001.clone.1, multiply.2001.clone.1), direction=NE, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(nan_to_num)/jit(isnan)/ne" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  select.1180.clone.1 = f32[8192]{0} select(compare.883.clone.1, broadcast.3384, multiply.2001.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(nan_to_num)/jit(_where)/select_n" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  compare.882.clone.1 = pred[8192]{0} compare(select.1180.clone.1, broadcast.3382), direction=EQ, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(nan_to_num)/eq" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  select.1179.clone.1 = f32[8192]{0} select(compare.882.clone.1, broadcast.3384, select.1180.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(nan_to_num)/jit(_where)/select_n" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  compare.881.clone.1 = pred[8192]{0} compare(select.1179.clone.1, broadcast.3381), direction=EQ, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(nan_to_num)/eq" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  select.1178.clone.1 = f32[8192]{0} select(compare.881.clone.1, broadcast.3384, select.1179.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(nan_to_num)/jit(_where)/select_n" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  multiply.2000.clone.1 = f32[8192]{0} multiply(broadcast.3386, select.1178.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=339}
  param_7.997 = f32[8192]{0} parameter(7)
  multiply.1999.clone.1 = f32[8192]{0} multiply(broadcast.3380, param_7.997), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=339}
  add.1262.clone.1 = f32[8192]{0} add(multiply.2000.clone.1, multiply.1999.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/add" source_file="/pax/praxis/praxis/optimizers.py" source_line=339}
  multiply.2031.clone.1 = f32[8192]{0} multiply(select.1178.clone.1, select.1178.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=340}
  multiply.2030.clone.1 = f32[8192]{0} multiply(broadcast.3430, multiply.2031.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=340}
  param_6.1378 = f32[8192]{0} parameter(6)
  multiply.2029.clone.1 = f32[8192]{0} multiply(broadcast.3424, param_6.1378), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=340}
  add.1270.clone.1 = f32[8192]{0} add(multiply.2030.clone.1, multiply.2029.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/add" source_file="/pax/praxis/praxis/optimizers.py" source_line=340}
  sqrt.94.clone.1 = f32[8192]{0} sqrt(add.1270.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/sqrt" source_file="/pax/praxis/praxis/optimizers.py" source_line=684}
  add.1269.clone.1 = f32[8192]{0} add(sqrt.94.clone.1, broadcast.3423), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/add" source_file="/pax/praxis/praxis/optimizers.py" source_line=684}
  divide.209.clone.1 = f32[8192]{0} divide(add.1262.clone.1, add.1269.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/div" source_file="/pax/praxis/praxis/optimizers.py" source_line=684}
  multiply.1586.clone.1 = f32[8192]{0} multiply(divide.209.clone.1, divide.209.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=2078}
  reduce.345.clone.1 = f32[] reduce(multiply.1586.clone.1, constant.1974), dimensions={0}, to_apply=region_15.791, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/reduce_sum[axes=(0,)]" source_file="/pax/praxis/praxis/optimizers.py" source_line=2066}
  ROOT tuple.161 = (f32[], f32[]) tuple(reduce.344, reduce.345.clone.1)
} // fused_computation.217

fused_computation.226 {
  constant.2004 = f32[] constant(1)
  constant.2003 = f32[] constant(0.99)
  param_0.951 = s32[] parameter(0)
  convert.95 = f32[] convert(param_0.951), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/convert_element_type[new_dtype=float32 weak_type=False]" source_file="/pax/praxis/praxis/schedules.py" source_line=96}
  power.73 = f32[] power(constant.2003, convert.95), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/pow" source_file="/pax/praxis/praxis/optimizers.py" source_line=331}
  subtract.313 = f32[] subtract(constant.2004, power.73), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/sub" source_file="/pax/praxis/praxis/optimizers.py" source_line=331}
  multiply.1590 = f32[] multiply(subtract.313, constant.2003), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=331}
  add.1106 = f32[] add(convert.95, constant.2004), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/add" source_file="/pax/praxis/praxis/optimizers.py" source_line=330}
  power.72 = f32[] power(constant.2003, add.1106), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/pow" source_file="/pax/praxis/praxis/optimizers.py" source_line=331}
  subtract.312 = f32[] subtract(constant.2004, power.72), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/sub" source_file="/pax/praxis/praxis/optimizers.py" source_line=331}
  ROOT divide.210 = f32[] divide(multiply.1590, subtract.312), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/div" source_file="/pax/praxis/praxis/optimizers.py" source_line=331}
} // fused_computation.226

fused_computation.229 {
  constant.1662 = f32[] constant(5)
  param_13.316 = f32[] parameter(13)
  param_14.272 = f32[] parameter(14)
  add.1010.clone.1 = f32[] add(param_13.316, param_14.272), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/reduce_sum[axes=(0,)]" source_file="/pax/paxml/paxml/learners.py" source_line=49}
  param_12.519 = f32[] parameter(12)
  add.1009.clone.1 = f32[] add(add.1010.clone.1, param_12.519), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/reduce_sum[axes=(0,)]" source_file="/pax/paxml/paxml/learners.py" source_line=49}
  param_11.615 = f32[] parameter(11)
  add.1008.clone.1 = f32[] add(add.1009.clone.1, param_11.615), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/reduce_sum[axes=(0,)]" source_file="/pax/paxml/paxml/learners.py" source_line=49}
  param_10.664 = f32[] parameter(10)
  add.1006.clone.1 = f32[] add(add.1008.clone.1, param_10.664), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/reduce_sum[axes=(0,)]" source_file="/pax/paxml/paxml/learners.py" source_line=49}
  param_9.778 = f32[] parameter(9)
  add.1005.clone.1 = f32[] add(add.1006.clone.1, param_9.778), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/reduce_sum[axes=(0,)]" source_file="/pax/paxml/paxml/learners.py" source_line=49}
  param_8.886 = f32[] parameter(8)
  add.1004.clone.1 = f32[] add(add.1005.clone.1, param_8.886), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/reduce_sum[axes=(0,)]" source_file="/pax/paxml/paxml/learners.py" source_line=49}
  param_7.925 = f32[] parameter(7)
  add.1002.clone.1 = f32[] add(add.1004.clone.1, param_7.925), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/reduce_sum[axes=(0,)]" source_file="/pax/paxml/paxml/learners.py" source_line=49}
  param_6.1272 = f32[] parameter(6)
  add.1001.clone.1 = f32[] add(add.1002.clone.1, param_6.1272), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/reduce_sum[axes=(0,)]" source_file="/pax/paxml/paxml/learners.py" source_line=49}
  param_5.1608 = f32[] parameter(5)
  add.1000.clone.1 = f32[] add(add.1001.clone.1, param_5.1608), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/reduce_sum[axes=(0,)]" source_file="/pax/paxml/paxml/learners.py" source_line=49}
  param_4.1809 = f32[] parameter(4)
  add.998.clone.1 = f32[] add(add.1000.clone.1, param_4.1809), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/reduce_sum[axes=(0,)]" source_file="/pax/paxml/paxml/learners.py" source_line=49}
  param_3.2077 = f32[] parameter(3)
  add.997.clone.1 = f32[] add(add.998.clone.1, param_3.2077), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/reduce_sum[axes=(0,)]" source_file="/pax/paxml/paxml/learners.py" source_line=49}
  param_2.2099 = f32[] parameter(2)
  add.996.clone.1 = f32[] add(add.997.clone.1, param_2.2099), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/reduce_sum[axes=(0,)]" source_file="/pax/paxml/paxml/learners.py" source_line=49}
  param_1.2313 = f32[] parameter(1)
  add.994.clone.1 = f32[] add(add.996.clone.1, param_1.2313), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/reduce_sum[axes=(0,)]" source_file="/pax/paxml/paxml/learners.py" source_line=49}
  param_0.1673 = f32[] parameter(0)
  add.993.clone.1 = f32[] add(add.994.clone.1, param_0.1673), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/reduce_sum[axes=(0,)]" source_file="/pax/paxml/paxml/learners.py" source_line=49}
  sqrt.92.clone.1 = f32[] sqrt(add.993.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/sqrt" source_file="/pax/paxml/paxml/learners.py" source_line=49}
  divide.211 = f32[] divide(constant.1662, sqrt.92.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/div" source_file="/pax/paxml/paxml/learners.py" source_line=264}
  constant.2009 = f32[] constant(1)
  minimum.16 = f32[] minimum(divide.211, constant.2009), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/min" source_file="/pax/paxml/paxml/learners.py" source_line=262}
  ROOT tuple.94 = (f32[], f32[]) tuple(minimum.16, sqrt.92.clone.1)
} // fused_computation.229

fused_computation.230 {
  constant.2230 = f32[] constant(1)
  constant.2229 = f32[] constant(0.9)
  param_0.1093 = s32[] parameter(0)
  convert.96 = f32[] convert(param_0.1093), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/convert_element_type[new_dtype=float32 weak_type=False]" source_file="/pax/praxis/praxis/schedules.py" source_line=96}
  power.75 = f32[] power(constant.2229, convert.96), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/pow" source_file="/pax/praxis/praxis/optimizers.py" source_line=331}
  subtract.315 = f32[] subtract(constant.2230, power.75), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/sub" source_file="/pax/praxis/praxis/optimizers.py" source_line=331}
  multiply.1594 = f32[] multiply(subtract.315, constant.2229), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=331}
  add.1108 = f32[] add(convert.96, constant.2230), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/add" source_file="/pax/praxis/praxis/optimizers.py" source_line=330}
  power.74 = f32[] power(constant.2229, add.1108), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/pow" source_file="/pax/praxis/praxis/optimizers.py" source_line=331}
  subtract.314 = f32[] subtract(constant.2230, power.74), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/sub" source_file="/pax/praxis/praxis/optimizers.py" source_line=331}
  ROOT divide.212 = f32[] divide(multiply.1594, subtract.314), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/div" source_file="/pax/praxis/praxis/optimizers.py" source_line=331}
} // fused_computation.230

fused_computation.231 {
  param_0.948 = s32[] parameter(0)
  constant.1988 = s32[] constant(4001)
  compare.632 = pred[] compare(param_0.948, constant.1988), direction=LT, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/lt" source_file="/usr/local/lib/python3.10/dist-packages/optax/_src/schedule.py" source_line=399}
  constant.1989 = s32[] constant(4000)
  compare.630 = pred[] compare(param_0.948, constant.1989), direction=LT, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/lt" source_file="/usr/local/lib/python3.10/dist-packages/optax/_src/schedule.py" source_line=399}
  convert.94 = f32[] convert(param_0.948), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/convert_element_type[new_dtype=float32 weak_type=False]" source_file="/pax/praxis/praxis/schedules.py" source_line=96}
  constant.1999 = f32[] constant(0)
  compare.629 = pred[] compare(convert.94, constant.1999), direction=LT, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/lt" source_file="/pax/praxis/praxis/schedules.py" source_line=105}
  constant.1990 = f32[] constant(4000)
  compare.628 = pred[] compare(convert.94, constant.1990), direction=GE, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/ge" source_file="/pax/praxis/praxis/schedules.py" source_line=105}
  constant.1998 = f32[] constant(1)
  constant.1991 = f32[] constant(0.00025)
  multiply.1598 = f32[] multiply(convert.94, constant.1991), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/div" source_file="/pax/praxis/praxis/schedules.py" source_line=99}
  select.927 = f32[] select(compare.628, constant.1998, multiply.1598), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(_where)/select_n" source_file="/pax/praxis/praxis/schedules.py" source_line=105}
  select.926 = f32[] select(compare.629, constant.1999, select.927), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(_where)/select_n" source_file="/pax/praxis/praxis/schedules.py" source_line=105}
  constant.1992 = s32[] constant(-4000)
  add.992 = s32[] add(param_0.948, constant.1992), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/sub" source_file="/usr/local/lib/python3.10/dist-packages/optax/_src/schedule.py" source_line=399}
  convert.86 = f32[] convert(add.992), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/convert_element_type[new_dtype=float32 weak_type=False]" source_file="/pax/praxis/praxis/schedules.py" source_line=96}
  compare.627 = pred[] compare(convert.86, constant.1999), direction=LT, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/lt" source_file="/pax/praxis/praxis/schedules.py" source_line=105}
  compare.626 = pred[] compare(convert.86, constant.1998), direction=GE, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/ge" source_file="/pax/praxis/praxis/schedules.py" source_line=105}
  multiply.1597 = f32[] multiply(convert.86, constant.1999), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/schedules.py" source_line=104}
  add.991 = f32[] add(multiply.1597, constant.1998), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/add" source_file="/pax/praxis/praxis/schedules.py" source_line=104}
  select.925 = f32[] select(compare.626, constant.1998, add.991), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(_where)/select_n" source_file="/pax/praxis/praxis/schedules.py" source_line=105}
  select.924 = f32[] select(compare.627, constant.1998, select.925), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(_where)/select_n" source_file="/pax/praxis/praxis/schedules.py" source_line=105}
  select.923 = f32[] select(compare.630, select.926, select.924), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(_where)/select_n" source_file="/usr/local/lib/python3.10/dist-packages/optax/_src/schedule.py" source_line=399}
  constant.1993 = s32[] constant(-4001)
  add.990 = s32[] add(param_0.948, constant.1993), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/sub" source_file="/usr/local/lib/python3.10/dist-packages/optax/_src/schedule.py" source_line=399}
  convert.85 = f32[] convert(add.990), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/convert_element_type[new_dtype=float32 weak_type=False]" source_file="/pax/praxis/praxis/schedules.py" source_line=96}
  compare.625 = pred[] compare(convert.85, constant.1999), direction=LT, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/lt" source_file="/pax/praxis/praxis/schedules.py" source_line=105}
  constant.1994 = f32[] constant(295999)
  compare.624 = pred[] compare(convert.85, constant.1994), direction=GE, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/ge" source_file="/pax/praxis/praxis/schedules.py" source_line=105}
  constant.1996 = f32[] constant(-2.30258512)
  constant.1995 = f32[] constant(-7.77903e-06)
  multiply.1596 = f32[] multiply(convert.85, constant.1995), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/schedules.py" source_line=104}
  select.922 = f32[] select(compare.624, constant.1996, multiply.1596), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(_where)/select_n" source_file="/pax/praxis/praxis/schedules.py" source_line=105}
  select.921 = f32[] select(compare.625, constant.1999, select.922), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(_where)/select_n" source_file="/pax/praxis/praxis/schedules.py" source_line=105}
  exponential.59 = f32[] exponential(select.921), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/exp" source_file="/pax/praxis/praxis/schedules.py" source_line=145}
  select.920 = f32[] select(compare.632, select.923, exponential.59), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(_where)/select_n" source_file="/usr/local/lib/python3.10/dist-packages/optax/_src/schedule.py" source_line=399}
  constant.1997 = f32[] constant(-0.00016)
  ROOT multiply.1595 = f32[] multiply(select.920, constant.1997), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=693}
} // fused_computation.231

fused_computation.233 {
  param_2.2258 = f32[8,1024,128,64]{3,2,1,0} parameter(2)
  param_4.1954 = f32[1024,128,64]{2,1,0} parameter(4)
  bitcast.8174 = f32[1,1024,128,64]{3,2,1,0} bitcast(param_4.1954)
  param_3.2223 = s32[] parameter(3)
  constant.2900 = s32[] constant(0)
  dynamic-update-slice.347 = f32[8,1024,128,64]{3,2,1,0} dynamic-update-slice(param_2.2258, bitcast.8174, param_3.2223, constant.2900, constant.2900, /*index=5*/constant.2900)
  param_1.2471 = f32[1024,128,64]{2,1,0} parameter(1)
  bitcast.7882 = f32[1,1024,128,64]{3,2,1,0} bitcast(param_1.2471)
  constant.2903 = s32[] constant(7)
  param_0.1739 = s32[] parameter(0)
  subtract.563 = s32[] subtract(constant.2903, param_0.1739), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  compare.796 = pred[] compare(subtract.563, constant.2900), direction=LT, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/lt" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  constant.2901 = s32[] constant(15)
  subtract.562 = s32[] subtract(constant.2901, param_0.1739), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/add" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  select.1094 = s32[] select(compare.796, subtract.562, subtract.563), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/select_n" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  dynamic-update-slice.123 = f32[8,1024,128,64]{3,2,1,0} dynamic-update-slice(dynamic-update-slice.347, bitcast.7882, select.1094, constant.2900, constant.2900, /*index=5*/constant.2900), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  multiply.1599 = f32[8,1024,128,64]{3,2,1,0} multiply(dynamic-update-slice.123, dynamic-update-slice.123), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/paxml/paxml/learners.py" source_line=47}
  bitcast.7429 = f32[8192,8192]{1,0} bitcast(multiply.1599), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/paxml/paxml/learners.py" source_line=47}
  constant.2062 = f32[] constant(0)
  ROOT reduce.346 = f32[8192]{0} reduce(bitcast.7429, constant.2062), dimensions={1}, to_apply=region_15.791, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/reduce_sum[axes=(0, 1, 2, 3)]" source_file="/pax/paxml/paxml/learners.py" source_line=47}
} // fused_computation.233

fused_computation.238 {
  param_1.1410 = f32[3,2,128,64,2048]{4,3,2,1,0} parameter(1)
  slice.95 = f32[1,2,128,64,2048]{4,3,2,1,0} slice(param_1.1410), slice={[0:1], [0:2], [0:128], [0:64], [0:2048]}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/combined_qkv/slice[start_indices=(0, 0, 0, 0, 0) limit_indices=(1, 16, 2048, 128, 64) strides=(1, 1, 1, 1, 1)]" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=882}
  bitcast.7591 = f32[2,128,64,2048]{3,2,1,0} bitcast(slice.95)
  param_0.991 = f32[2,128,64,2048]{3,2,1,0} parameter(0)
  multiply.1603 = f32[2,128,64,2048]{3,2,1,0} multiply(bitcast.7591, param_0.991), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._scale_query/per_dim_scale/mul" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=404}
  bitcast.7434 = f32[256,64,2048]{2,1,0} bitcast(multiply.1603), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._scale_query/per_dim_scale/mul" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=404}
  constant.2055 = f32[] constant(0)
  ROOT reduce.348 = f32[256,64]{1,0} reduce(bitcast.7434, constant.2055), dimensions={2}, to_apply=region_15.791
} // fused_computation.238

fused_computation.239 {
  param_2.2262 = f32[8,3,1024,128,64]{4,3,2,1,0} parameter(2)
  param_4.1958 = f32[3,128,64,1024]{2,1,0,3} parameter(4)
  bitcast.8180 = f32[1,1024,3,128,64]{4,3,2,1,0} bitcast(param_4.1958)
  transpose.350 = f32[1,3,1024,128,64]{4,3,2,1,0} transpose(bitcast.8180), dimensions={0,2,1,3,4}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/broadcast_in_dim[shape=(1, 3, 8192, 128, 64) broadcast_dimensions=(1, 2, 3, 4)]" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  param_3.2226 = s32[] parameter(3)
  constant.2974 = s32[] constant(0)
  dynamic-update-slice.353 = f32[8,3,1024,128,64]{4,3,2,1,0} dynamic-update-slice(param_2.2262, transpose.350, param_3.2226, constant.2974, constant.2974, /*index=5*/constant.2974, constant.2974)
  param_1.2475 = f32[3,128,64,1024]{2,1,0,3} parameter(1)
  bitcast.7914 = f32[1,1024,3,128,64]{4,3,2,1,0} bitcast(param_1.2475)
  transpose.316 = f32[1,3,1024,128,64]{4,3,2,1,0} transpose(bitcast.7914), dimensions={0,2,1,3,4}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/broadcast_in_dim[shape=(1, 3, 8192, 128, 64) broadcast_dimensions=(1, 2, 3, 4)]" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  constant.2977 = s32[] constant(7)
  param_0.1743 = s32[] parameter(0)
  subtract.591 = s32[] subtract(constant.2977, param_0.1743), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  compare.821 = pred[] compare(subtract.591, constant.2974), direction=LT, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/lt" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  constant.2975 = s32[] constant(15)
  subtract.590 = s32[] subtract(constant.2975, param_0.1743), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/add" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  select.1118 = s32[] select(compare.821, subtract.590, subtract.591), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/select_n" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  dynamic-update-slice.131 = f32[8,3,1024,128,64]{4,3,2,1,0} dynamic-update-slice(dynamic-update-slice.353, transpose.316, select.1118, constant.2974, constant.2974, /*index=5*/constant.2974, constant.2974), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  multiply.1604 = f32[8,3,1024,128,64]{4,3,2,1,0} multiply(dynamic-update-slice.131, dynamic-update-slice.131), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/paxml/paxml/learners.py" source_line=47}
  bitcast.7435 = f32[8192,128,192]{2,1,0} bitcast(multiply.1604), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/paxml/paxml/learners.py" source_line=47}
  constant.2046 = f32[] constant(0)
  ROOT reduce.349 = f32[8192,128]{1,0} reduce(bitcast.7435, constant.2046), dimensions={2}, to_apply=region_15.791, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/reduce_sum[axes=(0, 1, 2, 3, 4)]" source_file="/pax/paxml/paxml/learners.py" source_line=47}
} // fused_computation.239

fused_computation.242 {
  param_0.480 = f32[8,3,1024,128,64]{4,3,1,2,0} parameter(0)
  bitcast.7438 = f32[8,1024,3,128,64]{4,3,2,1,0} bitcast(param_0.480)
  ROOT transpose.252 = f32[8,3,1024,128,64]{4,3,2,1,0} transpose(bitcast.7438), dimensions={0,2,1,3,4}
}

fused_computation.243 {
  param_0.1391 = f32[8,8192]{1,0} parameter(0)
  param_2.1545 = f32[8192]{0} parameter(2)
  bitcast.7918 = f32[1,8192]{1,0} bitcast(param_2.1545)
  constant.2995 = s32[] constant(7)
  param_1.1899 = s32[] parameter(1)
  subtract.599 = s32[] subtract(constant.2995, param_1.1899), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  constant.2992 = s32[] constant(0)
  compare.825 = pred[] compare(subtract.599, constant.2992), direction=LT, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/lt" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  constant.2993 = s32[] constant(15)
  subtract.598 = s32[] subtract(constant.2993, param_1.1899), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/add" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  select.1122 = s32[] select(compare.825, subtract.598, subtract.599), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/select_n" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  dynamic-update-slice.135 = f32[8,8192]{1,0} dynamic-update-slice(param_0.1391, bitcast.7918, select.1122, constant.2992), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  multiply.1605 = f32[8,8192]{1,0} multiply(dynamic-update-slice.135, dynamic-update-slice.135), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/paxml/paxml/learners.py" source_line=47}
  bitcast.7439 = f32[256,256]{1,0} bitcast(multiply.1605), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/paxml/paxml/learners.py" source_line=47}
  constant.2043 = f32[] constant(0)
  reduce.350 = f32[256]{0} reduce(bitcast.7439, constant.2043), dimensions={1}, to_apply=region_15.791, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/reduce_sum[axes=(0, 1)]" source_file="/pax/paxml/paxml/learners.py" source_line=47}
  param_3.2244 = f32[8,8192]{1,0} parameter(3)
  param_4.1975 = f32[8192]{0} parameter(4)
  bitcast.7922.clone.1 = f32[1,8192]{1,0} bitcast(param_4.1975)
  dynamic-update-slice.139.clone.1 = f32[8,8192]{1,0} dynamic-update-slice(param_3.2244, bitcast.7922.clone.1, select.1122, constant.2992), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  multiply.1607.clone.1 = f32[8,8192]{1,0} multiply(dynamic-update-slice.139.clone.1, dynamic-update-slice.139.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/paxml/paxml/learners.py" source_line=47}
  bitcast.7442.clone.1 = f32[256,256]{1,0} bitcast(multiply.1607.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/paxml/paxml/learners.py" source_line=47}
  reduce.352.clone.1 = f32[256]{0} reduce(bitcast.7442.clone.1, constant.2043), dimensions={1}, to_apply=region_15.791, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/reduce_sum[axes=(0, 1)]" source_file="/pax/paxml/paxml/learners.py" source_line=47}
  param_5.1733 = f32[8,8192]{1,0} parameter(5)
  param_6.1384 = f32[8192]{0} parameter(6)
  bitcast.7926.clone.1 = f32[1,8192]{1,0} bitcast(param_6.1384)
  dynamic-update-slice.143.clone.1 = f32[8,8192]{1,0} dynamic-update-slice(param_5.1733, bitcast.7926.clone.1, select.1122, constant.2992), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  multiply.1608.clone.1 = f32[8,8192]{1,0} multiply(dynamic-update-slice.143.clone.1, dynamic-update-slice.143.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/paxml/paxml/learners.py" source_line=47}
  bitcast.7444.clone.1 = f32[256,256]{1,0} bitcast(multiply.1608.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/paxml/paxml/learners.py" source_line=47}
  reduce.353.clone.1 = f32[256]{0} reduce(bitcast.7444.clone.1, constant.2043), dimensions={1}, to_apply=region_15.791, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/reduce_sum[axes=(0, 1)]" source_file="/pax/paxml/paxml/learners.py" source_line=47}
  param_7.1007 = f32[8,8192]{1,0} parameter(7)
  param_8.940 = f32[8192]{0} parameter(8)
  bitcast.7930.clone.1 = f32[1,8192]{1,0} bitcast(param_8.940)
  dynamic-update-slice.147.clone.1 = f32[8,8192]{1,0} dynamic-update-slice(param_7.1007, bitcast.7930.clone.1, select.1122, constant.2992), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  multiply.1610.clone.1 = f32[8,8192]{1,0} multiply(dynamic-update-slice.147.clone.1, dynamic-update-slice.147.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/paxml/paxml/learners.py" source_line=47}
  bitcast.7447.clone.1 = f32[256,256]{1,0} bitcast(multiply.1610.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/paxml/paxml/learners.py" source_line=47}
  reduce.355.clone.1 = f32[256]{0} reduce(bitcast.7447.clone.1, constant.2043), dimensions={1}, to_apply=region_15.791, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/reduce_sum[axes=(0, 1)]" source_file="/pax/paxml/paxml/learners.py" source_line=47}
  param_9.821 = f32[8,8192]{1,0} parameter(9)
  param_10.699 = f32[8192]{0} parameter(10)
  bitcast.7938.clone.1 = f32[1,8192]{1,0} bitcast(param_10.699)
  dynamic-update-slice.155.clone.1 = f32[8,8192]{1,0} dynamic-update-slice(param_9.821, bitcast.7938.clone.1, select.1122, constant.2992), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  multiply.1614.clone.1 = f32[8,8192]{1,0} multiply(dynamic-update-slice.155.clone.1, dynamic-update-slice.155.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/paxml/paxml/learners.py" source_line=47}
  bitcast.7454.clone.1 = f32[256,256]{1,0} bitcast(multiply.1614.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/paxml/paxml/learners.py" source_line=47}
  reduce.358.clone.1 = f32[256]{0} reduce(bitcast.7454.clone.1, constant.2043), dimensions={1}, to_apply=region_15.791, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/reduce_sum[axes=(0, 1)]" source_file="/pax/paxml/paxml/learners.py" source_line=47}
  ROOT tuple.165 = (f32[256]{0}, f32[256]{0}, f32[256]{0}, f32[256]{0}, f32[256]{0}) tuple(reduce.350, reduce.352.clone.1, reduce.353.clone.1, reduce.355.clone.1, reduce.358.clone.1)
} // fused_computation.243

fused_computation.245 {
  param_0.985 = f32[2,2048,8192]{2,1,0} parameter(0)
  param_1.1407 = f32[4096,8192]{1,0} parameter(1)
  bitcast.7588 = f32[2,2048,8192]{2,1,0} bitcast(param_1.1407)
  multiply.1606 = f32[2,2048,8192]{2,1,0} multiply(param_0.985, bitcast.7588), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/layer_norm/mul" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=376}
  bitcast.7441 = f32[4096,8192]{1,0} bitcast(multiply.1606), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/layer_norm/mul" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=376}
  constant.2045 = f32[] constant(0)
  reduce.351 = f32[8192]{0} reduce(bitcast.7441, constant.2045), dimensions={0}, to_apply=region_15.791, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/layer_norm/reduce_sum[axes=(0, 1)]" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=376}
  reduce.422 = f32[8192]{0} reduce(param_1.1407, constant.2045), dimensions={0}, to_apply=region_15.791, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/layer_norm/reduce_sum[axes=(0, 1)]" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=378}
  ROOT tuple.98 = (f32[8192]{0}, f32[8192]{0}) tuple(reduce.351, reduce.422)
} // fused_computation.245

fused_computation.250 {
  param_0.982 = f32[2,2048,8192]{2,1,0} parameter(0)
  param_1.1406 = f32[4096,8192]{1,0} parameter(1)
  bitcast.7587 = f32[2,2048,8192]{2,1,0} bitcast(param_1.1406)
  multiply.1609 = f32[2,2048,8192]{2,1,0} multiply(param_0.982, bitcast.7587), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/mul" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=376}
  bitcast.7446 = f32[4096,8192]{1,0} bitcast(multiply.1609), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/mul" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=376}
  constant.2040 = f32[] constant(0)
  reduce.354 = f32[8192]{0} reduce(bitcast.7446, constant.2040), dimensions={0}, to_apply=region_15.791, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/reduce_sum[axes=(0, 1)]" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=376}
  reduce.423 = f32[8192]{0} reduce(param_1.1406, constant.2040), dimensions={0}, to_apply=region_15.791, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/reduce_sum[axes=(0, 1)]" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=378}
  ROOT tuple.104 = (f32[8192]{0}, f32[8192]{0}) tuple(reduce.354, reduce.423)
} // fused_computation.250

fused_computation.253 {
  param_0.977 = f32[16384]{0} parameter(0)
  bitcast.7449 = f32[128,128]{1,0} bitcast(param_0.977), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/reduce_sum[axes=(0, 1, 2)]" source_file="/pax/paxml/paxml/learners.py" source_line=47}
  constant.2032 = f32[] constant(0)
  ROOT reduce.356 = f32[128]{0} reduce(bitcast.7449, constant.2032), dimensions={1}, to_apply=region_15.791, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/reduce_sum[axes=(0, 1, 2)]" source_file="/pax/paxml/paxml/learners.py" source_line=47}
}

fused_computation.254 {
  param_2.2267 = f32[8,32768,1024]{2,1,0} parameter(2)
  param_4.1963 = f32[32768,1024]{0,1} parameter(4)
  bitcast.8188 = f32[1,1024,32768]{2,1,0} bitcast(param_4.1963)
  transpose.358 = f32[1,32768,1024]{2,1,0} transpose(bitcast.8188), dimensions={0,2,1}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/broadcast_in_dim[shape=(1, 32768, 8192) broadcast_dimensions=(1, 2)]" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  param_3.2229 = s32[] parameter(3)
  constant.3064 = s32[] constant(0)
  dynamic-update-slice.361 = f32[8,32768,1024]{2,1,0} dynamic-update-slice(param_2.2267, transpose.358, param_3.2229, constant.3064, constant.3064)
  param_1.2480 = f32[32768,1024]{0,1} parameter(1)
  bitcast.7934 = f32[1,1024,32768]{2,1,0} bitcast(param_1.2480)
  transpose.320 = f32[1,32768,1024]{2,1,0} transpose(bitcast.7934), dimensions={0,2,1}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/broadcast_in_dim[shape=(1, 32768, 8192) broadcast_dimensions=(1, 2)]" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  constant.3067 = s32[] constant(7)
  param_0.1748 = s32[] parameter(0)
  subtract.631 = s32[] subtract(constant.3067, param_0.1748), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  compare.841 = pred[] compare(subtract.631, constant.3064), direction=LT, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/lt" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  constant.3065 = s32[] constant(15)
  subtract.630 = s32[] subtract(constant.3065, param_0.1748), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/add" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  select.1138 = s32[] select(compare.841, subtract.630, subtract.631), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/select_n" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  dynamic-update-slice.151 = f32[8,32768,1024]{2,1,0} dynamic-update-slice(dynamic-update-slice.361, transpose.320, select.1138, constant.3064, constant.3064), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  multiply.1611 = f32[8,32768,1024]{2,1,0} multiply(dynamic-update-slice.151, dynamic-update-slice.151), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/paxml/paxml/learners.py" source_line=47}
  bitcast.7450 = f32[16384,128,128]{2,1,0} bitcast(multiply.1611), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/paxml/paxml/learners.py" source_line=47}
  constant.2033 = f32[] constant(0)
  ROOT reduce.357 = f32[16384,128]{1,0} reduce(bitcast.7450, constant.2033), dimensions={2}, to_apply=region_15.791, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/reduce_sum[axes=(0, 1, 2)]" source_file="/pax/paxml/paxml/learners.py" source_line=47}
} // fused_computation.254

fused_computation.258 {
  param_0.507 = f32[8,32768,1024]{1,2,0} parameter(0)
  bitcast.7453 = f32[8,1024,32768]{2,1,0} bitcast(param_0.507)
  ROOT transpose.255 = f32[8,32768,1024]{2,1,0} transpose(bitcast.7453), dimensions={0,2,1}
}

fused_computation.261 {
  param_0.971 = f32[16384]{0} parameter(0)
  bitcast.7456 = f32[128,128]{1,0} bitcast(param_0.971), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/reduce_sum[axes=(0, 1, 2)]" source_file="/pax/paxml/paxml/learners.py" source_line=47}
  constant.2025 = f32[] constant(0)
  ROOT reduce.359 = f32[128]{0} reduce(bitcast.7456, constant.2025), dimensions={1}, to_apply=region_15.791, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/reduce_sum[axes=(0, 1, 2)]" source_file="/pax/paxml/paxml/learners.py" source_line=47}
}

fused_computation.262 {
  param_0.1415 = f32[8,1024,32768]{2,1,0} parameter(0)
  param_2.1600 = f32[1024,32768]{1,0} parameter(2)
  bitcast.7942 = f32[1,1024,32768]{2,1,0} bitcast(param_2.1600)
  constant.3103 = s32[] constant(7)
  param_1.1929 = s32[] parameter(1)
  subtract.647 = s32[] subtract(constant.3103, param_1.1929), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  constant.3100 = s32[] constant(0)
  compare.849 = pred[] compare(subtract.647, constant.3100), direction=LT, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/lt" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  constant.3101 = s32[] constant(15)
  subtract.646 = s32[] subtract(constant.3101, param_1.1929), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/add" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  select.1146 = s32[] select(compare.849, subtract.646, subtract.647), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/select_n" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  dynamic-update-slice.159 = f32[8,1024,32768]{2,1,0} dynamic-update-slice(param_0.1415, bitcast.7942, select.1146, constant.3100, constant.3100), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  multiply.1615 = f32[8,1024,32768]{2,1,0} multiply(dynamic-update-slice.159, dynamic-update-slice.159), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/paxml/paxml/learners.py" source_line=47}
  bitcast.7457 = f32[16384,128,128]{2,1,0} bitcast(multiply.1615), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/paxml/paxml/learners.py" source_line=47}
  constant.2026 = f32[] constant(0)
  ROOT reduce.360 = f32[16384,128]{1,0} reduce(bitcast.7457, constant.2026), dimensions={2}, to_apply=region_15.791, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/reduce_sum[axes=(0, 1, 2)]" source_file="/pax/paxml/paxml/learners.py" source_line=47}
} // fused_computation.262

fused_computation.264 {
  param_0.516 = f32[8,1024,32768]{2,1,0} parameter(0)
  param_2.1012 = f32[1024,32768]{1,0} parameter(2)
  bitcast.7459 = f32[1,1024,32768]{2,1,0} bitcast(param_2.1012)
  param_1.789 = s32[] parameter(1)
  constant.2028 = s32[] constant(0)
  ROOT dynamic-update-slice.117 = f32[8,1024,32768]{2,1,0} dynamic-update-slice(param_0.516, bitcast.7459, param_1.789, constant.2028, constant.2028)
} // fused_computation.264

fused_computation.265 {
  param_0.1419 = f32[8,32768]{1,0} parameter(0)
  param_2.1609 = f32[32768]{0} parameter(2)
  bitcast.7946 = f32[1,32768]{1,0} bitcast(param_2.1609)
  constant.3121 = s32[] constant(7)
  param_1.1934 = s32[] parameter(1)
  subtract.655 = s32[] subtract(constant.3121, param_1.1934), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  constant.3118 = s32[] constant(0)
  compare.853 = pred[] compare(subtract.655, constant.3118), direction=LT, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/lt" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  constant.3119 = s32[] constant(15)
  subtract.654 = s32[] subtract(constant.3119, param_1.1934), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/add" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  select.1150 = s32[] select(compare.853, subtract.654, subtract.655), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/select_n" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  dynamic-update-slice.163 = f32[8,32768]{1,0} dynamic-update-slice(param_0.1419, bitcast.7946, select.1150, constant.3118), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  multiply.1616 = f32[8,32768]{1,0} multiply(dynamic-update-slice.163, dynamic-update-slice.163), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/paxml/paxml/learners.py" source_line=47}
  bitcast.7460 = f32[512,512]{1,0} bitcast(multiply.1616), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/paxml/paxml/learners.py" source_line=47}
  constant.2022 = f32[] constant(0)
  ROOT reduce.361 = f32[512]{0} reduce(bitcast.7460, constant.2022), dimensions={1}, to_apply=region_15.791, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/reduce_sum[axes=(0, 1)]" source_file="/pax/paxml/paxml/learners.py" source_line=47}
} // fused_computation.265

fused_computation.267 {
  param_0.961 = f32[1024,32000]{1,0} parameter(0)
  multiply.1617 = f32[1024,32000]{1,0} multiply(param_0.961, param_0.961), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/paxml/paxml/learners.py" source_line=47}
  bitcast.7462 = f32[4096,8000]{1,0} bitcast(multiply.1617), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/paxml/paxml/learners.py" source_line=47}
  constant.2015 = f32[] constant(0)
  ROOT reduce.362 = f32[4096]{0} reduce(bitcast.7462, constant.2015), dimensions={1}, to_apply=region_15.791, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/reduce_sum[axes=(0, 1)]" source_file="/pax/paxml/paxml/learners.py" source_line=47}
}

fused_computation.268 {
  param_3.500 = f32[2,2048,8192]{2,1,0} parameter(3)
  param_4.261 = f32[2,2048,8192]{2,1,0} parameter(4)
  add.1016 = f32[2,2048,8192]{2,1,0} add(param_3.500, param_4.261), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/layer_norm/add_any" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=371}
  param_2.635 = f32[2,2048,8192]{2,1,0} parameter(2)
  add.1014 = f32[2,2048,8192]{2,1,0} add(add.1016, param_2.635), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/layer_norm/add_any" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  param_0.525 = f32[2,2048]{1,0} parameter(0)
  param_1.805 = f32[2,2048]{1,0} parameter(1)
  add.1013 = f32[2,2048]{1,0} add(param_0.525, param_1.805), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/layer_norm/add_any" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  constant.2016 = f32[] constant(0.000122070312)
  broadcast.2563 = f32[2,2048]{1,0} broadcast(constant.2016), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/layer_norm/div" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=370}
  multiply.1619 = f32[2,2048]{1,0} multiply(add.1013, broadcast.2563), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/layer_norm/div" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=370}
  broadcast.2562 = f32[2,2048,8192]{2,1,0} broadcast(multiply.1619), dimensions={0,1}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/layer_norm/broadcast_in_dim[shape=(16, 2048, 8192) broadcast_dimensions=(0, 1)]" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=370}
  add.1012 = f32[2,2048,8192]{2,1,0} add(add.1014, broadcast.2562), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/layer_norm/add_any" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=370}
  constant.1663 = f32[] constant(90.5096664)
  broadcast.2561 = f32[2,2048,8192]{2,1,0} broadcast(constant.1663), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/lm._prepare_input/softmax.emb_lookup/mul" source_file="/pax/praxis/praxis/layers/embedding_softmax.py" source_line=399}
  ROOT multiply.1618 = f32[2,2048,8192]{2,1,0} multiply(add.1012, broadcast.2561), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/lm._prepare_input/softmax.emb_lookup/mul" source_file="/pax/praxis/praxis/layers/embedding_softmax.py" source_line=399}
} // fused_computation.268

fused_computation.269 {
  param_2.2103 = f32[4096,8192]{1,0} parameter(2)
  bitcast.7950.clone.1 = f32[2,2048,8192]{2,1,0} bitcast(param_2.2103)
  param_1.2320 = f32[1,8192]{1,0} parameter(1)
  bitcast.7949.clone.1 = f32[8192]{0} bitcast(param_1.2320)
  broadcast.3203.clone.1 = f32[2,2048,8192]{2,1,0} broadcast(bitcast.7949.clone.1), dimensions={2}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/layer_norm/mul" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=376}
  multiply.1975.clone.1 = f32[2,2048,8192]{2,1,0} multiply(bitcast.7950.clone.1, broadcast.3203.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/layer_norm/mul" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=376}
  param_0.1675 = f32[2,2048]{1,0} parameter(0)
  bitcast.7580.clone.1 = f32[1,2,2048]{2,1,0} bitcast(param_0.1675)
  rsqrt.44.clone.1 = f32[1,2,2048]{2,1,0} rsqrt(bitcast.7580.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/layer_norm/rsqrt" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  bitcast.7579.clone.1 = f32[2,2048]{1,0} bitcast(rsqrt.44.clone.1)
  broadcast.2564.clone.1 = f32[2,2048,8192]{2,1,0} broadcast(bitcast.7579.clone.1), dimensions={0,1}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/layer_norm/mul" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  multiply.1620.clone.1 = f32[2,2048,8192]{2,1,0} multiply(multiply.1975.clone.1, broadcast.2564.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/layer_norm/mul" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  negate.120 = f32[2,2048,8192]{2,1,0} negate(multiply.1620.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/layer_norm/neg" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  constant.2017 = f32[] constant(0)
  reduce.363 = f32[2,2048]{1,0} reduce(negate.120, constant.2017), dimensions={2}, to_apply=region_15.791, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/layer_norm/reduce_sum[axes=(2,)]" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  param_4.1823 = f32[8,2,2048,8192]{3,2,1,0} parameter(4)
  constant.2778.clone.1 = s32[] constant(7)
  param_5.1621 = s32[] parameter(5)
  subtract.512.clone.1 = s32[] subtract(constant.2778.clone.1, param_5.1621), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  constant.2775.clone.1 = s32[] constant(0)
  compare.774.clone.1 = pred[] compare(subtract.512.clone.1, constant.2775.clone.1), direction=LT, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/lt" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  constant.2776.clone.1 = s32[] constant(15)
  subtract.511.clone.1 = s32[] subtract(constant.2776.clone.1, param_5.1621), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/add" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  select.1067.clone.1 = s32[] select(compare.774.clone.1, subtract.511.clone.1, subtract.512.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/select_n" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  dynamic-slice.253.clone.1 = f32[1,2,2048,8192]{3,2,1,0} dynamic-slice(param_4.1823, select.1067.clone.1, constant.2775.clone.1, constant.2775.clone.1, constant.2775.clone.1), dynamic_slice_sizes={1,2,2048,8192}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/dynamic_slice[slice_sizes=(1, 16, 2048, 8192)]" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  bitcast.7844.clone.1 = f32[2,2048,8192]{2,1,0} bitcast(dynamic-slice.253.clone.1)
  param_3.2089 = f32[2,2048]{1,0} parameter(3)
  constant.2774.clone.1 = f32[] constant(0.000122070312)
  broadcast.3107.clone.1 = f32[2,2048]{1,0} broadcast(constant.2774.clone.1), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/layer_norm/div" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=370}
  multiply.1937.clone.1 = f32[2,2048]{1,0} multiply(param_3.2089, broadcast.3107.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/layer_norm/div" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=370}
  broadcast.3106.clone.1 = f32[2,2048,8192]{2,1,0} broadcast(multiply.1937.clone.1), dimensions={0,1}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/layer_norm/sub" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  subtract.510.clone.1 = f32[2,2048,8192]{2,1,0} subtract(bitcast.7844.clone.1, broadcast.3106.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/layer_norm/sub" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  multiply.1625.clone.1 = f32[2,2048,8192]{2,1,0} multiply(subtract.510.clone.1, multiply.1975.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/layer_norm/mul" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  reduce.365.clone.1 = f32[2,2048]{1,0} reduce(multiply.1625.clone.1, constant.2017), dimensions={2}, to_apply=region_15.791, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/layer_norm/reduce_sum[axes=(2,)]" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  ROOT tuple.97 = (f32[2,2048]{1,0}, f32[2,2048,8192]{2,1,0}, f32[2,2048]{1,0}) tuple(reduce.363, multiply.1620.clone.1, reduce.365.clone.1)
} // fused_computation.269

fused_computation.270 {
  param_3.2085 = f32[8,2,2048,8192]{3,2,1,0} parameter(3)
  constant.2802.clone.1 = s32[] constant(7)
  param_4.1815 = s32[] parameter(4)
  subtract.525.clone.1 = s32[] subtract(constant.2802.clone.1, param_4.1815), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  constant.2799.clone.1 = s32[] constant(0)
  compare.778.clone.1 = pred[] compare(subtract.525.clone.1, constant.2799.clone.1), direction=LT, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/lt" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  constant.2800.clone.1 = s32[] constant(15)
  subtract.523.clone.1 = s32[] subtract(constant.2800.clone.1, param_4.1815), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/add" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  select.1072.clone.1 = s32[] select(compare.778.clone.1, subtract.523.clone.1, subtract.525.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/select_n" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  dynamic-slice.257.clone.1 = f32[1,2,2048,8192]{3,2,1,0} dynamic-slice(param_3.2085, select.1072.clone.1, constant.2799.clone.1, constant.2799.clone.1, constant.2799.clone.1), dynamic_slice_sizes={1,2,2048,8192}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/dynamic_slice[slice_sizes=(1, 16, 2048, 8192)]" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  bitcast.7848.clone.1 = f32[2,2048,8192]{2,1,0} bitcast(dynamic-slice.257.clone.1)
  param_2.2113 = f32[2,2048]{1,0} parameter(2)
  constant.2798.clone.1 = f32[] constant(0.000122070312)
  broadcast.3115.clone.1 = f32[2,2048]{1,0} broadcast(constant.2798.clone.1), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/layer_norm/div" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=370}
  multiply.1941.clone.1 = f32[2,2048]{1,0} multiply(param_2.2113, broadcast.3115.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/layer_norm/div" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=370}
  broadcast.3114.clone.1 = f32[2,2048,8192]{2,1,0} broadcast(multiply.1941.clone.1), dimensions={0,1}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/layer_norm/sub" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  subtract.522.clone.1 = f32[2,2048,8192]{2,1,0} subtract(bitcast.7848.clone.1, broadcast.3114.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/layer_norm/sub" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  param_1.2327 = f32[2,2048]{1,0} parameter(1)
  bitcast.7464.clone.1 = f32[1,2,2048]{2,1,0} bitcast(param_1.2327)
  param_0.1677 = f32[2,2048]{1,0} parameter(0)
  bitcast.7581.clone.1 = f32[1,2,2048]{2,1,0} bitcast(param_0.1677)
  rsqrt.45.clone.1 = f32[1,2,2048]{2,1,0} rsqrt(bitcast.7581.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/layer_norm/rsqrt" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  divide.213.clone.1 = f32[1,2,2048]{2,1,0} divide(rsqrt.45.clone.1, bitcast.7581.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/layer_norm/div" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  constant.2019.clone.1 = f32[] constant(-0.5)
  broadcast.2568.clone.1 = f32[1,2,2048]{2,1,0} broadcast(constant.2019.clone.1), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/final_ln/mul" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  multiply.1624.clone.1 = f32[1,2,2048]{2,1,0} multiply(divide.213.clone.1, broadcast.2568.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/layer_norm/mul" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  multiply.1623.clone.1 = f32[1,2,2048]{2,1,0} multiply(bitcast.7464.clone.1, multiply.1624.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/layer_norm/mul" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  constant.2020.clone.1 = f32[] constant(0.000244140625)
  broadcast.2566.clone.1 = f32[1,2,2048]{2,1,0} broadcast(constant.2020.clone.1), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/final_ln/mul" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=371}
  multiply.1622.clone.1 = f32[1,2,2048]{2,1,0} multiply(multiply.1623.clone.1, broadcast.2566.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/layer_norm/mul" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=371}
  bitcast.7463.clone.1 = f32[2,2048]{1,0} bitcast(multiply.1622.clone.1)
  broadcast.2565.clone.1 = f32[2,2048,8192]{2,1,0} broadcast(bitcast.7463.clone.1), dimensions={0,1}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/layer_norm/mul" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=371}
  multiply.1621.clone.1 = f32[2,2048,8192]{2,1,0} multiply(subtract.522.clone.1, broadcast.2565.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/layer_norm/mul" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=371}
  negate.121 = f32[2,2048,8192]{2,1,0} negate(multiply.1621.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/layer_norm/neg" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=371}
  constant.2018 = f32[] constant(0)
  reduce.364 = f32[2,2048]{1,0} reduce(negate.121, constant.2018), dimensions={2}, to_apply=region_15.791, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/layer_norm/reduce_sum[axes=(2,)]" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=371}
  ROOT tuple.96 = (f32[2,2048]{1,0}, f32[2,2048,8192]{2,1,0}) tuple(reduce.364, multiply.1621.clone.1)
} // fused_computation.270

fused_computation.276 {
  param_0.538 = f32[256,2048,64]{2,1,0} parameter(0)
  bitcast.7469 = f32[2,128,2048,64]{3,2,1,0} bitcast(param_0.538)
  ROOT transpose.257 = f32[2,128,64,2048]{3,2,1,0} transpose(bitcast.7469), dimensions={0,1,3,2}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._atten_logits/qk_einsum/BTNH,BSNH->BNTS/dot_general[dimension_numbers=(((3,), (1,)), ((0, 1), (0, 2))) precision=None preferred_element_type=float32]" source_file="/pax/praxis/praxis/layers/base_ops.py" source_line=42}
}

fused_computation.277 {
  param_0.992 = f32[3,2,128,64,2048]{4,3,2,1,0} parameter(0)
  slice.96 = f32[1,2,128,64,2048]{4,3,2,1,0} slice(param_0.992), slice={[1:2], [0:2], [0:128], [0:64], [0:2048]}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/combined_qkv/slice[start_indices=(1, 0, 0, 0, 0) limit_indices=(2, 16, 2048, 128, 64) strides=(1, 1, 1, 1, 1)]" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=882}
  bitcast.7470 = f32[2,128,64,2048]{3,2,1,0} bitcast(slice.96)
  ROOT transpose.258 = f32[2,128,2048,64]{3,2,1,0} transpose(bitcast.7470), dimensions={0,1,3,2}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._shard_blnh/sharding_constraint[sharding=GSPMDSharding({devices=[8,1,1,1]<=[8]}) resource_env=ResourceEnv(Mesh(device_ids=array([[[0],\n        [1],\n        [2],\n        [3],\n        [4],\n        [5],\n        [6],\n        [7]]]), axis_names=(\'replica\', \'data\', \'mdl\')), ()) unconstrained_dims=set()]" source_file="/pax/praxis/praxis/py_utils.py" source_line=486}
}

fused_computation.278 {
  param_5.336 = pred[1,2,2048,2048]{3,2,1,0} parameter(5)
  bitcast.7593 = pred[2,2048,2048]{2,1,0} bitcast(param_5.336)
  broadcast.2574 = pred[2,128,2048,2048]{3,2,1,0} broadcast(bitcast.7593), dimensions={0,2,3}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/jit(_where)/broadcast_in_dim[shape=(16, 128, 2048, 2048) broadcast_dimensions=(0, 2, 3)]" source_file="/pax/praxis/praxis/py_utils.py" source_line=743}
  param_2.1029 = f32[2,128,2048]{2,1,0} parameter(2)
  negate.122 = f32[2,128,2048]{2,1,0} negate(param_2.1029), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/neg" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=1487}
  broadcast.2572 = f32[2,128,2048,2048]{3,2,1,0} broadcast(negate.122), dimensions={0,1,2}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/broadcast_in_dim[shape=(16, 128, 2048, 2048) broadcast_dimensions=(0, 1, 2)]" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=1487}
  param_4.453 = f32[256,2048,2048]{2,1,0} parameter(4)
  bitcast.7592 = f32[2,128,2048,2048]{3,2,1,0} bitcast(param_4.453)
  param_3.761 = f32[2,128,2048]{2,1,0} parameter(3)
  broadcast.2573 = f32[2,128,2048,2048]{3,2,1,0} broadcast(param_3.761), dimensions={0,1,2}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/div" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=1487}
  divide.214 = f32[2,128,2048,2048]{3,2,1,0} divide(bitcast.7592, broadcast.2573), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/div" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=1487}
  add.1021 = f32[2,128,2048,2048]{3,2,1,0} add(broadcast.2572, divide.214), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/add_any" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=1487}
  param_1.830 = f32[2,128,2048,2048]{3,2,1,0} parameter(1)
  multiply.1632 = f32[2,128,2048,2048]{3,2,1,0} multiply(add.1021, param_1.830), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/mul" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=1487}
  constant.2059 = f32[] constant(0)
  broadcast.2576 = f32[2,128,2048,2048]{3,2,1,0} broadcast(constant.2059), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/jit(_where)/broadcast_in_dim[shape=(16, 128, 2048, 2048) broadcast_dimensions=()]" source_file="/pax/praxis/praxis/py_utils.py" source_line=743}
  select.930 = f32[2,128,2048,2048]{3,2,1,0} select(broadcast.2574, multiply.1632, broadcast.2576), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/jit(_where)/select_n" source_file="/pax/praxis/praxis/py_utils.py" source_line=743}
  constant.2057 = f32[] constant(50)
  broadcast.2577 = f32[2,128,2048,2048]{3,2,1,0} broadcast(constant.2057), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._cap_logits/div" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=1384}
  multiply.1631 = f32[2,128,2048,2048]{3,2,1,0} multiply(select.930, broadcast.2577), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._cap_logits/mul" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=1384}
  constant.2058 = f32[] constant(1)
  broadcast.2575 = f32[2,128,2048,2048]{3,2,1,0} broadcast(constant.2058), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._cap_logits/sub" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=1384}
  param_0.543 = f32[2,128,2048,2048]{3,2,1,0} parameter(0)
  subtract.319 = f32[2,128,2048,2048]{3,2,1,0} subtract(broadcast.2575, param_0.543), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._cap_logits/sub" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=1384}
  multiply.1630 = f32[2,128,2048,2048]{3,2,1,0} multiply(multiply.1631, subtract.319), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._cap_logits/mul" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=1384}
  multiply.1629 = f32[2,128,2048,2048]{3,2,1,0} multiply(multiply.1630, param_0.543), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._cap_logits/mul" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=1384}
  add.1020 = f32[2,128,2048,2048]{3,2,1,0} add(multiply.1630, multiply.1629), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._cap_logits/add_any" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=1384}
  constant.2056 = f32[] constant(0.02)
  broadcast.2578 = f32[2,128,2048,2048]{3,2,1,0} broadcast(constant.2056), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._cap_logits/div" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=1384}
  ROOT multiply.1628 = f32[2,128,2048,2048]{3,2,1,0} multiply(add.1020, broadcast.2578), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._cap_logits/div" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=1384}
} // fused_computation.278

fused_computation.279 {
  param_2.1031 = f32[256,2048,2048]{2,1,0} parameter(2)
  bitcast.7594 = f32[2,128,2048,2048]{3,2,1,0} bitcast(param_2.1031)
  constant.2060 = f32[] constant(1)
  broadcast.2580 = f32[2,128,2048]{2,1,0} broadcast(constant.2060), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/broadcast_in_dim[shape=(16, 128, 2048, 1) broadcast_dimensions=()]" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=1487}
  param_1.1411 = f32[2,128,2048]{2,1,0} parameter(1)
  multiply.1635 = f32[2,128,2048]{2,1,0} multiply(param_1.1411, param_1.1411), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/mul" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=1487}
  divide.215 = f32[2,128,2048]{2,1,0} divide(broadcast.2580, multiply.1635), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/div" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=1487}
  broadcast.2579 = f32[2,128,2048,2048]{3,2,1,0} broadcast(divide.215), dimensions={0,1,2}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/mul" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=1487}
  multiply.1634 = f32[2,128,2048,2048]{3,2,1,0} multiply(bitcast.7594, broadcast.2579), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/mul" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=1487}
  param_0.993 = f32[2,128,2048,2048]{3,2,1,0} parameter(0)
  multiply.1633 = f32[2,128,2048,2048]{3,2,1,0} multiply(multiply.1634, param_0.993), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/mul" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=1487}
  constant.2061 = f32[] constant(0)
  ROOT reduce.366 = f32[2,128,2048]{2,1,0} reduce(multiply.1633, constant.2061), dimensions={3}, to_apply=region_15.791, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/reduce_sum[axes=(3,)]" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=1487}
} // fused_computation.279

fused_computation.280 {
  param_3.528 = f32[2,2048,8192]{2,1,0} parameter(3)
  param_4.285 = f32[2,2048,8192]{2,1,0} parameter(4)
  add.1026 = f32[2,2048,8192]{2,1,0} add(param_3.528, param_4.285), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/add_any" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=371}
  param_2.658 = f32[2,2048,8192]{2,1,0} parameter(2)
  add.1025 = f32[2,2048,8192]{2,1,0} add(add.1026, param_2.658), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/add_any" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  param_0.548 = f32[2,2048]{1,0} parameter(0)
  param_1.839 = f32[2,2048]{1,0} parameter(1)
  add.1024 = f32[2,2048]{1,0} add(param_0.548, param_1.839), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/add_any" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  constant.2064 = f32[] constant(0.000122070312)
  broadcast.2582 = f32[2,2048]{1,0} broadcast(constant.2064), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/layer_norm/div" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=370}
  multiply.1636 = f32[2,2048]{1,0} multiply(add.1024, broadcast.2582), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/div" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=370}
  broadcast.2581 = f32[2,2048,8192]{2,1,0} broadcast(multiply.1636), dimensions={0,1}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/broadcast_in_dim[shape=(16, 2048, 8192) broadcast_dimensions=(0, 1)]" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=370}
  ROOT add.1022 = f32[2,2048,8192]{2,1,0} add(add.1025, broadcast.2581), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/add_any" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=370}
} // fused_computation.280

fused_computation.281 {
  param_2.2118 = f32[4096,8192]{1,0} parameter(2)
  bitcast.7874.clone.1 = f32[2,2048,8192]{2,1,0} bitcast(param_2.2118)
  param_1.2335 = f32[1,8192]{1,0} parameter(1)
  bitcast.7873.clone.1 = f32[8192]{0} bitcast(param_1.2335)
  broadcast.3175.clone.1 = f32[2,2048,8192]{2,1,0} broadcast(bitcast.7873.clone.1), dimensions={2}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/mul" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=376}
  multiply.1959.clone.1 = f32[2,2048,8192]{2,1,0} multiply(bitcast.7874.clone.1, broadcast.3175.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/mul" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=376}
  param_0.1679 = f32[2,2048]{1,0} parameter(0)
  bitcast.7597.clone.1 = f32[1,2,2048]{2,1,0} bitcast(param_0.1679)
  rsqrt.46.clone.1 = f32[1,2,2048]{2,1,0} rsqrt(bitcast.7597.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/rsqrt" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  bitcast.7596.clone.1 = f32[2,2048]{1,0} bitcast(rsqrt.46.clone.1)
  broadcast.2583.clone.1 = f32[2,2048,8192]{2,1,0} broadcast(bitcast.7596.clone.1), dimensions={0,1}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/mul" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  multiply.1637.clone.1 = f32[2,2048,8192]{2,1,0} multiply(multiply.1959.clone.1, broadcast.2583.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/mul" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  negate.123 = f32[2,2048,8192]{2,1,0} negate(multiply.1637.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/neg" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  constant.2065 = f32[] constant(0)
  reduce.367 = f32[2,2048]{1,0} reduce(negate.123, constant.2065), dimensions={2}, to_apply=region_15.791, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/reduce_sum[axes=(2,)]" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  param_4.1838 = f32[4096,8192]{1,0} parameter(4)
  bitcast.7858.clone.1 = f32[2,2048,8192]{2,1,0} bitcast(param_4.1838)
  param_3.2100 = f32[2,2048]{1,0} parameter(3)
  constant.2837.clone.1 = f32[] constant(0.000122070312)
  broadcast.3143.clone.1 = f32[2,2048]{1,0} broadcast(constant.2837.clone.1), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/layer_norm/div" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=370}
  multiply.1947.clone.1 = f32[2,2048]{1,0} multiply(param_3.2100, broadcast.3143.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/div" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=370}
  broadcast.3142.clone.1 = f32[2,2048,8192]{2,1,0} broadcast(multiply.1947.clone.1), dimensions={0,1}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/sub" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=371}
  subtract.535.clone.1 = f32[2,2048,8192]{2,1,0} subtract(bitcast.7858.clone.1, broadcast.3142.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/sub" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=371}
  multiply.1642.clone.1 = f32[2,2048,8192]{2,1,0} multiply(subtract.535.clone.1, multiply.1959.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/mul" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  reduce.369.clone.1 = f32[2,2048]{1,0} reduce(multiply.1642.clone.1, constant.2065), dimensions={2}, to_apply=region_15.791, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/reduce_sum[axes=(2,)]" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  ROOT tuple.103 = (f32[2,2048]{1,0}, f32[2,2048,8192]{2,1,0}, f32[2,2048]{1,0}) tuple(reduce.367, multiply.1637.clone.1, reduce.369.clone.1)
} // fused_computation.281

fused_computation.282 {
  param_3.2096 = f32[4096,8192]{1,0} parameter(3)
  bitcast.7860.clone.1 = f32[2,2048,8192]{2,1,0} bitcast(param_3.2096)
  param_2.2128 = f32[2,2048]{1,0} parameter(2)
  constant.2840.clone.1 = f32[] constant(0.000122070312)
  broadcast.3147.clone.1 = f32[2,2048]{1,0} broadcast(constant.2840.clone.1), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/layer_norm/div" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=370}
  multiply.1949.clone.1 = f32[2,2048]{1,0} multiply(param_2.2128, broadcast.3147.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/div" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=370}
  broadcast.3146.clone.1 = f32[2,2048,8192]{2,1,0} broadcast(multiply.1949.clone.1), dimensions={0,1}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/sub" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=371}
  subtract.537.clone.1 = f32[2,2048,8192]{2,1,0} subtract(bitcast.7860.clone.1, broadcast.3146.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/sub" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=371}
  param_1.2342 = f32[2,2048]{1,0} parameter(1)
  bitcast.7472.clone.1 = f32[1,2,2048]{2,1,0} bitcast(param_1.2342)
  param_0.1681 = f32[2,2048]{1,0} parameter(0)
  bitcast.7598.clone.1 = f32[1,2,2048]{2,1,0} bitcast(param_0.1681)
  rsqrt.47.clone.1 = f32[1,2,2048]{2,1,0} rsqrt(bitcast.7598.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/rsqrt" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  divide.216.clone.1 = f32[1,2,2048]{2,1,0} divide(rsqrt.47.clone.1, bitcast.7598.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/div" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  constant.2067.clone.1 = f32[] constant(-0.5)
  broadcast.2587.clone.1 = f32[1,2,2048]{2,1,0} broadcast(constant.2067.clone.1), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/final_ln/mul" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  multiply.1641.clone.1 = f32[1,2,2048]{2,1,0} multiply(divide.216.clone.1, broadcast.2587.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/mul" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  multiply.1640.clone.1 = f32[1,2,2048]{2,1,0} multiply(bitcast.7472.clone.1, multiply.1641.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/mul" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  constant.2068.clone.1 = f32[] constant(0.000244140625)
  broadcast.2586.clone.1 = f32[1,2,2048]{2,1,0} broadcast(constant.2068.clone.1), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/final_ln/mul" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=371}
  multiply.1639.clone.1 = f32[1,2,2048]{2,1,0} multiply(multiply.1640.clone.1, broadcast.2586.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/mul" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=371}
  bitcast.7471.clone.1 = f32[2,2048]{1,0} bitcast(multiply.1639.clone.1)
  broadcast.2585.clone.1 = f32[2,2048,8192]{2,1,0} broadcast(bitcast.7471.clone.1), dimensions={0,1}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/mul" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=371}
  multiply.1638.clone.1 = f32[2,2048,8192]{2,1,0} multiply(subtract.537.clone.1, broadcast.2585.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/mul" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=371}
  negate.124 = f32[2,2048,8192]{2,1,0} negate(multiply.1638.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/neg" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=371}
  constant.2066 = f32[] constant(0)
  reduce.368 = f32[2,2048]{1,0} reduce(negate.124, constant.2066), dimensions={2}, to_apply=region_15.791, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/reduce_sum[axes=(2,)]" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=371}
  ROOT tuple.102 = (f32[2,2048]{1,0}, f32[2,2048,8192]{2,1,0}) tuple(reduce.368, multiply.1638.clone.1)
} // fused_computation.282

fused_computation.289 {
  param_0.1355 = f32[4096,32768]{1,0} parameter(0)
  param_1.1856 = f32[8,32768]{1,0} parameter(1)
  constant.2855 = s32[] constant(7)
  param_2.1483 = s32[] parameter(2)
  subtract.546 = s32[] subtract(constant.2855, param_2.1483), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  constant.2852 = s32[] constant(0)
  compare.788 = pred[] compare(subtract.546, constant.2852), direction=LT, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/lt" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  constant.2853 = s32[] constant(15)
  subtract.545 = s32[] subtract(constant.2853, param_2.1483), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/add" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  select.1086 = s32[] select(compare.788, subtract.545, subtract.546), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/select_n" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  dynamic-slice.263 = f32[1,32768]{1,0} dynamic-slice(param_1.1856, select.1086, constant.2852), dynamic_slice_sizes={1,32768}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/dynamic_slice[slice_sizes=(1, 32768)]" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  bitcast.7866 = f32[32768]{0} bitcast(dynamic-slice.263)
  broadcast.3157 = f32[4096,32768]{1,0} broadcast(bitcast.7866), dimensions={1}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/ffn_layer1/bias/add" source_file="/pax/praxis/praxis/layers/linears.py" source_line=143}
  add.1235 = f32[4096,32768]{1,0} add(param_0.1355, broadcast.3157), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/ffn_layer1/bias/add" source_file="/pax/praxis/praxis/layers/linears.py" source_line=143}
  bitcast.7602 = f32[2,2048,32768]{2,1,0} bitcast(add.1235)
  multiply.1802 = f32[2,2048,32768]{2,1,0} multiply(bitcast.7602, bitcast.7602), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/ffn_layer1/activation/mul" source_file="/pax/praxis/praxis/layers/activations.py" source_line=157}
  multiply.1657 = f32[2,2048,32768]{2,1,0} multiply(bitcast.7602, multiply.1802), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/ffn_layer1/activation/mul" source_file="/pax/praxis/praxis/layers/activations.py" source_line=157}
  constant.2078 = f32[] constant(0.044715)
  broadcast.2600 = f32[2,2048,32768]{2,1,0} broadcast(constant.2078), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/ff_layer/ffn_layer1/activation/mul" source_file="/pax/praxis/praxis/layers/activations.py" source_line=157}
  multiply.1656 = f32[2,2048,32768]{2,1,0} multiply(multiply.1657, broadcast.2600), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/ffn_layer1/activation/mul" source_file="/pax/praxis/praxis/layers/activations.py" source_line=157}
  add.1033 = f32[2,2048,32768]{2,1,0} add(bitcast.7602, multiply.1656), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/ffn_layer1/activation/add" source_file="/pax/praxis/praxis/layers/activations.py" source_line=157}
  constant.2079 = f32[] constant(0.797884583)
  broadcast.2599 = f32[2,2048,32768]{2,1,0} broadcast(constant.2079), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/ff_layer/ffn_layer1/activation/mul" source_file="/pax/praxis/praxis/layers/activations.py" source_line=157}
  multiply.1655 = f32[2,2048,32768]{2,1,0} multiply(add.1033, broadcast.2599), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/ffn_layer1/activation/mul" source_file="/pax/praxis/praxis/layers/activations.py" source_line=157}
  ROOT tanh.37 = f32[2,2048,32768]{2,1,0} tanh(multiply.1655), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/ffn_layer1/activation/tanh" source_file="/pax/praxis/praxis/layers/activations.py" source_line=157}
} // fused_computation.289

fused_computation.291 {
  constant.2075 = f32[] constant(1)
  broadcast.2602 = f32[2,2048]{1,0} broadcast(constant.2075), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/sub" source_file="/pax/praxis/praxis/layers/transformer_models.py" source_line=776}
  param_0.570 = f32[2,2048]{1,0} parameter(0)
  ROOT subtract.321 = f32[2,2048]{1,0} subtract(broadcast.2602, param_0.570), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/sub" source_file="/pax/praxis/praxis/layers/transformers.py" source_line=468}
}

fused_computation.293 {
  param_5.1645 = f32[4096,8192]{1,0} parameter(5)
  bitcast.7864.clone.1 = f32[2,2048,8192]{2,1,0} bitcast(param_5.1645)
  param_4.1855 = f32[2,2048]{1,0} parameter(4)
  constant.2846.clone.1 = f32[] constant(0.000122070312)
  broadcast.3155.clone.1 = f32[2,2048]{1,0} broadcast(constant.2846.clone.1), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/layer_norm/div" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=370}
  multiply.1953.clone.1 = f32[2,2048]{1,0} multiply(param_4.1855, broadcast.3155.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/div" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=370}
  broadcast.3154.clone.1 = f32[2,2048,8192]{2,1,0} broadcast(multiply.1953.clone.1), dimensions={0,1}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/sub" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=371}
  subtract.541.clone.1 = f32[2,2048,8192]{2,1,0} subtract(bitcast.7864.clone.1, broadcast.3154.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/sub" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=371}
  param_3.2112 = f32[2,2048]{1,0} parameter(3)
  bitcast.7605.clone.1 = f32[1,2,2048]{2,1,0} bitcast(param_3.2112)
  rsqrt.48.clone.1 = f32[1,2,2048]{2,1,0} rsqrt(bitcast.7605.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/rsqrt" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  bitcast.7604.clone.1 = f32[2,2048]{1,0} bitcast(rsqrt.48.clone.1)
  broadcast.2609.clone.1 = f32[2,2048,8192]{2,1,0} broadcast(bitcast.7604.clone.1), dimensions={0,1}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/mul" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  multiply.1660.clone.1 = f32[2,2048,8192]{2,1,0} multiply(subtract.541.clone.1, broadcast.2609.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/mul" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  param_1.2351 = f32[1,8192]{1,0} parameter(1)
  bitcast.7603 = f32[8192]{0} bitcast(param_1.2351)
  broadcast.2607 = f32[2,2048,8192]{2,1,0} broadcast(bitcast.7603), dimensions={2}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/mul" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=376}
  multiply.1659 = f32[2,2048,8192]{2,1,0} multiply(multiply.1660.clone.1, broadcast.2607), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/mul" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=376}
  param_0.573 = f32[8,8192]{1,0} parameter(0)
  constant.2659 = s32[] constant(7)
  param_2.2138 = s32[] parameter(2)
  subtract.446 = s32[] subtract(constant.2659, param_2.2138), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  constant.2081 = s32[] constant(0)
  compare.739 = pred[] compare(subtract.446, constant.2081), direction=LT, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/lt" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  constant.2657 = s32[] constant(15)
  subtract.445 = s32[] subtract(constant.2657, param_2.2138), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/add" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  select.1037 = s32[] select(compare.739, subtract.445, subtract.446), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/select_n" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  dynamic-slice.201 = f32[1,8192]{1,0} dynamic-slice(param_0.573, select.1037, constant.2081), dynamic_slice_sizes={1,8192}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/dynamic_slice[slice_sizes=(1, 8192)]" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  bitcast.7475 = f32[8192]{0} bitcast(dynamic-slice.201)
  broadcast.2605 = f32[2,2048,8192]{2,1,0} broadcast(bitcast.7475), dimensions={2}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/add" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=378}
  add.1036 = f32[2,2048,8192]{2,1,0} add(multiply.1659, broadcast.2605), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/add" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=378}
  ROOT tuple.108 = (f32[2,2048,8192]{2,1,0}, f32[2,2048,8192]{2,1,0}) tuple(add.1036, multiply.1660.clone.1)
} // fused_computation.293

fused_computation.294 {
  param_0.576 = f32[8,8192]{1,0} parameter(0)
  constant.2652 = s32[] constant(7)
  param_1.1794 = s32[] parameter(1)
  subtract.442 = s32[] subtract(constant.2652, param_1.1794), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  constant.2082 = s32[] constant(0)
  compare.737 = pred[] compare(subtract.442, constant.2082), direction=LT, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/lt" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  constant.2650 = s32[] constant(15)
  subtract.441 = s32[] subtract(constant.2650, param_1.1794), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/add" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  select.1035 = s32[] select(compare.737, subtract.441, subtract.442), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/select_n" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  dynamic-slice.202 = f32[1,8192]{1,0} dynamic-slice(param_0.576, select.1035, constant.2082), dynamic_slice_sizes={1,8192}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/dynamic_slice[slice_sizes=(1, 8192)]" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  constant.2083 = f32[] constant(1)
  broadcast.2608 = f32[1,8192]{1,0} broadcast(constant.2083), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/layer_norm/add" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=376}
  ROOT add.1037 = f32[1,8192]{1,0} add(dynamic-slice.202, broadcast.2608), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/add" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=376}
} // fused_computation.294

fused_computation.296 {
  param_0.580 = f32[2,2048]{1,0} parameter(0)
  constant.2085 = f32[] constant(0.000122070312)
  broadcast.2611 = f32[2,2048]{1,0} broadcast(constant.2085), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/layer_norm/div" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=370}
  multiply.1661 = f32[2,2048]{1,0} multiply(param_0.580, broadcast.2611), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/div" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=371}
  constant.2084 = f32[] constant(1e-06)
  broadcast.2610 = f32[2,2048]{1,0} broadcast(constant.2084), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/layer_norm/add" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  ROOT add.1038 = f32[2,2048]{1,0} add(multiply.1661, broadcast.2610), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/add" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
} // fused_computation.296

fused_computation.297 {
  param_1.1848 = f32[4096,8192]{1,0} parameter(1)
  bitcast.7862 = f32[2,2048,8192]{2,1,0} bitcast(param_1.1848)
  param_0.1351 = f32[2,2048]{1,0} parameter(0)
  constant.2843 = f32[] constant(0.000122070312)
  broadcast.3151 = f32[2,2048]{1,0} broadcast(constant.2843), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/layer_norm/div" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=370}
  multiply.1951 = f32[2,2048]{1,0} multiply(param_0.1351, broadcast.3151), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/div" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=370}
  broadcast.3150 = f32[2,2048,8192]{2,1,0} broadcast(multiply.1951), dimensions={0,1}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/sub" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=371}
  subtract.539 = f32[2,2048,8192]{2,1,0} subtract(bitcast.7862, broadcast.3150), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/sub" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=371}
  multiply.1662 = f32[2,2048,8192]{2,1,0} multiply(subtract.539, subtract.539), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/mul" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=371}
  constant.2086 = f32[] constant(0)
  ROOT reduce.370 = f32[2,2048]{1,0} reduce(multiply.1662, constant.2086), dimensions={2}, to_apply=region_15.791, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/reduce_sum[axes=(2,)]" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=371}
} // fused_computation.297

fused_computation.299 {
  param_0.585 = f32[256,64,2048]{2,1,0} parameter(0)
  bitcast.7476 = f32[2,128,64,2048]{3,2,1,0} bitcast(param_0.585)
  ROOT transpose.259 = f32[2,2048,128,64]{3,2,1,0} transpose(bitcast.7476), dimensions={0,3,1,2}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/pv_einsum/BNTS,BSNH->BTNH/transpose[permutation=(0, 3, 1, 2)]" source_file="/pax/praxis/praxis/layers/base_ops.py" source_line=42}
}

fused_computation.300 {
  param_0.586 = f32[2,128,2048,2048]{3,2,1,0} parameter(0)
  param_1.897 = f32[2,128,2048]{2,1,0} parameter(1)
  broadcast.2614 = f32[2,128,2048,2048]{3,2,1,0} broadcast(param_1.897), dimensions={0,1,2}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/div" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=1487}
  ROOT divide.217 = f32[2,128,2048,2048]{3,2,1,0} divide(param_0.586, broadcast.2614), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/div" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=1487}
}

fused_computation.304 {
  param_1.1438 = f32[3,2,128,64,2048]{4,3,2,1,0} parameter(1)
  slice.97 = f32[1,2,128,64,2048]{4,3,2,1,0} slice(param_1.1438), slice={[0:1], [0:2], [0:128], [0:64], [0:2048]}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/combined_qkv/slice[start_indices=(0, 0, 0, 0, 0) limit_indices=(1, 16, 2048, 128, 64) strides=(1, 1, 1, 1, 1)]" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=882}
  bitcast.7609 = f32[2,128,64,2048]{3,2,1,0} bitcast(slice.97)
  param_0.1009 = f32[64]{0} parameter(0)
  broadcast.2620 = f32[2,128,64,2048]{3,2,1,0} broadcast(param_0.1009), dimensions={2}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._scale_query/per_dim_scale/mul" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=404}
  multiply.1666 = f32[2,128,64,2048]{3,2,1,0} multiply(bitcast.7609, broadcast.2620), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._scale_query/per_dim_scale/mul" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=404}
  ROOT transpose.260 = f32[2,128,2048,64]{3,2,1,0} transpose(multiply.1666), dimensions={0,1,3,2}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._scale_query/per_dim_scale/mul" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=404}
} // fused_computation.304

fused_computation.305 {
  param_0.1339 = f32[8,64]{1,0} parameter(0)
  constant.2824 = s32[] constant(7)
  param_1.1831 = s32[] parameter(1)
  subtract.533 = s32[] subtract(constant.2824, param_1.1831), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  constant.2821 = s32[] constant(0)
  compare.786 = pred[] compare(subtract.533, constant.2821), direction=LT, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/lt" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  constant.2822 = s32[] constant(15)
  subtract.532 = s32[] subtract(constant.2822, param_1.1831), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/add" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  select.1080 = s32[] select(compare.786, subtract.532, subtract.533), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/select_n" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  dynamic-slice.261 = f32[1,64]{1,0} dynamic-slice(param_0.1339, select.1080, constant.2821), dynamic_slice_sizes={1,64}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/dynamic_slice[slice_sizes=(1, 64)]" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  bitcast.7852 = f32[64]{0} bitcast(dynamic-slice.261)
  compare.785 = pred[64]{0} compare(bitcast.7852, bitcast.7852), direction=NE, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._scale_query/per_dim_scale/jit(softplus)/jit(logaddexp)/ne" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=403}
  constant.2820 = f32[] constant(0)
  broadcast.3119 = f32[64]{0} broadcast(constant.2820), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._scale_query/per_dim_scale/jit(softplus)/jit(logaddexp)/max" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=403}
  maximum.85 = f32[64]{0} maximum(bitcast.7852, broadcast.3119), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._scale_query/per_dim_scale/jit(softplus)/jit(logaddexp)/max" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=403}
  abs.36 = f32[64]{0} abs(bitcast.7852), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._scale_query/per_dim_scale/jit(softplus)/jit(logaddexp)/abs" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=403}
  negate.152 = f32[64]{0} negate(abs.36), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._scale_query/per_dim_scale/jit(softplus)/jit(logaddexp)/neg" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=403}
  exponential.82 = f32[64]{0} exponential(negate.152), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._scale_query/per_dim_scale/jit(softplus)/jit(logaddexp)/exp" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=403}
  log-plus-one.36 = f32[64]{0} log-plus-one(exponential.82), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._scale_query/per_dim_scale/jit(softplus)/jit(logaddexp)/log1p" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=403}
  add.1233 = f32[64]{0} add(maximum.85, log-plus-one.36), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._scale_query/per_dim_scale/jit(softplus)/jit(logaddexp)/add" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=403}
  select.1079 = f32[64]{0} select(compare.785, bitcast.7852, add.1233), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._scale_query/per_dim_scale/jit(softplus)/jit(logaddexp)/select_n" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=403}
  constant.2093 = f32[] constant(0.180336878)
  broadcast.2622 = f32[64]{0} broadcast(constant.2093), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._scale_query/per_dim_scale/mul" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=403}
  ROOT multiply.1667 = f32[64]{0} multiply(select.1079, broadcast.2622), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._scale_query/per_dim_scale/mul" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=403}
} // fused_computation.305

fused_computation.307 {
  param_0.604 = f32[2,1,2048,2048]{3,2,0,1} parameter(0)
  bitcast.7478 = f32[1,2,2048,2048]{3,2,1,0} bitcast(param_0.604)
  iota.80 = s32[2048,2048]{1,0} iota(), iota_dimension=0, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/broadcast_in_dim[shape=(1, 2048, 2048, 1) broadcast_dimensions=(0, 1, 3)]" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=102}
  iota.79 = s32[2048,2048]{1,0} iota(), iota_dimension=1, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/broadcast_in_dim[shape=(2048, 1, 1, 2048) broadcast_dimensions=(1, 2, 3)]" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=101}
  compare.699 = pred[2048,2048]{1,0} compare(iota.80, iota.79), direction=LT, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/lt" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=103}
  constant.2434 = f32[] constant(-2.38197633e+38)
  broadcast.2941 = f32[2048,2048]{1,0} broadcast(constant.2434), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/mul" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=103}
  constant.2433 = f32[] constant(0)
  broadcast.2940 = f32[2048,2048]{1,0} broadcast(constant.2433), dimensions={}
  select.993 = f32[2048,2048]{1,0} select(compare.699, broadcast.2941, broadcast.2940), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/mul" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=103}
  broadcast.2625 = f32[1,2,2048,2048]{3,2,1,0} broadcast(select.993), dimensions={2,3}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/sub.body_fn/sub/min" source_file="/pax/praxis/praxis/layers/transformers.py" source_line=128}
  minimum.17 = f32[1,2,2048,2048]{3,2,1,0} minimum(bitcast.7478, broadcast.2625), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/min" source_file="/pax/praxis/praxis/layers/transformers.py" source_line=128}
  constant.2091 = f32[] constant(-1.19098816e+38)
  broadcast.2624 = f32[1,2,2048,2048]{3,2,1,0} broadcast(constant.2091), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/ge" source_file="/pax/praxis/praxis/py_utils.py" source_line=743}
  ROOT compare.636 = pred[1,2,2048,2048]{3,2,1,0} compare(minimum.17, broadcast.2624), direction=GE, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/ge" source_file="/pax/praxis/praxis/py_utils.py" source_line=743}
} // fused_computation.307

fused_computation.308 {
  param_0.606 = f32[24576,4096]{1,0} parameter(0)
  bitcast.7479 = f32[3,128,64,2,2048]{4,3,2,1,0} bitcast(param_0.606)
  ROOT transpose.261 = f32[3,2,128,64,2048]{4,3,2,1,0} transpose(bitcast.7479), dimensions={0,3,1,2,4}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/combined_qkv/einsum/ABD,KDNH->KABNH/dot_general[dimension_numbers=(((1,), (2,)), ((), ())) precision=None preferred_element_type=float32]" source_file="/pax/praxis/praxis/layers/base_ops.py" source_line=42}
}

fused_computation.309 {
  param_5.1650 = f32[8,2,2048,8192]{3,2,1,0} parameter(5)
  constant.2629 = s32[] constant(7)
  param_2.2146 = s32[] parameter(2)
  subtract.506.clone.1 = s32[] subtract(constant.2629, param_2.2146), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  constant.2096 = s32[] constant(0)
  compare.772.clone.1 = pred[] compare(subtract.506.clone.1, constant.2096), direction=LT, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/lt" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  constant.2627 = s32[] constant(15)
  subtract.505.clone.1 = s32[] subtract(constant.2627, param_2.2146), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/add" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  select.1065.clone.1 = s32[] select(compare.772.clone.1, subtract.505.clone.1, subtract.506.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/select_n" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  dynamic-slice.251.clone.1 = f32[1,2,2048,8192]{3,2,1,0} dynamic-slice(param_5.1650, select.1065.clone.1, constant.2096, constant.2096, constant.2096), dynamic_slice_sizes={1,2,2048,8192}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/dynamic_slice[slice_sizes=(1, 16, 2048, 8192)]" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  bitcast.7842.clone.1 = f32[2,2048,8192]{2,1,0} bitcast(dynamic-slice.251.clone.1)
  param_4.1866 = f32[2,2048]{1,0} parameter(4)
  constant.2763.clone.1 = f32[] constant(0.000122070312)
  broadcast.3103.clone.1 = f32[2,2048]{1,0} broadcast(constant.2763.clone.1), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/layer_norm/div" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=370}
  multiply.1935.clone.1 = f32[2,2048]{1,0} multiply(param_4.1866, broadcast.3103.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/layer_norm/div" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=370}
  broadcast.3102.clone.1 = f32[2,2048,8192]{2,1,0} broadcast(multiply.1935.clone.1), dimensions={0,1}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/layer_norm/sub" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  subtract.504.clone.1 = f32[2,2048,8192]{2,1,0} subtract(bitcast.7842.clone.1, broadcast.3102.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/layer_norm/sub" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  param_3.2120 = f32[2,2048]{1,0} parameter(3)
  bitcast.7613.clone.1 = f32[1,2,2048]{2,1,0} bitcast(param_3.2120)
  rsqrt.49.clone.1 = f32[1,2,2048]{2,1,0} rsqrt(bitcast.7613.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/layer_norm/rsqrt" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  bitcast.7612.clone.1 = f32[2,2048]{1,0} bitcast(rsqrt.49.clone.1)
  broadcast.2630.clone.1 = f32[2,2048,8192]{2,1,0} broadcast(bitcast.7612.clone.1), dimensions={0,1}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/layer_norm/mul" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  multiply.1669.clone.1 = f32[2,2048,8192]{2,1,0} multiply(subtract.504.clone.1, broadcast.2630.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/layer_norm/mul" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  param_1.2357 = f32[1,8192]{1,0} parameter(1)
  bitcast.7611 = f32[8192]{0} bitcast(param_1.2357)
  broadcast.2628 = f32[2,2048,8192]{2,1,0} broadcast(bitcast.7611), dimensions={2}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/layer_norm/mul" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=376}
  multiply.1668 = f32[2,2048,8192]{2,1,0} multiply(multiply.1669.clone.1, broadcast.2628), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/layer_norm/mul" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=376}
  param_0.608 = f32[8,8192]{1,0} parameter(0)
  dynamic-slice.203 = f32[1,8192]{1,0} dynamic-slice(param_0.608, select.1065.clone.1, constant.2096), dynamic_slice_sizes={1,8192}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/dynamic_slice[slice_sizes=(1, 8192)]" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  bitcast.7480 = f32[8192]{0} bitcast(dynamic-slice.203)
  broadcast.2626 = f32[2,2048,8192]{2,1,0} broadcast(bitcast.7480), dimensions={2}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/layer_norm/add" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=378}
  add.1041 = f32[2,2048,8192]{2,1,0} add(multiply.1668, broadcast.2626), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/layer_norm/add" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=378}
  ROOT tuple.112 = (f32[2,2048,8192]{2,1,0}, f32[2,2048,8192]{2,1,0}, f32[1,2,2048,8192]{3,2,1,0}) tuple(add.1041, multiply.1669.clone.1, dynamic-slice.251.clone.1)
} // fused_computation.309

fused_computation.310 {
  param_0.611 = f32[8,8192]{1,0} parameter(0)
  constant.2622 = s32[] constant(7)
  param_1.1785 = s32[] parameter(1)
  subtract.426 = s32[] subtract(constant.2622, param_1.1785), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  constant.2097 = s32[] constant(0)
  compare.729 = pred[] compare(subtract.426, constant.2097), direction=LT, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/lt" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  constant.2620 = s32[] constant(15)
  subtract.425 = s32[] subtract(constant.2620, param_1.1785), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/add" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  select.1027 = s32[] select(compare.729, subtract.425, subtract.426), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/select_n" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  dynamic-slice.204 = f32[1,8192]{1,0} dynamic-slice(param_0.611, select.1027, constant.2097), dynamic_slice_sizes={1,8192}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/dynamic_slice[slice_sizes=(1, 8192)]" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  constant.2098 = f32[] constant(1)
  broadcast.2629 = f32[1,8192]{1,0} broadcast(constant.2098), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/layer_norm/add" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=376}
  ROOT add.1042 = f32[1,8192]{1,0} add(dynamic-slice.204, broadcast.2629), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/layer_norm/add" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=376}
} // fused_computation.310

fused_computation.312 {
  param_0.615 = f32[2,2048]{1,0} parameter(0)
  constant.2100 = f32[] constant(0.000122070312)
  broadcast.2632 = f32[2,2048]{1,0} broadcast(constant.2100), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/layer_norm/div" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=370}
  multiply.1670 = f32[2,2048]{1,0} multiply(param_0.615, broadcast.2632), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/layer_norm/div" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=371}
  constant.2099 = f32[] constant(1e-06)
  broadcast.2631 = f32[2,2048]{1,0} broadcast(constant.2099), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/layer_norm/add" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  ROOT add.1044 = f32[2,2048]{1,0} add(multiply.1670, broadcast.2631), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/layer_norm/add" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
} // fused_computation.312

fused_computation.313 {
  param_1.1821 = f32[8,2,2048,8192]{3,2,1,0} parameter(1)
  constant.2791 = s32[] constant(7)
  param_2.1445 = s32[] parameter(2)
  subtract.518 = s32[] subtract(constant.2791, param_2.1445), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  constant.2786 = s32[] constant(0)
  compare.776 = pred[] compare(subtract.518, constant.2786), direction=LT, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/lt" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  constant.2787 = s32[] constant(15)
  subtract.517 = s32[] subtract(constant.2787, param_2.1445), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/add" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  select.1070 = s32[] select(compare.776, subtract.517, subtract.518), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/select_n" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  dynamic-slice.255 = f32[1,2,2048,8192]{3,2,1,0} dynamic-slice(param_1.1821, select.1070, constant.2786, constant.2786, constant.2786), dynamic_slice_sizes={1,2,2048,8192}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/dynamic_slice[slice_sizes=(1, 16, 2048, 8192)]" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  bitcast.7846 = f32[2,2048,8192]{2,1,0} bitcast(dynamic-slice.255)
  param_0.1331 = f32[2,2048]{1,0} parameter(0)
  constant.2785 = f32[] constant(0.000122070312)
  broadcast.3111 = f32[2,2048]{1,0} broadcast(constant.2785), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/layer_norm/div" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=370}
  multiply.1939 = f32[2,2048]{1,0} multiply(param_0.1331, broadcast.3111), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/layer_norm/div" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=370}
  broadcast.3110 = f32[2,2048,8192]{2,1,0} broadcast(multiply.1939), dimensions={0,1}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/layer_norm/sub" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  subtract.516 = f32[2,2048,8192]{2,1,0} subtract(bitcast.7846, broadcast.3110), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/layer_norm/sub" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  multiply.1671 = f32[2,2048,8192]{2,1,0} multiply(subtract.516, subtract.516), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/layer_norm/mul" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=371}
  constant.2101 = f32[] constant(0)
  ROOT reduce.371 = f32[2,2048]{1,0} reduce(multiply.1671, constant.2101), dimensions={2}, to_apply=region_15.791, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/layer_norm/reduce_sum[axes=(2,)]" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=371}
} // fused_computation.313

fused_computation.317 {
  param_0.626 = f32[8,32768,1024]{2,1,0} parameter(0)
  slice.80 = f32[1,32768,1024]{2,1,0} slice(param_0.626), slice={[6:7], [0:32768], [0:1024]}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/dynamic_slice[slice_sizes=(1, 32768, 8192)]" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  ROOT transpose.262 = f32[1,1024,32768]{2,1,0} transpose(slice.80), dimensions={0,2,1}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/dynamic_slice[slice_sizes=(1, 32768, 8192)]" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
}

fused_computation.318 {
  param_0.628 = f32[8,3,1024,128,64]{4,3,2,1,0} parameter(0)
  slice.81 = f32[1,3,1024,128,64]{4,3,2,1,0} slice(param_0.628), slice={[6:7], [0:3], [0:1024], [0:128], [0:64]}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/dynamic_slice[slice_sizes=(1, 3, 8192, 128, 64)]" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  ROOT transpose.263 = f32[1,1024,3,128,64]{4,3,2,1,0} transpose(slice.81), dimensions={0,2,1,3,4}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/dynamic_slice[slice_sizes=(1, 3, 8192, 128, 64)]" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
}

fused_computation.319 {
  param_0.1248 = f32[64]{0} parameter(0)
  constant.2109 = f32[] constant(0.180336878)
  broadcast.2638 = f32[64]{0} broadcast(constant.2109), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._scale_query/per_dim_scale/mul" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=403}
  multiply.1676 = f32[64]{0} multiply(param_0.1248, broadcast.2638), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._scale_query/per_dim_scale/mul" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=403}
  param_1.1716 = f32[8,64]{1,0} parameter(1)
  slice.98 = f32[1,64]{1,0} slice(param_1.1716), slice={[7:8], [0:64]}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/dynamic_slice[slice_sizes=(1, 64)]" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  bitcast.7617 = f32[64]{0} bitcast(slice.98)
  constant.2110 = f32[] constant(inf)
  broadcast.2637 = f32[64]{0} broadcast(constant.2110), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._scale_query/per_dim_scale/jit(softplus)/eq" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=403}
  compare.639 = pred[64]{0} compare(bitcast.7617, broadcast.2637), direction=EQ, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._scale_query/per_dim_scale/jit(softplus)/eq" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=403}
  constant.2111 = f32[] constant(0)
  broadcast.2639 = f32[64]{0} broadcast(constant.2111), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._scale_query/per_dim_scale/jit(softplus)/jit(logaddexp)/max" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=403}
  select.935 = f32[64]{0} select(compare.639, broadcast.2639, bitcast.7617), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._scale_query/per_dim_scale/jit(softplus)/select_n" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=403}
  compare.719 = pred[64]{0} compare(bitcast.7617, bitcast.7617), direction=NE, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._scale_query/per_dim_scale/jit(softplus)/jit(logaddexp)/ne" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=403}
  maximum.79 = f32[64]{0} maximum(bitcast.7617, broadcast.2639), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._scale_query/per_dim_scale/jit(softplus)/jit(logaddexp)/max" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=403}
  abs.30 = f32[64]{0} abs(bitcast.7617), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._scale_query/per_dim_scale/jit(softplus)/jit(logaddexp)/abs" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=403}
  negate.146 = f32[64]{0} negate(abs.30), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._scale_query/per_dim_scale/jit(softplus)/jit(logaddexp)/neg" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=403}
  exponential.76 = f32[64]{0} exponential(negate.146), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._scale_query/per_dim_scale/jit(softplus)/jit(logaddexp)/exp" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=403}
  log-plus-one.30 = f32[64]{0} log-plus-one(exponential.76), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._scale_query/per_dim_scale/jit(softplus)/jit(logaddexp)/log1p" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=403}
  add.1187 = f32[64]{0} add(maximum.79, log-plus-one.30), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._scale_query/per_dim_scale/jit(softplus)/jit(logaddexp)/add" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=403}
  select.1013 = f32[64]{0} select(compare.719, bitcast.7617, add.1187), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._scale_query/per_dim_scale/jit(softplus)/jit(logaddexp)/select_n" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=403}
  compare.638 = pred[64]{0} compare(select.1013, broadcast.2637), direction=EQ, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._scale_query/per_dim_scale/jit(softplus)/eq" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=403}
  select.934 = f32[64]{0} select(compare.638, broadcast.2639, select.1013), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._scale_query/per_dim_scale/jit(softplus)/select_n" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=403}
  subtract.327 = f32[64]{0} subtract(select.935, select.934), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._scale_query/per_dim_scale/jit(softplus)/sub" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=403}
  exponential.63 = f32[64]{0} exponential(subtract.327), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._scale_query/per_dim_scale/jit(softplus)/exp" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=403}
  multiply.1675 = f32[64]{0} multiply(multiply.1676, exponential.63), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._scale_query/per_dim_scale/jit(softplus)/mul" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=403}
  bitcast.7481 = f32[1,64]{1,0} bitcast(multiply.1675)
  ROOT pad.44 = f32[8,64]{1,0} pad(bitcast.7481, constant.2111), padding=7_0x0_0, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
} // fused_computation.319

fused_computation.320 {
  param_1.1455 = f32[3,2,128,64,2048]{4,3,2,1,0} parameter(1)
  slice.99 = f32[1,2,128,64,2048]{4,3,2,1,0} slice(param_1.1455), slice={[0:1], [0:2], [0:128], [0:64], [0:2048]}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/combined_qkv/slice[start_indices=(0, 0, 0, 0, 0) limit_indices=(1, 16, 2048, 128, 64) strides=(1, 1, 1, 1, 1)]" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=882}
  bitcast.7618 = f32[2,128,64,2048]{3,2,1,0} bitcast(slice.99)
  param_0.1019 = f32[2,128,64,2048]{3,2,1,0} parameter(0)
  multiply.1677 = f32[2,128,64,2048]{3,2,1,0} multiply(bitcast.7618, param_0.1019), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._scale_query/per_dim_scale/mul" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=404}
  bitcast.7482 = f32[256,64,2048]{2,1,0} bitcast(multiply.1677), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._scale_query/per_dim_scale/mul" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=404}
  constant.2112 = f32[] constant(0)
  ROOT reduce.372 = f32[256,64]{1,0} reduce(bitcast.7482, constant.2112), dimensions={2}, to_apply=region_15.791
} // fused_computation.320

fused_computation.322 {
  param_0.1021 = f32[2,2048,8192]{2,1,0} parameter(0)
  param_1.1456 = f32[4096,8192]{1,0} parameter(1)
  bitcast.7619 = f32[2,2048,8192]{2,1,0} bitcast(param_1.1456)
  multiply.1678 = f32[2,2048,8192]{2,1,0} multiply(param_0.1021, bitcast.7619), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/layer_norm/mul" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=376}
  bitcast.7484 = f32[4096,8192]{1,0} bitcast(multiply.1678), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/layer_norm/mul" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=376}
  constant.2114 = f32[] constant(0)
  reduce.373 = f32[8192]{0} reduce(bitcast.7484, constant.2114), dimensions={0}, to_apply=region_15.791, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/layer_norm/reduce_sum[axes=(0, 1)]" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=376}
  reduce.425 = f32[8192]{0} reduce(param_1.1456, constant.2114), dimensions={0}, to_apply=region_15.791, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/layer_norm/reduce_sum[axes=(0, 1)]" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=378}
  ROOT tuple.116 = (f32[8192]{0}, f32[8192]{0}) tuple(reduce.373, reduce.425)
} // fused_computation.322

fused_computation.325 {
  param_0.1024 = f32[2,2048,8192]{2,1,0} parameter(0)
  param_1.1457 = f32[4096,8192]{1,0} parameter(1)
  bitcast.7620 = f32[2,2048,8192]{2,1,0} bitcast(param_1.1457)
  multiply.1679 = f32[2,2048,8192]{2,1,0} multiply(param_0.1024, bitcast.7620), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/mul" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=376}
  bitcast.7487 = f32[4096,8192]{1,0} bitcast(multiply.1679), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/mul" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=376}
  constant.2117 = f32[] constant(0)
  reduce.374 = f32[8192]{0} reduce(bitcast.7487, constant.2117), dimensions={0}, to_apply=region_15.791, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/reduce_sum[axes=(0, 1)]" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=376}
  reduce.426 = f32[8192]{0} reduce(param_1.1457, constant.2117), dimensions={0}, to_apply=region_15.791, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/reduce_sum[axes=(0, 1)]" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=378}
  ROOT tuple.122 = (f32[8192]{0}, f32[8192]{0}) tuple(reduce.374, reduce.426)
} // fused_computation.325

fused_computation.328 {
  param_0.1030 = f32[32768]{0} parameter(0)
  bitcast.7490 = f32[1,32768]{1,0} bitcast(param_0.1030)
  constant.2121 = f32[] constant(0)
  ROOT pad.50 = f32[8,32768]{1,0} pad(bitcast.7490, constant.2121), padding=7_0x0_0, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
}

fused_computation.329 {
  param_3.574 = f32[2,2048,8192]{2,1,0} parameter(3)
  param_4.313 = f32[2,2048,8192]{2,1,0} parameter(4)
  add.1049 = f32[2,2048,8192]{2,1,0} add(param_3.574, param_4.313), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/layer_norm/add_any" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=371}
  param_2.730 = f32[2,2048,8192]{2,1,0} parameter(2)
  add.1048 = f32[2,2048,8192]{2,1,0} add(add.1049, param_2.730), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/layer_norm/add_any" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  param_0.651 = f32[2,2048]{1,0} parameter(0)
  param_1.976 = f32[2,2048]{1,0} parameter(1)
  add.1046 = f32[2,2048]{1,0} add(param_0.651, param_1.976), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/layer_norm/add_any" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  constant.2123 = f32[] constant(0.000122070312)
  broadcast.2642 = f32[2,2048]{1,0} broadcast(constant.2123), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/layer_norm/div" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=370}
  multiply.1680 = f32[2,2048]{1,0} multiply(add.1046, broadcast.2642), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/layer_norm/div" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=370}
  broadcast.2640 = f32[2,2048,8192]{2,1,0} broadcast(multiply.1680), dimensions={0,1}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/layer_norm/broadcast_in_dim[shape=(16, 2048, 8192) broadcast_dimensions=(0, 1)]" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=370}
  ROOT add.1045 = f32[2,2048,8192]{2,1,0} add(add.1048, broadcast.2640), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/layer_norm/add_any" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=370}
} // fused_computation.329

fused_computation.330 {
  param_2.2150 = f32[4096,8192]{1,0} parameter(2)
  bitcast.7836.clone.1 = f32[2,2048,8192]{2,1,0} bitcast(param_2.2150)
  param_1.2364 = f32[1,8192]{1,0} parameter(1)
  bitcast.7835.clone.1 = f32[8192]{0} bitcast(param_1.2364)
  broadcast.3096.clone.1 = f32[2,2048,8192]{2,1,0} broadcast(bitcast.7835.clone.1), dimensions={2}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/layer_norm/mul" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=376}
  multiply.1931.clone.1 = f32[2,2048,8192]{2,1,0} multiply(bitcast.7836.clone.1, broadcast.3096.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/layer_norm/mul" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=376}
  param_0.1689 = f32[2,2048]{1,0} parameter(0)
  bitcast.7624.clone.1 = f32[1,2,2048]{2,1,0} bitcast(param_0.1689)
  rsqrt.50.clone.1 = f32[1,2,2048]{2,1,0} rsqrt(bitcast.7624.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/layer_norm/rsqrt" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  bitcast.7623.clone.1 = f32[2,2048]{1,0} bitcast(rsqrt.50.clone.1)
  broadcast.2644.clone.1 = f32[2,2048,8192]{2,1,0} broadcast(bitcast.7623.clone.1), dimensions={0,1}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/layer_norm/mul" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  multiply.1682.clone.1 = f32[2,2048,8192]{2,1,0} multiply(multiply.1931.clone.1, broadcast.2644.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/layer_norm/mul" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  negate.126 = f32[2,2048,8192]{2,1,0} negate(multiply.1682.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/layer_norm/neg" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  constant.2124 = f32[] constant(0)
  reduce.375 = f32[2,2048]{1,0} reduce(negate.126, constant.2124), dimensions={2}, to_apply=region_15.791, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/layer_norm/reduce_sum[axes=(2,)]" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  param_4.1876 = f32[8,2,2048,8192]{3,2,1,0} parameter(4)
  slice.112.clone.1 = f32[1,2,2048,8192]{3,2,1,0} slice(param_4.1876), slice={[7:8], [0:2], [0:2048], [0:8192]}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/dynamic_slice[slice_sizes=(1, 16, 2048, 8192)]" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  bitcast.7778.clone.1 = f32[2,2048,8192]{2,1,0} bitcast(slice.112.clone.1)
  param_3.2132 = f32[2,2048]{1,0} parameter(3)
  constant.2523.clone.1 = f32[] constant(0.000122070312)
  broadcast.3001.clone.1 = f32[2,2048]{1,0} broadcast(constant.2523.clone.1), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/layer_norm/div" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=370}
  multiply.1893.clone.1 = f32[2,2048]{1,0} multiply(param_3.2132, broadcast.3001.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/layer_norm/div" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=370}
  broadcast.3000.clone.1 = f32[2,2048,8192]{2,1,0} broadcast(multiply.1893.clone.1), dimensions={0,1}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/layer_norm/sub" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  subtract.398.clone.1 = f32[2,2048,8192]{2,1,0} subtract(bitcast.7778.clone.1, broadcast.3000.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/layer_norm/sub" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  multiply.1688.clone.1 = f32[2,2048,8192]{2,1,0} multiply(subtract.398.clone.1, multiply.1931.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/layer_norm/mul" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  reduce.377.clone.1 = f32[2,2048]{1,0} reduce(multiply.1688.clone.1, constant.2124), dimensions={2}, to_apply=region_15.791, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/layer_norm/reduce_sum[axes=(2,)]" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  ROOT tuple.115 = (f32[2,2048]{1,0}, f32[2,2048,8192]{2,1,0}, f32[2,2048]{1,0}) tuple(reduce.375, multiply.1682.clone.1, reduce.377.clone.1)
} // fused_computation.330

fused_computation.331 {
  param_3.2128 = f32[8,2,2048,8192]{3,2,1,0} parameter(3)
  slice.116.clone.1 = f32[1,2,2048,8192]{3,2,1,0} slice(param_3.2128), slice={[7:8], [0:2], [0:2048], [0:8192]}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/dynamic_slice[slice_sizes=(1, 16, 2048, 8192)]" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  bitcast.7782.clone.1 = f32[2,2048,8192]{2,1,0} bitcast(slice.116.clone.1)
  param_2.2160 = f32[2,2048]{1,0} parameter(2)
  constant.2530.clone.1 = f32[] constant(0.000122070312)
  broadcast.3013.clone.1 = f32[2,2048]{1,0} broadcast(constant.2530.clone.1), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/layer_norm/div" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=370}
  multiply.1897.clone.1 = f32[2,2048]{1,0} multiply(param_2.2160, broadcast.3013.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/layer_norm/div" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=370}
  broadcast.3012.clone.1 = f32[2,2048,8192]{2,1,0} broadcast(multiply.1897.clone.1), dimensions={0,1}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/layer_norm/sub" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  subtract.402.clone.1 = f32[2,2048,8192]{2,1,0} subtract(bitcast.7782.clone.1, broadcast.3012.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/layer_norm/sub" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  param_1.2371 = f32[2,2048]{1,0} parameter(1)
  bitcast.7492.clone.1 = f32[1,2,2048]{2,1,0} bitcast(param_1.2371)
  param_0.1691 = f32[2,2048]{1,0} parameter(0)
  bitcast.7625.clone.1 = f32[1,2,2048]{2,1,0} bitcast(param_0.1691)
  rsqrt.51.clone.1 = f32[1,2,2048]{2,1,0} rsqrt(bitcast.7625.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/layer_norm/rsqrt" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  divide.218.clone.1 = f32[1,2,2048]{2,1,0} divide(rsqrt.51.clone.1, bitcast.7625.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/layer_norm/div" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  constant.2126.clone.1 = f32[] constant(-0.5)
  broadcast.2647.clone.1 = f32[1,2,2048]{2,1,0} broadcast(constant.2126.clone.1), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/final_ln/mul" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  multiply.1687.clone.1 = f32[1,2,2048]{2,1,0} multiply(divide.218.clone.1, broadcast.2647.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/layer_norm/mul" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  multiply.1686.clone.1 = f32[1,2,2048]{2,1,0} multiply(bitcast.7492.clone.1, multiply.1687.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/layer_norm/mul" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  constant.2127.clone.1 = f32[] constant(0.000244140625)
  broadcast.2646.clone.1 = f32[1,2,2048]{2,1,0} broadcast(constant.2127.clone.1), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/final_ln/mul" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=371}
  multiply.1685.clone.1 = f32[1,2,2048]{2,1,0} multiply(multiply.1686.clone.1, broadcast.2646.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/layer_norm/mul" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=371}
  bitcast.7491.clone.1 = f32[2,2048]{1,0} bitcast(multiply.1685.clone.1)
  broadcast.2645.clone.1 = f32[2,2048,8192]{2,1,0} broadcast(bitcast.7491.clone.1), dimensions={0,1}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/layer_norm/mul" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=371}
  multiply.1683.clone.1 = f32[2,2048,8192]{2,1,0} multiply(subtract.402.clone.1, broadcast.2645.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/layer_norm/mul" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=371}
  negate.127 = f32[2,2048,8192]{2,1,0} negate(multiply.1683.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/layer_norm/neg" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=371}
  constant.2125 = f32[] constant(0)
  reduce.376 = f32[2,2048]{1,0} reduce(negate.127, constant.2125), dimensions={2}, to_apply=region_15.791, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/layer_norm/reduce_sum[axes=(2,)]" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=371}
  ROOT tuple.114 = (f32[2,2048]{1,0}, f32[2,2048,8192]{2,1,0}) tuple(reduce.376, multiply.1683.clone.1)
} // fused_computation.331

fused_computation.337 {
  param_0.664 = f32[256,2048,64]{2,1,0} parameter(0)
  bitcast.7497 = f32[2,128,2048,64]{3,2,1,0} bitcast(param_0.664)
  ROOT transpose.265 = f32[2,128,64,2048]{3,2,1,0} transpose(bitcast.7497), dimensions={0,1,3,2}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._atten_logits/qk_einsum/BTNH,BSNH->BNTS/dot_general[dimension_numbers=(((3,), (1,)), ((0, 1), (0, 2))) precision=None preferred_element_type=float32]" source_file="/pax/praxis/praxis/layers/base_ops.py" source_line=42}
}

fused_computation.338 {
  param_0.1040 = f32[3,2,128,64,2048]{4,3,2,1,0} parameter(0)
  slice.100 = f32[1,2,128,64,2048]{4,3,2,1,0} slice(param_0.1040), slice={[1:2], [0:2], [0:128], [0:64], [0:2048]}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/combined_qkv/slice[start_indices=(1, 0, 0, 0, 0) limit_indices=(2, 16, 2048, 128, 64) strides=(1, 1, 1, 1, 1)]" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=882}
  bitcast.7498 = f32[2,128,64,2048]{3,2,1,0} bitcast(slice.100)
  ROOT transpose.266 = f32[2,128,2048,64]{3,2,1,0} transpose(bitcast.7498), dimensions={0,1,3,2}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._shard_blnh/sharding_constraint[sharding=GSPMDSharding({devices=[8,1,1,1]<=[8]}) resource_env=ResourceEnv(Mesh(device_ids=array([[[0],\n        [1],\n        [2],\n        [3],\n        [4],\n        [5],\n        [6],\n        [7]]]), axis_names=(\'replica\', \'data\', \'mdl\')), ()) unconstrained_dims=set()]" source_file="/pax/praxis/praxis/py_utils.py" source_line=486}
}

fused_computation.339 {
  param_5.346 = pred[1,2,2048,2048]{3,2,1,0} parameter(5)
  bitcast.7629 = pred[2,2048,2048]{2,1,0} bitcast(param_5.346)
  broadcast.2656 = pred[2,128,2048,2048]{3,2,1,0} broadcast(bitcast.7629), dimensions={0,2,3}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/jit(_where)/broadcast_in_dim[shape=(16, 128, 2048, 2048) broadcast_dimensions=(0, 2, 3)]" source_file="/pax/praxis/praxis/py_utils.py" source_line=743}
  param_2.1065 = f32[2,128,2048]{2,1,0} parameter(2)
  negate.128 = f32[2,128,2048]{2,1,0} negate(param_2.1065), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/neg" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=1487}
  broadcast.2652 = f32[2,128,2048,2048]{3,2,1,0} broadcast(negate.128), dimensions={0,1,2}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/broadcast_in_dim[shape=(16, 128, 2048, 2048) broadcast_dimensions=(0, 1, 2)]" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=1487}
  param_4.469 = f32[256,2048,2048]{2,1,0} parameter(4)
  bitcast.7628 = f32[2,128,2048,2048]{3,2,1,0} bitcast(param_4.469)
  param_3.780 = f32[2,128,2048]{2,1,0} parameter(3)
  broadcast.2653 = f32[2,128,2048,2048]{3,2,1,0} broadcast(param_3.780), dimensions={0,1,2}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/div" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=1487}
  divide.219 = f32[2,128,2048,2048]{3,2,1,0} divide(bitcast.7628, broadcast.2653), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/div" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=1487}
  add.1054 = f32[2,128,2048,2048]{3,2,1,0} add(broadcast.2652, divide.219), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/add_any" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=1487}
  param_1.1472 = f32[2,128,2048,2048]{3,2,1,0} parameter(1)
  multiply.1697 = f32[2,128,2048,2048]{3,2,1,0} multiply(add.1054, param_1.1472), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/mul" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=1487}
  constant.2133 = f32[] constant(0)
  broadcast.2651 = f32[2,128,2048,2048]{3,2,1,0} broadcast(constant.2133), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/jit(_where)/broadcast_in_dim[shape=(16, 128, 2048, 2048) broadcast_dimensions=()]" source_file="/pax/praxis/praxis/py_utils.py" source_line=743}
  select.936 = f32[2,128,2048,2048]{3,2,1,0} select(broadcast.2656, multiply.1697, broadcast.2651), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/jit(_where)/select_n" source_file="/pax/praxis/praxis/py_utils.py" source_line=743}
  constant.2131 = f32[] constant(50)
  broadcast.2654 = f32[2,128,2048,2048]{3,2,1,0} broadcast(constant.2131), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._cap_logits/div" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=1384}
  multiply.1695 = f32[2,128,2048,2048]{3,2,1,0} multiply(select.936, broadcast.2654), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._cap_logits/mul" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=1384}
  constant.2132 = f32[] constant(1)
  broadcast.2650 = f32[2,128,2048,2048]{3,2,1,0} broadcast(constant.2132), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._cap_logits/sub" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=1384}
  param_0.669 = f32[2,128,2048,2048]{3,2,1,0} parameter(0)
  subtract.328 = f32[2,128,2048,2048]{3,2,1,0} subtract(broadcast.2650, param_0.669), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._cap_logits/sub" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=1384}
  multiply.1694 = f32[2,128,2048,2048]{3,2,1,0} multiply(multiply.1695, subtract.328), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._cap_logits/mul" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=1384}
  multiply.1693 = f32[2,128,2048,2048]{3,2,1,0} multiply(multiply.1694, param_0.669), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._cap_logits/mul" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=1384}
  add.1053 = f32[2,128,2048,2048]{3,2,1,0} add(multiply.1694, multiply.1693), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._cap_logits/add_any" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=1384}
  constant.2130 = f32[] constant(0.02)
  broadcast.2655 = f32[2,128,2048,2048]{3,2,1,0} broadcast(constant.2130), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._cap_logits/div" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=1384}
  ROOT multiply.1692 = f32[2,128,2048,2048]{3,2,1,0} multiply(add.1053, broadcast.2655), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._cap_logits/div" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=1384}
} // fused_computation.339

fused_computation.340 {
  param_2.1067 = f32[256,2048,2048]{2,1,0} parameter(2)
  bitcast.7630 = f32[2,128,2048,2048]{3,2,1,0} bitcast(param_2.1067)
  constant.2134 = f32[] constant(1)
  broadcast.2659 = f32[2,128,2048]{2,1,0} broadcast(constant.2134), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/broadcast_in_dim[shape=(16, 128, 2048, 1) broadcast_dimensions=()]" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=1487}
  param_1.1473 = f32[2,128,2048]{2,1,0} parameter(1)
  multiply.1700 = f32[2,128,2048]{2,1,0} multiply(param_1.1473, param_1.1473), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/mul" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=1487}
  divide.220 = f32[2,128,2048]{2,1,0} divide(broadcast.2659, multiply.1700), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/div" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=1487}
  broadcast.2657 = f32[2,128,2048,2048]{3,2,1,0} broadcast(divide.220), dimensions={0,1,2}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/mul" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=1487}
  multiply.1699 = f32[2,128,2048,2048]{3,2,1,0} multiply(bitcast.7630, broadcast.2657), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/mul" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=1487}
  param_0.1041 = f32[2,128,2048,2048]{3,2,1,0} parameter(0)
  multiply.1698 = f32[2,128,2048,2048]{3,2,1,0} multiply(multiply.1699, param_0.1041), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/mul" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=1487}
  constant.2135 = f32[] constant(0)
  ROOT reduce.378 = f32[2,128,2048]{2,1,0} reduce(multiply.1698, constant.2135), dimensions={3}, to_apply=region_15.791, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/reduce_sum[axes=(3,)]" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=1487}
} // fused_computation.340

fused_computation.341 {
  param_6.353 = f32[2,2048,8192]{2,1,0} parameter(6)
  param_7.345 = f32[2,2048,8192]{2,1,0} parameter(7)
  add.1218 = f32[2,2048,8192]{2,1,0} add(param_6.353, param_7.345), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/final_ln/add_any" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  param_4.597 = f32[2,2048]{1,0} parameter(4)
  param_5.449 = f32[2,2048]{1,0} parameter(5)
  add.1217 = f32[2,2048]{1,0} add(param_4.597, param_5.449), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/final_ln/add_any" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  constant.2136 = f32[] constant(0.000122070312)
  broadcast.3081 = f32[2,2048]{1,0} broadcast(constant.2136), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/layer_norm/div" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=370}
  multiply.1921 = f32[2,2048]{1,0} multiply(add.1217, broadcast.3081), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/final_ln/div" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=370}
  broadcast.3080 = f32[2,2048,8192]{2,1,0} broadcast(multiply.1921), dimensions={0,1}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/final_ln/broadcast_in_dim[shape=(16, 2048, 8192) broadcast_dimensions=(0, 1)]" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=370}
  add.1215 = f32[2,2048,8192]{2,1,0} add(add.1218, broadcast.3080), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/final_ln/add_any" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=370}
  param_3.999 = f32[2,2048,8192]{2,1,0} parameter(3)
  add.1060 = f32[2,2048,8192]{2,1,0} add(add.1215, param_3.999), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/add_any" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=371}
  param_2.752 = f32[2,2048,8192]{2,1,0} parameter(2)
  add.1058 = f32[2,2048,8192]{2,1,0} add(add.1060, param_2.752), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/add_any" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  param_0.674 = f32[2,2048]{1,0} parameter(0)
  param_1.1010 = f32[2,2048]{1,0} parameter(1)
  add.1057 = f32[2,2048]{1,0} add(param_0.674, param_1.1010), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/add_any" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  multiply.1701 = f32[2,2048]{1,0} multiply(add.1057, broadcast.3081), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/div" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=370}
  broadcast.2660 = f32[2,2048,8192]{2,1,0} broadcast(multiply.1701), dimensions={0,1}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/broadcast_in_dim[shape=(16, 2048, 8192) broadcast_dimensions=(0, 1)]" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=370}
  ROOT add.1056 = f32[2,2048,8192]{2,1,0} add(add.1058, broadcast.2660), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/add_any" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=370}
} // fused_computation.341

fused_computation.342 {
  param_2.2165 = f32[4096,8192]{1,0} parameter(2)
  bitcast.7812.clone.1 = f32[2,2048,8192]{2,1,0} bitcast(param_2.2165)
  param_1.2379 = f32[1,8192]{1,0} parameter(1)
  bitcast.7811.clone.1 = f32[8192]{0} bitcast(param_1.2379)
  broadcast.3085.clone.1 = f32[2,2048,8192]{2,1,0} broadcast(bitcast.7811.clone.1), dimensions={2}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/mul" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=376}
  multiply.1923.clone.1 = f32[2,2048,8192]{2,1,0} multiply(bitcast.7812.clone.1, broadcast.3085.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/mul" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=376}
  param_0.1693 = f32[2,2048]{1,0} parameter(0)
  bitcast.7634.clone.1 = f32[1,2,2048]{2,1,0} bitcast(param_0.1693)
  rsqrt.52.clone.1 = f32[1,2,2048]{2,1,0} rsqrt(bitcast.7634.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/rsqrt" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  bitcast.7633.clone.1 = f32[2,2048]{1,0} bitcast(rsqrt.52.clone.1)
  broadcast.2662.clone.1 = f32[2,2048,8192]{2,1,0} broadcast(bitcast.7633.clone.1), dimensions={0,1}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/mul" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  multiply.1703.clone.1 = f32[2,2048,8192]{2,1,0} multiply(multiply.1923.clone.1, broadcast.2662.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/mul" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  negate.129 = f32[2,2048,8192]{2,1,0} negate(multiply.1703.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/neg" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  constant.2137 = f32[] constant(0)
  reduce.379 = f32[2,2048]{1,0} reduce(negate.129, constant.2137), dimensions={2}, to_apply=region_15.791, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/reduce_sum[axes=(2,)]" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  param_4.1891 = f32[4096,8192]{1,0} parameter(4)
  bitcast.7792.clone.1 = f32[2,2048,8192]{2,1,0} bitcast(param_4.1891)
  param_3.2143 = f32[2,2048]{1,0} parameter(3)
  constant.2550.clone.1 = f32[] constant(0.000122070312)
  broadcast.3033.clone.1 = f32[2,2048]{1,0} broadcast(constant.2550.clone.1), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/layer_norm/div" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=370}
  multiply.1903.clone.1 = f32[2,2048]{1,0} multiply(param_3.2143, broadcast.3033.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/div" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=370}
  broadcast.3032.clone.1 = f32[2,2048,8192]{2,1,0} broadcast(multiply.1903.clone.1), dimensions={0,1}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/sub" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=371}
  subtract.404.clone.1 = f32[2,2048,8192]{2,1,0} subtract(bitcast.7792.clone.1, broadcast.3032.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/sub" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=371}
  multiply.1709.clone.1 = f32[2,2048,8192]{2,1,0} multiply(subtract.404.clone.1, multiply.1923.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/mul" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  reduce.381.clone.1 = f32[2,2048]{1,0} reduce(multiply.1709.clone.1, constant.2137), dimensions={2}, to_apply=region_15.791, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/reduce_sum[axes=(2,)]" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  ROOT tuple.121 = (f32[2,2048]{1,0}, f32[2,2048,8192]{2,1,0}, f32[2,2048]{1,0}) tuple(reduce.379, multiply.1703.clone.1, reduce.381.clone.1)
} // fused_computation.342

fused_computation.343 {
  param_3.2139 = f32[4096,8192]{1,0} parameter(3)
  bitcast.7794.clone.1 = f32[2,2048,8192]{2,1,0} bitcast(param_3.2139)
  param_2.2175 = f32[2,2048]{1,0} parameter(2)
  constant.2553.clone.1 = f32[] constant(0.000122070312)
  broadcast.3040.clone.1 = f32[2,2048]{1,0} broadcast(constant.2553.clone.1), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/layer_norm/div" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=370}
  multiply.1905.clone.1 = f32[2,2048]{1,0} multiply(param_2.2175, broadcast.3040.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/div" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=370}
  broadcast.3038.clone.1 = f32[2,2048,8192]{2,1,0} broadcast(multiply.1905.clone.1), dimensions={0,1}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/sub" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=371}
  subtract.406.clone.1 = f32[2,2048,8192]{2,1,0} subtract(bitcast.7794.clone.1, broadcast.3038.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/sub" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=371}
  param_1.2386 = f32[2,2048]{1,0} parameter(1)
  bitcast.7500.clone.1 = f32[1,2,2048]{2,1,0} bitcast(param_1.2386)
  param_0.1695 = f32[2,2048]{1,0} parameter(0)
  bitcast.7635.clone.1 = f32[1,2,2048]{2,1,0} bitcast(param_0.1695)
  rsqrt.53.clone.1 = f32[1,2,2048]{2,1,0} rsqrt(bitcast.7635.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/rsqrt" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  divide.221.clone.1 = f32[1,2,2048]{2,1,0} divide(rsqrt.53.clone.1, bitcast.7635.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/div" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  constant.2139.clone.1 = f32[] constant(-0.5)
  broadcast.2666.clone.1 = f32[1,2,2048]{2,1,0} broadcast(constant.2139.clone.1), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/final_ln/mul" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  multiply.1707.clone.1 = f32[1,2,2048]{2,1,0} multiply(divide.221.clone.1, broadcast.2666.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/mul" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  multiply.1706.clone.1 = f32[1,2,2048]{2,1,0} multiply(bitcast.7500.clone.1, multiply.1707.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/mul" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  constant.2140.clone.1 = f32[] constant(0.000244140625)
  broadcast.2665.clone.1 = f32[1,2,2048]{2,1,0} broadcast(constant.2140.clone.1), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/final_ln/mul" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=371}
  multiply.1705.clone.1 = f32[1,2,2048]{2,1,0} multiply(multiply.1706.clone.1, broadcast.2665.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/mul" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=371}
  bitcast.7499.clone.1 = f32[2,2048]{1,0} bitcast(multiply.1705.clone.1)
  broadcast.2663.clone.1 = f32[2,2048,8192]{2,1,0} broadcast(bitcast.7499.clone.1), dimensions={0,1}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/mul" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=371}
  multiply.1704.clone.1 = f32[2,2048,8192]{2,1,0} multiply(subtract.406.clone.1, broadcast.2663.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/mul" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=371}
  negate.130 = f32[2,2048,8192]{2,1,0} negate(multiply.1704.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/neg" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=371}
  constant.2138 = f32[] constant(0)
  reduce.380 = f32[2,2048]{1,0} reduce(negate.130, constant.2138), dimensions={2}, to_apply=region_15.791, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/reduce_sum[axes=(2,)]" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=371}
  ROOT tuple.120 = (f32[2,2048]{1,0}, f32[2,2048,8192]{2,1,0}) tuple(reduce.380, multiply.1704.clone.1)
} // fused_computation.343

fused_computation.350 {
  param_0.1269 = f32[4096,32768]{1,0} parameter(0)
  param_1.1742 = f32[8,32768]{1,0} parameter(1)
  slice.122 = f32[1,32768]{1,0} slice(param_1.1742), slice={[7:8], [0:32768]}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/dynamic_slice[slice_sizes=(1, 32768)]" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  bitcast.7800 = f32[32768]{0} bitcast(slice.122)
  broadcast.3055 = f32[4096,32768]{1,0} broadcast(bitcast.7800), dimensions={1}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/ffn_layer1/bias/add" source_file="/pax/praxis/praxis/layers/linears.py" source_line=143}
  add.1192 = f32[4096,32768]{1,0} add(param_0.1269, broadcast.3055), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/ffn_layer1/bias/add" source_file="/pax/praxis/praxis/layers/linears.py" source_line=143}
  bitcast.7643 = f32[2,2048,32768]{2,1,0} bitcast(add.1192)
  multiply.1806 = f32[2,2048,32768]{2,1,0} multiply(bitcast.7643, bitcast.7643), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/ffn_layer1/activation/mul" source_file="/pax/praxis/praxis/layers/activations.py" source_line=157}
  multiply.1727 = f32[2,2048,32768]{2,1,0} multiply(bitcast.7643, multiply.1806), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/ffn_layer1/activation/mul" source_file="/pax/praxis/praxis/layers/activations.py" source_line=157}
  constant.2157 = f32[] constant(0.044715)
  broadcast.2679 = f32[2,2048,32768]{2,1,0} broadcast(constant.2157), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/ff_layer/ffn_layer1/activation/mul" source_file="/pax/praxis/praxis/layers/activations.py" source_line=157}
  multiply.1725 = f32[2,2048,32768]{2,1,0} multiply(multiply.1727, broadcast.2679), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/ffn_layer1/activation/mul" source_file="/pax/praxis/praxis/layers/activations.py" source_line=157}
  add.1066 = f32[2,2048,32768]{2,1,0} add(bitcast.7643, multiply.1725), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/ffn_layer1/activation/add" source_file="/pax/praxis/praxis/layers/activations.py" source_line=157}
  constant.2158 = f32[] constant(0.797884583)
  broadcast.2677 = f32[2,2048,32768]{2,1,0} broadcast(constant.2158), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/ff_layer/ffn_layer1/activation/mul" source_file="/pax/praxis/praxis/layers/activations.py" source_line=157}
  multiply.1724 = f32[2,2048,32768]{2,1,0} multiply(add.1066, broadcast.2677), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/ffn_layer1/activation/mul" source_file="/pax/praxis/praxis/layers/activations.py" source_line=157}
  ROOT tanh.39 = f32[2,2048,32768]{2,1,0} tanh(multiply.1724), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/ffn_layer1/activation/tanh" source_file="/pax/praxis/praxis/layers/activations.py" source_line=157}
} // fused_computation.350

fused_computation.351 {
  param_0.695 = f32[8,32768,1024]{2,1,0} parameter(0)
  slice.82 = f32[1,32768,1024]{2,1,0} slice(param_0.695), slice={[7:8], [0:32768], [0:1024]}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/dynamic_slice[slice_sizes=(1, 32768, 8192)]" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  ROOT transpose.267 = f32[1,1024,32768]{2,1,0} transpose(slice.82), dimensions={0,2,1}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/dynamic_slice[slice_sizes=(1, 32768, 8192)]" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
}

fused_computation.354 {
  param_4.1906 = f32[4096,8192]{1,0} parameter(4)
  bitcast.7798.clone.1 = f32[2,2048,8192]{2,1,0} bitcast(param_4.1906)
  param_3.2167 = f32[2,2048]{1,0} parameter(3)
  constant.2559.clone.1 = f32[] constant(0.000122070312)
  broadcast.3051.clone.1 = f32[2,2048]{1,0} broadcast(constant.2559.clone.1), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/layer_norm/div" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=370}
  multiply.1909.clone.1 = f32[2,2048]{1,0} multiply(param_3.2167, broadcast.3051.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/div" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=370}
  broadcast.3050.clone.1 = f32[2,2048,8192]{2,1,0} broadcast(multiply.1909.clone.1), dimensions={0,1}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/sub" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=371}
  subtract.410.clone.1 = f32[2,2048,8192]{2,1,0} subtract(bitcast.7798.clone.1, broadcast.3050.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/sub" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=371}
  param_2.2202 = f32[2,2048]{1,0} parameter(2)
  bitcast.7646.clone.1 = f32[1,2,2048]{2,1,0} bitcast(param_2.2202)
  rsqrt.56.clone.1 = f32[1,2,2048]{2,1,0} rsqrt(bitcast.7646.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/rsqrt" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  bitcast.7645.clone.1 = f32[2,2048]{1,0} bitcast(rsqrt.56.clone.1)
  broadcast.2686.clone.1 = f32[2,2048,8192]{2,1,0} broadcast(bitcast.7645.clone.1), dimensions={0,1}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/mul" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  multiply.1730.clone.1 = f32[2,2048,8192]{2,1,0} multiply(subtract.410.clone.1, broadcast.2686.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/mul" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  param_1.2410 = f32[1,8192]{1,0} parameter(1)
  bitcast.7644 = f32[8192]{0} bitcast(param_1.2410)
  broadcast.2684 = f32[2,2048,8192]{2,1,0} broadcast(bitcast.7644), dimensions={2}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/mul" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=376}
  multiply.1729 = f32[2,2048,8192]{2,1,0} multiply(multiply.1730.clone.1, broadcast.2684), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/mul" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=376}
  param_0.699 = f32[8,8192]{1,0} parameter(0)
  slice.84 = f32[1,8192]{1,0} slice(param_0.699), slice={[7:8], [0:8192]}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/dynamic_slice[slice_sizes=(1, 8192)]" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  bitcast.7503 = f32[8192]{0} bitcast(slice.84)
  broadcast.2683 = f32[2,2048,8192]{2,1,0} broadcast(bitcast.7503), dimensions={2}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/add" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=378}
  add.1068 = f32[2,2048,8192]{2,1,0} add(multiply.1729, broadcast.2683), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/add" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=378}
  ROOT tuple.128 = (f32[2,2048,8192]{2,1,0}, f32[2,2048,8192]{2,1,0}) tuple(add.1068, multiply.1730.clone.1)
} // fused_computation.354

fused_computation.355 {
  param_0.702 = f32[8,8192]{1,0} parameter(0)
  slice.85 = f32[1,8192]{1,0} slice(param_0.702), slice={[7:8], [0:8192]}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/dynamic_slice[slice_sizes=(1, 8192)]" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  constant.2159 = f32[] constant(1)
  broadcast.2685 = f32[1,8192]{1,0} broadcast(constant.2159), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/layer_norm/add" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=376}
  ROOT add.1069 = f32[1,8192]{1,0} add(slice.85, broadcast.2685), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/add" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=376}
}

fused_computation.357 {
  param_0.706 = f32[2,2048]{1,0} parameter(0)
  constant.2161 = f32[] constant(0.000122070312)
  broadcast.2688 = f32[2,2048]{1,0} broadcast(constant.2161), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/layer_norm/div" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=370}
  multiply.1731 = f32[2,2048]{1,0} multiply(param_0.706, broadcast.2688), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/div" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=371}
  constant.2160 = f32[] constant(1e-06)
  broadcast.2687 = f32[2,2048]{1,0} broadcast(constant.2160), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/layer_norm/add" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  ROOT add.1070 = f32[2,2048]{1,0} add(multiply.1731, broadcast.2687), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/add" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
} // fused_computation.357

fused_computation.358 {
  param_1.1734 = f32[4096,8192]{1,0} parameter(1)
  bitcast.7796 = f32[2,2048,8192]{2,1,0} bitcast(param_1.1734)
  param_0.1265 = f32[2,2048]{1,0} parameter(0)
  constant.2556 = f32[] constant(0.000122070312)
  broadcast.3045 = f32[2,2048]{1,0} broadcast(constant.2556), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/layer_norm/div" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=370}
  multiply.1907 = f32[2,2048]{1,0} multiply(param_0.1265, broadcast.3045), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/div" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=370}
  broadcast.3044 = f32[2,2048,8192]{2,1,0} broadcast(multiply.1907), dimensions={0,1}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/sub" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=371}
  subtract.408 = f32[2,2048,8192]{2,1,0} subtract(bitcast.7796, broadcast.3044), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/sub" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=371}
  multiply.1733 = f32[2,2048,8192]{2,1,0} multiply(subtract.408, subtract.408), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/mul" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=371}
  constant.2162 = f32[] constant(0)
  ROOT reduce.382 = f32[2,2048]{1,0} reduce(multiply.1733, constant.2162), dimensions={2}, to_apply=region_15.791, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/reduce_sum[axes=(2,)]" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=371}
} // fused_computation.358

fused_computation.360 {
  param_0.711 = f32[256,64,2048]{2,1,0} parameter(0)
  bitcast.7504 = f32[2,128,64,2048]{3,2,1,0} bitcast(param_0.711)
  ROOT transpose.268 = f32[2,2048,128,64]{3,2,1,0} transpose(bitcast.7504), dimensions={0,3,1,2}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/pv_einsum/BNTS,BSNH->BTNH/transpose[permutation=(0, 3, 1, 2)]" source_file="/pax/praxis/praxis/layers/base_ops.py" source_line=42}
}

fused_computation.361 {
  param_0.712 = f32[2,128,2048,2048]{3,2,1,0} parameter(0)
  param_1.1066 = f32[2,128,2048]{2,1,0} parameter(1)
  broadcast.2691 = f32[2,128,2048,2048]{3,2,1,0} broadcast(param_1.1066), dimensions={0,1,2}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/div" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=1487}
  ROOT divide.222 = f32[2,128,2048,2048]{3,2,1,0} divide(param_0.712, broadcast.2691), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/div" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=1487}
}

fused_computation.365 {
  param_1.1506 = f32[3,2,128,64,2048]{4,3,2,1,0} parameter(1)
  slice.101 = f32[1,2,128,64,2048]{4,3,2,1,0} slice(param_1.1506), slice={[0:1], [0:2], [0:128], [0:64], [0:2048]}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/combined_qkv/slice[start_indices=(0, 0, 0, 0, 0) limit_indices=(1, 16, 2048, 128, 64) strides=(1, 1, 1, 1, 1)]" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=882}
  bitcast.7650 = f32[2,128,64,2048]{3,2,1,0} bitcast(slice.101)
  param_0.1062 = f32[64]{0} parameter(0)
  broadcast.2698 = f32[2,128,64,2048]{3,2,1,0} broadcast(param_0.1062), dimensions={2}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._scale_query/per_dim_scale/mul" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=404}
  multiply.1737 = f32[2,128,64,2048]{3,2,1,0} multiply(bitcast.7650, broadcast.2698), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._scale_query/per_dim_scale/mul" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=404}
  ROOT transpose.269 = f32[2,128,2048,64]{3,2,1,0} transpose(multiply.1737), dimensions={0,1,3,2}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._scale_query/per_dim_scale/mul" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=404}
} // fused_computation.365

fused_computation.366 {
  param_0.1253 = f32[8,64]{1,0} parameter(0)
  slice.120 = f32[1,64]{1,0} slice(param_0.1253), slice={[7:8], [0:64]}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/dynamic_slice[slice_sizes=(1, 64)]" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  bitcast.7786 = f32[64]{0} bitcast(slice.120)
  compare.721 = pred[64]{0} compare(bitcast.7786, bitcast.7786), direction=NE, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._scale_query/per_dim_scale/jit(softplus)/jit(logaddexp)/ne" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=403}
  constant.2537 = f32[] constant(0)
  broadcast.3017 = f32[64]{0} broadcast(constant.2537), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._scale_query/per_dim_scale/jit(softplus)/jit(logaddexp)/max" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=403}
  maximum.81 = f32[64]{0} maximum(bitcast.7786, broadcast.3017), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._scale_query/per_dim_scale/jit(softplus)/jit(logaddexp)/max" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=403}
  abs.32 = f32[64]{0} abs(bitcast.7786), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._scale_query/per_dim_scale/jit(softplus)/jit(logaddexp)/abs" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=403}
  negate.148 = f32[64]{0} negate(abs.32), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._scale_query/per_dim_scale/jit(softplus)/jit(logaddexp)/neg" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=403}
  exponential.78 = f32[64]{0} exponential(negate.148), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._scale_query/per_dim_scale/jit(softplus)/jit(logaddexp)/exp" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=403}
  log-plus-one.32 = f32[64]{0} log-plus-one(exponential.78), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._scale_query/per_dim_scale/jit(softplus)/jit(logaddexp)/log1p" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=403}
  add.1190 = f32[64]{0} add(maximum.81, log-plus-one.32), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._scale_query/per_dim_scale/jit(softplus)/jit(logaddexp)/add" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=403}
  select.1015 = f32[64]{0} select(compare.721, bitcast.7786, add.1190), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._scale_query/per_dim_scale/jit(softplus)/jit(logaddexp)/select_n" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=403}
  constant.2168 = f32[] constant(0.180336878)
  broadcast.2699 = f32[64]{0} broadcast(constant.2168), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._scale_query/per_dim_scale/mul" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=403}
  ROOT multiply.1739 = f32[64]{0} multiply(select.1015, broadcast.2699), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._scale_query/per_dim_scale/mul" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=403}
} // fused_computation.366

fused_computation.368 {
  param_0.727 = f32[24576,4096]{1,0} parameter(0)
  bitcast.7506 = f32[3,128,64,2,2048]{4,3,2,1,0} bitcast(param_0.727)
  ROOT transpose.270 = f32[3,2,128,64,2048]{4,3,2,1,0} transpose(bitcast.7506), dimensions={0,3,1,2,4}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/combined_qkv/einsum/ABD,KDNH->KABNH/dot_general[dimension_numbers=(((1,), (2,)), ((), ())) precision=None preferred_element_type=float32]" source_file="/pax/praxis/praxis/layers/base_ops.py" source_line=42}
}

fused_computation.369 {
  param_4.1915 = f32[8,2,2048,8192]{3,2,1,0} parameter(4)
  slice.110.clone.1 = f32[1,2,2048,8192]{3,2,1,0} slice(param_4.1915), slice={[7:8], [0:2], [0:2048], [0:8192]}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/dynamic_slice[slice_sizes=(1, 16, 2048, 8192)]" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  bitcast.7776.clone.1 = f32[2,2048,8192]{2,1,0} bitcast(slice.110.clone.1)
  param_3.2180 = f32[2,2048]{1,0} parameter(3)
  constant.2520.clone.1 = f32[] constant(0.000122070312)
  broadcast.2995.clone.1 = f32[2,2048]{1,0} broadcast(constant.2520.clone.1), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/layer_norm/div" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=370}
  multiply.1891.clone.1 = f32[2,2048]{1,0} multiply(param_3.2180, broadcast.2995.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/layer_norm/div" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=370}
  broadcast.2994.clone.1 = f32[2,2048,8192]{2,1,0} broadcast(multiply.1891.clone.1), dimensions={0,1}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/layer_norm/sub" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  subtract.396.clone.1 = f32[2,2048,8192]{2,1,0} subtract(bitcast.7776.clone.1, broadcast.2994.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/layer_norm/sub" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  param_2.2211 = f32[2,2048]{1,0} parameter(2)
  bitcast.7654.clone.1 = f32[1,2,2048]{2,1,0} bitcast(param_2.2211)
  rsqrt.57.clone.1 = f32[1,2,2048]{2,1,0} rsqrt(bitcast.7654.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/layer_norm/rsqrt" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  bitcast.7653.clone.1 = f32[2,2048]{1,0} bitcast(rsqrt.57.clone.1)
  broadcast.2705.clone.1 = f32[2,2048,8192]{2,1,0} broadcast(bitcast.7653.clone.1), dimensions={0,1}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/layer_norm/mul" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  multiply.1741.clone.1 = f32[2,2048,8192]{2,1,0} multiply(subtract.396.clone.1, broadcast.2705.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/layer_norm/mul" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  param_1.2416 = f32[1,8192]{1,0} parameter(1)
  bitcast.7652 = f32[8192]{0} bitcast(param_1.2416)
  broadcast.2703 = f32[2,2048,8192]{2,1,0} broadcast(bitcast.7652), dimensions={2}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/layer_norm/mul" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=376}
  multiply.1740 = f32[2,2048,8192]{2,1,0} multiply(multiply.1741.clone.1, broadcast.2703), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/layer_norm/mul" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=376}
  param_0.729 = f32[8,8192]{1,0} parameter(0)
  slice.86 = f32[1,8192]{1,0} slice(param_0.729), slice={[7:8], [0:8192]}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/dynamic_slice[slice_sizes=(1, 8192)]" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  bitcast.7507 = f32[8192]{0} bitcast(slice.86)
  broadcast.2702 = f32[2,2048,8192]{2,1,0} broadcast(bitcast.7507), dimensions={2}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/layer_norm/add" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=378}
  add.1072 = f32[2,2048,8192]{2,1,0} add(multiply.1740, broadcast.2702), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/layer_norm/add" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=378}
  ROOT tuple.131 = (f32[2,2048,8192]{2,1,0}, f32[2,2048,8192]{2,1,0}) tuple(add.1072, multiply.1741.clone.1)
} // fused_computation.369

fused_computation.370 {
  param_0.732 = f32[8,8192]{1,0} parameter(0)
  slice.87 = f32[1,8192]{1,0} slice(param_0.732), slice={[7:8], [0:8192]}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/dynamic_slice[slice_sizes=(1, 8192)]" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  constant.2170 = f32[] constant(1)
  broadcast.2704 = f32[1,8192]{1,0} broadcast(constant.2170), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/layer_norm/add" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=376}
  ROOT add.1074 = f32[1,8192]{1,0} add(slice.87, broadcast.2704), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/layer_norm/add" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=376}
}

fused_computation.372 {
  param_0.736 = f32[2,2048]{1,0} parameter(0)
  constant.2172 = f32[] constant(0.000122070312)
  broadcast.2708 = f32[2,2048]{1,0} broadcast(constant.2172), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/layer_norm/div" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=370}
  multiply.1742 = f32[2,2048]{1,0} multiply(param_0.736, broadcast.2708), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/layer_norm/div" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=371}
  constant.2171 = f32[] constant(1e-06)
  broadcast.2706 = f32[2,2048]{1,0} broadcast(constant.2171), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/layer_norm/add" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  ROOT add.1075 = f32[2,2048]{1,0} add(multiply.1742, broadcast.2706), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/layer_norm/add" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
} // fused_computation.372

fused_computation.373 {
  param_1.1713 = f32[8,2,2048,8192]{3,2,1,0} parameter(1)
  slice.114 = f32[1,2,2048,8192]{3,2,1,0} slice(param_1.1713), slice={[7:8], [0:2], [0:2048], [0:8192]}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/dynamic_slice[slice_sizes=(1, 16, 2048, 8192)]" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  bitcast.7780 = f32[2,2048,8192]{2,1,0} bitcast(slice.114)
  param_0.1244 = f32[2,2048]{1,0} parameter(0)
  constant.2526 = f32[] constant(0.000122070312)
  broadcast.3007 = f32[2,2048]{1,0} broadcast(constant.2526), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/layer_norm/div" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=370}
  multiply.1895 = f32[2,2048]{1,0} multiply(param_0.1244, broadcast.3007), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/layer_norm/div" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=370}
  broadcast.3005 = f32[2,2048,8192]{2,1,0} broadcast(multiply.1895), dimensions={0,1}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/layer_norm/sub" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  subtract.400 = f32[2,2048,8192]{2,1,0} subtract(bitcast.7780, broadcast.3005), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/layer_norm/sub" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  multiply.1743 = f32[2,2048,8192]{2,1,0} multiply(subtract.400, subtract.400), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/layer_norm/mul" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=371}
  constant.2173 = f32[] constant(0)
  ROOT reduce.383 = f32[2,2048]{1,0} reduce(multiply.1743, constant.2173), dimensions={2}, to_apply=region_15.791, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/layer_norm/reduce_sum[axes=(2,)]" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=371}
} // fused_computation.373

fused_computation.375 {
  param_0.740 = f32[8,2,2048,8192]{3,2,1,0} parameter(0)
  param_1.1666 = f32[2,2048,8192]{2,1,0} parameter(1)
  bitcast.7508 = f32[1,2,2048,8192]{3,2,1,0} bitcast(param_1.1666)
  param_2.1248 = s32[] parameter(2)
  constant.2176 = s32[] constant(0)
  compare.703 = pred[] compare(param_2.1248, constant.2176), direction=LT, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/lt" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  constant.2443 = s32[] constant(8)
  add.1163 = s32[] add(param_2.1248, constant.2443), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/add" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  select.997 = s32[] select(compare.703, add.1163, param_2.1248), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/select_n" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  ROOT dynamic-update-slice.119 = f32[8,2,2048,8192]{3,2,1,0} dynamic-update-slice(param_0.740, bitcast.7508, select.997, constant.2176, constant.2176, /*index=5*/constant.2176), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
} // fused_computation.375

fused_computation.376 {
  param_0.742 = f32[8,3,1024,128,64]{4,3,2,1,0} parameter(0)
  slice.88 = f32[1,3,1024,128,64]{4,3,2,1,0} slice(param_0.742), slice={[7:8], [0:3], [0:1024], [0:128], [0:64]}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/dynamic_slice[slice_sizes=(1, 3, 8192, 128, 64)]" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  ROOT transpose.271 = f32[1,1024,3,128,64]{4,3,2,1,0} transpose(slice.88), dimensions={0,2,1,3,4}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/dynamic_slice[slice_sizes=(1, 3, 8192, 128, 64)]" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
}

fused_computation.378 {
  param_2.2192 = f32[4096,8192]{1,0} parameter(2)
  bitcast.7806.clone.1 = f32[2,2048,8192]{2,1,0} bitcast(param_2.2192)
  param_1.2403 = f32[8192]{0} parameter(1)
  broadcast.3069.clone.1 = f32[2,2048,8192]{2,1,0} broadcast(param_1.2403), dimensions={2}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/final_ln/mul" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=376}
  multiply.1915.clone.1 = f32[2,2048,8192]{2,1,0} multiply(bitcast.7806.clone.1, broadcast.3069.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/final_ln/mul" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=376}
  param_0.1702 = f32[2,2048]{1,0} parameter(0)
  bitcast.7640.clone.1 = f32[1,2,2048]{2,1,0} bitcast(param_0.1702)
  rsqrt.54.clone.1 = f32[1,2,2048]{2,1,0} rsqrt(bitcast.7640.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/final_ln/rsqrt" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  bitcast.7639.clone.1 = f32[2,2048]{1,0} bitcast(rsqrt.54.clone.1)
  broadcast.2713.clone.1 = f32[2,2048,8192]{2,1,0} broadcast(bitcast.7639.clone.1), dimensions={0,1}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/final_ln/mul" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  multiply.1747.clone.1 = f32[2,2048,8192]{2,1,0} multiply(multiply.1915.clone.1, broadcast.2713.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/final_ln/mul" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  negate.132 = f32[2,2048,8192]{2,1,0} negate(multiply.1747.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/final_ln/neg" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  constant.2148 = f32[] constant(0)
  reduce.384 = f32[2,2048]{1,0} reduce(negate.132, constant.2148), dimensions={2}, to_apply=region_15.791, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/final_ln/reduce_sum[axes=(2,)]" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  param_3.2182 = f32[2,2048,8192]{2,1,0} parameter(3)
  multiply.1753.clone.1 = f32[2,2048,8192]{2,1,0} multiply(param_3.2182, multiply.1915.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/final_ln/mul" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  reduce.386.clone.1 = f32[2,2048]{1,0} reduce(multiply.1753.clone.1, constant.2148), dimensions={2}, to_apply=region_15.791, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/final_ln/reduce_sum[axes=(2,)]" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  ROOT tuple.133 = (f32[2,2048]{1,0}, f32[2,2048,8192]{2,1,0}, f32[2,2048]{1,0}) tuple(reduce.384, multiply.1747.clone.1, reduce.386.clone.1)
} // fused_computation.378

fused_computation.379 {
  param_0.1703 = f32[2,2048,8192]{2,1,0} parameter(0)
  param_2.2200 = f32[2,2048]{1,0} parameter(2)
  bitcast.7510.clone.1 = f32[1,2,2048]{2,1,0} bitcast(param_2.2200)
  param_1.2409 = f32[2,2048]{1,0} parameter(1)
  bitcast.7641.clone.1 = f32[1,2,2048]{2,1,0} bitcast(param_1.2409)
  rsqrt.55.clone.1 = f32[1,2,2048]{2,1,0} rsqrt(bitcast.7641.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/final_ln/rsqrt" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  divide.223.clone.1 = f32[1,2,2048]{2,1,0} divide(rsqrt.55.clone.1, bitcast.7641.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/final_ln/div" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  constant.2152.clone.1 = f32[] constant(-0.5)
  broadcast.2718.clone.1 = f32[1,2,2048]{2,1,0} broadcast(constant.2152.clone.1), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/final_ln/mul" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  multiply.1752.clone.1 = f32[1,2,2048]{2,1,0} multiply(divide.223.clone.1, broadcast.2718.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/final_ln/mul" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  multiply.1751.clone.1 = f32[1,2,2048]{2,1,0} multiply(bitcast.7510.clone.1, multiply.1752.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/final_ln/mul" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  constant.2153.clone.1 = f32[] constant(0.000244140625)
  broadcast.2716.clone.1 = f32[1,2,2048]{2,1,0} broadcast(constant.2153.clone.1), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/final_ln/mul" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=371}
  multiply.1749.clone.1 = f32[1,2,2048]{2,1,0} multiply(multiply.1751.clone.1, broadcast.2716.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/final_ln/mul" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=371}
  bitcast.7509.clone.1 = f32[2,2048]{1,0} bitcast(multiply.1749.clone.1)
  broadcast.2714.clone.1 = f32[2,2048,8192]{2,1,0} broadcast(bitcast.7509.clone.1), dimensions={0,1}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/final_ln/mul" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=371}
  multiply.1748.clone.1 = f32[2,2048,8192]{2,1,0} multiply(param_0.1703, broadcast.2714.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/final_ln/mul" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=371}
  negate.133 = f32[2,2048,8192]{2,1,0} negate(multiply.1748.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/final_ln/neg" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=371}
  constant.2151 = f32[] constant(0)
  reduce.385 = f32[2,2048]{1,0} reduce(negate.133, constant.2151), dimensions={2}, to_apply=region_15.791, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/final_ln/reduce_sum[axes=(2,)]" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=371}
  ROOT tuple.126 = (f32[2,2048]{1,0}, f32[2,2048,8192]{2,1,0}) tuple(reduce.385, multiply.1748.clone.1)
} // fused_computation.379

fused_computation.384 {
  param_0.957 = f32[32000]{0} parameter(0)
  multiply.1755 = f32[32000]{0} multiply(param_0.957, param_0.957), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/paxml/paxml/learners.py" source_line=47}
  bitcast.7511 = f32[128,250]{1,0} bitcast(multiply.1755), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/paxml/paxml/learners.py" source_line=47}
  constant.2013 = f32[] constant(0)
  ROOT reduce.387 = f32[128]{0} reduce(bitcast.7511, constant.2013), dimensions={1}, to_apply=region_15.791, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/reduce_sum[axes=(0,)]" source_file="/pax/paxml/paxml/learners.py" source_line=47}
}

fused_computation.386 {
  param_0.955 = f32[2,2048,8192]{2,1,0} parameter(0)
  param_1.1390 = f32[4096,8192]{1,0} parameter(1)
  bitcast.7577 = f32[2,2048,8192]{2,1,0} bitcast(param_1.1390)
  multiply.1758 = f32[2,2048,8192]{2,1,0} multiply(param_0.955, bitcast.7577), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/final_ln/mul" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=376}
  bitcast.7512 = f32[4096,8192]{1,0} bitcast(multiply.1758), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/final_ln/mul" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=376}
  constant.2011 = f32[] constant(0)
  reduce.389 = f32[8192]{0} reduce(bitcast.7512, constant.2011), dimensions={0}, to_apply=region_15.791, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/final_ln/reduce_sum[axes=(0, 1)]" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=376}
  reduce.428 = f32[8192]{0} reduce(param_1.1390, constant.2011), dimensions={0}, to_apply=region_15.791, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/final_ln/reduce_sum[axes=(0, 1)]" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=378}
  ROOT tuple.134 = (f32[8192]{0}, f32[8192]{0}) tuple(reduce.389, reduce.428)
} // fused_computation.386

fused_computation.387 {
  param_0.956 = f32[8192]{0} parameter(0)
  multiply.1759 = f32[8192]{0} multiply(param_0.956, param_0.956), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/paxml/paxml/learners.py" source_line=47}
  constant.2012 = f32[] constant(0)
  reduce.390 = f32[] reduce(multiply.1759, constant.2012), dimensions={0}, to_apply=region_15.791, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/reduce_sum[axes=(0,)]" source_file="/pax/paxml/paxml/learners.py" source_line=47}
  param_1.2492 = f32[8192]{0} parameter(1)
  multiply.1757.clone.1 = f32[8192]{0} multiply(param_1.2492, param_1.2492), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/paxml/paxml/learners.py" source_line=47}
  reduce.388.clone.1 = f32[] reduce(multiply.1757.clone.1, constant.2012), dimensions={0}, to_apply=region_15.791, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/reduce_sum[axes=(0,)]" source_file="/pax/paxml/paxml/learners.py" source_line=47}
  ROOT tuple.160 = (f32[], f32[]) tuple(reduce.390, reduce.388.clone.1)
} // fused_computation.387

fused_computation.389 {
  param_1.1700 = f32[4096,32000]{1,0} parameter(1)
  bitcast.7772 = f32[2,2048,32000]{2,1,0} bitcast(param_1.1700)
  constant.2514 = f32[] constant(30)
  broadcast.2985 = f32[2,2048,32000]{2,1,0} broadcast(constant.2514), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/lm.compute_loss/softmax/softmax.get_logits/div" source_file="/pax/praxis/praxis/layers/embedding_softmax.py" source_line=245}
  multiply.1887 = f32[2,2048,32000]{2,1,0} multiply(bitcast.7772, broadcast.2985), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/lm.compute_loss/softmax/softmax.get_logits/mul" source_file="/pax/praxis/praxis/layers/embedding_softmax.py" source_line=245}
  param_0.1236 = f32[2,2048]{1,0} parameter(0)
  broadcast.2984 = f32[2,2048,32000]{2,1,0} broadcast(param_0.1236), dimensions={0,1}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/lm.compute_loss/softmax/jit(log_softmax)/sub" source_file="/pax/praxis/praxis/layers/embedding_softmax.py" source_line=296}
  subtract.392 = f32[2,2048,32000]{2,1,0} subtract(multiply.1887, broadcast.2984), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/lm.compute_loss/softmax/jit(log_softmax)/sub" source_file="/pax/praxis/praxis/layers/embedding_softmax.py" source_line=296}
  exponential.70 = f32[2,2048,32000]{2,1,0} exponential(subtract.392), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/lm.compute_loss/softmax/jit(log_softmax)/exp" source_file="/pax/praxis/praxis/layers/embedding_softmax.py" source_line=296}
  bitcast.7513 = f32[2,2048,128,250]{3,2,1,0} bitcast(exponential.70), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/lm.compute_loss/softmax/jit(log_softmax)/exp" source_file="/pax/praxis/praxis/layers/embedding_softmax.py" source_line=296}
  constant.2180 = f32[] constant(0)
  ROOT reduce.391 = f32[2,2048,128]{2,1,0} reduce(bitcast.7513, constant.2180), dimensions={3}, to_apply=region_15.791, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/lm.compute_loss/softmax/jit(log_softmax)/reduce_sum[axes=(2,)]" source_file="/pax/praxis/praxis/layers/embedding_softmax.py" source_line=296}
} // fused_computation.389

fused_computation.391 {
  param_0.1713 = f32[4096,32000]{1,0} parameter(0)
  param_1.2429 = f32[32000]{0} parameter(1)
  broadcast.2727.clone.1 = f32[4096,32000]{1,0} broadcast(param_1.2429), dimensions={1}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/lm.compute_loss/softmax/softmax.get_logits/logits_ffn/bias/add" source_file="/pax/praxis/praxis/layers/linears.py" source_line=143}
  add.1082.clone.1 = f32[4096,32000]{1,0} add(param_0.1713, broadcast.2727.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/lm.compute_loss/softmax/softmax.get_logits/logits_ffn/bias/add" source_file="/pax/praxis/praxis/layers/linears.py" source_line=143}
  constant.2189.clone.1 = f32[] constant(0.0333333351)
  broadcast.2726.clone.1 = f32[4096,32000]{1,0} broadcast(constant.2189.clone.1), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/lm.compute_loss/softmax/softmax.get_logits/div" source_file="/pax/praxis/praxis/layers/embedding_softmax.py" source_line=245}
  multiply.1767.clone.1 = f32[4096,32000]{1,0} multiply(add.1082.clone.1, broadcast.2726.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/lm.compute_loss/softmax/softmax.get_logits/div" source_file="/pax/praxis/praxis/layers/embedding_softmax.py" source_line=245}
  tanh.41.clone.1 = f32[4096,32000]{1,0} tanh(multiply.1767.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/lm.compute_loss/softmax/softmax.get_logits/tanh" source_file="/pax/praxis/praxis/layers/embedding_softmax.py" source_line=245}
  bitcast.7768 = f32[2,2048,32000]{2,1,0} bitcast(tanh.41.clone.1)
  constant.2508 = f32[] constant(30)
  broadcast.2977 = f32[2,2048,32000]{2,1,0} broadcast(constant.2508), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/lm.compute_loss/softmax/softmax.get_logits/div" source_file="/pax/praxis/praxis/layers/embedding_softmax.py" source_line=245}
  multiply.1883 = f32[2,2048,32000]{2,1,0} multiply(bitcast.7768, broadcast.2977), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/lm.compute_loss/softmax/softmax.get_logits/mul" source_file="/pax/praxis/praxis/layers/embedding_softmax.py" source_line=245}
  bitcast.7515 = f32[2,2048,128,250]{3,2,1,0} bitcast(multiply.1883), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/lm.compute_loss/softmax/softmax.get_logits/mul" source_file="/pax/praxis/praxis/layers/embedding_softmax.py" source_line=245}
  iota.54 = s32[2,2048,32000]{2,1,0} iota(), iota_dimension=2, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/lm.compute_loss/softmax/iota[dtype=int32 shape=(16, 2048, 32000) dimension=2]" source_file="/pax/praxis/praxis/layers/embedding_softmax.py" source_line=323}
  bitcast.7514 = s32[2,2048,128,250]{3,2,1,0} bitcast(iota.54), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/lm.compute_loss/softmax/iota[dtype=int32 shape=(16, 2048, 32000) dimension=2]" source_file="/pax/praxis/praxis/layers/embedding_softmax.py" source_line=323}
  constant.2183 = f32[] constant(-inf)
  constant.2182 = s32[] constant(0)
  reduce.392 = (f32[2,2048,128]{2,1,0}, s32[2,2048,128]{2,1,0}) reduce(bitcast.7515, bitcast.7514, constant.2183, constant.2182), dimensions={3}, to_apply=region_13.759, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/lm.compute_loss/softmax/reduce[computation=<function _compute_argminmax.<locals>.reducer_fn at 0x7f7f7dce49d0> consts=() dimensions=(2,)]" source_file="/pax/praxis/praxis/layers/embedding_softmax.py" source_line=323}
  ROOT tuple.136 = ((f32[2,2048,128]{2,1,0}, s32[2,2048,128]{2,1,0}), f32[4096,32000]{1,0}) tuple(reduce.392, tanh.41.clone.1)
} // fused_computation.391

fused_computation.394 {
  param_2.2223 = f32[2,2048,8192]{2,1,0} parameter(2)
  param_3.2194 = f32[2,2048]{1,0} parameter(3)
  bitcast.7660.clone.1 = f32[1,2,2048]{2,1,0} bitcast(param_3.2194)
  rsqrt.58.clone.1 = f32[1,2,2048]{2,1,0} rsqrt(bitcast.7660.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/final_ln/rsqrt" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  bitcast.7659.clone.1 = f32[2,2048]{1,0} bitcast(rsqrt.58.clone.1)
  broadcast.2731.clone.1 = f32[2,2048,8192]{2,1,0} broadcast(bitcast.7659.clone.1), dimensions={0,1}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/final_ln/mul" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  multiply.1770.clone.1 = f32[2,2048,8192]{2,1,0} multiply(param_2.2223, broadcast.2731.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/final_ln/mul" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  param_1.2430 = f32[8192]{0} parameter(1)
  broadcast.2729 = f32[2,2048,8192]{2,1,0} broadcast(param_1.2430), dimensions={2}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/final_ln/mul" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=376}
  multiply.1769 = f32[2,2048,8192]{2,1,0} multiply(multiply.1770.clone.1, broadcast.2729), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/final_ln/mul" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=376}
  param_0.775 = f32[8192]{0} parameter(0)
  broadcast.2728 = f32[2,2048,8192]{2,1,0} broadcast(param_0.775), dimensions={2}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/final_ln/add" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=378}
  add.1083 = f32[2,2048,8192]{2,1,0} add(multiply.1769, broadcast.2728), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/final_ln/add" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=378}
  ROOT tuple.137 = (f32[2,2048,8192]{2,1,0}, f32[2,2048,8192]{2,1,0}) tuple(add.1083, multiply.1770.clone.1)
} // fused_computation.394

fused_computation.395 {
  param_0.776 = f32[8192]{0} parameter(0)
  constant.2190 = f32[] constant(1)
  broadcast.2730 = f32[8192]{0} broadcast(constant.2190), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/layer_norm/add" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=376}
  ROOT add.1084 = f32[8192]{0} add(param_0.776, broadcast.2730), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/final_ln/add" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=376}
}

fused_computation.397 {
  param_0.780 = f32[2,2048]{1,0} parameter(0)
  constant.2192 = f32[] constant(0.000122070312)
  broadcast.2734 = f32[2,2048]{1,0} broadcast(constant.2192), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/layer_norm/div" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=370}
  multiply.1771 = f32[2,2048]{1,0} multiply(param_0.780, broadcast.2734), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/final_ln/div" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=371}
  constant.2191 = f32[] constant(1e-06)
  broadcast.2733 = f32[2,2048]{1,0} broadcast(constant.2191), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/layer_norm/add" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  ROOT add.1086 = f32[2,2048]{1,0} add(multiply.1771, broadcast.2733), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/final_ln/add" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
} // fused_computation.397

fused_computation.398 {
  param_5.1694 = f32[4096,8192]{1,0} parameter(5)
  bitcast.7756.clone.1 = f32[2,2048,8192]{2,1,0} bitcast(param_5.1694)
  param_2.2229 = f32[4096,8192]{1,0} parameter(2)
  param_3.2200 = f32[8,8192]{1,0} parameter(3)
  param_4.1932 = s32[] parameter(4)
  constant.2491.clone.1 = s32[] constant(0)
  compare.715.clone.1 = pred[] compare(param_4.1932, constant.2491.clone.1), direction=LT, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/lt" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  constant.2493.clone.1 = s32[] constant(8)
  add.1179.clone.1 = s32[] add(param_4.1932, constant.2493.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/add" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  select.1009.clone.1 = s32[] select(compare.715.clone.1, add.1179.clone.1, param_4.1932), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/select_n" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  dynamic-slice.244.clone.1 = f32[1,8192]{1,0} dynamic-slice(param_3.2200, select.1009.clone.1, constant.2491.clone.1), dynamic_slice_sizes={1,8192}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/dynamic_slice[slice_sizes=(1, 8192)]" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  bitcast.7755.clone.1 = f32[8192]{0} bitcast(dynamic-slice.244.clone.1)
  broadcast.2969.clone.1 = f32[4096,8192]{1,0} broadcast(bitcast.7755.clone.1), dimensions={1}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/ff_layer/ffn_layer2/bias/add" source_file="/pax/praxis/praxis/layers/linears.py" source_line=143}
  add.1178.clone.1 = f32[4096,8192]{1,0} add(param_2.2229, broadcast.2969.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/ff_layer/ffn_layer2/bias/add" source_file="/pax/praxis/praxis/layers/linears.py" source_line=143}
  bitcast.7754.clone.1 = f32[2,2048,8192]{2,1,0} bitcast(add.1178.clone.1)
  param_1.2435 = f32[2,2048,1]{1,0,2} parameter(1)
  bitcast.7753.clone.1 = f32[2,2048]{1,0} bitcast(param_1.2435)
  broadcast.2967.clone.1 = f32[2,2048,8192]{2,1,0} broadcast(bitcast.7753.clone.1), dimensions={0,1}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/ff_layer/mul" source_file="/pax/praxis/praxis/layers/transformers.py" source_line=468}
  multiply.1877.clone.1 = f32[2,2048,8192]{2,1,0} multiply(bitcast.7754.clone.1, broadcast.2967.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/ff_layer/mul" source_file="/pax/praxis/praxis/layers/transformers.py" source_line=468}
  add.1177.clone.1 = f32[2,2048,8192]{2,1,0} add(bitcast.7756.clone.1, multiply.1877.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/ff_layer/add" source_file="/pax/praxis/praxis/layers/transformers.py" source_line=489}
  param_0.1715 = f32[2,2048]{1,0} parameter(0)
  constant.2196.clone.1 = f32[] constant(0.000122070312)
  broadcast.2736.clone.1 = f32[2,2048]{1,0} broadcast(constant.2196.clone.1), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/layer_norm/div" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=370}
  multiply.1773.clone.1 = f32[2,2048]{1,0} multiply(param_0.1715, broadcast.2736.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/final_ln/div" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=370}
  broadcast.2735.clone.1 = f32[2,2048,8192]{2,1,0} broadcast(multiply.1773.clone.1), dimensions={0,1}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/final_ln/sub" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  subtract.336.clone.1 = f32[2,2048,8192]{2,1,0} subtract(add.1177.clone.1, broadcast.2735.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/final_ln/sub" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  multiply.1772 = f32[2,2048,8192]{2,1,0} multiply(subtract.336.clone.1, subtract.336.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/final_ln/mul" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=371}
  constant.2195 = f32[] constant(0)
  reduce.393 = f32[2,2048]{1,0} reduce(multiply.1772, constant.2195), dimensions={2}, to_apply=region_15.791, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/final_ln/reduce_sum[axes=(2,)]" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=371}
  ROOT tuple.138 = (f32[2,2048]{1,0}, f32[2,2048,8192]{2,1,0}) tuple(reduce.393, subtract.336.clone.1)
} // fused_computation.398

fused_computation.401 {
  param_0.1081 = f32[4096,32768]{1,0} parameter(0)
  param_1.1533 = f32[8,32768]{1,0} parameter(1)
  param_3.922 = s32[] parameter(3)
  constant.2201 = s32[] constant(0)
  compare.701 = pred[] compare(param_3.922, constant.2201), direction=LT, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/lt" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  constant.2438 = s32[] constant(8)
  add.1161 = s32[] add(param_3.922, constant.2438), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/add" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  select.995 = s32[] select(compare.701, add.1161, param_3.922), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/select_n" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  dynamic-slice.206 = f32[1,32768]{1,0} dynamic-slice(param_1.1533, select.995, constant.2201), dynamic_slice_sizes={1,32768}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/dynamic_slice[slice_sizes=(1, 32768)]" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  bitcast.7519 = f32[32768]{0} bitcast(dynamic-slice.206)
  broadcast.2746 = f32[4096,32768]{1,0} broadcast(bitcast.7519), dimensions={1}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/ff_layer/ffn_layer1/bias/add" source_file="/pax/praxis/praxis/layers/linears.py" source_line=143}
  add.1092 = f32[4096,32768]{1,0} add(param_0.1081, broadcast.2746), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/ff_layer/ffn_layer1/bias/add" source_file="/pax/praxis/praxis/layers/linears.py" source_line=143}
  bitcast.7518 = f32[2,2048,32768]{2,1,0} bitcast(add.1092)
  multiply.1781 = f32[2,2048,32768]{2,1,0} multiply(bitcast.7518, bitcast.7518), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/ff_layer/ffn_layer1/activation/mul" source_file="/pax/praxis/praxis/layers/activations.py" source_line=157}
  multiply.1780 = f32[2,2048,32768]{2,1,0} multiply(bitcast.7518, multiply.1781), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/ff_layer/ffn_layer1/activation/mul" source_file="/pax/praxis/praxis/layers/activations.py" source_line=157}
  constant.2198 = f32[] constant(0.044715)
  broadcast.2745 = f32[2,2048,32768]{2,1,0} broadcast(constant.2198), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/ff_layer/ffn_layer1/activation/mul" source_file="/pax/praxis/praxis/layers/activations.py" source_line=157}
  multiply.1779 = f32[2,2048,32768]{2,1,0} multiply(multiply.1780, broadcast.2745), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/ff_layer/ffn_layer1/activation/mul" source_file="/pax/praxis/praxis/layers/activations.py" source_line=157}
  add.1091 = f32[2,2048,32768]{2,1,0} add(bitcast.7518, multiply.1779), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/ff_layer/ffn_layer1/activation/add" source_file="/pax/praxis/praxis/layers/activations.py" source_line=157}
  constant.2199 = f32[] constant(0.797884583)
  broadcast.2743 = f32[2,2048,32768]{2,1,0} broadcast(constant.2199), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/ff_layer/ffn_layer1/activation/mul" source_file="/pax/praxis/praxis/layers/activations.py" source_line=157}
  multiply.1778 = f32[2,2048,32768]{2,1,0} multiply(add.1091, broadcast.2743), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/ff_layer/ffn_layer1/activation/mul" source_file="/pax/praxis/praxis/layers/activations.py" source_line=157}
  tanh.42 = f32[2,2048,32768]{2,1,0} tanh(multiply.1778), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/ff_layer/ffn_layer1/activation/tanh" source_file="/pax/praxis/praxis/layers/activations.py" source_line=157}
  constant.2202 = f32[] constant(1)
  broadcast.2742 = f32[2,2048,32768]{2,1,0} broadcast(constant.2202), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/ff_layer/ffn_layer1/activation/add" source_file="/pax/praxis/praxis/layers/activations.py" source_line=157}
  add.1090 = f32[2,2048,32768]{2,1,0} add(tanh.42, broadcast.2742), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/ff_layer/ffn_layer1/activation/add" source_file="/pax/praxis/praxis/layers/activations.py" source_line=157}
  constant.2200 = f32[] constant(0.5)
  broadcast.2741 = f32[2,2048,32768]{2,1,0} broadcast(constant.2200), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/ff_layer/ffn_layer1/activation/mul" source_file="/pax/praxis/praxis/layers/activations.py" source_line=157}
  multiply.1777 = f32[2,2048,32768]{2,1,0} multiply(add.1090, broadcast.2741), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/ff_layer/ffn_layer1/activation/mul" source_file="/pax/praxis/praxis/layers/activations.py" source_line=157}
  multiply.1776 = f32[2,2048,32768]{2,1,0} multiply(bitcast.7518, multiply.1777), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/ff_layer/ffn_layer1/activation/mul" source_file="/pax/praxis/praxis/layers/activations.py" source_line=157}
  param_2.1246 = f32[2,2048,1]{1,0,2} parameter(2)
  bitcast.7663 = f32[2,2048]{1,0} bitcast(param_2.1246)
  broadcast.2740 = f32[2,2048,32768]{2,1,0} broadcast(bitcast.7663), dimensions={0,1}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/ff_layer/mul" source_file="/pax/praxis/praxis/layers/transformers.py" source_line=455}
  ROOT multiply.1775 = f32[2,2048,32768]{2,1,0} multiply(multiply.1776, broadcast.2740), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/ff_layer/mul" source_file="/pax/praxis/praxis/layers/transformers.py" source_line=455}
} // fused_computation.401

fused_computation.402 {
  param_5.424 = f32[4096,8192]{1,0} parameter(5)
  bitcast.7748 = f32[2,2048,8192]{2,1,0} bitcast(param_5.424)
  param_4.565 = f32[2,2048]{1,0} parameter(4)
  constant.2204 = f32[] constant(0.000122070312)
  broadcast.2962 = f32[2,2048]{1,0} broadcast(constant.2204), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/layer_norm/div" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=370}
  multiply.1875 = f32[2,2048]{1,0} multiply(param_4.565, broadcast.2962), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/div" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=370}
  broadcast.2960 = f32[2,2048,8192]{2,1,0} broadcast(multiply.1875), dimensions={0,1}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/sub" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  subtract.388 = f32[2,2048,8192]{2,1,0} subtract(bitcast.7748, broadcast.2960), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/sub" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  param_2.1261 = f32[2,2048]{1,0} parameter(2)
  multiply.1784 = f32[2,2048]{1,0} multiply(param_2.1261, broadcast.2962), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/div" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=371}
  constant.2203 = f32[] constant(1e-06)
  broadcast.2751 = f32[2,2048]{1,0} broadcast(constant.2203), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/layer_norm/add" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  add.1096 = f32[2,2048]{1,0} add(multiply.1784, broadcast.2751), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/add" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  rsqrt.36 = f32[2,2048]{1,0} rsqrt(add.1096), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/rsqrt" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  broadcast.2749 = f32[2,2048,8192]{2,1,0} broadcast(rsqrt.36), dimensions={0,1}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/mul" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  multiply.1783 = f32[2,2048,8192]{2,1,0} multiply(subtract.388, broadcast.2749), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/mul" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  param_1.1667 = f32[8,8192]{1,0} parameter(1)
  param_3.936 = s32[] parameter(3)
  constant.2205 = s32[] constant(0)
  compare.705 = pred[] compare(param_3.936, constant.2205), direction=LT, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/lt" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  constant.2448 = s32[] constant(8)
  add.1165 = s32[] add(param_3.936, constant.2448), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/add" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  select.999 = s32[] select(compare.705, add.1165, param_3.936), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/select_n" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  dynamic-slice.208 = f32[1,8192]{1,0} dynamic-slice(param_1.1667, select.999, constant.2205), dynamic_slice_sizes={1,8192}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/dynamic_slice[slice_sizes=(1, 8192)]" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  constant.2206 = f32[] constant(1)
  broadcast.2750 = f32[1,8192]{1,0} broadcast(constant.2206), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/layer_norm/add" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=376}
  add.1095 = f32[1,8192]{1,0} add(dynamic-slice.208, broadcast.2750), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/add" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=376}
  bitcast.7521 = f32[8192]{0} bitcast(add.1095)
  broadcast.2748 = f32[2,2048,8192]{2,1,0} broadcast(bitcast.7521), dimensions={2}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/mul" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=376}
  multiply.1782 = f32[2,2048,8192]{2,1,0} multiply(multiply.1783, broadcast.2748), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/mul" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=376}
  param_0.788 = f32[8,8192]{1,0} parameter(0)
  dynamic-slice.207 = f32[1,8192]{1,0} dynamic-slice(param_0.788, select.999, constant.2205), dynamic_slice_sizes={1,8192}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/dynamic_slice[slice_sizes=(1, 8192)]" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  bitcast.7520 = f32[8192]{0} bitcast(dynamic-slice.207)
  broadcast.2747 = f32[2,2048,8192]{2,1,0} broadcast(bitcast.7520), dimensions={2}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/add" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=378}
  ROOT add.1094 = f32[2,2048,8192]{2,1,0} add(multiply.1782, broadcast.2747), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/add" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=378}
} // fused_computation.402

fused_computation.403 {
  param_1.1681 = f32[4096,8192]{1,0} parameter(1)
  bitcast.7746 = f32[2,2048,8192]{2,1,0} bitcast(param_1.1681)
  param_0.1220 = f32[2,2048]{1,0} parameter(0)
  constant.2483 = f32[] constant(0.000122070312)
  broadcast.2957 = f32[2,2048]{1,0} broadcast(constant.2483), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/layer_norm/div" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=370}
  multiply.1873 = f32[2,2048]{1,0} multiply(param_0.1220, broadcast.2957), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/div" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=370}
  broadcast.2956 = f32[2,2048,8192]{2,1,0} broadcast(multiply.1873), dimensions={0,1}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/sub" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  subtract.386 = f32[2,2048,8192]{2,1,0} subtract(bitcast.7746, broadcast.2956), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/sub" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  multiply.1785 = f32[2,2048,8192]{2,1,0} multiply(subtract.386, subtract.386), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/mul" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=371}
  constant.2207 = f32[] constant(0)
  ROOT reduce.394 = f32[2,2048]{1,0} reduce(multiply.1785, constant.2207), dimensions={2}, to_apply=region_15.791, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/reduce_sum[axes=(2,)]" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=371}
} // fused_computation.403

fused_computation.405 {
  param_0.793 = f32[256,64,2048]{2,1,0} parameter(0)
  bitcast.7522 = f32[2,128,64,2048]{3,2,1,0} bitcast(param_0.793)
  ROOT transpose.272 = f32[2,2048,128,64]{3,2,1,0} transpose(bitcast.7522), dimensions={0,3,1,2}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/pv_einsum/BNTS,BSNH->BTNH/transpose[permutation=(0, 3, 1, 2)]" source_file="/pax/praxis/praxis/layers/base_ops.py" source_line=42}
}

fused_computation.406 {
  param_0.794 = f32[2,128,2048,2048]{3,2,1,0} parameter(0)
  param_1.1184 = f32[2,128,2048]{2,1,0} parameter(1)
  broadcast.2757 = f32[2,128,2048,2048]{3,2,1,0} broadcast(param_1.1184), dimensions={0,1,2}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/div" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=1487}
  ROOT divide.225 = f32[2,128,2048,2048]{3,2,1,0} divide(param_0.794, broadcast.2757), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/div" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=1487}
}

fused_computation.410 {
  param_0.1088 = f32[8,64]{1,0} parameter(0)
  param_1.1670 = s32[] parameter(1)
  constant.2215 = s32[] constant(0)
  compare.709 = pred[] compare(param_1.1670, constant.2215), direction=LT, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/lt" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  constant.2460 = s32[] constant(8)
  add.1169 = s32[] add(param_1.1670, constant.2460), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/add" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  select.1003 = s32[] select(compare.709, add.1169, param_1.1670), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/select_n" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  dynamic-slice.222 = f32[1,64]{1,0} dynamic-slice(param_0.1088, select.1003, constant.2215), dynamic_slice_sizes={1,64}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/dynamic_slice[slice_sizes=(1, 64)]" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  abs.24 = f32[1,64]{1,0} abs(dynamic-slice.222), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._scale_query/per_dim_scale/jit(softplus)/jit(logaddexp)/abs" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=403}
  negate.134 = f32[1,64]{1,0} negate(abs.24), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._scale_query/per_dim_scale/jit(softplus)/jit(logaddexp)/neg" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=403}
  exponential.67 = f32[1,64]{1,0} exponential(negate.134), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._scale_query/per_dim_scale/jit(softplus)/jit(logaddexp)/exp" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=403}
  ROOT log-plus-one.24 = f32[1,64]{1,0} log-plus-one(exponential.67), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._scale_query/per_dim_scale/jit(softplus)/jit(logaddexp)/log1p" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=403}
} // fused_computation.410

fused_computation.412 {
  param_4.563 = f32[2,2048,8192]{2,1,0} parameter(4)
  param_5.420 = f32[2,2048]{1,0} parameter(5)
  constant.2217 = f32[] constant(0.000122070312)
  broadcast.2951 = f32[2,2048]{1,0} broadcast(constant.2217), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/layer_norm/div" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=370}
  multiply.1871 = f32[2,2048]{1,0} multiply(param_5.420, broadcast.2951), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/layer_norm/div" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=370}
  broadcast.2949 = f32[2,2048,8192]{2,1,0} broadcast(multiply.1871), dimensions={0,1}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/layer_norm/sub" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  subtract.384 = f32[2,2048,8192]{2,1,0} subtract(param_4.563, broadcast.2949), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/layer_norm/sub" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  param_2.1257 = f32[2,2048]{1,0} parameter(2)
  multiply.1793 = f32[2,2048]{1,0} multiply(param_2.1257, broadcast.2951), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/layer_norm/div" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=371}
  constant.2216 = f32[] constant(1e-06)
  broadcast.2768 = f32[2,2048]{1,0} broadcast(constant.2216), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/layer_norm/add" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  add.1102 = f32[2,2048]{1,0} add(multiply.1793, broadcast.2768), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/layer_norm/add" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  rsqrt.37 = f32[2,2048]{1,0} rsqrt(add.1102), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/layer_norm/rsqrt" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  broadcast.2767 = f32[2,2048,8192]{2,1,0} broadcast(rsqrt.37), dimensions={0,1}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/layer_norm/mul" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  multiply.1792 = f32[2,2048,8192]{2,1,0} multiply(subtract.384, broadcast.2767), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/layer_norm/mul" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  param_1.1668 = f32[8,8192]{1,0} parameter(1)
  param_3.933 = s32[] parameter(3)
  constant.2218 = s32[] constant(0)
  compare.707 = pred[] compare(param_3.933, constant.2218), direction=LT, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/lt" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  constant.2453 = s32[] constant(8)
  add.1167 = s32[] add(param_3.933, constant.2453), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/add" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  select.1001 = s32[] select(compare.707, add.1167, param_3.933), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/select_n" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  dynamic-slice.210 = f32[1,8192]{1,0} dynamic-slice(param_1.1668, select.1001, constant.2218), dynamic_slice_sizes={1,8192}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/dynamic_slice[slice_sizes=(1, 8192)]" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  constant.2219 = f32[] constant(1)
  broadcast.2766 = f32[1,8192]{1,0} broadcast(constant.2219), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/layer_norm/add" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=376}
  add.1100 = f32[1,8192]{1,0} add(dynamic-slice.210, broadcast.2766), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/layer_norm/add" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=376}
  bitcast.7528 = f32[8192]{0} bitcast(add.1100)
  broadcast.2765 = f32[2,2048,8192]{2,1,0} broadcast(bitcast.7528), dimensions={2}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/layer_norm/mul" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=376}
  multiply.1791 = f32[2,2048,8192]{2,1,0} multiply(multiply.1792, broadcast.2765), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/layer_norm/mul" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=376}
  param_0.809 = f32[8,8192]{1,0} parameter(0)
  dynamic-slice.209 = f32[1,8192]{1,0} dynamic-slice(param_0.809, select.1001, constant.2218), dynamic_slice_sizes={1,8192}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/dynamic_slice[slice_sizes=(1, 8192)]" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  bitcast.7527 = f32[8192]{0} bitcast(dynamic-slice.209)
  broadcast.2764 = f32[2,2048,8192]{2,1,0} broadcast(bitcast.7527), dimensions={2}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/layer_norm/add" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=378}
  ROOT add.1099 = f32[2,2048,8192]{2,1,0} add(multiply.1791, broadcast.2764), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/layer_norm/add" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=378}
} // fused_computation.412

fused_computation.414 {
  param_0.1207 = f32[2,2048,8192]{2,1,0} parameter(0)
  param_1.1674 = f32[2,2048]{1,0} parameter(1)
  constant.2474 = f32[] constant(0.000122070312)
  broadcast.2945 = f32[2,2048]{1,0} broadcast(constant.2474), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/layer_norm/div" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=370}
  multiply.1869 = f32[2,2048]{1,0} multiply(param_1.1674, broadcast.2945), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/layer_norm/div" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=370}
  broadcast.2944 = f32[2,2048,8192]{2,1,0} broadcast(multiply.1869), dimensions={0,1}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/layer_norm/sub" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  subtract.382 = f32[2,2048,8192]{2,1,0} subtract(param_0.1207, broadcast.2944), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/layer_norm/sub" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  multiply.1794 = f32[2,2048,8192]{2,1,0} multiply(subtract.382, subtract.382), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/layer_norm/mul" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=371}
  constant.2220 = f32[] constant(0)
  ROOT reduce.395 = f32[2,2048]{1,0} reduce(multiply.1794, constant.2220), dimensions={2}, to_apply=region_15.791, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/layer_norm/reduce_sum[axes=(2,)]" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=371}
} // fused_computation.414

fused_computation.416 {
  param_0.816 = f32[8,32768,1024]{2,1,0} parameter(0)
  slice.90 = f32[1,32768,1024]{2,1,0} slice(param_0.816), slice={[0:1], [0:32768], [0:1024]}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/dynamic_slice[slice_sizes=(1, 32768, 8192)]" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  ROOT transpose.275 = f32[1,1024,32768]{2,1,0} transpose(slice.90), dimensions={0,2,1}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/dynamic_slice[slice_sizes=(1, 32768, 8192)]" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
}

fused_computation.417 {
  param_0.818 = f32[8,3,1024,128,64]{4,3,2,1,0} parameter(0)
  slice.91 = f32[1,3,1024,128,64]{4,3,2,1,0} slice(param_0.818), slice={[0:1], [0:3], [0:1024], [0:128], [0:64]}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/dynamic_slice[slice_sizes=(1, 3, 8192, 128, 64)]" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  ROOT transpose.276 = f32[1,1024,3,128,64]{4,3,2,1,0} transpose(slice.91), dimensions={0,2,1,3,4}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/dynamic_slice[slice_sizes=(1, 3, 8192, 128, 64)]" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
}

fused_computation.418 {
  param_0.1726 = f32[2,2048]{1,0} parameter(0)
  convert.87.clone.1 = s32[2,2048]{1,0} convert(param_0.1726), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/convert_element_type[new_dtype=int32 weak_type=False]" source_file="/pax/praxis/praxis/layers/transformer_models.py" source_line=776}
  broadcast.2780.clone.1 = s32[2,2048,2048]{2,1,0} broadcast(convert.87.clone.1), dimensions={0,1}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/ne" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=132}
  broadcast.2779.clone.1 = s32[2,2048,2048]{2,1,0} broadcast(convert.87.clone.1), dimensions={0,2}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/ne" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=132}
  compare.644.clone.1 = pred[2,2048,2048]{2,1,0} compare(broadcast.2780.clone.1, broadcast.2779.clone.1), direction=NE, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/ne" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=132}
  constant.2424 = f32[] constant(-2.38197633e+38)
  broadcast.2778.clone.1 = f32[2,2048,2048]{2,1,0} broadcast(constant.2424), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/mul" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=134}
  constant.2423 = f32[] constant(0)
  broadcast.2777.clone.1 = f32[2,2048,2048]{2,1,0} broadcast(constant.2423), dimensions={}
  select.942.clone.1 = f32[2,2048,2048]{2,1,0} select(compare.644.clone.1, broadcast.2778.clone.1, broadcast.2777.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/mul" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=134}
  iota.76.clone.1 = s32[2048,2048]{1,0} iota(), iota_dimension=0, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/broadcast_in_dim[shape=(1, 2048, 2048, 1) broadcast_dimensions=(0, 1, 3)]" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=102}
  iota.75.clone.1 = s32[2048,2048]{1,0} iota(), iota_dimension=1, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/broadcast_in_dim[shape=(2048, 1, 1, 2048) broadcast_dimensions=(1, 2, 3)]" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=101}
  compare.697.clone.1 = pred[2048,2048]{1,0} compare(iota.76.clone.1, iota.75.clone.1), direction=LT, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/lt" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=103}
  broadcast.2937.clone.1 = f32[2048,2048]{1,0} broadcast(constant.2424), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/mul" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=103}
  broadcast.2936.clone.1 = f32[2048,2048]{1,0} broadcast(constant.2423), dimensions={}
  select.991.clone.1 = f32[2048,2048]{1,0} select(compare.697.clone.1, broadcast.2937.clone.1, broadcast.2936.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/mul" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=103}
  broadcast.2776.clone.1 = f32[2,2048,2048]{2,1,0} broadcast(select.991.clone.1), dimensions={1,2}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/min" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=165}
  minimum.19.clone.1 = f32[2,2048,2048]{2,1,0} minimum(select.942.clone.1, broadcast.2776.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/min" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=165}
  bitcast.7529 = f32[1,2,2048,2048]{3,2,1,0} bitcast(minimum.19.clone.1)
  broadcast.2774 = f32[1,2,2048,2048]{3,2,1,0} broadcast(select.991.clone.1), dimensions={2,3}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/sub.body_fn/sub/min" source_file="/pax/praxis/praxis/layers/transformers.py" source_line=128}
  minimum.18 = f32[1,2,2048,2048]{3,2,1,0} minimum(bitcast.7529, broadcast.2774), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/sub.body_fn/sub/min" source_file="/pax/praxis/praxis/layers/transformers.py" source_line=128}
  constant.2223 = f32[] constant(-1.19098816e+38)
  broadcast.2773 = f32[1,2,2048,2048]{3,2,1,0} broadcast(constant.2223), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/ge" source_file="/pax/praxis/praxis/py_utils.py" source_line=743}
  compare.643 = pred[1,2,2048,2048]{3,2,1,0} compare(minimum.18, broadcast.2773), direction=GE, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/ge" source_file="/pax/praxis/praxis/py_utils.py" source_line=743}
  ROOT tuple.143 = (pred[1,2,2048,2048]{3,2,1,0}, f32[2,2048,2048]{2,1,0}) tuple(compare.643, minimum.19.clone.1)
} // fused_computation.418

fused_computation.421 {
  constant.2226 = f32[] constant(1)
  broadcast.2784 = f32[2,2048]{1,0} broadcast(constant.2226), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/sub" source_file="/pax/praxis/praxis/layers/transformer_models.py" source_line=776}
  param_0.826 = f32[2,2048]{1,0} parameter(0)
  ROOT subtract.340 = f32[2,2048]{1,0} subtract(broadcast.2784, param_0.826), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/sub" source_file="/pax/praxis/praxis/layers/transformer_models.py" source_line=776}
}

fused_computation.422 {
  iota.58 = s32[2,2048,1]{1,0,2} iota(), iota_dimension=1, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/broadcast_in_dim[shape=(16, 1, 1, 2048) broadcast_dimensions=(1, 2, 3)]" source_file="/pax/praxis/praxis/layers/transformer_models.py" source_line=777}
  bitcast.7531 = s32[1,2,2048]{2,1,0} bitcast(iota.58)
  convert.88 = f32[1,2,2048]{2,1,0} convert(bitcast.7531), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/lm._prepare_input/position_emb/convert_element_type[new_dtype=float32 weak_type=False]" source_file="/pax/praxis/praxis/layers/embedding_softmax.py" source_line=849}
  bitcast.7530 = f32[2,2048]{1,0} bitcast(convert.88)
  broadcast.2787 = f32[2,2048,4096]{2,1,0} broadcast(bitcast.7530), dimensions={0,1}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/lm._prepare_input/position_emb/mul" source_file="/pax/praxis/praxis/layers/embedding_softmax.py" source_line=849}
  iota.57 = f32[4096]{0} iota(), iota_dimension=0, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/lm._prepare_input/position_emb/iota[dtype=float32 shape=(4096,) dimension=0]" source_file="/pax/praxis/praxis/layers/embedding_softmax.py" source_line=846}
  constant.1666 = f32[] constant(-0.0022491673)
  broadcast.2786 = f32[4096]{0} broadcast(constant.1666), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/lm._prepare_input/position_emb/mul" source_file="/pax/praxis/praxis/layers/embedding_softmax.py" source_line=846}
  multiply.1797 = f32[4096]{0} multiply(iota.57, broadcast.2786), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/lm._prepare_input/position_emb/mul" source_file="/pax/praxis/praxis/layers/embedding_softmax.py" source_line=846}
  exponential.68 = f32[4096]{0} exponential(multiply.1797), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/lm._prepare_input/position_emb/exp" source_file="/pax/praxis/praxis/layers/embedding_softmax.py" source_line=845}
  broadcast.2785 = f32[2,2048,4096]{2,1,0} broadcast(exponential.68), dimensions={2}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/lm._prepare_input/position_emb/mul" source_file="/pax/praxis/praxis/layers/embedding_softmax.py" source_line=849}
  multiply.1796 = f32[2,2048,4096]{2,1,0} multiply(broadcast.2787, broadcast.2785), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/lm._prepare_input/position_emb/mul" source_file="/pax/praxis/praxis/layers/embedding_softmax.py" source_line=849}
  sine.2 = f32[2,2048,4096]{2,1,0} sine(multiply.1796), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/lm._prepare_input/position_emb/sin" source_file="/pax/praxis/praxis/layers/embedding_softmax.py" source_line=853}
  cosine.2 = f32[2,2048,4096]{2,1,0} cosine(multiply.1796), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/lm._prepare_input/position_emb/cos" source_file="/pax/praxis/praxis/layers/embedding_softmax.py" source_line=853}
  ROOT concatenate.2 = f32[2,2048,8192]{2,1,0} concatenate(sine.2, cosine.2), dimensions={2}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/lm._prepare_input/position_emb/concatenate[dimension=2]" source_file="/pax/praxis/praxis/layers/embedding_softmax.py" source_line=852}
} // fused_computation.422

fused_computation.423 {
  param_0.837 = s32[2,2048]{1,0} parameter(0)
  broadcast.2788 = s32[2,2048,32000]{2,1,0} broadcast(param_0.837), dimensions={0,1}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/lm._prepare_input/softmax.emb_lookup/jit(_one_hot)/eq" source_file="/pax/praxis/praxis/layers/embedding_softmax.py" source_line=391}
  iota.59 = s32[2,2048,32000]{2,1,0} iota(), iota_dimension=2, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/lm._prepare_input/softmax.emb_lookup/jit(_one_hot)/eq" source_file="/pax/praxis/praxis/layers/embedding_softmax.py" source_line=391}
  compare.646 = pred[2,2048,32000]{2,1,0} compare(broadcast.2788, iota.59), direction=EQ, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/lm._prepare_input/softmax.emb_lookup/jit(_one_hot)/eq" source_file="/pax/praxis/praxis/layers/embedding_softmax.py" source_line=391}
  bitcast.7532 = pred[4096,32000]{1,0} bitcast(compare.646)
  ROOT convert.89 = f32[4096,32000]{1,0} convert(bitcast.7532), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/lm._prepare_input/softmax.emb_lookup/jit(_one_hot)/convert_element_type[new_dtype=float32 weak_type=False]" source_file="/pax/praxis/praxis/layers/embedding_softmax.py" source_line=391}
} // fused_computation.423

fused_computation.426 {
  param_0.1076 = f32[2,2048]{1,0} parameter(0)
  bitcast.7534 = f32[4096]{0} bitcast(param_0.1076), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/sharding_constraint[sharding=GSPMDSharding({devices=[8,1]<=[8]}) resource_env=ResourceEnv(Mesh(device_ids=array([[[0],\n        [1],\n        [2],\n        [3],\n        [4],\n        [5],\n        [6],\n        [7]]]), axis_names=(\'replica\', \'data\', \'mdl\')), ()) unconstrained_dims=set()]" source_file="/pax/praxis/praxis/py_utils.py" source_line=486}
  constant.2188 = f32[] constant(0)
  ROOT reduce.397 = f32[] reduce(bitcast.7534, constant.2188), dimensions={0}, to_apply=region_15.791, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/lm.compute_loss/softmax/reduce_sum[axes=(0, 1, 2)]" source_file="/pax/praxis/praxis/layers/embedding_softmax.py" source_line=331}
}

fused_computation.436 {
  param_6.1346 = s32[2,2048]{1,0} parameter(6)
  broadcast.2929.clone.1 = s32[2,2048,32000]{2,1,0} broadcast(param_6.1346), dimensions={0,1}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/lm.compute_loss/softmax/jit(_one_hot)/eq" source_file="/pax/praxis/praxis/layers/embedding_softmax.py" source_line=299}
  iota.68.clone.1 = s32[2,2048,32000]{2,1,0} iota(), iota_dimension=2, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/lm.compute_loss/softmax/jit(_one_hot)/eq" source_file="/pax/praxis/praxis/layers/embedding_softmax.py" source_line=299}
  compare.693.clone.1 = pred[2,2048,32000]{2,1,0} compare(broadcast.2929.clone.1, iota.68.clone.1), direction=EQ, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/lm.compute_loss/softmax/jit(_one_hot)/eq" source_file="/pax/praxis/praxis/layers/embedding_softmax.py" source_line=299}
  constant.2179.clone.1 = f32[] constant(1)
  param_5.1690 = f32[] parameter(5)
  constant.2416.clone.1 = f32[] constant(1e-06)
  add.1159.clone.1 = f32[] add(param_5.1690, constant.2416.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/lm.compute_loss/softmax/add" source_file="/pax/praxis/praxis/layers/embedding_softmax.py" source_line=349}
  divide.231.clone.1 = f32[] divide(constant.2179.clone.1, add.1159.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/lm.compute_loss/softmax/div" source_file="/pax/praxis/praxis/layers/embedding_softmax.py" source_line=349}
  broadcast.2928.clone.1 = f32[2,2048]{1,0} broadcast(divide.231.clone.1), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/lm.compute_loss/softmax/broadcast_in_dim[shape=(16, 2048, 1) broadcast_dimensions=()]" source_file="/pax/praxis/praxis/layers/embedding_softmax.py" source_line=327}
  param_4.1927 = f32[2,2048]{1,0} parameter(4)
  multiply.1867.clone.1 = f32[2,2048]{1,0} multiply(broadcast.2928.clone.1, param_4.1927), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/lm.compute_loss/softmax/mul" source_file="/pax/praxis/praxis/layers/embedding_softmax.py" source_line=328}
  negate.144.clone.1 = f32[2,2048]{1,0} negate(multiply.1867.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/lm.compute_loss/softmax/neg" source_file="/pax/praxis/praxis/layers/embedding_softmax.py" source_line=317}
  broadcast.2927.clone.1 = f32[2,2048,32000]{2,1,0} broadcast(negate.144.clone.1), dimensions={0,1}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/lm.compute_loss/softmax/broadcast_in_dim[shape=(16, 2048, 32000) broadcast_dimensions=(0, 1)]" source_file="/pax/praxis/praxis/layers/embedding_softmax.py" source_line=317}
  constant.2014 = f32[] constant(0)
  broadcast.2926.clone.1 = f32[2,2048,32000]{2,1,0} broadcast(constant.2014), dimensions={}
  select.987.clone.1 = f32[2,2048,32000]{2,1,0} select(compare.693.clone.1, broadcast.2927.clone.1, broadcast.2926.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/lm.compute_loss/softmax/mul" source_file="/pax/praxis/praxis/layers/embedding_softmax.py" source_line=318}
  param_2.2222 = f32[2,2048]{1,0} parameter(2)
  param_3.2189 = f32[2,2048]{1,0} parameter(3)
  divide.224.clone.1 = f32[2,2048]{1,0} divide(param_2.2222, param_3.2189), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/lm.compute_loss/softmax/jit(log_softmax)/div" source_file="/pax/praxis/praxis/layers/embedding_softmax.py" source_line=296}
  broadcast.2722.clone.1 = f32[2,2048,32000]{2,1,0} broadcast(divide.224.clone.1), dimensions={0,1}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/lm.compute_loss/softmax/jit(log_softmax)/broadcast_in_dim[shape=(16, 2048, 32000) broadcast_dimensions=(0, 1)]" source_file="/pax/praxis/praxis/layers/embedding_softmax.py" source_line=296}
  param_1.2425 = f32[4096,32000]{1,0} parameter(1)
  bitcast.7774.clone.1 = f32[2,2048,32000]{2,1,0} bitcast(param_1.2425)
  constant.2177.clone.1 = f32[] constant(30)
  broadcast.2989.clone.1 = f32[2,2048,32000]{2,1,0} broadcast(constant.2177.clone.1), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/lm.compute_loss/softmax/softmax.get_logits/div" source_file="/pax/praxis/praxis/layers/embedding_softmax.py" source_line=245}
  multiply.1889.clone.1 = f32[2,2048,32000]{2,1,0} multiply(bitcast.7774.clone.1, broadcast.2989.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/lm.compute_loss/softmax/softmax.get_logits/mul" source_file="/pax/praxis/praxis/layers/embedding_softmax.py" source_line=245}
  param_0.1710 = f32[2,2048]{1,0} parameter(0)
  broadcast.2988.clone.1 = f32[2,2048,32000]{2,1,0} broadcast(param_0.1710), dimensions={0,1}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/lm.compute_loss/softmax/jit(log_softmax)/sub" source_file="/pax/praxis/praxis/layers/embedding_softmax.py" source_line=296}
  subtract.394.clone.1 = f32[2,2048,32000]{2,1,0} subtract(multiply.1889.clone.1, broadcast.2988.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/lm.compute_loss/softmax/jit(log_softmax)/sub" source_file="/pax/praxis/praxis/layers/embedding_softmax.py" source_line=296}
  exponential.69.clone.1 = f32[2,2048,32000]{2,1,0} exponential(subtract.394.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/lm.compute_loss/softmax/jit(log_softmax)/exp" source_file="/pax/praxis/praxis/layers/embedding_softmax.py" source_line=296}
  multiply.1765.clone.1 = f32[2,2048,32000]{2,1,0} multiply(broadcast.2722.clone.1, exponential.69.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/lm.compute_loss/softmax/jit(log_softmax)/mul" source_file="/pax/praxis/praxis/layers/embedding_softmax.py" source_line=296}
  add.1081.clone.1 = f32[2,2048,32000]{2,1,0} add(select.987.clone.1, multiply.1765.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/lm.compute_loss/softmax/jit(log_softmax)/add_any" source_file="/pax/praxis/praxis/layers/embedding_softmax.py" source_line=296}
  multiply.1764.clone.1 = f32[2,2048,32000]{2,1,0} multiply(add.1081.clone.1, broadcast.2989.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/lm.compute_loss/softmax/softmax.get_logits/mul" source_file="/pax/praxis/praxis/layers/embedding_softmax.py" source_line=245}
  broadcast.2721.clone.1 = f32[2,2048,32000]{2,1,0} broadcast(constant.2179.clone.1), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/lm.compute_loss/softmax/softmax.get_logits/sub" source_file="/pax/praxis/praxis/layers/embedding_softmax.py" source_line=245}
  subtract.334.clone.1 = f32[2,2048,32000]{2,1,0} subtract(broadcast.2721.clone.1, bitcast.7774.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/lm.compute_loss/softmax/softmax.get_logits/sub" source_file="/pax/praxis/praxis/layers/embedding_softmax.py" source_line=245}
  multiply.1763.clone.1 = f32[2,2048,32000]{2,1,0} multiply(multiply.1764.clone.1, subtract.334.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/lm.compute_loss/softmax/softmax.get_logits/mul" source_file="/pax/praxis/praxis/layers/embedding_softmax.py" source_line=245}
  multiply.1761.clone.1 = f32[2,2048,32000]{2,1,0} multiply(multiply.1763.clone.1, bitcast.7774.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/lm.compute_loss/softmax/softmax.get_logits/mul" source_file="/pax/praxis/praxis/layers/embedding_softmax.py" source_line=245}
  add.1080.clone.1 = f32[2,2048,32000]{2,1,0} add(multiply.1763.clone.1, multiply.1761.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/lm.compute_loss/softmax/softmax.get_logits/add_any" source_file="/pax/praxis/praxis/layers/embedding_softmax.py" source_line=245}
  constant.2178.clone.1 = f32[] constant(0.0333333351)
  broadcast.2720.clone.1 = f32[2,2048,32000]{2,1,0} broadcast(constant.2178.clone.1), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/lm.compute_loss/softmax/softmax.get_logits/div" source_file="/pax/praxis/praxis/layers/embedding_softmax.py" source_line=245}
  multiply.1760.clone.1 = f32[2,2048,32000]{2,1,0} multiply(add.1080.clone.1, broadcast.2720.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/lm.compute_loss/softmax/softmax.get_logits/div" source_file="/pax/praxis/praxis/layers/embedding_softmax.py" source_line=245}
  bitcast.7578 = f32[4096,32000]{1,0} bitcast(multiply.1760.clone.1)
  reduce.403 = f32[32000]{0} reduce(bitcast.7578, constant.2014), dimensions={0}, to_apply=region_15.791, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/lm.compute_loss/softmax/softmax.get_logits/logits_ffn/bias/reduce_sum[axes=(0, 1)]" source_file="/pax/praxis/praxis/layers/linears.py" source_line=143}
  ROOT tuple.135 = (f32[32000]{0}, f32[2,2048,32000]{2,1,0}) tuple(reduce.403, multiply.1760.clone.1)
} // fused_computation.436

fused_computation.437 {
  param_3.2110 = f32[4096,32768]{1,0} parameter(3)
  param_4.1848 = f32[8,32768]{1,0} parameter(4)
  constant.2873.clone.1 = s32[] constant(7)
  param_5.1641 = s32[] parameter(5)
  subtract.555.clone.1 = s32[] subtract(constant.2873.clone.1, param_5.1641), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  constant.2870.clone.1 = s32[] constant(0)
  compare.792.clone.1 = pred[] compare(subtract.555.clone.1, constant.2870.clone.1), direction=LT, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/lt" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  constant.2871.clone.1 = s32[] constant(15)
  subtract.554.clone.1 = s32[] subtract(constant.2871.clone.1, param_5.1641), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/add" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  select.1090.clone.1 = s32[] select(compare.792.clone.1, subtract.554.clone.1, subtract.555.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/select_n" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  dynamic-slice.267.clone.1 = f32[1,32768]{1,0} dynamic-slice(param_4.1848, select.1090.clone.1, constant.2870.clone.1), dynamic_slice_sizes={1,32768}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/dynamic_slice[slice_sizes=(1, 32768)]" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  bitcast.7870.clone.1 = f32[32768]{0} bitcast(dynamic-slice.267.clone.1)
  broadcast.3161.clone.1 = f32[4096,32768]{1,0} broadcast(bitcast.7870.clone.1), dimensions={1}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/ffn_layer1/bias/add" source_file="/pax/praxis/praxis/layers/linears.py" source_line=143}
  add.1240.clone.1 = f32[4096,32768]{1,0} add(param_3.2110, broadcast.3161.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/ffn_layer1/bias/add" source_file="/pax/praxis/praxis/layers/linears.py" source_line=143}
  bitcast.7601.clone.1 = f32[2,2048,32768]{2,1,0} bitcast(add.1240.clone.1)
  param_2.2137 = f32[4096,32768]{1,0} parameter(2)
  bitcast.7473.clone.1 = f32[2,2048,32768]{2,1,0} bitcast(param_2.2137)
  param_1.2348 = f32[2,2048]{1,0} parameter(1)
  broadcast.2589.clone.1 = f32[2,2048,32768]{2,1,0} broadcast(param_1.2348), dimensions={0,1}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/mul" source_file="/pax/praxis/praxis/layers/transformers.py" source_line=455}
  multiply.1653.clone.1 = f32[2,2048,32768]{2,1,0} multiply(bitcast.7473.clone.1, broadcast.2589.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/mul" source_file="/pax/praxis/praxis/layers/transformers.py" source_line=455}
  multiply.1652.clone.1 = f32[2,2048,32768]{2,1,0} multiply(bitcast.7601.clone.1, multiply.1653.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/ffn_layer1/activation/mul" source_file="/pax/praxis/praxis/layers/activations.py" source_line=157}
  constant.2073.clone.1 = f32[] constant(0.5)
  broadcast.2593.clone.1 = f32[2,2048,32768]{2,1,0} broadcast(constant.2073.clone.1), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/ff_layer/ffn_layer1/activation/mul" source_file="/pax/praxis/praxis/layers/activations.py" source_line=157}
  multiply.1651.clone.1 = f32[2,2048,32768]{2,1,0} multiply(multiply.1652.clone.1, broadcast.2593.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/ffn_layer1/activation/mul" source_file="/pax/praxis/praxis/layers/activations.py" source_line=157}
  constant.2074.clone.1 = f32[] constant(1)
  broadcast.2594.clone.1 = f32[2,2048,32768]{2,1,0} broadcast(constant.2074.clone.1), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/ff_layer/ffn_layer1/activation/add" source_file="/pax/praxis/praxis/layers/activations.py" source_line=157}
  param_0.1684 = f32[2,2048,32768]{2,1,0} parameter(0)
  subtract.320.clone.1 = f32[2,2048,32768]{2,1,0} subtract(broadcast.2594.clone.1, param_0.1684), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/ffn_layer1/activation/sub" source_file="/pax/praxis/praxis/layers/activations.py" source_line=157}
  multiply.1650.clone.1 = f32[2,2048,32768]{2,1,0} multiply(multiply.1651.clone.1, subtract.320.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/ffn_layer1/activation/mul" source_file="/pax/praxis/praxis/layers/activations.py" source_line=157}
  multiply.1649.clone.1 = f32[2,2048,32768]{2,1,0} multiply(multiply.1650.clone.1, param_0.1684), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/ffn_layer1/activation/mul" source_file="/pax/praxis/praxis/layers/activations.py" source_line=157}
  add.1030.clone.1 = f32[2,2048,32768]{2,1,0} add(multiply.1650.clone.1, multiply.1649.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/ffn_layer1/activation/add_any" source_file="/pax/praxis/praxis/layers/activations.py" source_line=157}
  constant.2072.clone.1 = f32[] constant(0.797884583)
  broadcast.2595.clone.1 = f32[2,2048,32768]{2,1,0} broadcast(constant.2072.clone.1), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/ff_layer/ffn_layer1/activation/mul" source_file="/pax/praxis/praxis/layers/activations.py" source_line=157}
  multiply.1648.clone.1 = f32[2,2048,32768]{2,1,0} multiply(add.1030.clone.1, broadcast.2595.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/ffn_layer1/activation/mul" source_file="/pax/praxis/praxis/layers/activations.py" source_line=157}
  constant.2070.clone.1 = f32[] constant(0.0356774069)
  broadcast.2592.clone.1 = f32[2,2048,32768]{2,1,0} broadcast(constant.2070.clone.1), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/ffn_layer1/activation/mul" source_file="/pax/praxis/praxis/layers/activations.py" source_line=157}
  multiply.1647.clone.1 = f32[2,2048,32768]{2,1,0} multiply(add.1030.clone.1, broadcast.2592.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/ffn_layer1/activation/mul" source_file="/pax/praxis/praxis/layers/activations.py" source_line=157}
  multiply.1801.clone.1 = f32[2,2048,32768]{2,1,0} multiply(bitcast.7601.clone.1, bitcast.7601.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/ffn_layer1/activation/mul" source_file="/pax/praxis/praxis/layers/activations.py" source_line=157}
  constant.2071.clone.1 = f32[] constant(3)
  broadcast.2591.clone.1 = f32[2,2048,32768]{2,1,0} broadcast(constant.2071.clone.1), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/ffn_layer1/activation/mul" source_file="/pax/praxis/praxis/layers/activations.py" source_line=157}
  multiply.1646.clone.1 = f32[2,2048,32768]{2,1,0} multiply(multiply.1801.clone.1, broadcast.2591.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/ffn_layer1/activation/mul" source_file="/pax/praxis/praxis/layers/activations.py" source_line=157}
  multiply.1645.clone.1 = f32[2,2048,32768]{2,1,0} multiply(multiply.1647.clone.1, multiply.1646.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/ffn_layer1/activation/mul" source_file="/pax/praxis/praxis/layers/activations.py" source_line=157}
  add.1029.clone.1 = f32[2,2048,32768]{2,1,0} add(multiply.1648.clone.1, multiply.1645.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/ffn_layer1/activation/add_any" source_file="/pax/praxis/praxis/layers/activations.py" source_line=157}
  add.1244.clone.1 = f32[2,2048,32768]{2,1,0} add(param_0.1684, broadcast.2594.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/ffn_layer1/activation/add" source_file="/pax/praxis/praxis/layers/activations.py" source_line=157}
  multiply.1957.clone.1 = f32[2,2048,32768]{2,1,0} multiply(add.1244.clone.1, broadcast.2593.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/ffn_layer1/activation/mul" source_file="/pax/praxis/praxis/layers/activations.py" source_line=157}
  multiply.1644.clone.1 = f32[2,2048,32768]{2,1,0} multiply(multiply.1653.clone.1, multiply.1957.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/ffn_layer1/activation/mul" source_file="/pax/praxis/praxis/layers/activations.py" source_line=157}
  add.1028.clone.1 = f32[2,2048,32768]{2,1,0} add(add.1029.clone.1, multiply.1644.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/ffn_layer1/activation/add_any" source_file="/pax/praxis/praxis/layers/activations.py" source_line=157}
  bitcast.7584 = f32[4096,32768]{1,0} bitcast(add.1028.clone.1)
  constant.2024 = f32[] constant(0)
  reduce.404 = f32[32768]{0} reduce(bitcast.7584, constant.2024), dimensions={0}, to_apply=region_15.791, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/ffn_layer1/bias/reduce_sum[axes=(0, 1)]" source_file="/pax/praxis/praxis/layers/linears.py" source_line=143}
  multiply.1613.clone.1 = f32[2,2048,32768]{2,1,0} multiply(bitcast.7601.clone.1, multiply.1957.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/ffn_layer1/activation/mul" source_file="/pax/praxis/praxis/layers/activations.py" source_line=157}
  multiply.1612.clone.1 = f32[2,2048,32768]{2,1,0} multiply(multiply.1613.clone.1, broadcast.2589.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/mul" source_file="/pax/praxis/praxis/layers/transformers.py" source_line=455}
  ROOT tuple.107 = (f32[32768]{0}, f32[2,2048,32768]{2,1,0}, f32[2,2048,32768]{2,1,0}) tuple(reduce.404, add.1028.clone.1, multiply.1612.clone.1)
} // fused_computation.437

fused_computation.438 {
  param_0.1685 = f32[2,2048,8192]{2,1,0} parameter(0)
  param_1.2350 = f32[2,2048]{1,0} parameter(1)
  broadcast.2601.clone.1 = f32[2,2048,8192]{2,1,0} broadcast(param_1.2350), dimensions={0,1}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/mul" source_file="/pax/praxis/praxis/layers/transformers.py" source_line=468}
  multiply.1658.clone.1 = f32[2,2048,8192]{2,1,0} multiply(param_0.1685, broadcast.2601.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/mul" source_file="/pax/praxis/praxis/layers/transformers.py" source_line=468}
  bitcast.7585 = f32[4096,8192]{1,0} bitcast(multiply.1658.clone.1)
  constant.2031 = f32[] constant(0)
  reduce.405 = f32[8192]{0} reduce(bitcast.7585, constant.2031), dimensions={0}, to_apply=region_15.791, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/ffn_layer2/bias/reduce_sum[axes=(0, 1)]" source_file="/pax/praxis/praxis/layers/linears.py" source_line=143}
  ROOT tuple.106 = (f32[8192]{0}, f32[2,2048,8192]{2,1,0}) tuple(reduce.405, multiply.1658.clone.1)
} // fused_computation.438

fused_computation.440 {
  param_0.995 = f32[4096,8192]{1,0} parameter(0)
  bitcast.7595 = f32[2,2048,128,64]{3,2,1,0} bitcast(param_0.995)
  transpose.280 = f32[2,128,2048,64]{3,2,1,0} transpose(bitcast.7595), dimensions={0,2,1,3}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/post/einsum/ABNH,DNH->ABD/dot_general[dimension_numbers=(((2,), (0,)), ((), ())) precision=None preferred_element_type=float32]" source_file="/pax/praxis/praxis/layers/base_ops.py" source_line=42}
  transpose.279.clone.1 = f32[2,128,64,2048]{3,2,1,0} transpose(bitcast.7595), dimensions={0,2,3,1}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/pv_einsum/BNTS,BSNH->BTNH/transpose[permutation=(0, 2, 3, 1)]" source_file="/pax/praxis/praxis/layers/base_ops.py" source_line=42}
  ROOT tuple.100 = (f32[2,128,2048,64]{3,2,1,0}, f32[2,128,64,2048]{3,2,1,0}) tuple(transpose.280, transpose.279.clone.1)
}

fused_computation.441 {
  param_0.1008 = f32[4096,8192]{1,0} parameter(0)
  bitcast.7607 = f32[2,2048,8192]{2,1,0} bitcast(param_0.1008)
  constant.2088 = f32[] constant(0)
  ROOT reduce.406 = f32[2,2048]{1,0} reduce(bitcast.7607, constant.2088), dimensions={2}, to_apply=region_15.791, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/reduce_sum[axes=(2,)]" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=370}
}

fused_computation.442 {
  param_0.1016 = f32[8,2,2048,8192]{3,2,1,0} parameter(0)
  constant.2756 = s32[] constant(7)
  param_1.1809 = s32[] parameter(1)
  subtract.500 = s32[] subtract(constant.2756, param_1.1809), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  constant.2104 = s32[] constant(0)
  compare.770 = pred[] compare(subtract.500, constant.2104), direction=LT, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/lt" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  constant.2754 = s32[] constant(15)
  subtract.499 = s32[] subtract(constant.2754, param_1.1809), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/add" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  select.1063 = s32[] select(compare.770, subtract.499, subtract.500), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/select_n" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  dynamic-slice.220 = f32[1,2,2048,8192]{3,2,1,0} dynamic-slice(param_0.1016, select.1063, constant.2104, constant.2104, constant.2104), dynamic_slice_sizes={1,2,2048,8192}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/dynamic_slice[slice_sizes=(1, 16, 2048, 8192)]" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  bitcast.7615 = f32[2,2048,8192]{2,1,0} bitcast(dynamic-slice.220)
  constant.2105 = f32[] constant(0)
  ROOT reduce.407 = f32[2,2048]{1,0} reduce(bitcast.7615, constant.2105), dimensions={2}, to_apply=region_15.791, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/layer_norm/reduce_sum[axes=(2,)]" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=370}
} // fused_computation.442

fused_computation.443 {
  param_3.2157 = f32[2,2048,8192]{2,1,0} parameter(3)
  param_4.1902 = f32[2,2048,8192]{2,1,0} parameter(4)
  add.1210.clone.1 = f32[2,2048,8192]{2,1,0} add(param_3.2157, param_4.1902), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/final_ln/add_any" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  param_1.2396 = f32[2,2048]{1,0} parameter(1)
  param_2.2189 = f32[2,2048]{1,0} parameter(2)
  add.1209.clone.1 = f32[2,2048]{1,0} add(param_1.2396, param_2.2189), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/final_ln/add_any" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  constant.2579.clone.1 = f32[] constant(0.000122070312)
  broadcast.3075.clone.1 = f32[2,2048]{1,0} broadcast(constant.2579.clone.1), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/layer_norm/div" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=370}
  multiply.1919.clone.1 = f32[2,2048]{1,0} multiply(add.1209.clone.1, broadcast.3075.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/final_ln/div" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=370}
  broadcast.3074.clone.1 = f32[2,2048,8192]{2,1,0} broadcast(multiply.1919.clone.1), dimensions={0,1}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/final_ln/broadcast_in_dim[shape=(16, 2048, 8192) broadcast_dimensions=(0, 1)]" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=370}
  add.1208.clone.1 = f32[2,2048,8192]{2,1,0} add(add.1210.clone.1, broadcast.3074.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/final_ln/add_any" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=370}
  param_0.1700 = f32[2,2048]{1,0} parameter(0)
  broadcast.2681.clone.1 = f32[2,2048,8192]{2,1,0} broadcast(param_0.1700), dimensions={0,1}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/mul" source_file="/pax/praxis/praxis/layers/transformers.py" source_line=468}
  multiply.1728.clone.1 = f32[2,2048,8192]{2,1,0} multiply(add.1208.clone.1, broadcast.2681.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/mul" source_file="/pax/praxis/praxis/layers/transformers.py" source_line=468}
  bitcast.7621 = f32[4096,8192]{1,0} bitcast(multiply.1728.clone.1)
  constant.2120 = f32[] constant(0)
  reduce.408 = f32[8192]{0} reduce(bitcast.7621, constant.2120), dimensions={0}, to_apply=region_15.791, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/ffn_layer2/bias/reduce_sum[axes=(0, 1)]" source_file="/pax/praxis/praxis/layers/linears.py" source_line=143}
  ROOT tuple.124 = (f32[8192]{0}, f32[2,2048,8192]{2,1,0}) tuple(reduce.408, multiply.1728.clone.1)
} // fused_computation.443

fused_computation.444 {
  param_3.2153 = f32[4096,32768]{1,0} parameter(3)
  param_4.1901 = f32[8,32768]{1,0} parameter(4)
  slice.126.clone.1 = f32[1,32768]{1,0} slice(param_4.1901), slice={[7:8], [0:32768]}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/dynamic_slice[slice_sizes=(1, 32768)]" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  bitcast.7804.clone.1 = f32[32768]{0} bitcast(slice.126.clone.1)
  broadcast.3059.clone.1 = f32[4096,32768]{1,0} broadcast(bitcast.7804.clone.1), dimensions={1}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/ffn_layer1/bias/add" source_file="/pax/praxis/praxis/layers/linears.py" source_line=143}
  add.1197.clone.1 = f32[4096,32768]{1,0} add(param_3.2153, broadcast.3059.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/ffn_layer1/bias/add" source_file="/pax/praxis/praxis/layers/linears.py" source_line=143}
  bitcast.7638.clone.1 = f32[2,2048,32768]{2,1,0} bitcast(add.1197.clone.1)
  param_2.2184 = f32[4096,32768]{1,0} parameter(2)
  bitcast.7501.clone.1 = f32[2,2048,32768]{2,1,0} bitcast(param_2.2184)
  param_1.2392 = f32[2,2048]{1,0} parameter(1)
  broadcast.2671.clone.1 = f32[2,2048,32768]{2,1,0} broadcast(param_1.2392), dimensions={0,1}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/mul" source_file="/pax/praxis/praxis/layers/transformers.py" source_line=455}
  multiply.1722.clone.1 = f32[2,2048,32768]{2,1,0} multiply(bitcast.7501.clone.1, broadcast.2671.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/mul" source_file="/pax/praxis/praxis/layers/transformers.py" source_line=455}
  multiply.1721.clone.1 = f32[2,2048,32768]{2,1,0} multiply(bitcast.7638.clone.1, multiply.1722.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/ffn_layer1/activation/mul" source_file="/pax/praxis/praxis/layers/activations.py" source_line=157}
  constant.2145.clone.1 = f32[] constant(0.5)
  broadcast.2672.clone.1 = f32[2,2048,32768]{2,1,0} broadcast(constant.2145.clone.1), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/ff_layer/ffn_layer1/activation/mul" source_file="/pax/praxis/praxis/layers/activations.py" source_line=157}
  multiply.1719.clone.1 = f32[2,2048,32768]{2,1,0} multiply(multiply.1721.clone.1, broadcast.2672.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/ffn_layer1/activation/mul" source_file="/pax/praxis/praxis/layers/activations.py" source_line=157}
  constant.2146.clone.1 = f32[] constant(1)
  broadcast.2673.clone.1 = f32[2,2048,32768]{2,1,0} broadcast(constant.2146.clone.1), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/ff_layer/ffn_layer1/activation/add" source_file="/pax/praxis/praxis/layers/activations.py" source_line=157}
  param_0.1698 = f32[2,2048,32768]{2,1,0} parameter(0)
  subtract.329.clone.1 = f32[2,2048,32768]{2,1,0} subtract(broadcast.2673.clone.1, param_0.1698), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/ffn_layer1/activation/sub" source_file="/pax/praxis/praxis/layers/activations.py" source_line=157}
  multiply.1718.clone.1 = f32[2,2048,32768]{2,1,0} multiply(multiply.1719.clone.1, subtract.329.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/ffn_layer1/activation/mul" source_file="/pax/praxis/praxis/layers/activations.py" source_line=157}
  multiply.1717.clone.1 = f32[2,2048,32768]{2,1,0} multiply(multiply.1718.clone.1, param_0.1698), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/ffn_layer1/activation/mul" source_file="/pax/praxis/praxis/layers/activations.py" source_line=157}
  add.1064.clone.1 = f32[2,2048,32768]{2,1,0} add(multiply.1718.clone.1, multiply.1717.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/ffn_layer1/activation/add_any" source_file="/pax/praxis/praxis/layers/activations.py" source_line=157}
  constant.2144.clone.1 = f32[] constant(0.797884583)
  broadcast.2674.clone.1 = f32[2,2048,32768]{2,1,0} broadcast(constant.2144.clone.1), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/ff_layer/ffn_layer1/activation/mul" source_file="/pax/praxis/praxis/layers/activations.py" source_line=157}
  multiply.1716.clone.1 = f32[2,2048,32768]{2,1,0} multiply(add.1064.clone.1, broadcast.2674.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/ffn_layer1/activation/mul" source_file="/pax/praxis/praxis/layers/activations.py" source_line=157}
  constant.2142.clone.1 = f32[] constant(0.0356774069)
  broadcast.2669.clone.1 = f32[2,2048,32768]{2,1,0} broadcast(constant.2142.clone.1), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/ffn_layer1/activation/mul" source_file="/pax/praxis/praxis/layers/activations.py" source_line=157}
  multiply.1715.clone.1 = f32[2,2048,32768]{2,1,0} multiply(add.1064.clone.1, broadcast.2669.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/ffn_layer1/activation/mul" source_file="/pax/praxis/praxis/layers/activations.py" source_line=157}
  multiply.1804.clone.1 = f32[2,2048,32768]{2,1,0} multiply(bitcast.7638.clone.1, bitcast.7638.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/ffn_layer1/activation/mul" source_file="/pax/praxis/praxis/layers/activations.py" source_line=157}
  constant.2143.clone.1 = f32[] constant(3)
  broadcast.2668.clone.1 = f32[2,2048,32768]{2,1,0} broadcast(constant.2143.clone.1), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/ffn_layer1/activation/mul" source_file="/pax/praxis/praxis/layers/activations.py" source_line=157}
  multiply.1713.clone.1 = f32[2,2048,32768]{2,1,0} multiply(multiply.1804.clone.1, broadcast.2668.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/ffn_layer1/activation/mul" source_file="/pax/praxis/praxis/layers/activations.py" source_line=157}
  multiply.1712.clone.1 = f32[2,2048,32768]{2,1,0} multiply(multiply.1715.clone.1, multiply.1713.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/ffn_layer1/activation/mul" source_file="/pax/praxis/praxis/layers/activations.py" source_line=157}
  add.1062.clone.1 = f32[2,2048,32768]{2,1,0} add(multiply.1716.clone.1, multiply.1712.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/ffn_layer1/activation/add_any" source_file="/pax/praxis/praxis/layers/activations.py" source_line=157}
  add.1202.clone.1 = f32[2,2048,32768]{2,1,0} add(param_0.1698, broadcast.2673.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/ffn_layer1/activation/add" source_file="/pax/praxis/praxis/layers/activations.py" source_line=157}
  multiply.1913.clone.1 = f32[2,2048,32768]{2,1,0} multiply(add.1202.clone.1, broadcast.2672.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/ffn_layer1/activation/mul" source_file="/pax/praxis/praxis/layers/activations.py" source_line=157}
  multiply.1711.clone.1 = f32[2,2048,32768]{2,1,0} multiply(multiply.1722.clone.1, multiply.1913.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/ffn_layer1/activation/mul" source_file="/pax/praxis/praxis/layers/activations.py" source_line=157}
  add.1061.clone.1 = f32[2,2048,32768]{2,1,0} add(add.1062.clone.1, multiply.1711.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/ffn_layer1/activation/add_any" source_file="/pax/praxis/praxis/layers/activations.py" source_line=157}
  bitcast.7622 = f32[4096,32768]{1,0} bitcast(add.1061.clone.1)
  constant.2122 = f32[] constant(0)
  reduce.409 = f32[32768]{0} reduce(bitcast.7622, constant.2122), dimensions={0}, to_apply=region_15.791, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/ffn_layer1/bias/reduce_sum[axes=(0, 1)]" source_file="/pax/praxis/praxis/layers/linears.py" source_line=143}
  multiply.1674.clone.1 = f32[2,2048,32768]{2,1,0} multiply(bitcast.7638.clone.1, multiply.1913.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/ffn_layer1/activation/mul" source_file="/pax/praxis/praxis/layers/activations.py" source_line=157}
  multiply.1673.clone.1 = f32[2,2048,32768]{2,1,0} multiply(multiply.1674.clone.1, broadcast.2671.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/mul" source_file="/pax/praxis/praxis/layers/transformers.py" source_line=455}
  ROOT tuple.127 = (f32[32768]{0}, f32[2,2048,32768]{2,1,0}, f32[2,2048,32768]{2,1,0}) tuple(reduce.409, add.1061.clone.1, multiply.1673.clone.1)
} // fused_computation.444

fused_computation.446 {
  param_0.1045 = f32[4096,8192]{1,0} parameter(0)
  bitcast.7632 = f32[2,2048,128,64]{3,2,1,0} bitcast(param_0.1045)
  transpose.282 = f32[2,128,64,2048]{3,2,1,0} transpose(bitcast.7632), dimensions={0,2,3,1}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/pv_einsum/BNTS,BSNH->BTNH/transpose[permutation=(0, 2, 3, 1)]" source_file="/pax/praxis/praxis/layers/base_ops.py" source_line=42}
  transpose.281.clone.1 = f32[2,128,2048,64]{3,2,1,0} transpose(bitcast.7632), dimensions={0,2,1,3}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/post/einsum/ABNH,DNH->ABD/dot_general[dimension_numbers=(((2,), (0,)), ((), ())) precision=None preferred_element_type=float32]" source_file="/pax/praxis/praxis/layers/base_ops.py" source_line=42}
  ROOT tuple.118 = (f32[2,128,64,2048]{3,2,1,0}, f32[2,128,2048,64]{3,2,1,0}) tuple(transpose.282, transpose.281.clone.1)
}

fused_computation.447 {
  param_0.1061 = f32[4096,8192]{1,0} parameter(0)
  bitcast.7648 = f32[2,2048,8192]{2,1,0} bitcast(param_0.1061)
  constant.2164 = f32[] constant(0)
  ROOT reduce.410 = f32[2,2048]{1,0} reduce(bitcast.7648, constant.2164), dimensions={2}, to_apply=region_15.791, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/reduce_sum[axes=(2,)]" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=370}
}

fused_computation.448 {
  param_0.1069 = f32[8,2,2048,8192]{3,2,1,0} parameter(0)
  slice.104 = f32[1,2,2048,8192]{3,2,1,0} slice(param_0.1069), slice={[7:8], [0:2], [0:2048], [0:8192]}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/dynamic_slice[slice_sizes=(1, 16, 2048, 8192)]" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  bitcast.7656 = f32[2,2048,8192]{2,1,0} bitcast(slice.104)
  constant.2175 = f32[] constant(0)
  ROOT reduce.411 = f32[2,2048]{1,0} reduce(bitcast.7656, constant.2175), dimensions={2}, to_apply=region_15.791, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/layer_norm/reduce_sum[axes=(2,)]" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=370}
}

fused_computation.449 {
  param_0.1086 = f32[4096,8192]{1,0} parameter(0)
  bitcast.7665 = f32[2,2048,8192]{2,1,0} bitcast(param_0.1086)
  constant.2209 = f32[] constant(0)
  ROOT reduce.412 = f32[2,2048]{1,0} reduce(bitcast.7665, constant.2209), dimensions={2}, to_apply=region_15.791, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/reduce_sum[axes=(2,)]" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=370}
}

fused_computation.450 {
  param_0.1091 = pred[1,2,2048,2048]{3,2,1,0} parameter(0)
  bitcast.7666 = pred[2,2048,2048]{2,1,0} bitcast(param_0.1091)
  ROOT broadcast.2795 = pred[2,128,2048,2048]{3,2,1,0} broadcast(bitcast.7666), dimensions={0,2,3}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/jit(_where)/broadcast_in_dim[shape=(16, 128, 2048, 2048) broadcast_dimensions=(0, 2, 3)]" source_file="/pax/praxis/praxis/py_utils.py" source_line=743}
}

fused_computation.460 {
  param_0.1217 = f32[24576,4096]{1,0} parameter(0)
  bitcast.7744 = f32[3,128,64,2,2048]{4,3,2,1,0} bitcast(param_0.1217)
  transpose.300 = f32[3,2,128,64,2048]{4,3,2,1,0} transpose(bitcast.7744), dimensions={0,3,1,2,4}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/self_attention/combined_qkv/einsum/ABD,KDNH->KABNH/dot_general[dimension_numbers=(((1,), (2,)), ((), ())) precision=None preferred_element_type=float32]" source_file="/pax/praxis/praxis/layers/base_ops.py" source_line=42}
  slice.108 = f32[1,2,128,64,2048]{4,3,2,1,0} slice(transpose.300), slice={[1:2], [0:2], [0:128], [0:64], [0:2048]}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/self_attention/combined_qkv/slice[start_indices=(1, 0, 0, 0, 0) limit_indices=(2, 16, 2048, 128, 64) strides=(1, 1, 1, 1, 1)]" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=882}
  slice.107.clone.1 = f32[1,2,128,64,2048]{4,3,2,1,0} slice(transpose.300), slice={[2:3], [0:2], [0:128], [0:64], [0:2048]}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/self_attention/combined_qkv/slice[start_indices=(2, 0, 0, 0, 0) limit_indices=(3, 16, 2048, 128, 64) strides=(1, 1, 1, 1, 1)]" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=882}
  slice.89.clone.1 = f32[1,2,128,64,2048]{4,3,2,1,0} slice(transpose.300), slice={[0:1], [0:2], [0:128], [0:64], [0:2048]}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/self_attention/combined_qkv/slice[start_indices=(0, 0, 0, 0, 0) limit_indices=(1, 16, 2048, 128, 64) strides=(1, 1, 1, 1, 1)]" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=882}
  param_2.2241 = f32[8,64]{1,0} parameter(2)
  param_3.2211 = s32[] parameter(3)
  constant.2213.clone.1 = s32[] constant(0)
  compare.713.clone.1 = pred[] compare(param_3.2211, constant.2213.clone.1), direction=LT, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/lt" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  constant.2470.clone.1 = s32[] constant(8)
  add.1173.clone.1 = s32[] add(param_3.2211, constant.2470.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/add" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  select.1007.clone.1 = s32[] select(compare.713.clone.1, add.1173.clone.1, param_3.2211), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/select_n" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  dynamic-slice.221.clone.1 = f32[1,64]{1,0} dynamic-slice(param_2.2241, select.1007.clone.1, constant.2213.clone.1), dynamic_slice_sizes={1,64}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/dynamic_slice[slice_sizes=(1, 64)]" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  compare.641.clone.1 = pred[1,64]{1,0} compare(dynamic-slice.221.clone.1, dynamic-slice.221.clone.1), direction=NE, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._scale_query/per_dim_scale/jit(softplus)/jit(logaddexp)/ne" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=403}
  constant.2214.clone.1 = f32[] constant(0)
  broadcast.2763.clone.1 = f32[1,64]{1,0} broadcast(constant.2214.clone.1), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._scale_query/per_dim_scale/jit(softplus)/jit(logaddexp)/max" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=403}
  maximum.73.clone.1 = f32[1,64]{1,0} maximum(dynamic-slice.221.clone.1, broadcast.2763.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._scale_query/per_dim_scale/jit(softplus)/jit(logaddexp)/max" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=403}
  param_1.2446 = f32[1,64]{1,0} parameter(1)
  add.1098.clone.1 = f32[1,64]{1,0} add(maximum.73.clone.1, param_1.2446), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._scale_query/per_dim_scale/jit(softplus)/jit(logaddexp)/add" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=403}
  select.940.clone.1 = f32[1,64]{1,0} select(compare.641.clone.1, dynamic-slice.221.clone.1, add.1098.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._scale_query/per_dim_scale/jit(softplus)/jit(logaddexp)/select_n" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=403}
  constant.2212.clone.1 = f32[] constant(0.180336878)
  broadcast.2762.clone.1 = f32[1,64]{1,0} broadcast(constant.2212.clone.1), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._scale_query/per_dim_scale/mul" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=403}
  multiply.1790.clone.1 = f32[1,64]{1,0} multiply(select.940.clone.1, broadcast.2762.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._scale_query/per_dim_scale/mul" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=403}
  bitcast.7525.clone.1 = f32[64]{0} bitcast(multiply.1790.clone.1)
  broadcast.2761.clone.1 = f32[1,2,128,64,2048]{4,3,2,1,0} broadcast(bitcast.7525.clone.1), dimensions={3}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._scale_query/per_dim_scale/mul" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=404}
  multiply.1789.clone.1 = f32[1,2,128,64,2048]{4,3,2,1,0} multiply(slice.89.clone.1, broadcast.2761.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._scale_query/per_dim_scale/mul" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=404}
  bitcast.7524.clone.1 = f32[2,128,64,2048]{3,2,1,0} bitcast(multiply.1789.clone.1)
  transpose.273.clone.1 = f32[2,128,2048,64]{3,2,1,0} transpose(bitcast.7524.clone.1), dimensions={0,1,3,2}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._scale_query/per_dim_scale/mul" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=404}
  ROOT tuple.142 = (f32[1,2,128,64,2048]{4,3,2,1,0}, f32[1,2,128,64,2048]{4,3,2,1,0}, f32[2,128,2048,64]{3,2,1,0}) tuple(slice.108, slice.107.clone.1, transpose.273.clone.1)
} // fused_computation.460

fused_computation.461 {
  param_4.1952 = f32[4096,8192]{1,0} parameter(4)
  bitcast.7764 = f32[2,2048,8192]{2,1,0} bitcast(param_4.1952)
  param_1.2467 = f32[4096,8192]{1,0} parameter(1)
  param_2.2255 = f32[8,8192]{1,0} parameter(2)
  param_3.2221 = s32[] parameter(3)
  constant.2500 = s32[] constant(0)
  compare.717 = pred[] compare(param_3.2221, constant.2500), direction=LT, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/lt" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  constant.2501 = s32[] constant(8)
  add.1185 = s32[] add(param_3.2221, constant.2501), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/add" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  select.1011 = s32[] select(compare.717, add.1185, param_3.2221), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/select_n" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  dynamic-slice.246 = f32[1,8192]{1,0} dynamic-slice(param_2.2255, select.1011, constant.2500), dynamic_slice_sizes={1,8192}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/dynamic_slice[slice_sizes=(1, 8192)]" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  bitcast.7763 = f32[8192]{0} bitcast(dynamic-slice.246)
  broadcast.2973 = f32[4096,8192]{1,0} broadcast(bitcast.7763), dimensions={1}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/ff_layer/ffn_layer2/bias/add" source_file="/pax/praxis/praxis/layers/linears.py" source_line=143}
  add.1184 = f32[4096,8192]{1,0} add(param_1.2467, broadcast.2973), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/ff_layer/ffn_layer2/bias/add" source_file="/pax/praxis/praxis/layers/linears.py" source_line=143}
  bitcast.7762 = f32[2,2048,8192]{2,1,0} bitcast(add.1184)
  param_0.1735 = f32[2,2048,1]{1,0,2} parameter(0)
  bitcast.7761 = f32[2,2048]{1,0} bitcast(param_0.1735)
  broadcast.2972 = f32[2,2048,8192]{2,1,0} broadcast(bitcast.7761), dimensions={0,1}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/ff_layer/mul" source_file="/pax/praxis/praxis/layers/transformers.py" source_line=468}
  multiply.1879 = f32[2,2048,8192]{2,1,0} multiply(bitcast.7762, broadcast.2972), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/ff_layer/mul" source_file="/pax/praxis/praxis/layers/transformers.py" source_line=468}
  add.1183 = f32[2,2048,8192]{2,1,0} add(bitcast.7764, multiply.1879), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/ff_layer/add" source_file="/pax/praxis/praxis/layers/transformers.py" source_line=489}
  constant.5013 = f32[] constant(0)
  ROOT reduce.414 = f32[2,2048]{1,0} reduce(add.1183, constant.5013), dimensions={2}, to_apply=region_15.791, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/final_ln/reduce_sum[axes=(2,)]" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=370}
} // fused_computation.461

fused_computation.462 {
  param_0.1734 = pred[1,2,2048,2048]{3,2,1,0} parameter(0)
  bitcast.7790 = pred[2,2048,2048]{2,1,0} bitcast(param_0.1734)
  broadcast.3029 = pred[2,128,2048,2048]{3,2,1,0} broadcast(bitcast.7790), dimensions={0,2,3}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/jit(_where)/broadcast_in_dim[shape=(16, 128, 2048, 2048) broadcast_dimensions=(0, 2, 3)]" source_file="/pax/praxis/praxis/py_utils.py" source_line=743}
  param_1.2466 = f32[256,2048,2048]{2,1,0} parameter(1)
  bitcast.7505.clone.1 = f32[2,128,2048,2048]{3,2,1,0} bitcast(param_1.2466)
  constant.2167.clone.1 = f32[] constant(0.02)
  broadcast.2697.clone.1 = f32[2,128,2048,2048]{3,2,1,0} broadcast(constant.2167.clone.1), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._cap_logits/div" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=1384}
  multiply.1736.clone.1 = f32[2,128,2048,2048]{3,2,1,0} multiply(bitcast.7505.clone.1, broadcast.2697.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._cap_logits/div" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=1384}
  tanh.40.clone.1 = f32[2,128,2048,2048]{3,2,1,0} tanh(multiply.1736.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._cap_logits/tanh" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=1384}
  constant.2547 = f32[] constant(50)
  broadcast.3028 = f32[2,128,2048,2048]{3,2,1,0} broadcast(constant.2547), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._cap_logits/div" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=1384}
  multiply.1901 = f32[2,128,2048,2048]{3,2,1,0} multiply(tanh.40.clone.1, broadcast.3028), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._cap_logits/mul" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=1384}
  constant.2546 = f32[] constant(-2.38197633e+38)
  broadcast.3027 = f32[2,128,2048,2048]{3,2,1,0} broadcast(constant.2546), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/jit(_where)/broadcast_in_dim[shape=(16, 128, 2048, 2048) broadcast_dimensions=()]" source_file="/pax/praxis/praxis/py_utils.py" source_line=743}
  select.1019 = f32[2,128,2048,2048]{3,2,1,0} select(broadcast.3029, multiply.1901, broadcast.3027), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/jit(_where)/select_n" source_file="/pax/praxis/praxis/py_utils.py" source_line=743}
  constant.5011 = f32[] constant(-inf)
  reduce.415 = f32[2,128,2048]{2,1,0} reduce(select.1019, constant.5011), dimensions={3}, to_apply=region_35.988, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/reduce_max[axes=(3,)]" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=1487}
  ROOT tuple.130 = (f32[2,128,2048]{2,1,0}, f32[2,128,2048,2048]{3,2,1,0}) tuple(reduce.415, tanh.40.clone.1)
} // fused_computation.462

fused_computation.464 {
  param_3.1023 = f32[256,2048,64]{2,1,0} parameter(3)
  bitcast.7832 = f32[2,128,2048,64]{3,2,1,0} bitcast(param_3.1023)
  transpose.306 = f32[2,128,64,2048]{3,2,1,0} transpose(bitcast.7832), dimensions={0,1,3,2}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._atten_logits/qk_einsum/BTNH,BSNH->BNTS/dot_general[dimension_numbers=(((2,), (1,)), ((0, 1), (0, 2))) precision=None preferred_element_type=float32]" source_file="/pax/praxis/praxis/layers/base_ops.py" source_line=42}
  bitcast.7831 = f32[1,2,128,64,2048]{4,3,2,1,0} bitcast(transpose.306)
  constant.2590 = f32[] constant(0)
  pad.77 = f32[3,2,128,64,2048]{4,3,2,1,0} pad(bitcast.7831, constant.2590), padding=1_1x0_0x0_0x0_0x0_0, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/combined_qkv/pad[padding_config=((1, 1, 0), (0, 0, 0), (0, 0, 0), (0, 0, 0), (0, 0, 0))]" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=882}
  param_1.1773 = f32[2,128,64,2048]{3,2,1,0} parameter(1)
  param_2.1353 = f32[64]{0} parameter(2)
  broadcast.3093 = f32[2,128,64,2048]{3,2,1,0} broadcast(param_2.1353), dimensions={2}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._scale_query/per_dim_scale/mul" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=404}
  multiply.1929 = f32[2,128,64,2048]{3,2,1,0} multiply(param_1.1773, broadcast.3093), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._scale_query/per_dim_scale/mul" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=404}
  bitcast.7830 = f32[1,2,128,64,2048]{4,3,2,1,0} bitcast(multiply.1929)
  pad.76 = f32[3,2,128,64,2048]{4,3,2,1,0} pad(bitcast.7830, constant.2590), padding=0_2x0_0x0_0x0_0x0_0, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/combined_qkv/pad[padding_config=((0, 2, 0), (0, 0, 0), (0, 0, 0), (0, 0, 0), (0, 0, 0))]" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=882}
  add.1228 = f32[3,2,128,64,2048]{4,3,2,1,0} add(pad.77, pad.76), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/combined_qkv/add_any" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=882}
  param_0.1295 = f32[256,64,2048]{2,1,0} parameter(0)
  bitcast.7829 = f32[1,2,128,64,2048]{4,3,2,1,0} bitcast(param_0.1295)
  pad.75 = f32[3,2,128,64,2048]{4,3,2,1,0} pad(bitcast.7829, constant.2590), padding=2_0x0_0x0_0x0_0x0_0, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/combined_qkv/pad[padding_config=((2, 0, 0), (0, 0, 0), (0, 0, 0), (0, 0, 0), (0, 0, 0))]" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=882}
  add.1227 = f32[3,2,128,64,2048]{4,3,2,1,0} add(add.1228, pad.75), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/combined_qkv/add_any" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=882}
  transpose.304 = f32[2,2048,3,128,64]{4,3,2,1,0} transpose(add.1227), dimensions={1,4,0,2,3}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/combined_qkv/einsum/ABD,KDNH->KABNH/transpose[permutation=(0, 3, 4, 1, 2)]" source_file="/pax/praxis/praxis/layers/base_ops.py" source_line=42}
  transpose.301.clone.1 = f32[3,128,64,2,2048]{4,3,2,1,0} transpose(add.1227), dimensions={0,2,3,1,4}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/combined_qkv/einsum/ABD,KDNH->KABNH/transpose[permutation=(0, 3, 4, 1, 2)]" source_file="/pax/praxis/praxis/layers/base_ops.py" source_line=42}
  ROOT tuple.117 = (f32[2,2048,3,128,64]{4,3,2,1,0}, f32[3,128,64,2,2048]{4,3,2,1,0}) tuple(transpose.304, transpose.301.clone.1)
} // fused_computation.464

fused_computation.466 {
  param_0.1307 = f32[8,1024,128,64]{3,2,1,0} parameter(0)
  constant.2645 = s32[] constant(7)
  param_1.2462 = s32[] parameter(1)
  subtract.438 = s32[] subtract(constant.2645, param_1.2462), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  constant.2644 = s32[] constant(0)
  compare.735 = pred[] compare(subtract.438, constant.2644), direction=LT, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/lt" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  constant.2643 = s32[] constant(15)
  subtract.437 = s32[] subtract(constant.2643, param_1.2462), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/add" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  select.1033 = s32[] select(compare.735, subtract.437, subtract.438), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/select_n" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  ROOT dynamic-slice.248 = f32[1,1024,128,64]{3,2,1,0} dynamic-slice(param_0.1307, select.1033, constant.2644, constant.2644, constant.2644), dynamic_slice_sizes={1,1024,128,64}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/dynamic_slice[slice_sizes=(1, 8192, 128, 64)]" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
} // fused_computation.466

fused_computation.467 {
  param_0.1311 = f32[8,1024,32768]{2,1,0} parameter(0)
  constant.2666 = s32[] constant(7)
  param_1.2461 = s32[] parameter(1)
  subtract.450 = s32[] subtract(constant.2666, param_1.2461), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  constant.2665 = s32[] constant(0)
  compare.741 = pred[] compare(subtract.450, constant.2665), direction=LT, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/lt" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  constant.2664 = s32[] constant(15)
  subtract.449 = s32[] subtract(constant.2664, param_1.2461), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/add" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  select.1039 = s32[] select(compare.741, subtract.449, subtract.450), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/select_n" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  ROOT dynamic-slice.249 = f32[1,1024,32768]{2,1,0} dynamic-slice(param_0.1311, select.1039, constant.2665, constant.2665), dynamic_slice_sizes={1,1024,32768}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/dynamic_slice[slice_sizes=(1, 8192, 32768)]" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
} // fused_computation.467

fused_computation.468 {
  param_0.1732 = pred[1,2,2048,2048]{3,2,1,0} parameter(0)
  bitcast.7856 = pred[2,2048,2048]{2,1,0} bitcast(param_0.1732)
  broadcast.3137 = pred[2,128,2048,2048]{3,2,1,0} broadcast(bitcast.7856), dimensions={0,2,3}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/jit(_where)/broadcast_in_dim[shape=(16, 128, 2048, 2048) broadcast_dimensions=(0, 2, 3)]" source_file="/pax/praxis/praxis/py_utils.py" source_line=743}
  param_1.2464 = f32[256,2048,2048]{2,1,0} parameter(1)
  bitcast.7477.clone.1 = f32[2,128,2048,2048]{3,2,1,0} bitcast(param_1.2464)
  constant.2092.clone.1 = f32[] constant(0.02)
  broadcast.2619.clone.1 = f32[2,128,2048,2048]{3,2,1,0} broadcast(constant.2092.clone.1), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._cap_logits/div" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=1384}
  multiply.1665.clone.1 = f32[2,128,2048,2048]{3,2,1,0} multiply(bitcast.7477.clone.1, broadcast.2619.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._cap_logits/div" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=1384}
  tanh.38.clone.1 = f32[2,128,2048,2048]{3,2,1,0} tanh(multiply.1665.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._cap_logits/tanh" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=1384}
  constant.2834 = f32[] constant(50)
  broadcast.3136 = f32[2,128,2048,2048]{3,2,1,0} broadcast(constant.2834), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._cap_logits/div" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=1384}
  multiply.1945 = f32[2,128,2048,2048]{3,2,1,0} multiply(tanh.38.clone.1, broadcast.3136), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._cap_logits/mul" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=1384}
  constant.2833 = f32[] constant(-2.38197633e+38)
  broadcast.3134 = f32[2,128,2048,2048]{3,2,1,0} broadcast(constant.2833), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/jit(_where)/broadcast_in_dim[shape=(16, 128, 2048, 2048) broadcast_dimensions=()]" source_file="/pax/praxis/praxis/py_utils.py" source_line=743}
  select.1084 = f32[2,128,2048,2048]{3,2,1,0} select(broadcast.3137, multiply.1945, broadcast.3134), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/jit(_where)/select_n" source_file="/pax/praxis/praxis/py_utils.py" source_line=743}
  constant.5006 = f32[] constant(-inf)
  reduce.416 = f32[2,128,2048]{2,1,0} reduce(select.1084, constant.5006), dimensions={3}, to_apply=region_35.988, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/reduce_max[axes=(3,)]" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=1487}
  ROOT tuple.110 = (f32[2,128,2048]{2,1,0}, f32[2,128,2048,2048]{3,2,1,0}) tuple(reduce.416, tanh.38.clone.1)
} // fused_computation.468

fused_computation.470 {
  param_3.1215 = f32[256,2048,64]{2,1,0} parameter(3)
  bitcast.7910 = f32[2,128,2048,64]{3,2,1,0} bitcast(param_3.1215)
  transpose.312 = f32[2,128,64,2048]{3,2,1,0} transpose(bitcast.7910), dimensions={0,1,3,2}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._atten_logits/qk_einsum/BTNH,BSNH->BNTS/dot_general[dimension_numbers=(((2,), (1,)), ((0, 1), (0, 2))) precision=None preferred_element_type=float32]" source_file="/pax/praxis/praxis/layers/base_ops.py" source_line=42}
  bitcast.7909 = f32[1,2,128,64,2048]{4,3,2,1,0} bitcast(transpose.312)
  constant.2959 = f32[] constant(0)
  pad.89 = f32[3,2,128,64,2048]{4,3,2,1,0} pad(bitcast.7909, constant.2959), padding=1_1x0_0x0_0x0_0x0_0, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/combined_qkv/pad[padding_config=((1, 1, 0), (0, 0, 0), (0, 0, 0), (0, 0, 0), (0, 0, 0))]" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=882}
  param_1.1889 = f32[2,128,64,2048]{3,2,1,0} parameter(1)
  param_2.1526 = f32[64]{0} parameter(2)
  broadcast.3201 = f32[2,128,64,2048]{3,2,1,0} broadcast(param_2.1526), dimensions={2}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._scale_query/per_dim_scale/mul" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=404}
  multiply.1973 = f32[2,128,64,2048]{3,2,1,0} multiply(param_1.1889, broadcast.3201), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._scale_query/per_dim_scale/mul" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=404}
  bitcast.7908 = f32[1,2,128,64,2048]{4,3,2,1,0} bitcast(multiply.1973)
  pad.88 = f32[3,2,128,64,2048]{4,3,2,1,0} pad(bitcast.7908, constant.2959), padding=0_2x0_0x0_0x0_0x0_0, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/combined_qkv/pad[padding_config=((0, 2, 0), (0, 0, 0), (0, 0, 0), (0, 0, 0), (0, 0, 0))]" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=882}
  add.1256 = f32[3,2,128,64,2048]{4,3,2,1,0} add(pad.89, pad.88), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/combined_qkv/add_any" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=882}
  param_0.1383 = f32[256,64,2048]{2,1,0} parameter(0)
  bitcast.7907 = f32[1,2,128,64,2048]{4,3,2,1,0} bitcast(param_0.1383)
  pad.87 = f32[3,2,128,64,2048]{4,3,2,1,0} pad(bitcast.7907, constant.2959), padding=2_0x0_0x0_0x0_0x0_0, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/combined_qkv/pad[padding_config=((2, 0, 0), (0, 0, 0), (0, 0, 0), (0, 0, 0), (0, 0, 0))]" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=882}
  add.1255 = f32[3,2,128,64,2048]{4,3,2,1,0} add(add.1256, pad.87), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/combined_qkv/add_any" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=882}
  transpose.310 = f32[2,2048,3,128,64]{4,3,2,1,0} transpose(add.1255), dimensions={1,4,0,2,3}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/combined_qkv/einsum/ABD,KDNH->KABNH/transpose[permutation=(0, 3, 4, 1, 2)]" source_file="/pax/praxis/praxis/layers/base_ops.py" source_line=42}
  transpose.307.clone.1 = f32[3,128,64,2,2048]{4,3,2,1,0} transpose(add.1255), dimensions={0,2,3,1,4}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/combined_qkv/einsum/ABD,KDNH->KABNH/transpose[permutation=(0, 3, 4, 1, 2)]" source_file="/pax/praxis/praxis/layers/base_ops.py" source_line=42}
  ROOT tuple.99 = (f32[2,2048,3,128,64]{4,3,2,1,0}, f32[3,128,64,2,2048]{4,3,2,1,0}) tuple(transpose.310, transpose.307.clone.1)
} // fused_computation.470

fused_computation.474 {
  param_2.2253 = pred[1,2,2048,2048]{3,2,1,0} parameter(2)
  bitcast.7854.clone.1 = pred[2,2048,2048]{2,1,0} bitcast(param_2.2253)
  broadcast.3129.clone.1 = pred[2,128,2048,2048]{3,2,1,0} broadcast(bitcast.7854.clone.1), dimensions={0,2,3}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/jit(_where)/broadcast_in_dim[shape=(16, 128, 2048, 2048) broadcast_dimensions=(0, 2, 3)]" source_file="/pax/praxis/praxis/py_utils.py" source_line=743}
  param_1.2463 = f32[2,128,2048,2048]{3,2,1,0} parameter(1)
  constant.2829.clone.1 = f32[] constant(50)
  broadcast.3128.clone.1 = f32[2,128,2048,2048]{3,2,1,0} broadcast(constant.2829.clone.1), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._cap_logits/div" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=1384}
  multiply.1943.clone.1 = f32[2,128,2048,2048]{3,2,1,0} multiply(param_1.2463, broadcast.3128.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._cap_logits/mul" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=1384}
  constant.2828.clone.1 = f32[] constant(-2.38197633e+38)
  broadcast.3126.clone.1 = f32[2,128,2048,2048]{3,2,1,0} broadcast(constant.2828.clone.1), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/jit(_where)/broadcast_in_dim[shape=(16, 128, 2048, 2048) broadcast_dimensions=()]" source_file="/pax/praxis/praxis/py_utils.py" source_line=743}
  select.1082.clone.1 = f32[2,128,2048,2048]{3,2,1,0} select(broadcast.3129.clone.1, multiply.1943.clone.1, broadcast.3126.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/jit(_where)/select_n" source_file="/pax/praxis/praxis/py_utils.py" source_line=743}
  param_0.1731 = f32[2,128,2048]{2,1,0} parameter(0)
  broadcast.2615.clone.1 = f32[2,128,2048,2048]{3,2,1,0} broadcast(param_0.1731), dimensions={0,1,2}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/sub" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=1487}
  subtract.323.clone.1 = f32[2,128,2048,2048]{3,2,1,0} subtract(select.1082.clone.1, broadcast.2615.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/sub" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=1487}
  exponential.61.clone.1 = f32[2,128,2048,2048]{3,2,1,0} exponential(subtract.323.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/exp" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=1487}
  constant.5005 = f32[] constant(0)
  reduce.424 = f32[2,128,2048]{2,1,0} reduce(exponential.61.clone.1, constant.5005), dimensions={3}, to_apply=region_15.791, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/reduce_sum[axes=(3,)]" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=1487}
  ROOT tuple.109 = (f32[2,128,2048]{2,1,0}, f32[2,128,2048,2048]{3,2,1,0}) tuple(reduce.424, exponential.61.clone.1)
} // fused_computation.474

fused_computation.475 {
  param_2.2254 = pred[1,2,2048,2048]{3,2,1,0} parameter(2)
  bitcast.7788.clone.1 = pred[2,2048,2048]{2,1,0} bitcast(param_2.2254)
  broadcast.3023.clone.1 = pred[2,128,2048,2048]{3,2,1,0} broadcast(bitcast.7788.clone.1), dimensions={0,2,3}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/jit(_where)/broadcast_in_dim[shape=(16, 128, 2048, 2048) broadcast_dimensions=(0, 2, 3)]" source_file="/pax/praxis/praxis/py_utils.py" source_line=743}
  param_1.2465 = f32[2,128,2048,2048]{3,2,1,0} parameter(1)
  constant.2542.clone.1 = f32[] constant(50)
  broadcast.3022.clone.1 = f32[2,128,2048,2048]{3,2,1,0} broadcast(constant.2542.clone.1), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._cap_logits/div" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=1384}
  multiply.1899.clone.1 = f32[2,128,2048,2048]{3,2,1,0} multiply(param_1.2465, broadcast.3022.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._cap_logits/mul" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=1384}
  constant.2541.clone.1 = f32[] constant(-2.38197633e+38)
  broadcast.3021.clone.1 = f32[2,128,2048,2048]{3,2,1,0} broadcast(constant.2541.clone.1), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/jit(_where)/broadcast_in_dim[shape=(16, 128, 2048, 2048) broadcast_dimensions=()]" source_file="/pax/praxis/praxis/py_utils.py" source_line=743}
  select.1017.clone.1 = f32[2,128,2048,2048]{3,2,1,0} select(broadcast.3023.clone.1, multiply.1899.clone.1, broadcast.3021.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/jit(_where)/select_n" source_file="/pax/praxis/praxis/py_utils.py" source_line=743}
  param_0.1733 = f32[2,128,2048]{2,1,0} parameter(0)
  broadcast.2692.clone.1 = f32[2,128,2048,2048]{3,2,1,0} broadcast(param_0.1733), dimensions={0,1,2}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/sub" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=1487}
  subtract.331.clone.1 = f32[2,128,2048,2048]{3,2,1,0} subtract(select.1017.clone.1, broadcast.2692.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/sub" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=1487}
  exponential.64.clone.1 = f32[2,128,2048,2048]{3,2,1,0} exponential(subtract.331.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/exp" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=1487}
  constant.5010 = f32[] constant(0)
  reduce.427 = f32[2,128,2048]{2,1,0} reduce(exponential.64.clone.1, constant.5010), dimensions={3}, to_apply=region_15.791, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/reduce_sum[axes=(3,)]" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=1487}
  ROOT tuple.129 = (f32[2,128,2048]{2,1,0}, f32[2,128,2048,2048]{3,2,1,0}) tuple(reduce.427, exponential.64.clone.1)
} // fused_computation.475

fused_computation.476 {
  param_0.1736 = f32[2,128,2048,2048]{3,2,1,0} parameter(0)
  param_1.2468 = f32[2,128,2048]{2,1,0} parameter(1)
  broadcast.2758.clone.1 = f32[2,128,2048,2048]{3,2,1,0} broadcast(param_1.2468), dimensions={0,1,2}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/sub" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=1487}
  subtract.338.clone.1 = f32[2,128,2048,2048]{3,2,1,0} subtract(param_0.1736, broadcast.2758.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/sub" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=1487}
  exponential.66.clone.1 = f32[2,128,2048,2048]{3,2,1,0} exponential(subtract.338.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/exp" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=1487}
  constant.5014 = f32[] constant(0)
  reduce.429 = f32[2,128,2048]{2,1,0} reduce(exponential.66.clone.1, constant.5014), dimensions={3}, to_apply=region_15.791, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/reduce_sum[axes=(3,)]" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=1487}
  ROOT tuple.139 = (f32[2,128,2048]{2,1,0}, f32[2,128,2048,2048]{3,2,1,0}) tuple(reduce.429, exponential.66.clone.1)
} // fused_computation.476

fused_computation.477 {
  param_0.1737 = pred[2,128,2048,2048]{3,2,1,0} parameter(0)
  param_2.2256 = f32[256,2048,2048]{2,1,0} parameter(2)
  bitcast.7523.clone.1 = f32[2,128,2048,2048]{3,2,1,0} bitcast(param_2.2256)
  constant.2210.clone.1 = f32[] constant(0.02)
  broadcast.2760.clone.1 = f32[2,128,2048,2048]{3,2,1,0} broadcast(constant.2210.clone.1), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._cap_logits/div" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=1384}
  multiply.1788.clone.1 = f32[2,128,2048,2048]{3,2,1,0} multiply(bitcast.7523.clone.1, broadcast.2760.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._cap_logits/div" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=1384}
  tanh.43.clone.1 = f32[2,128,2048,2048]{3,2,1,0} tanh(multiply.1788.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._cap_logits/tanh" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=1384}
  constant.2211.clone.1 = f32[] constant(50)
  broadcast.2759.clone.1 = f32[2,128,2048,2048]{3,2,1,0} broadcast(constant.2211.clone.1), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._cap_logits/div" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=1384}
  multiply.1787.clone.1 = f32[2,128,2048,2048]{3,2,1,0} multiply(tanh.43.clone.1, broadcast.2759.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._cap_logits/mul" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=1384}
  param_1.2469 = f32[2,128,2048,2048]{3,2,1,0} parameter(1)
  select.939.clone.1 = f32[2,128,2048,2048]{3,2,1,0} select(param_0.1737, multiply.1787.clone.1, param_1.2469), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/jit(_where)/select_n" source_file="/pax/praxis/praxis/py_utils.py" source_line=743}
  constant.5015 = f32[] constant(-inf)
  reduce.430 = f32[2,128,2048]{2,1,0} reduce(select.939.clone.1, constant.5015), dimensions={3}, to_apply=region_35.988, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/reduce_max[axes=(3,)]" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=1487}
  ROOT tuple.140 = (f32[2,128,2048]{2,1,0}, f32[2,128,2048,2048]{3,2,1,0}) tuple(reduce.430, select.939.clone.1)
} // fused_computation.477

horizontally_fused_computation {
  param_0_1 = f32[] parameter(1)
  is-finite.56 = pred[] is-finite(param_0_1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(isfinite)/is_finite" source_file="/pax/paxml/paxml/learners.py" source_line=256}
  param_0_0 = s32[] parameter(0)
  constant.5049 = s32[] constant(1)
  add.1530 = s32[] add(param_0_0, constant.5049), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/add" source_file="/pax/praxis/praxis/optimizers.py" source_line=599}
  select.2195 = s32[] select(is-finite.56, add.1530, param_0_0), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(_where)/select_n" source_file="/pax/paxml/paxml/learners.py" source_line=349}
  param_1_0 = s32[] parameter(2)
  add.1531 = s32[] add(param_1_0, constant.5049), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/add" source_file="/pax/praxis/praxis/optimizers.py" source_line=697}
  select.2196 = s32[] select(is-finite.56, add.1531, param_1_0), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(_where)/select_n" source_file="/pax/paxml/paxml/learners.py" source_line=349}
  param_3.2230 = s32[] parameter(3)
  add.1532 = s32[] add(param_3.2230, constant.5049), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/add" source_file="/pax/praxis/praxis/optimizers.py" source_line=547}
  select.2197 = s32[] select(is-finite.56, add.1532, param_3.2230), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(_where)/select_n" source_file="/pax/paxml/paxml/learners.py" source_line=349}
  param_4.1965 = s32[] parameter(4)
  add.1533 = s32[] add(param_4.1965, constant.5049), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/add" source_file="/pax/praxis/praxis/optimizers.py" source_line=547}
  select.2198 = s32[] select(is-finite.56, add.1533, param_4.1965), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(_where)/select_n" source_file="/pax/paxml/paxml/learners.py" source_line=349}
  ROOT tuple.146 = (s32[], s32[], s32[], s32[]) tuple(select.2195, select.2196, select.2197, select.2198)
} // horizontally_fused_computation

horizontally_fused_computation.1 {
  param_0_1.1 = f32[] parameter(1)
  is-finite.60 = pred[] is-finite(param_0_1.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(isfinite)/is_finite" source_file="/pax/paxml/paxml/learners.py" source_line=256}
  broadcast.4872 = pred[8]{0} broadcast(is-finite.60), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(_where)/broadcast_in_dim[shape=(8,) broadcast_dimensions=()]" source_file="/pax/paxml/paxml/learners.py" source_line=349}
  param_0_0.1 = s32[8]{0} parameter(0)
  constant.5053 = s32[] constant(1)
  broadcast.4873 = s32[8]{0} broadcast(constant.5053), dimensions={}
  add.1534 = s32[8]{0} add(param_0_0.1, broadcast.4873), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/add" source_file="/pax/praxis/praxis/optimizers.py" source_line=599}
  select.2199 = s32[8]{0} select(broadcast.4872, add.1534, param_0_0.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(_where)/select_n" source_file="/pax/paxml/paxml/learners.py" source_line=349}
  param_1_0.1 = s32[8]{0} parameter(2)
  add.1535 = s32[8]{0} add(param_1_0.1, broadcast.4873), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/add" source_file="/pax/praxis/praxis/optimizers.py" source_line=547}
  select.2200 = s32[8]{0} select(broadcast.4872, add.1535, param_1_0.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(_where)/select_n" source_file="/pax/paxml/paxml/learners.py" source_line=349}
  param_3.2231 = s32[8]{0} parameter(3)
  add.1536 = s32[8]{0} add(param_3.2231, broadcast.4873), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/add" source_file="/pax/praxis/praxis/optimizers.py" source_line=547}
  select.2201 = s32[8]{0} select(broadcast.4872, add.1536, param_3.2231), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(_where)/select_n" source_file="/pax/paxml/paxml/learners.py" source_line=349}
  ROOT tuple.147 = (s32[8]{0}, s32[8]{0}, s32[8]{0}) tuple(select.2199, select.2200, select.2201)
} // horizontally_fused_computation.1

horizontally_fused_computation.2 {
  param_0_0.2 = f32[] parameter(0)
  param_0_1.2 = f32[] parameter(1)
  constant.5056 = f32[] constant(1)
  maximum.108 = f32[] maximum(param_0_1.2, constant.5056), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_loss/max" source_file="/pax/praxis/praxis/layers/models.py" source_line=129}
  divide.232 = f32[] divide(param_0_0.2, maximum.108), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_loss/div" source_file="/pax/praxis/praxis/layers/models.py" source_line=129}
  param_1_0.2 = f32[] parameter(2)
  constant.5057 = f32[] constant(1e-06)
  add.1537 = f32[] add(param_0_1.2, constant.5057), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/lm.compute_loss/softmax/add" source_file="/pax/praxis/praxis/layers/embedding_softmax.py" source_line=349}
  divide.233 = f32[] divide(param_1_0.2, add.1537), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/lm.compute_loss/softmax/div" source_file="/pax/praxis/praxis/layers/embedding_softmax.py" source_line=349}
  ROOT tuple.148 = (f32[], f32[]) tuple(divide.232, divide.233)
} // horizontally_fused_computation.2

horizontally_fused_computation.3 {
  param_0_0.3 = f32[8192]{0} parameter(0)
  param_0_3 = f32[] parameter(3)
  is-finite.63 = pred[] is-finite(param_0_3), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(isfinite)/is_finite" source_file="/pax/paxml/paxml/learners.py" source_line=256}
  broadcast.4878 = pred[8192]{0} broadcast(is-finite.63), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(_where)/broadcast_in_dim[shape=(8192,) broadcast_dimensions=()]" source_file="/pax/paxml/paxml/learners.py" source_line=340}
  param_0_2 = f32[] parameter(2)
  broadcast.4879 = f32[8192]{0} broadcast(param_0_2), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=695}
  constant.5058 = f32[] constant(1)
  param_0_5 = f32[] parameter(5)
  subtract.1133 = f32[] subtract(constant.5058, param_0_5), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/sub" source_file="/pax/praxis/praxis/optimizers.py" source_line=339}
  broadcast.4880 = f32[8192]{0} broadcast(subtract.1133), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=339}
  param_0_6 = f32[8192]{0} parameter(6)
  param_0_7 = f32[] parameter(7)
  broadcast.4881 = f32[8192]{0} broadcast(param_0_7), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/paxml/paxml/learners.py" source_line=266}
  multiply.2792 = f32[8192]{0} multiply(param_0_6, broadcast.4881), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/paxml/paxml/learners.py" source_line=266}
  compare.1890 = pred[8192]{0} compare(multiply.2792, multiply.2792), direction=NE, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(nan_to_num)/jit(isnan)/ne" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  constant.5059 = f32[] constant(nan)
  broadcast.4882 = f32[8192]{0} broadcast(constant.5059), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(nan_to_num)/jit(_where)/broadcast_in_dim[shape=(8192,) broadcast_dimensions=()]" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  select.2202 = f32[8192]{0} select(compare.1890, broadcast.4882, multiply.2792), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(nan_to_num)/jit(_where)/select_n" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  constant.5060 = f32[] constant(inf)
  broadcast.4883 = f32[8192]{0} broadcast(constant.5060), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(nan_to_num)/eq" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  compare.1891 = pred[8192]{0} compare(select.2202, broadcast.4883), direction=EQ, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(nan_to_num)/eq" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  select.2203 = f32[8192]{0} select(compare.1891, broadcast.4882, select.2202), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(nan_to_num)/jit(_where)/select_n" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  constant.5061 = f32[] constant(-inf)
  broadcast.4884 = f32[8192]{0} broadcast(constant.5061), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(nan_to_num)/eq" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  compare.1892 = pred[8192]{0} compare(select.2203, broadcast.4884), direction=EQ, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(nan_to_num)/eq" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  select.2204 = f32[8192]{0} select(compare.1892, broadcast.4882, select.2203), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(nan_to_num)/jit(_where)/select_n" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  multiply.2793 = f32[8192]{0} multiply(broadcast.4880, select.2204), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=339}
  broadcast.4885 = f32[8192]{0} broadcast(param_0_5), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=339}
  param_0_4 = f32[8192]{0} parameter(4)
  multiply.2794 = f32[8192]{0} multiply(broadcast.4885, param_0_4), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=339}
  add.1538 = f32[8192]{0} add(multiply.2793, multiply.2794), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/add" source_file="/pax/praxis/praxis/optimizers.py" source_line=339}
  param_0_9 = f32[] parameter(9)
  subtract.1134 = f32[] subtract(constant.5058, param_0_9), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/sub" source_file="/pax/praxis/praxis/optimizers.py" source_line=340}
  broadcast.4886 = f32[8192]{0} broadcast(subtract.1134), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=340}
  multiply.2795 = f32[8192]{0} multiply(select.2204, select.2204), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=340}
  multiply.2796 = f32[8192]{0} multiply(broadcast.4886, multiply.2795), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=340}
  broadcast.4887 = f32[8192]{0} broadcast(param_0_9), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=340}
  param_0_8 = f32[8192]{0} parameter(8)
  multiply.2797 = f32[8192]{0} multiply(broadcast.4887, param_0_8), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=340}
  add.1539 = f32[8192]{0} add(multiply.2796, multiply.2797), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/add" source_file="/pax/praxis/praxis/optimizers.py" source_line=340}
  sqrt.133 = f32[8192]{0} sqrt(add.1539), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/sqrt" source_file="/pax/praxis/praxis/optimizers.py" source_line=684}
  constant.5062 = f32[] constant(1e-06)
  broadcast.4888 = f32[8192]{0} broadcast(constant.5062), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/add" source_file="/pax/praxis/praxis/optimizers.py" source_line=684}
  add.1540 = f32[8192]{0} add(sqrt.133, broadcast.4888), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/add" source_file="/pax/praxis/praxis/optimizers.py" source_line=684}
  param_0_1.3 = f32[] parameter(1)
  constant.5063 = f32[] constant(0.000122070312)
  multiply.2798 = f32[] multiply(param_0_1.3, constant.5063), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/div" source_file="/pax/praxis/praxis/optimizers.py" source_line=2066}
  sqrt.134 = f32[] sqrt(multiply.2798), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/sqrt" source_file="/pax/praxis/praxis/optimizers.py" source_line=2080}
  compare.1893 = pred[] compare(sqrt.134, sqrt.134), direction=NE, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(nan_to_num)/jit(isnan)/ne" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  select.2205 = f32[] select(compare.1893, constant.5059, sqrt.134), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(nan_to_num)/jit(_where)/select_n" source_file="/usr/local/lib/python3.10/dist-packages/optax/_src/schedule.py" source_line=399}
  compare.1894 = pred[] compare(select.2205, constant.5060), direction=EQ, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(nan_to_num)/eq" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  select.2206 = f32[] select(compare.1894, constant.5059, select.2205), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(nan_to_num)/jit(_where)/select_n" source_file="/usr/local/lib/python3.10/dist-packages/optax/_src/schedule.py" source_line=399}
  compare.1895 = pred[] compare(select.2206, constant.5061), direction=EQ, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(nan_to_num)/eq" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  select.2207 = f32[] select(compare.1895, constant.5059, select.2206), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(nan_to_num)/jit(_where)/select_n" source_file="/usr/local/lib/python3.10/dist-packages/optax/_src/schedule.py" source_line=399}
  maximum.109 = f32[] maximum(select.2207, constant.5058), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/max" source_file="/pax/praxis/praxis/optimizers.py" source_line=346}
  broadcast.4889 = f32[8192]{0} broadcast(maximum.109), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/div" source_file="/pax/praxis/praxis/optimizers.py" source_line=347}
  multiply.2799 = f32[8192]{0} multiply(add.1540, broadcast.4889)
  divide.234 = f32[8192]{0} divide(add.1538, multiply.2799), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/div" source_file="/pax/praxis/praxis/optimizers.py" source_line=347}
  constant.5064 = f32[] constant(0.001)
  broadcast.4890 = f32[8192]{0} broadcast(constant.5064), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=691}
  multiply.2800 = f32[8192]{0} multiply(param_0_0.3, broadcast.4890), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=691}
  add.1541 = f32[8192]{0} add(divide.234, multiply.2800), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/add" source_file="/pax/praxis/praxis/optimizers.py" source_line=691}
  multiply.2801 = f32[8192]{0} multiply(broadcast.4879, add.1541), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=695}
  constant.5065 = f32[] constant(0)
  broadcast.4891 = f32[8192]{0} broadcast(constant.5065), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/broadcast_in_dim[shape=(8192,) broadcast_dimensions=()]" source_file="/pax/paxml/paxml/learners.py" source_line=340}
  select.2208 = f32[8192]{0} select(broadcast.4878, multiply.2801, broadcast.4891), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(_where)/select_n" source_file="/pax/paxml/paxml/learners.py" source_line=340}
  add.1542 = f32[8192]{0} add(param_0_0.3, select.2208), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/add" source_file="/pax/paxml/paxml/learners.py" source_line=408}
  select.798.clone.2 = f32[8192]{0} select(broadcast.4878, add.1539, param_0_8), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(_where)/select_n" source_file="/pax/paxml/paxml/learners.py" source_line=340}
  select.802.clone.2 = f32[8192]{0} select(broadcast.4878, add.1538, param_0_4), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(_where)/select_n" source_file="/pax/paxml/paxml/learners.py" source_line=340}
  param_1_0.3 = f32[8192]{0} parameter(10)
  param_13.330 = f32[8192]{0} parameter(13)
  multiply.2802 = f32[8192]{0} multiply(param_13.330, broadcast.4881), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/paxml/paxml/learners.py" source_line=266}
  compare.1896 = pred[8192]{0} compare(multiply.2802, multiply.2802), direction=NE, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(nan_to_num)/jit(isnan)/ne" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  select.2209 = f32[8192]{0} select(compare.1896, broadcast.4882, multiply.2802), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(nan_to_num)/jit(_where)/select_n" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  compare.1897 = pred[8192]{0} compare(select.2209, broadcast.4883), direction=EQ, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(nan_to_num)/eq" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  select.2210 = f32[8192]{0} select(compare.1897, broadcast.4882, select.2209), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(nan_to_num)/jit(_where)/select_n" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  compare.1898 = pred[8192]{0} compare(select.2210, broadcast.4884), direction=EQ, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(nan_to_num)/eq" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  select.2211 = f32[8192]{0} select(compare.1898, broadcast.4882, select.2210), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(nan_to_num)/jit(_where)/select_n" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  multiply.2803 = f32[8192]{0} multiply(broadcast.4880, select.2211), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=339}
  param_12.535 = f32[8192]{0} parameter(12)
  multiply.2805 = f32[8192]{0} multiply(broadcast.4885, param_12.535), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=339}
  add.1543 = f32[8192]{0} add(multiply.2803, multiply.2805), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/add" source_file="/pax/praxis/praxis/optimizers.py" source_line=339}
  multiply.2806 = f32[8192]{0} multiply(select.2211, select.2211), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=340}
  multiply.2807 = f32[8192]{0} multiply(broadcast.4886, multiply.2806), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=340}
  param_14.285 = f32[8192]{0} parameter(14)
  multiply.2808 = f32[8192]{0} multiply(broadcast.4887, param_14.285), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=340}
  add.1544 = f32[8192]{0} add(multiply.2807, multiply.2808), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/add" source_file="/pax/praxis/praxis/optimizers.py" source_line=340}
  sqrt.135 = f32[8192]{0} sqrt(add.1544), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/sqrt" source_file="/pax/praxis/praxis/optimizers.py" source_line=684}
  add.1545 = f32[8192]{0} add(sqrt.135, broadcast.4888), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/add" source_file="/pax/praxis/praxis/optimizers.py" source_line=684}
  param_1_1.3 = f32[] parameter(11)
  multiply.2809 = f32[] multiply(param_1_1.3, constant.5063), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/div" source_file="/pax/praxis/praxis/optimizers.py" source_line=2066}
  sqrt.136 = f32[] sqrt(multiply.2809), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/sqrt" source_file="/pax/praxis/praxis/optimizers.py" source_line=2080}
  compare.1899 = pred[] compare(sqrt.136, sqrt.136), direction=NE, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(nan_to_num)/jit(isnan)/ne" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  select.2212 = f32[] select(compare.1899, constant.5059, sqrt.136), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(nan_to_num)/jit(_where)/select_n" source_file="/usr/local/lib/python3.10/dist-packages/optax/_src/schedule.py" source_line=399}
  compare.1900 = pred[] compare(select.2212, constant.5060), direction=EQ, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(nan_to_num)/eq" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  select.2213 = f32[] select(compare.1900, constant.5059, select.2212), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(nan_to_num)/jit(_where)/select_n" source_file="/usr/local/lib/python3.10/dist-packages/optax/_src/schedule.py" source_line=399}
  compare.1901 = pred[] compare(select.2213, constant.5061), direction=EQ, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(nan_to_num)/eq" source_file="/pax/praxis/praxis/optimizers.py" source_line=308}
  select.2214 = f32[] select(compare.1901, constant.5059, select.2213), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(nan_to_num)/jit(_where)/select_n" source_file="/usr/local/lib/python3.10/dist-packages/optax/_src/schedule.py" source_line=399}
  maximum.110 = f32[] maximum(select.2214, constant.5058), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/max" source_file="/pax/praxis/praxis/optimizers.py" source_line=346}
  broadcast.4903 = f32[8192]{0} broadcast(maximum.110), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/div" source_file="/pax/praxis/praxis/optimizers.py" source_line=347}
  multiply.2810 = f32[8192]{0} multiply(add.1545, broadcast.4903)
  divide.235 = f32[8192]{0} divide(add.1543, multiply.2810), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/div" source_file="/pax/praxis/praxis/optimizers.py" source_line=347}
  multiply.2811 = f32[8192]{0} multiply(param_1_0.3, broadcast.4890), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=691}
  add.1546 = f32[8192]{0} add(divide.235, multiply.2811), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/add" source_file="/pax/praxis/praxis/optimizers.py" source_line=691}
  multiply.2812 = f32[8192]{0} multiply(broadcast.4879, add.1546), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=695}
  select.2215 = f32[8192]{0} select(broadcast.4878, multiply.2812, broadcast.4891), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(_where)/select_n" source_file="/pax/paxml/paxml/learners.py" source_line=340}
  add.1547 = f32[8192]{0} add(param_1_0.3, select.2215), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/add" source_file="/pax/paxml/paxml/learners.py" source_line=408}
  select.799.clone.2 = f32[8192]{0} select(broadcast.4878, add.1544, param_14.285), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(_where)/select_n" source_file="/pax/paxml/paxml/learners.py" source_line=340}
  select.803.clone.2 = f32[8192]{0} select(broadcast.4878, add.1543, param_12.535), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(_where)/select_n" source_file="/pax/paxml/paxml/learners.py" source_line=340}
  ROOT tuple.151 = (f32[8192]{0}, f32[8192]{0}, f32[8192]{0}, f32[8192]{0}, f32[8192]{0}, /*index=5*/f32[8192]{0}) tuple(add.1542, select.798.clone.2, select.802.clone.2, add.1547, select.799.clone.2, /*index=5*/select.803.clone.2)
} // horizontally_fused_computation.3

horizontally_fused_computation.4 {
  param_0_0.4 = f32[8192]{0} parameter(0)
  bitcast.8201 = f32[1,8192]{1,0} bitcast(param_0_0.4)
  constant.5074 = f32[] constant(0)
  pad.90 = f32[8,8192]{1,0} pad(bitcast.8201, constant.5074), padding=7_0x0_0, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  param_1_0.4 = f32[8192]{0} parameter(1)
  bitcast.8202 = f32[1,8192]{1,0} bitcast(param_1_0.4)
  pad.91 = f32[8,8192]{1,0} pad(bitcast.8202, constant.5074), padding=7_0x0_0, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  param_2_0.2 = f32[8192]{0} parameter(2)
  bitcast.8203 = f32[1,8192]{1,0} bitcast(param_2_0.2)
  pad.92 = f32[8,8192]{1,0} pad(bitcast.8203, constant.5074), padding=7_0x0_0, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  param_3_0.1 = f32[8192]{0} parameter(3)
  bitcast.8204 = f32[1,8192]{1,0} bitcast(param_3_0.1)
  pad.93 = f32[8,8192]{1,0} pad(bitcast.8204, constant.5074), padding=7_0x0_0, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  param_4_0 = f32[8192]{0} parameter(4)
  bitcast.8205 = f32[1,8192]{1,0} bitcast(param_4_0)
  pad.94 = f32[8,8192]{1,0} pad(bitcast.8205, constant.5074), padding=7_0x0_0, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  ROOT tuple.154 = (f32[8,8192]{1,0}, f32[8,8192]{1,0}, f32[8,8192]{1,0}, f32[8,8192]{1,0}, f32[8,8192]{1,0}) tuple(pad.90, pad.91, pad.92, pad.93, pad.94)
} // horizontally_fused_computation.4

fused_computation.478 {
  param_0.1752 = f32[128]{0} parameter(0)
  param_1.2484 = f32[] parameter(1)
  ROOT reduce.431 = f32[] reduce(param_0.1752, param_1.2484), dimensions={0}, to_apply=region_15.791, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/reduce_sum[axes=(0,)]" source_file="/pax/paxml/paxml/learners.py" source_line=47}
}

fused_computation.479 {
  param_0.1753 = f32[256]{0} parameter(0)
  param_1.2485 = f32[] parameter(1)
  reduce.432 = f32[] reduce(param_0.1753, param_1.2485), dimensions={0}, to_apply=region_15.791, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/reduce_sum[axes=(0, 1)]" source_file="/pax/paxml/paxml/learners.py" source_line=47}
  param_2.2271 = f32[256]{0} parameter(2)
  reduce.433.clone.1 = f32[] reduce(param_2.2271, param_1.2485), dimensions={0}, to_apply=region_15.791, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/reduce_sum[axes=(0, 1)]" source_file="/pax/paxml/paxml/learners.py" source_line=47}
  param_3.2232 = f32[256]{0} parameter(3)
  reduce.434.clone.1 = f32[] reduce(param_3.2232, param_1.2485), dimensions={0}, to_apply=region_15.791, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/reduce_sum[axes=(0, 1)]" source_file="/pax/paxml/paxml/learners.py" source_line=47}
  param_4.1966 = f32[256]{0} parameter(4)
  reduce.435.clone.1 = f32[] reduce(param_4.1966, param_1.2485), dimensions={0}, to_apply=region_15.791, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/reduce_sum[axes=(0, 1)]" source_file="/pax/paxml/paxml/learners.py" source_line=47}
  param_5.1718 = f32[256]{0} parameter(5)
  reduce.436.clone.1 = f32[] reduce(param_5.1718, param_1.2485), dimensions={0}, to_apply=region_15.791, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/reduce_sum[axes=(0, 1)]" source_file="/pax/paxml/paxml/learners.py" source_line=47}
  ROOT tuple.158 = (f32[], f32[], f32[], f32[], f32[]) tuple(reduce.432, reduce.433.clone.1, reduce.434.clone.1, reduce.435.clone.1, reduce.436.clone.1)
} // fused_computation.479

fused_computation.484 {
  param_0.1758 = f32[512]{0} parameter(0)
  param_1.2490 = f32[] parameter(1)
  reduce.437 = f32[] reduce(param_0.1758, param_1.2490), dimensions={0}, to_apply=region_15.791, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/reduce_sum[axes=(0, 1)]" source_file="/pax/paxml/paxml/learners.py" source_line=47}
  param_2.2274 = f32[8,64]{1,0} parameter(2)
  param_5.1725 = f32[64]{0} parameter(5)
  constant.2953.clone.1 = f32[] constant(0.180336878)
  broadcast.3197.clone.1 = f32[64]{0} broadcast(constant.2953.clone.1), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._scale_query/per_dim_scale/mul" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=403}
  multiply.1969.clone.1 = f32[64]{0} multiply(param_5.1725, broadcast.3197.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._scale_query/per_dim_scale/mul" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=403}
  param_3.2240 = f32[8,64]{1,0} parameter(3)
  constant.2946.clone.1 = s32[] constant(7)
  param_4.1972 = s32[] parameter(4)
  subtract.583.clone.1 = s32[] subtract(constant.2946.clone.1, param_4.1972), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  constant.2943.clone.1 = s32[] constant(0)
  compare.817.clone.1 = pred[] compare(subtract.583.clone.1, constant.2943.clone.1), direction=LT, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/lt" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  constant.2944.clone.1 = s32[] constant(15)
  subtract.582.clone.1 = s32[] subtract(constant.2944.clone.1, param_4.1972), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/add" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  select.1114.clone.1 = s32[] select(compare.817.clone.1, subtract.582.clone.1, subtract.583.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/select_n" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  dynamic-slice.275.clone.1 = f32[1,64]{1,0} dynamic-slice(param_3.2240, select.1114.clone.1, constant.2943.clone.1), dynamic_slice_sizes={1,64}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/dynamic_slice[slice_sizes=(1, 64)]" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  bitcast.7894.clone.1 = f32[64]{0} bitcast(dynamic-slice.275.clone.1)
  constant.2948.clone.1 = f32[] constant(inf)
  broadcast.3196.clone.1 = f32[64]{0} broadcast(constant.2948.clone.1), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._scale_query/per_dim_scale/jit(softplus)/eq" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=403}
  compare.816.clone.1 = pred[64]{0} compare(bitcast.7894.clone.1, broadcast.3196.clone.1), direction=EQ, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._scale_query/per_dim_scale/jit(softplus)/eq" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=403}
  constant.2050.clone.1 = f32[] constant(0)
  broadcast.3195.clone.1 = f32[64]{0} broadcast(constant.2050.clone.1), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._scale_query/per_dim_scale/jit(softplus)/jit(logaddexp)/max" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=403}
  select.1113.clone.1 = f32[64]{0} select(compare.816.clone.1, broadcast.3195.clone.1, bitcast.7894.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._scale_query/per_dim_scale/jit(softplus)/select_n" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=403}
  compare.814.clone.1 = pred[64]{0} compare(bitcast.7894.clone.1, bitcast.7894.clone.1), direction=NE, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._scale_query/per_dim_scale/jit(softplus)/jit(logaddexp)/ne" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=403}
  maximum.89.clone.1 = f32[64]{0} maximum(bitcast.7894.clone.1, broadcast.3195.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._scale_query/per_dim_scale/jit(softplus)/jit(logaddexp)/max" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=403}
  abs.40.clone.1 = f32[64]{0} abs(bitcast.7894.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._scale_query/per_dim_scale/jit(softplus)/jit(logaddexp)/abs" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=403}
  negate.156.clone.1 = f32[64]{0} negate(abs.40.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._scale_query/per_dim_scale/jit(softplus)/jit(logaddexp)/neg" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=403}
  exponential.90.clone.1 = f32[64]{0} exponential(negate.156.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._scale_query/per_dim_scale/jit(softplus)/jit(logaddexp)/exp" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=403}
  log-plus-one.40.clone.1 = f32[64]{0} log-plus-one(exponential.90.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._scale_query/per_dim_scale/jit(softplus)/jit(logaddexp)/log1p" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=403}
  add.1248.clone.1 = f32[64]{0} add(maximum.89.clone.1, log-plus-one.40.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._scale_query/per_dim_scale/jit(softplus)/jit(logaddexp)/add" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=403}
  select.1111.clone.1 = f32[64]{0} select(compare.814.clone.1, bitcast.7894.clone.1, add.1248.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._scale_query/per_dim_scale/jit(softplus)/jit(logaddexp)/select_n" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=403}
  compare.813.clone.1 = pred[64]{0} compare(select.1111.clone.1, broadcast.3196.clone.1), direction=EQ, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._scale_query/per_dim_scale/jit(softplus)/eq" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=403}
  select.1110.clone.1 = f32[64]{0} select(compare.813.clone.1, broadcast.3195.clone.1, select.1111.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._scale_query/per_dim_scale/jit(softplus)/select_n" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=403}
  subtract.579.clone.1 = f32[64]{0} subtract(select.1113.clone.1, select.1110.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._scale_query/per_dim_scale/jit(softplus)/sub" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=403}
  exponential.89.clone.1 = f32[64]{0} exponential(subtract.579.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._scale_query/per_dim_scale/jit(softplus)/exp" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=403}
  multiply.1968.clone.1 = f32[64]{0} multiply(multiply.1969.clone.1, exponential.89.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._scale_query/per_dim_scale/jit(softplus)/mul" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=403}
  bitcast.7892.clone.1 = f32[1,64]{1,0} bitcast(multiply.1968.clone.1)
  dynamic-update-slice.127.clone.1 = f32[8,64]{1,0} dynamic-update-slice(param_2.2274, bitcast.7892.clone.1, select.1114.clone.1, constant.2943.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  multiply.1600.clone.1 = f32[8,64]{1,0} multiply(dynamic-update-slice.127.clone.1, dynamic-update-slice.127.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/paxml/paxml/learners.py" source_line=47}
  bitcast.7432.clone.1 = f32[512]{0} bitcast(multiply.1600.clone.1), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/paxml/paxml/learners.py" source_line=47}
  reduce.347.clone.1 = f32[] reduce(bitcast.7432.clone.1, constant.2050.clone.1), dimensions={0}, to_apply=region_15.791, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/reduce_sum[axes=(0, 1)]" source_file="/pax/paxml/paxml/learners.py" source_line=47}
  ROOT tuple.159 = (f32[], f32[]) tuple(reduce.437, reduce.347.clone.1)
} // fused_computation.484

ENTRY main.4503_spmd {
  param.4 = u32[] parameter(0), sharding={replicated}
  constant.1005 = u32[] constant(1)
  add.649 = u32[] add(param.4, constant.1005), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/add" source_file="/pax/paxml/paxml/train_states.py" source_line=58}
  param.22 = f32[8192]{0} parameter(2), sharding={replicated}
  param.27 = f32[8192]{0} parameter(20), sharding={replicated}
  param.24 = s32[] parameter(18), sharding={replicated}
  fusion.230 = f32[] fusion(param.24), kind=kLoop, calls=fused_computation.230, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/div" source_file="/pax/praxis/praxis/optimizers.py" source_line=331}
  param.5 = f32[8192]{0} parameter(1), sharding={replicated}
  fusion.395 = f32[8192]{0} fusion(param.22), kind=kLoop, calls=fused_computation.395, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/final_ln/add" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=376}
  constant.1011 = s32[] constant(0)
  param.8 = s32[2,2048]{1,0} parameter(54), sharding={devices=[8,1]<=[8]}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/sharding_constraint[sharding=GSPMDSharding({devices=[8,1]<=[8]}) resource_env=ResourceEnv(Mesh(device_ids=array([[[0],\n        [1],\n        [2],\n        [3],\n        [4],\n        [5],\n        [6],\n        [7]]]), axis_names=(\'replica\', \'data\', \'mdl\')), ()) unconstrained_dims=set()]" source_file="/pax/praxis/praxis/py_utils.py" source_line=486}
  fusion.423 = f32[4096,32000]{1,0} fusion(param.8), kind=kLoop, calls=fused_computation.423, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/lm._prepare_input/softmax.emb_lookup/jit(_one_hot)/convert_element_type[new_dtype=float32 weak_type=False]" source_file="/pax/praxis/praxis/layers/embedding_softmax.py" source_line=391}
  param.9 = f32[1024,32000]{1,0} parameter(4), sharding={devices=[8,1]<=[8]}
  bitcast.1925 = f32[32000,1024]{0,1} bitcast(param.9)
  all-gather.8 = f32[32000,8192]{0,1} all-gather(bitcast.1925), channel_id=2, replica_groups={{0,1,2,3,4,5,6,7}}, dimensions={1}, use_global_device_ids=true, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/lm._prepare_input/softmax.emb_lookup/einsum/...y,yz->...z/dot_general[dimension_numbers=(((2,), (0,)), ((), ())) precision=None preferred_element_type=float32]" source_file="/pax/praxis/praxis/layers/base_ops.py" source_line=42}
  fusion.422 = f32[2,2048,8192]{2,1,0} fusion(), kind=kLoop, calls=fused_computation.422, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/lm._prepare_input/position_emb/concatenate[dimension=2]" source_file="/pax/praxis/praxis/layers/embedding_softmax.py" source_line=852}
  bitcast.1948 = f32[4096,8192]{1,0} bitcast(fusion.422)
  cublas-gemm.5 = f32[4096,8192]{1,0} custom-call(fusion.423, all-gather.8, bitcast.1948), custom_call_target="__cublas$gemm", output_to_operand_aliasing={{}: (2, {})}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/lm._prepare_input/softmax.emb_lookup/einsum/...y,yz->...z/dot_general[dimension_numbers=(((2,), (0,)), ((), ())) precision=None preferred_element_type=float32]" source_file="/pax/praxis/praxis/layers/base_ops.py" source_line=42}, backend_config={"alpha_real":90.5096664428711,"alpha_imag":0,"beta":1,"dot_dimension_numbers":{"lhs_contracting_dimensions":["1"],"rhs_contracting_dimensions":["0"],"lhs_batch_dimensions":[],"rhs_batch_dimensions":[]},"precision_config":{"operand_precision":["DEFAULT","DEFAULT"]},"epilogue":"DEFAULT"}
  bitcast.1952 = f32[2,2048,8192]{2,1,0} bitcast(cublas-gemm.5)
  constant.1007 = f32[] constant(0)
  broadcast.1703 = f32[8,2,2048,8192]{3,2,1,0} broadcast(constant.1007), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/broadcast_in_dim[shape=(8, 16, 2048, 8192) broadcast_dimensions=()]" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  param.10 = f32[8,32768]{1,0} parameter(5), sharding={replicated}
  param.11 = f32[8,1024,32768]{2,1,0} parameter(6), sharding={devices=[1,8,1]<=[8]}
  param.12 = f32[8,8192]{1,0} parameter(7), sharding={replicated}
  param.13 = f32[8,32768,1024]{2,1,0} parameter(8), sharding={devices=[1,1,8]<=[8]}
  transpose.192 = f32[8,1024,32768]{2,1,0} transpose(param.13), dimensions={0,2,1}
  bitcast.1964 = f32[8,32768,1024]{1,2,0} bitcast(transpose.192)
  param.14 = f32[8,8192]{1,0} parameter(9), sharding={replicated}
  param.15 = f32[8,8192]{1,0} parameter(10), sharding={replicated}
  param.16 = f32[8,8192]{1,0} parameter(11), sharding={replicated}
  param.17 = f32[8,8192]{1,0} parameter(12), sharding={replicated}
  param.18 = f32[8,3,1024,128,64]{4,3,2,1,0} parameter(13), sharding={devices=[1,1,8,1,1]<=[8]}
  transpose.193 = f32[8,1024,3,128,64]{4,3,2,1,0} transpose(param.18), dimensions={0,2,1,3,4}
  bitcast.1975 = f32[8,3,1024,128,64]{4,3,1,2,0} bitcast(transpose.193)
  param.19 = f32[8,64]{1,0} parameter(14), sharding={replicated}
  param.20 = f32[8,1024,128,64]{3,2,1,0} parameter(15), sharding={devices=[1,8,1,1]<=[8]}
  param.21 = f32[2,2048]{1,0} parameter(56), sharding={devices=[8,1]<=[8]}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/sharding_constraint[sharding=GSPMDSharding({devices=[8,1]<=[8]}) resource_env=ResourceEnv(Mesh(device_ids=array([[[0],\n        [1],\n        [2],\n        [3],\n        [4],\n        [5],\n        [6],\n        [7]]]), axis_names=(\'replica\', \'data\', \'mdl\')), ()) unconstrained_dims=set()]" source_file="/pax/praxis/praxis/py_utils.py" source_line=486}
  fusion.421 = f32[2,2048]{1,0} fusion(param.21), kind=kLoop, calls=fused_computation.421, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/sub" source_file="/pax/praxis/praxis/layers/transformer_models.py" source_line=776}
  fusion.418 = (pred[1,2,2048,2048]{3,2,1,0}, f32[2,2048,2048]{2,1,0}) fusion(fusion.421), kind=kLoop, calls=fused_computation.418, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/ge" source_file="/pax/praxis/praxis/py_utils.py" source_line=743}
  get-tuple-element.696 = pred[1,2,2048,2048]{3,2,1,0} get-tuple-element(fusion.418), index=0
  fusion.450 = pred[2,128,2048,2048]{3,2,1,0} fusion(get-tuple-element.696), kind=kLoop, calls=fused_computation.450, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/jit(_where)/broadcast_in_dim[shape=(16, 128, 2048, 2048) broadcast_dimensions=(0, 2, 3)]" source_file="/pax/praxis/praxis/py_utils.py" source_line=743}
  constant.1016 = f32[] constant(-2.38197633e+38)
  broadcast.1715 = f32[2,128,2048,2048]{3,2,1,0} broadcast(constant.1016), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/jit(_where)/broadcast_in_dim[shape=(16, 128, 2048, 2048) broadcast_dimensions=()]" source_file="/pax/praxis/praxis/py_utils.py" source_line=743}
  bitcast.2030 = f32[2,2048,1]{1,0,2} bitcast(fusion.421)
  fusion.417 = f32[1,1024,3,128,64]{4,3,2,1,0} fusion(param.18), kind=kLoop, calls=fused_computation.417, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/dynamic_slice[slice_sizes=(1, 3, 8192, 128, 64)]" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  bitcast.2036 = f32[3,1024,128,64]{3,2,0,1} bitcast(fusion.417)
  all-gather.16 = f32[3,8192,128,64]{3,2,0,1} all-gather(bitcast.2036), channel_id=49, replica_groups={{0,1,2,3,4,5,6,7}}, dimensions={1}, use_global_device_ids=true, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/self_attention/combined_qkv/einsum/ABD,KDNH->KABNH/dot_general[dimension_numbers=(((1,), (2,)), ((), ())) precision=None preferred_element_type=float32]" source_file="/pax/praxis/praxis/layers/base_ops.py" source_line=42}
  slice.54 = f32[1,1024,128,64]{3,2,1,0} slice(param.20), slice={[0:1], [0:1024], [0:128], [0:64]}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/dynamic_slice[slice_sizes=(1, 8192, 128, 64)]" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  bitcast.2043 = f32[1024,128,64]{2,1,0} bitcast(slice.54)
  all-gather.17 = f32[8192,128,64]{2,1,0} all-gather(bitcast.2043), channel_id=50, replica_groups={{0,1,2,3,4,5,6,7}}, dimensions={0}, use_global_device_ids=true, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/self_attention/post/einsum/ABNH,DNH->ABD/dot_general[dimension_numbers=(((3, 2), (2, 1)), ((), ())) precision=None preferred_element_type=float32]" source_file="/pax/praxis/praxis/layers/base_ops.py" source_line=42}
  slice.55 = f32[1,1024,32768]{2,1,0} slice(param.11), slice={[0:1], [0:1024], [0:32768]}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/dynamic_slice[slice_sizes=(1, 8192, 32768)]" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  bitcast.2050 = f32[1024,32768]{1,0} bitcast(slice.55)
  all-gather.18 = f32[8192,32768]{1,0} all-gather(bitcast.2050), channel_id=51, replica_groups={{0,1,2,3,4,5,6,7}}, dimensions={0}, use_global_device_ids=true, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/ff_layer/ffn_layer1/linear/einsum/...y,yz->...z/dot_general[dimension_numbers=(((2,), (0,)), ((), ())) precision=None preferred_element_type=float32]" source_file="/pax/praxis/praxis/layers/base_ops.py" source_line=42}
  fusion.416 = f32[1,1024,32768]{2,1,0} fusion(param.13), kind=kInput, calls=fused_computation.416, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/dynamic_slice[slice_sizes=(1, 32768, 8192)]" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  bitcast.2058 = f32[32768,1024]{0,1} bitcast(fusion.416)
  all-gather.19 = f32[32768,8192]{0,1} all-gather(bitcast.2058), channel_id=52, replica_groups={{0,1,2,3,4,5,6,7}}, dimensions={1}, use_global_device_ids=true, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/ff_layer/ffn_layer2/linear/einsum/...y,yz->...z/dot_general[dimension_numbers=(((2,), (0,)), ((), ())) precision=None preferred_element_type=float32]" source_file="/pax/praxis/praxis/layers/base_ops.py" source_line=42}
  constant.1407 = s32[] constant(1)
  tuple.24 = (s32[], f32[2,2048,8192]{2,1,0}, f32[8,2,2048,8192]{3,2,1,0}, f32[8,32768]{1,0}, f32[8,1024,32768]{2,1,0}, /*index=5*/f32[8,8192]{1,0}, f32[8,32768,1024]{1,2,0}, f32[8,8192]{1,0}, f32[8,8192]{1,0}, f32[8,8192]{1,0}, /*index=10*/f32[8,8192]{1,0}, f32[8,3,1024,128,64]{4,3,1,2,0}, f32[8,64]{1,0}, f32[8,1024,128,64]{3,2,1,0}, pred[2,128,2048,2048]{3,2,1,0}, /*index=15*/f32[2,128,2048,2048]{3,2,1,0}, f32[2,2048,1]{1,0,2}, f32[3,8192,128,64]{3,2,0,1}, f32[8192,128,64]{2,1,0}, f32[8192,32768]{1,0}, /*index=20*/f32[32768,8192]{0,1}, s32[]) tuple(constant.1011, bitcast.1952, broadcast.1703, param.10, param.11, /*index=5*/param.12, bitcast.1964, param.14, param.15, param.16, /*index=10*/param.17, bitcast.1975, param.19, param.20, fusion.450, /*index=15*/broadcast.1715, bitcast.2030, all-gather.16, all-gather.17, all-gather.18, /*index=20*/all-gather.19, constant.1407)
  while.4 = (s32[], f32[2,2048,8192]{2,1,0}, f32[8,2,2048,8192]{3,2,1,0}, f32[8,32768]{1,0}, f32[8,1024,32768]{2,1,0}, /*index=5*/f32[8,8192]{1,0}, f32[8,32768,1024]{1,2,0}, f32[8,8192]{1,0}, f32[8,8192]{1,0}, f32[8,8192]{1,0}, /*index=10*/f32[8,8192]{1,0}, f32[8,3,1024,128,64]{4,3,1,2,0}, f32[8,64]{1,0}, f32[8,1024,128,64]{3,2,1,0}, pred[2,128,2048,2048]{3,2,1,0}, /*index=15*/f32[2,128,2048,2048]{3,2,1,0}, f32[2,2048,1]{1,0,2}, f32[3,8192,128,64]{3,2,0,1}, f32[8192,128,64]{2,1,0}, f32[8192,32768]{1,0}, /*index=20*/f32[32768,8192]{0,1}, s32[]) while(tuple.24), condition=region_7.609.clone_spmd.clone.1, body=region_0.369.clone_spmd.clone.1, backend_config={"known_trip_count":{"n":"7"}}
  get-tuple-element.225 = f32[2,2048,1]{1,0,2} get-tuple-element(while.4), index=16
  get-tuple-element.221 = f32[8,8192]{1,0} get-tuple-element(while.4), index=7
  get-tuple-element.220 = f32[8,8192]{1,0} get-tuple-element(while.4), index=8
  get-tuple-element.211 = f32[3,8192,128,64]{3,2,0,1} get-tuple-element(while.4), index=17
  bitcast.2065 = f32[24576,8192]{0,1} bitcast(get-tuple-element.211)
  get-tuple-element.214 = f32[8,8192]{1,0} get-tuple-element(while.4), index=9
  get-tuple-element.213 = f32[8,8192]{1,0} get-tuple-element(while.4), index=10
  get-tuple-element.212 = f32[2,2048,8192]{2,1,0} get-tuple-element(while.4), index=1
  reduce.120 = f32[2,2048]{1,0} reduce(get-tuple-element.212, constant.1007), dimensions={2}, to_apply=region_15.791, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/layer_norm/reduce_sum[axes=(2,)]" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=370}
  fusion.414 = f32[2,2048]{1,0} fusion(get-tuple-element.212, reduce.120), kind=kInput, calls=fused_computation.414, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/layer_norm/reduce_sum[axes=(2,)]" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=371}
  get-tuple-element.209 = s32[] get-tuple-element(while.4), index=0
  fusion.412 = f32[2,2048,8192]{2,1,0} fusion(get-tuple-element.214, get-tuple-element.213, fusion.414, get-tuple-element.209, get-tuple-element.212, /*index=5*/reduce.120), kind=kLoop, calls=fused_computation.412, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/layer_norm/add" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=378}
  bitcast.2125 = f32[8192,4096]{0,1} bitcast(fusion.412)
  custom-call.31 = f32[24576,4096]{1,0} custom-call(bitcast.2065, bitcast.2125), custom_call_target="__cublas$gemm", metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/self_attention/combined_qkv/einsum/ABD,KDNH->KABNH/dot_general[dimension_numbers=(((1,), (2,)), ((), ())) precision=None preferred_element_type=float32]" source_file="/pax/praxis/praxis/layers/base_ops.py" source_line=42}, backend_config={"alpha_real":1,"alpha_imag":0,"beta":0,"dot_dimension_numbers":{"lhs_contracting_dimensions":["1"],"rhs_contracting_dimensions":["0"],"lhs_batch_dimensions":[],"rhs_batch_dimensions":[]},"precision_config":{"operand_precision":["DEFAULT","DEFAULT"]},"epilogue":"DEFAULT"}
  get-tuple-element.216 = f32[8,64]{1,0} get-tuple-element(while.4), index=12
  fusion.410 = f32[1,64]{1,0} fusion(get-tuple-element.216, get-tuple-element.209), kind=kLoop, calls=fused_computation.410, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._scale_query/per_dim_scale/jit(softplus)/jit(logaddexp)/log1p" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=403}
  fusion.460 = (f32[1,2,128,64,2048]{4,3,2,1,0}, f32[1,2,128,64,2048]{4,3,2,1,0}, f32[2,128,2048,64]{3,2,1,0}) fusion(custom-call.31, fusion.410, get-tuple-element.216, get-tuple-element.209), kind=kInput, calls=fused_computation.460, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/self_attention/combined_qkv/slice[start_indices=(1, 0, 0, 0, 0) limit_indices=(2, 16, 2048, 128, 64) strides=(1, 1, 1, 1, 1)]" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=882}
  get-tuple-element.694 = f32[1,2,128,64,2048]{4,3,2,1,0} get-tuple-element(fusion.460), index=1
  bitcast.2135 = f32[256,64,2048]{2,1,0} bitcast(get-tuple-element.694)
  get-tuple-element.215 = pred[2,128,2048,2048]{3,2,1,0} get-tuple-element(while.4), index=14
  get-tuple-element.217 = f32[2,128,2048,2048]{3,2,1,0} get-tuple-element(while.4), index=15
  get-tuple-element.695 = f32[2,128,2048,64]{3,2,1,0} get-tuple-element(fusion.460), index=2
  bitcast.2174 = f32[256,2048,64]{2,1,0} bitcast(get-tuple-element.695)
  get-tuple-element.693 = f32[1,2,128,64,2048]{4,3,2,1,0} get-tuple-element(fusion.460), index=0
  bitcast.2179 = f32[256,64,2048]{2,1,0} bitcast(get-tuple-element.693)
  custom-call.32 = f32[256,2048,2048]{2,1,0} custom-call(bitcast.2174, bitcast.2179), custom_call_target="__cublas$gemm", metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._atten_logits/qk_einsum/BTNH,BSNH->BNTS/dot_general[dimension_numbers=(((3,), (3,)), ((0, 2), (0, 2))) precision=None preferred_element_type=float32]" source_file="/pax/praxis/praxis/layers/base_ops.py" source_line=42}, backend_config={"alpha_real":1,"alpha_imag":0,"beta":0,"dot_dimension_numbers":{"lhs_contracting_dimensions":["2"],"rhs_contracting_dimensions":["1"],"lhs_batch_dimensions":["0"],"rhs_batch_dimensions":["0"]},"precision_config":{"operand_precision":["DEFAULT","DEFAULT"]},"epilogue":"DEFAULT"}
  fusion.477 = (f32[2,128,2048]{2,1,0}, f32[2,128,2048,2048]{3,2,1,0}) fusion(get-tuple-element.215, get-tuple-element.217, custom-call.32), kind=kInput, calls=fused_computation.477, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/reduce_max[axes=(3,)]" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=1487}
  get-tuple-element.692 = f32[2,128,2048,2048]{3,2,1,0} get-tuple-element(fusion.477), index=1
  get-tuple-element.691 = f32[2,128,2048]{2,1,0} get-tuple-element(fusion.477), index=0
  fusion.476 = (f32[2,128,2048]{2,1,0}, f32[2,128,2048,2048]{3,2,1,0}) fusion(get-tuple-element.692, get-tuple-element.691), kind=kInput, calls=fused_computation.476, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/reduce_sum[axes=(3,)]" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=1487}
  get-tuple-element.690 = f32[2,128,2048,2048]{3,2,1,0} get-tuple-element(fusion.476), index=1
  get-tuple-element.689 = f32[2,128,2048]{2,1,0} get-tuple-element(fusion.476), index=0
  fusion.406 = f32[2,128,2048,2048]{3,2,1,0} fusion(get-tuple-element.690, get-tuple-element.689), kind=kLoop, calls=fused_computation.406, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/div" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=1487}
  bitcast.2211 = f32[256,2048,2048]{2,1,0} bitcast(fusion.406)
  custom-call.33 = f32[256,64,2048]{2,1,0} custom-call(bitcast.2135, bitcast.2211), custom_call_target="__cublas$gemm", metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/pv_einsum/BNTS,BSNH->BTNH/dot_general[dimension_numbers=(((1,), (3,)), ((0, 2), (0, 1))) precision=None preferred_element_type=float32]" source_file="/pax/praxis/praxis/layers/base_ops.py" source_line=42}, backend_config={"alpha_real":1,"alpha_imag":0,"beta":0,"dot_dimension_numbers":{"lhs_contracting_dimensions":["2"],"rhs_contracting_dimensions":["2"],"lhs_batch_dimensions":["0"],"rhs_batch_dimensions":["0"]},"precision_config":{"operand_precision":["DEFAULT","DEFAULT"]},"epilogue":"DEFAULT"}
  fusion.405 = f32[2,2048,128,64]{3,2,1,0} fusion(custom-call.33), kind=kInput, calls=fused_computation.405, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/pv_einsum/BNTS,BSNH->BTNH/transpose[permutation=(0, 3, 1, 2)]" source_file="/pax/praxis/praxis/layers/base_ops.py" source_line=42}
  bitcast.2218 = f32[4096,8192]{1,0} bitcast(fusion.405)
  get-tuple-element.219 = f32[8192,128,64]{2,1,0} get-tuple-element(while.4), index=18
  bitcast.2222 = f32[8192,8192]{0,1} bitcast(get-tuple-element.219)
  bitcast.2226 = f32[4096,8192]{1,0} bitcast(get-tuple-element.212)
  cublas-gemm.7 = f32[4096,8192]{1,0} custom-call(bitcast.2218, bitcast.2222, bitcast.2226), custom_call_target="__cublas$gemm", output_to_operand_aliasing={{}: (2, {})}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/self_attention/post/einsum/ABNH,DNH->ABD/dot_general[dimension_numbers=(((3, 2), (2, 1)), ((), ())) precision=None preferred_element_type=float32]" source_file="/pax/praxis/praxis/layers/base_ops.py" source_line=42}, backend_config={"alpha_real":1,"alpha_imag":0,"beta":1,"dot_dimension_numbers":{"lhs_contracting_dimensions":["1"],"rhs_contracting_dimensions":["0"],"lhs_batch_dimensions":[],"rhs_batch_dimensions":[]},"precision_config":{"operand_precision":["DEFAULT","DEFAULT"]},"epilogue":"DEFAULT"}
  fusion.449 = f32[2,2048]{1,0} fusion(cublas-gemm.7), kind=kInput, calls=fused_computation.449, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/reduce_sum[axes=(2,)]" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=370}
  fusion.403 = f32[2,2048]{1,0} fusion(fusion.449, cublas-gemm.7), kind=kInput, calls=fused_computation.403, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/reduce_sum[axes=(2,)]" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=371}
  fusion.402 = f32[2,2048,8192]{2,1,0} fusion(get-tuple-element.221, get-tuple-element.220, fusion.403, get-tuple-element.209, fusion.449, /*index=5*/cublas-gemm.7), kind=kLoop, calls=fused_computation.402, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/add" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=378}
  bitcast.2286 = f32[4096,8192]{1,0} bitcast(fusion.402)
  get-tuple-element.223 = f32[8192,32768]{1,0} get-tuple-element(while.4), index=19
  custom-call.35 = f32[4096,32768]{1,0} custom-call(bitcast.2286, get-tuple-element.223), custom_call_target="__cublas$gemm", metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/ff_layer/ffn_layer1/linear/einsum/...y,yz->...z/dot_general[dimension_numbers=(((2,), (0,)), ((), ())) precision=None preferred_element_type=float32]" source_file="/pax/praxis/praxis/layers/base_ops.py" source_line=42}, backend_config={"alpha_real":1,"alpha_imag":0,"beta":0,"dot_dimension_numbers":{"lhs_contracting_dimensions":["1"],"rhs_contracting_dimensions":["0"],"lhs_batch_dimensions":[],"rhs_batch_dimensions":[]},"precision_config":{"operand_precision":["DEFAULT","DEFAULT"]},"epilogue":"DEFAULT"}
  get-tuple-element.224 = f32[8,32768]{1,0} get-tuple-element(while.4), index=3
  fusion.401 = f32[2,2048,32768]{2,1,0} fusion(custom-call.35, get-tuple-element.224, get-tuple-element.225, get-tuple-element.209), kind=kLoop, calls=fused_computation.401, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/ff_layer/mul" source_file="/pax/praxis/praxis/layers/transformers.py" source_line=455}
  bitcast.2335 = f32[4096,32768]{1,0} bitcast(fusion.401)
  get-tuple-element.227 = f32[32768,8192]{0,1} get-tuple-element(while.4), index=20
  custom-call.36 = f32[4096,8192]{1,0} custom-call(bitcast.2335, get-tuple-element.227), custom_call_target="__cublas$gemm", metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/sub.body_fn/sub/x_layers_0/ff_layer/ffn_layer2/linear/einsum/...y,yz->...z/dot_general[dimension_numbers=(((2,), (0,)), ((), ())) precision=None preferred_element_type=float32]" source_file="/pax/praxis/praxis/layers/base_ops.py" source_line=42}, backend_config={"alpha_real":1,"alpha_imag":0,"beta":0,"dot_dimension_numbers":{"lhs_contracting_dimensions":["1"],"rhs_contracting_dimensions":["0"],"lhs_batch_dimensions":[],"rhs_batch_dimensions":[]},"precision_config":{"operand_precision":["DEFAULT","DEFAULT"]},"epilogue":"DEFAULT"}
  get-tuple-element.228 = f32[8,8192]{1,0} get-tuple-element(while.4), index=5
  fusion.461 = f32[2,2048]{1,0} fusion(get-tuple-element.225, custom-call.36, get-tuple-element.228, get-tuple-element.209, cublas-gemm.7), kind=kInput, calls=fused_computation.461, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/final_ln/reduce_sum[axes=(2,)]" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=370}
  fusion.398 = (f32[2,2048]{1,0}, f32[2,2048,8192]{2,1,0}) fusion(fusion.461, get-tuple-element.225, custom-call.36, get-tuple-element.228, get-tuple-element.209, /*index=5*/cublas-gemm.7), kind=kInput, calls=fused_computation.398, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/final_ln/reduce_sum[axes=(2,)]" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=371}
  get-tuple-element.688 = f32[2,2048,8192]{2,1,0} get-tuple-element(fusion.398), index=1
  get-tuple-element.687 = f32[2,2048]{1,0} get-tuple-element(fusion.398), index=0
  fusion.397 = f32[2,2048]{1,0} fusion(get-tuple-element.687), kind=kLoop, calls=fused_computation.397, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/final_ln/add" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  fusion.394 = (f32[2,2048,8192]{2,1,0}, f32[2,2048,8192]{2,1,0}) fusion(param.5, fusion.395, get-tuple-element.688, fusion.397), kind=kLoop, calls=fused_computation.394, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/final_ln/add" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=378}
  get-tuple-element.686 = f32[2,2048,8192]{2,1,0} get-tuple-element(fusion.394), index=1
  get-tuple-element.685 = f32[2,2048,8192]{2,1,0} get-tuple-element(fusion.394), index=0
  bitcast.2403 = f32[4096,8192]{1,0} bitcast(get-tuple-element.685)
  all-gather.9 = f32[8192,32000]{1,0} all-gather(param.9), channel_id=7, replica_groups={{0,1,2,3,4,5,6,7}}, dimensions={0}, use_global_device_ids=true, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/lm.compute_loss/softmax/softmax.get_logits/logits_ffn/linear/einsum/...y,yz->...z/dot_general[dimension_numbers=(((2,), (0,)), ((), ())) precision=None preferred_element_type=float32]" source_file="/pax/praxis/praxis/layers/base_ops.py" source_line=42}
  custom-call.37 = f32[4096,32000]{1,0} custom-call(bitcast.2403, all-gather.9), custom_call_target="__cublas$gemm", metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/lm.compute_loss/softmax/softmax.get_logits/logits_ffn/linear/einsum/...y,yz->...z/dot_general[dimension_numbers=(((2,), (0,)), ((), ())) precision=None preferred_element_type=float32]" source_file="/pax/praxis/praxis/layers/base_ops.py" source_line=42}, backend_config={"alpha_real":1,"alpha_imag":0,"beta":0,"dot_dimension_numbers":{"lhs_contracting_dimensions":["1"],"rhs_contracting_dimensions":["0"],"lhs_batch_dimensions":[],"rhs_batch_dimensions":[]},"precision_config":{"operand_precision":["DEFAULT","DEFAULT"]},"epilogue":"DEFAULT"}
  param.23 = f32[32000]{0} parameter(3), sharding={replicated}
  fusion.391 = ((f32[2,2048,128]{2,1,0}, s32[2,2048,128]{2,1,0}), f32[4096,32000]{1,0}) fusion(custom-call.37, param.23), kind=kInput, calls=fused_computation.391, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/lm.compute_loss/softmax/reduce[computation=<function _compute_argminmax.<locals>.reducer_fn at 0x7f7f7dce49d0> consts=() dimensions=(2,)]" source_file="/pax/praxis/praxis/layers/embedding_softmax.py" source_line=323}
  get-tuple-element.683 = (f32[2,2048,128]{2,1,0}, s32[2,2048,128]{2,1,0}) get-tuple-element(fusion.391), index=0
  get-tuple-element.452 = f32[2,2048,128]{2,1,0} get-tuple-element(get-tuple-element.683), index=0
  get-tuple-element.453 = s32[2,2048,128]{2,1,0} get-tuple-element(get-tuple-element.683), index=1
  constant.1033 = f32[] constant(-inf)
  reduce.63 = (f32[2,2048]{1,0}, s32[2,2048]{1,0}) reduce(get-tuple-element.452, get-tuple-element.453, constant.1033, constant.1011), dimensions={2}, to_apply=region_13.759, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/lm.compute_loss/softmax/reduce[computation=<function _compute_argminmax.<locals>.reducer_fn at 0x7f7f7dce49d0> consts=() dimensions=(2,)]" source_file="/pax/praxis/praxis/layers/embedding_softmax.py" source_line=323}
  get-tuple-element.106 = f32[2,2048]{1,0} get-tuple-element(reduce.63), index=0, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/lm.compute_loss/softmax/jit(log_softmax)/reduce_max[axes=(2,)]" source_file="/pax/praxis/praxis/layers/embedding_softmax.py" source_line=296}
  get-tuple-element.684 = f32[4096,32000]{1,0} get-tuple-element(fusion.391), index=1
  fusion.389 = f32[2,2048,128]{2,1,0} fusion(get-tuple-element.106, get-tuple-element.684), kind=kInput, calls=fused_computation.389, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/lm.compute_loss/softmax/jit(log_softmax)/reduce_sum[axes=(2,)]" source_file="/pax/praxis/praxis/layers/embedding_softmax.py" source_line=296}
  reduce.64 = f32[2,2048]{1,0} reduce(fusion.389, constant.1007), dimensions={2}, to_apply=region_15.791, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/lm.compute_loss/softmax/jit(log_softmax)/reduce_sum[axes=(2,)]" source_file="/pax/praxis/praxis/layers/embedding_softmax.py" source_line=296}
  log.3 = f32[2,2048]{1,0} log(reduce.64), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/lm.compute_loss/softmax/jit(log_softmax)/log" source_file="/pax/praxis/praxis/layers/embedding_softmax.py" source_line=296}
  param.6 = s32[2,2048]{1,0} parameter(55), sharding={devices=[8,1]<=[8]}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/sharding_constraint[sharding=GSPMDSharding({devices=[8,1]<=[8]}) resource_env=ResourceEnv(Mesh(device_ids=array([[[0],\n        [1],\n        [2],\n        [3],\n        [4],\n        [5],\n        [6],\n        [7]]]), axis_names=(\'replica\', \'data\', \'mdl\')), ()) unconstrained_dims=set()]" source_file="/pax/praxis/praxis/py_utils.py" source_line=486}
  param.7 = f32[2,2048]{1,0} parameter(57), sharding={devices=[8,1]<=[8]}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/sharding_constraint[sharding=GSPMDSharding({devices=[8,1]<=[8]}) resource_env=ResourceEnv(Mesh(device_ids=array([[[0],\n        [1],\n        [2],\n        [3],\n        [4],\n        [5],\n        [6],\n        [7]]]), axis_names=(\'replica\', \'data\', \'mdl\')), ()) unconstrained_dims=set()]" source_file="/pax/praxis/praxis/py_utils.py" source_line=486}
  fusion.426 = f32[] fusion(param.7), kind=kInput, calls=fused_computation.426, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/lm.compute_loss/softmax/reduce_sum[axes=(0, 1, 2)]" source_file="/pax/praxis/praxis/layers/embedding_softmax.py" source_line=331}
  all-reduce.11 = f32[] all-reduce(fusion.426), channel_id=1, replica_groups={{0}}, to_apply=region_15.791, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/lm.compute_loss/softmax/reduce_sum[axes=(0, 1, 2)]" source_file="/pax/praxis/praxis/layers/embedding_softmax.py" source_line=331}
  fusion.93 = (f32[2,2048,128]{2,1,0}, f32[2,2048,128]{2,1,0}) fusion(log.3, param.6, get-tuple-element.106, get-tuple-element.684, param.7, /*index=5*/all-reduce.11), kind=kInput, calls=fused_computation.93, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/lm.compute_loss/softmax/reduce_sum[axes=(2,)]" source_file="/pax/praxis/praxis/layers/embedding_softmax.py" source_line=317}
  get-tuple-element.699 = f32[2,2048,128]{2,1,0} get-tuple-element(fusion.93), index=1
  reduce.60 = f32[2,2048]{1,0} reduce(get-tuple-element.699, constant.1007), dimensions={2}, to_apply=region_15.791, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/lm.compute_loss/softmax/jit(log_softmax)/reduce_sum[axes=(2,)]" source_file="/pax/praxis/praxis/layers/embedding_softmax.py" source_line=296}
  fusion.436 = (f32[32000]{0}, f32[2,2048,32000]{2,1,0}) fusion(get-tuple-element.106, get-tuple-element.684, reduce.60, reduce.64, param.7, /*index=5*/all-reduce.11, param.6), kind=kInput, calls=fused_computation.436, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/lm.compute_loss/softmax/softmax.get_logits/logits_ffn/bias/reduce_sum[axes=(0, 1)]" source_file="/pax/praxis/praxis/layers/linears.py" source_line=143}
  get-tuple-element.682 = f32[2,2048,32000]{2,1,0} get-tuple-element(fusion.436), index=1
  bitcast.2504 = f32[4096,32000]{1,0} bitcast(get-tuple-element.682)
  custom-call.38 = f32[4096,8192]{1,0} custom-call(bitcast.2504, all-gather.9), custom_call_target="__cublas$gemm", metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/lm.compute_loss/softmax/softmax.get_logits/logits_ffn/linear/einsum/...y,yz->...z/dot_general[dimension_numbers=(((2,), (1,)), ((), ())) precision=None preferred_element_type=float32]" source_file="/pax/praxis/praxis/layers/base_ops.py" source_line=42}, backend_config={"alpha_real":1,"alpha_imag":0,"beta":0,"dot_dimension_numbers":{"lhs_contracting_dimensions":["1"],"rhs_contracting_dimensions":["1"],"lhs_batch_dimensions":[],"rhs_batch_dimensions":[]},"precision_config":{"operand_precision":["DEFAULT","DEFAULT"]},"epilogue":"DEFAULT"}
  fusion.386 = (f32[8192]{0}, f32[8192]{0}) fusion(get-tuple-element.686, custom-call.38), kind=kInput, calls=fused_computation.386, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/final_ln/reduce_sum[axes=(0, 1)]" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=376}
  get-tuple-element.679 = f32[8192]{0} get-tuple-element(fusion.386), index=0
  all-reduce.13 = f32[8192]{0} all-reduce(get-tuple-element.679), channel_id=9, replica_groups={{0}}, to_apply=region_15.791, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/final_ln/reduce_sum[axes=(0, 1)]" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=376}
  get-tuple-element.229 = f32[8,2,2048,8192]{3,2,1,0} get-tuple-element(while.4), index=2
  fusion.375 = f32[8,2,2048,8192]{3,2,1,0} fusion(get-tuple-element.229, get-tuple-element.212, get-tuple-element.209), kind=kLoop, calls=fused_computation.375, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  fusion.448 = f32[2,2048]{1,0} fusion(fusion.375), kind=kInput, calls=fused_computation.448, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/layer_norm/reduce_sum[axes=(2,)]" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=370}
  fusion.373 = f32[2,2048]{1,0} fusion(fusion.448, fusion.375), kind=kInput, calls=fused_computation.373, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/layer_norm/reduce_sum[axes=(2,)]" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=371}
  fusion.372 = f32[2,2048]{1,0} fusion(fusion.373), kind=kLoop, calls=fused_computation.372, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/layer_norm/add" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  fusion.370 = f32[1,8192]{1,0} fusion(param.17), kind=kLoop, calls=fused_computation.370, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/layer_norm/add" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=376}
  fusion.376 = f32[1,1024,3,128,64]{4,3,2,1,0} fusion(param.18), kind=kLoop, calls=fused_computation.376, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/dynamic_slice[slice_sizes=(1, 3, 8192, 128, 64)]" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  bitcast.2569 = f32[3,1024,128,64]{3,2,0,1} bitcast(fusion.376)
  all-gather.28 = f32[3,8192,128,64]{3,2,0,1} all-gather(bitcast.2569), channel_id=61, replica_groups={{0,1,2,3,4,5,6,7}}, dimensions={1}, use_global_device_ids=true, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/combined_qkv/einsum/ABD,KDNH->KABNH/dot_general[dimension_numbers=(((1,), (2,)), ((), ())) precision=None preferred_element_type=float32]" source_file="/pax/praxis/praxis/layers/base_ops.py" source_line=42}
  bitcast.3120 = f32[24576,8192]{0,1} bitcast(all-gather.28)
  fusion.369 = (f32[2,2048,8192]{2,1,0}, f32[2,2048,8192]{2,1,0}) fusion(param.16, fusion.370, fusion.372, fusion.448, fusion.375), kind=kLoop, calls=fused_computation.369, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/layer_norm/add" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=378}
  get-tuple-element.675 = f32[2,2048,8192]{2,1,0} get-tuple-element(fusion.369), index=0
  bitcast.2636 = f32[8192,4096]{0,1} bitcast(get-tuple-element.675)
  custom-call.40 = f32[24576,4096]{1,0} custom-call(bitcast.3120, bitcast.2636), custom_call_target="__cublas$gemm", metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/combined_qkv/einsum/ABD,KDNH->KABNH/dot_general[dimension_numbers=(((1,), (2,)), ((), ())) precision=None preferred_element_type=float32]" source_file="/pax/praxis/praxis/layers/base_ops.py" source_line=42}, backend_config={"alpha_real":1,"alpha_imag":0,"beta":0,"dot_dimension_numbers":{"lhs_contracting_dimensions":["1"],"rhs_contracting_dimensions":["0"],"lhs_batch_dimensions":[],"rhs_batch_dimensions":[]},"precision_config":{"operand_precision":["DEFAULT","DEFAULT"]},"epilogue":"DEFAULT"}
  fusion.368 = f32[3,2,128,64,2048]{4,3,2,1,0} fusion(custom-call.40), kind=kLoop, calls=fused_computation.368, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/combined_qkv/einsum/ABD,KDNH->KABNH/dot_general[dimension_numbers=(((1,), (2,)), ((), ())) precision=None preferred_element_type=float32]" source_file="/pax/praxis/praxis/layers/base_ops.py" source_line=42}
  slice.64 = f32[1,2,128,64,2048]{4,3,2,1,0} slice(fusion.368), slice={[2:3], [0:2], [0:128], [0:64], [0:2048]}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/combined_qkv/slice[start_indices=(2, 0, 0, 0, 0) limit_indices=(3, 16, 2048, 128, 64) strides=(1, 1, 1, 1, 1)]" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=882}
  bitcast.2646 = f32[256,64,2048]{2,1,0} bitcast(slice.64)
  fusion.366 = f32[64]{0} fusion(param.19), kind=kLoop, calls=fused_computation.366, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._scale_query/per_dim_scale/mul" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=403}
  fusion.365 = f32[2,128,2048,64]{3,2,1,0} fusion(fusion.366, fusion.368), kind=kInput, calls=fused_computation.365, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._scale_query/per_dim_scale/mul" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=404}
  bitcast.2702 = f32[256,2048,64]{2,1,0} bitcast(fusion.365)
  slice.67 = f32[1,2,128,64,2048]{4,3,2,1,0} slice(fusion.368), slice={[1:2], [0:2], [0:128], [0:64], [0:2048]}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/combined_qkv/slice[start_indices=(1, 0, 0, 0, 0) limit_indices=(2, 16, 2048, 128, 64) strides=(1, 1, 1, 1, 1)]" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=882}
  bitcast.2707 = f32[256,64,2048]{2,1,0} bitcast(slice.67)
  custom-call.41 = f32[256,2048,2048]{2,1,0} custom-call(bitcast.2702, bitcast.2707), custom_call_target="__cublas$gemm", metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._atten_logits/qk_einsum/BTNH,BSNH->BNTS/dot_general[dimension_numbers=(((3,), (3,)), ((0, 2), (0, 2))) precision=None preferred_element_type=float32]" source_file="/pax/praxis/praxis/layers/base_ops.py" source_line=42}, backend_config={"alpha_real":1,"alpha_imag":0,"beta":0,"dot_dimension_numbers":{"lhs_contracting_dimensions":["2"],"rhs_contracting_dimensions":["1"],"lhs_batch_dimensions":["0"],"rhs_batch_dimensions":["0"]},"precision_config":{"operand_precision":["DEFAULT","DEFAULT"]},"epilogue":"DEFAULT"}
  fusion.462 = (f32[2,128,2048]{2,1,0}, f32[2,128,2048,2048]{3,2,1,0}) fusion(get-tuple-element.696, custom-call.41), kind=kInput, calls=fused_computation.462, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/reduce_max[axes=(3,)]" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=1487}
  get-tuple-element.673 = f32[2,128,2048]{2,1,0} get-tuple-element(fusion.462), index=0
  get-tuple-element.674 = f32[2,128,2048,2048]{3,2,1,0} get-tuple-element(fusion.462), index=1
  fusion.475 = (f32[2,128,2048]{2,1,0}, f32[2,128,2048,2048]{3,2,1,0}) fusion(get-tuple-element.673, get-tuple-element.674, get-tuple-element.696), kind=kInput, calls=fused_computation.475, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/reduce_sum[axes=(3,)]" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=1487}
  get-tuple-element.672 = f32[2,128,2048,2048]{3,2,1,0} get-tuple-element(fusion.475), index=1
  get-tuple-element.671 = f32[2,128,2048]{2,1,0} get-tuple-element(fusion.475), index=0
  fusion.361 = f32[2,128,2048,2048]{3,2,1,0} fusion(get-tuple-element.672, get-tuple-element.671), kind=kLoop, calls=fused_computation.361, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/div" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=1487}
  bitcast.2740 = f32[256,2048,2048]{2,1,0} bitcast(fusion.361)
  custom-call.42 = f32[256,64,2048]{2,1,0} custom-call(bitcast.2646, bitcast.2740), custom_call_target="__cublas$gemm", metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/pv_einsum/BNTS,BSNH->BTNH/dot_general[dimension_numbers=(((1,), (3,)), ((0, 2), (0, 1))) precision=None preferred_element_type=float32]" source_file="/pax/praxis/praxis/layers/base_ops.py" source_line=42}, backend_config={"alpha_real":1,"alpha_imag":0,"beta":0,"dot_dimension_numbers":{"lhs_contracting_dimensions":["2"],"rhs_contracting_dimensions":["2"],"lhs_batch_dimensions":["0"],"rhs_batch_dimensions":["0"]},"precision_config":{"operand_precision":["DEFAULT","DEFAULT"]},"epilogue":"DEFAULT"}
  fusion.360 = f32[2,2048,128,64]{3,2,1,0} fusion(custom-call.42), kind=kInput, calls=fused_computation.360, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/pv_einsum/BNTS,BSNH->BTNH/transpose[permutation=(0, 3, 1, 2)]" source_file="/pax/praxis/praxis/layers/base_ops.py" source_line=42}
  bitcast.3378 = f32[4096,8192]{1,0} bitcast(fusion.360)
  slice.68 = f32[1,1024,128,64]{3,2,1,0} slice(param.20), slice={[7:8], [0:1024], [0:128], [0:64]}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/dynamic_slice[slice_sizes=(1, 8192, 128, 64)]" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  bitcast.2752 = f32[1024,128,64]{2,1,0} bitcast(slice.68)
  all-gather.38 = f32[8192,128,64]{2,1,0} all-gather(bitcast.2752), channel_id=93, replica_groups={{0,1,2,3,4,5,6,7}}, dimensions={0}, use_global_device_ids=true, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/post/einsum/ABNH,DNH->ABD/dot_general[dimension_numbers=(((3, 2), (2, 1)), ((), ())) precision=None preferred_element_type=float32]" source_file="/pax/praxis/praxis/layers/base_ops.py" source_line=42}
  bitcast.2756 = f32[8192,8192]{0,1} bitcast(all-gather.38)
  slice.61 = f32[1,2,2048,8192]{3,2,1,0} slice(fusion.375), slice={[7:8], [0:2], [0:2048], [0:8192]}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/dynamic_slice[slice_sizes=(1, 16, 2048, 8192)]" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  bitcast.2760 = f32[4096,8192]{1,0} bitcast(slice.61)
  cublas-gemm.9 = f32[4096,8192]{1,0} custom-call(bitcast.3378, bitcast.2756, bitcast.2760), custom_call_target="__cublas$gemm", output_to_operand_aliasing={{}: (2, {})}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/post/einsum/ABNH,DNH->ABD/dot_general[dimension_numbers=(((3, 2), (2, 1)), ((), ())) precision=None preferred_element_type=float32]" source_file="/pax/praxis/praxis/layers/base_ops.py" source_line=42}, backend_config={"alpha_real":1,"alpha_imag":0,"beta":1,"dot_dimension_numbers":{"lhs_contracting_dimensions":["1"],"rhs_contracting_dimensions":["0"],"lhs_batch_dimensions":[],"rhs_batch_dimensions":[]},"precision_config":{"operand_precision":["DEFAULT","DEFAULT"]},"epilogue":"DEFAULT"}
  fusion.447 = f32[2,2048]{1,0} fusion(cublas-gemm.9), kind=kInput, calls=fused_computation.447, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/reduce_sum[axes=(2,)]" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=370}
  fusion.358 = f32[2,2048]{1,0} fusion(fusion.447, cublas-gemm.9), kind=kInput, calls=fused_computation.358, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/reduce_sum[axes=(2,)]" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=371}
  fusion.357 = f32[2,2048]{1,0} fusion(fusion.358), kind=kLoop, calls=fused_computation.357, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/add" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  fusion.355 = f32[1,8192]{1,0} fusion(param.15), kind=kLoop, calls=fused_computation.355, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/add" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=376}
  fusion.354 = (f32[2,2048,8192]{2,1,0}, f32[2,2048,8192]{2,1,0}) fusion(param.14, fusion.355, fusion.357, fusion.447, cublas-gemm.9), kind=kLoop, calls=fused_computation.354, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/add" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=378}
  get-tuple-element.669 = f32[2,2048,8192]{2,1,0} get-tuple-element(fusion.354), index=0
  bitcast.2818 = f32[4096,8192]{1,0} bitcast(get-tuple-element.669)
  slice.71 = f32[1,1024,32768]{2,1,0} slice(param.11), slice={[7:8], [0:1024], [0:32768]}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/dynamic_slice[slice_sizes=(1, 8192, 32768)]" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  bitcast.2823 = f32[1024,32768]{1,0} bitcast(slice.71)
  all-gather.39 = f32[8192,32768]{1,0} all-gather(bitcast.2823), channel_id=94, replica_groups={{0,1,2,3,4,5,6,7}}, dimensions={0}, use_global_device_ids=true, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/ffn_layer1/linear/einsum/...y,yz->...z/dot_general[dimension_numbers=(((2,), (0,)), ((), ())) precision=None preferred_element_type=float32]" source_file="/pax/praxis/praxis/layers/base_ops.py" source_line=42}
  custom-call.44 = f32[4096,32768]{1,0} custom-call(bitcast.2818, all-gather.39), custom_call_target="__cublas$gemm", metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/ffn_layer1/linear/einsum/...y,yz->...z/dot_general[dimension_numbers=(((2,), (0,)), ((), ())) precision=None preferred_element_type=float32]" source_file="/pax/praxis/praxis/layers/base_ops.py" source_line=42}, backend_config={"alpha_real":1,"alpha_imag":0,"beta":0,"dot_dimension_numbers":{"lhs_contracting_dimensions":["1"],"rhs_contracting_dimensions":["0"],"lhs_batch_dimensions":[],"rhs_batch_dimensions":[]},"precision_config":{"operand_precision":["DEFAULT","DEFAULT"]},"epilogue":"DEFAULT"}
  fusion.350 = f32[2,2048,32768]{2,1,0} fusion(custom-call.44, param.10), kind=kLoop, calls=fused_computation.350, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/ffn_layer1/activation/tanh" source_file="/pax/praxis/praxis/layers/activations.py" source_line=157}
  fusion.378 = (f32[2,2048]{1,0}, f32[2,2048,8192]{2,1,0}, f32[2,2048]{1,0}) fusion(fusion.397, fusion.395, custom-call.38, get-tuple-element.688), kind=kInput, calls=fused_computation.378, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/final_ln/reduce_sum[axes=(2,)]" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  get-tuple-element.678 = f32[2,2048]{1,0} get-tuple-element(fusion.378), index=2
  fusion.379 = (f32[2,2048]{1,0}, f32[2,2048,8192]{2,1,0}) fusion(get-tuple-element.688, fusion.397, get-tuple-element.678), kind=kInput, calls=fused_computation.379, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/final_ln/reduce_sum[axes=(2,)]" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=371}
  get-tuple-element.666 = f32[2,2048]{1,0} get-tuple-element(fusion.379), index=0
  get-tuple-element.664 = f32[2,2048]{1,0} get-tuple-element(fusion.378), index=0
  get-tuple-element.667 = f32[2,2048,8192]{2,1,0} get-tuple-element(fusion.379), index=1
  get-tuple-element.665 = f32[2,2048,8192]{2,1,0} get-tuple-element(fusion.378), index=1
  fusion.443 = (f32[8192]{0}, f32[2,2048,8192]{2,1,0}) fusion(fusion.421, get-tuple-element.666, get-tuple-element.664, get-tuple-element.667, get-tuple-element.665), kind=kInput, calls=fused_computation.443, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/ffn_layer2/bias/reduce_sum[axes=(0, 1)]" source_file="/pax/praxis/praxis/layers/linears.py" source_line=143}
  get-tuple-element.663 = f32[2,2048,8192]{2,1,0} get-tuple-element(fusion.443), index=1
  bitcast.3355 = f32[4096,8192]{1,0} bitcast(get-tuple-element.663)
  fusion.351 = f32[1,1024,32768]{2,1,0} fusion(param.13), kind=kInput, calls=fused_computation.351, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/dynamic_slice[slice_sizes=(1, 32768, 8192)]" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  bitcast.2854 = f32[32768,1024]{0,1} bitcast(fusion.351)
  all-gather.29 = f32[32768,8192]{0,1} all-gather(bitcast.2854), channel_id=62, replica_groups={{0,1,2,3,4,5,6,7}}, dimensions={1}, use_global_device_ids=true, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/ffn_layer2/linear/einsum/...y,yz->...z/dot_general[dimension_numbers=(((2,), (1,)), ((), ())) precision=None preferred_element_type=float32]" source_file="/pax/praxis/praxis/layers/base_ops.py" source_line=42}
  custom-call.45 = f32[4096,32768]{1,0} custom-call(bitcast.3355, all-gather.29), custom_call_target="__cublas$gemm", metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/ffn_layer2/linear/einsum/...y,yz->...z/dot_general[dimension_numbers=(((2,), (1,)), ((), ())) precision=None preferred_element_type=float32]" source_file="/pax/praxis/praxis/layers/base_ops.py" source_line=42}, backend_config={"alpha_real":1,"alpha_imag":0,"beta":0,"dot_dimension_numbers":{"lhs_contracting_dimensions":["1"],"rhs_contracting_dimensions":["1"],"lhs_batch_dimensions":[],"rhs_batch_dimensions":[]},"precision_config":{"operand_precision":["DEFAULT","DEFAULT"]},"epilogue":"DEFAULT"}
  fusion.444 = (f32[32768]{0}, f32[2,2048,32768]{2,1,0}, f32[2,2048,32768]{2,1,0}) fusion(fusion.350, fusion.421, custom-call.45, custom-call.44, param.10), kind=kInput, calls=fused_computation.444, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/ffn_layer1/bias/reduce_sum[axes=(0, 1)]" source_file="/pax/praxis/praxis/layers/linears.py" source_line=143}
  get-tuple-element.661 = f32[2,2048,32768]{2,1,0} get-tuple-element(fusion.444), index=1
  bitcast.3341 = f32[4096,32768]{1,0} bitcast(get-tuple-element.661)
  custom-call.46 = f32[4096,8192]{1,0} custom-call(bitcast.3341, all-gather.39), custom_call_target="__cublas$gemm", metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/ffn_layer1/linear/einsum/...y,yz->...z/dot_general[dimension_numbers=(((2,), (1,)), ((), ())) precision=None preferred_element_type=float32]" source_file="/pax/praxis/praxis/layers/base_ops.py" source_line=42}, backend_config={"alpha_real":1,"alpha_imag":0,"beta":0,"dot_dimension_numbers":{"lhs_contracting_dimensions":["1"],"rhs_contracting_dimensions":["1"],"lhs_batch_dimensions":[],"rhs_batch_dimensions":[]},"precision_config":{"operand_precision":["DEFAULT","DEFAULT"]},"epilogue":"DEFAULT"}
  fusion.342 = (f32[2,2048]{1,0}, f32[2,2048,8192]{2,1,0}, f32[2,2048]{1,0}) fusion(fusion.357, fusion.355, custom-call.46, fusion.447, cublas-gemm.9), kind=kInput, calls=fused_computation.342, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/reduce_sum[axes=(2,)]" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  get-tuple-element.657 = f32[2,2048]{1,0} get-tuple-element(fusion.342), index=2
  fusion.343 = (f32[2,2048]{1,0}, f32[2,2048,8192]{2,1,0}) fusion(fusion.357, get-tuple-element.657, fusion.447, cublas-gemm.9), kind=kInput, calls=fused_computation.343, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/reduce_sum[axes=(2,)]" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=371}
  get-tuple-element.655 = f32[2,2048]{1,0} get-tuple-element(fusion.343), index=0
  get-tuple-element.653 = f32[2,2048]{1,0} get-tuple-element(fusion.342), index=0
  get-tuple-element.654 = f32[2,2048,8192]{2,1,0} get-tuple-element(fusion.342), index=1
  get-tuple-element.656 = f32[2,2048,8192]{2,1,0} get-tuple-element(fusion.343), index=1
  fusion.341 = f32[2,2048,8192]{2,1,0} fusion(get-tuple-element.655, get-tuple-element.653, get-tuple-element.654, get-tuple-element.656, get-tuple-element.666, /*index=5*/get-tuple-element.664, get-tuple-element.667, get-tuple-element.665), kind=kLoop, calls=fused_computation.341, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/add_any" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=370}
  bitcast.2985 = f32[4096,8192]{1,0} bitcast(fusion.341)
  bitcast.2989 = f32[8192,8192]{1,0} bitcast(all-gather.38)
  custom-call.47 = f32[4096,8192]{1,0} custom-call(bitcast.2985, bitcast.2989), custom_call_target="__cublas$gemm", metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/post/einsum/ABNH,DNH->ABD/dot_general[dimension_numbers=(((2,), (0,)), ((), ())) precision=None preferred_element_type=float32]" source_file="/pax/praxis/praxis/layers/base_ops.py" source_line=42}, backend_config={"alpha_real":1,"alpha_imag":0,"beta":0,"dot_dimension_numbers":{"lhs_contracting_dimensions":["1"],"rhs_contracting_dimensions":["0"],"lhs_batch_dimensions":[],"rhs_batch_dimensions":[]},"precision_config":{"operand_precision":["DEFAULT","DEFAULT"]},"epilogue":"DEFAULT"}
  fusion.446 = (f32[2,128,64,2048]{3,2,1,0}, f32[2,128,2048,64]{3,2,1,0}) fusion(custom-call.47), kind=kInput, calls=fused_computation.446, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/pv_einsum/BNTS,BSNH->BTNH/transpose[permutation=(0, 2, 3, 1)]" source_file="/pax/praxis/praxis/layers/base_ops.py" source_line=42}
  get-tuple-element.632 = f32[2,128,64,2048]{3,2,1,0} get-tuple-element(fusion.446), index=0
  bitcast.3101 = f32[256,64,2048]{2,1,0} bitcast(get-tuple-element.632)
  custom-call.51 = f32[256,64,2048]{2,1,0} custom-call(bitcast.3101, bitcast.2740), custom_call_target="__cublas$gemm", metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/pv_einsum/BNTS,BSNH->BTNH/dot_general[dimension_numbers=(((3,), (2,)), ((0, 1), (0, 1))) precision=None preferred_element_type=float32]" source_file="/pax/praxis/praxis/layers/base_ops.py" source_line=42}, backend_config={"alpha_real":1,"alpha_imag":0,"beta":0,"dot_dimension_numbers":{"lhs_contracting_dimensions":["2"],"rhs_contracting_dimensions":["1"],"lhs_batch_dimensions":["0"],"rhs_batch_dimensions":["0"]},"precision_config":{"operand_precision":["DEFAULT","DEFAULT"]},"epilogue":"DEFAULT"}
  get-tuple-element.652 = f32[2,128,2048,64]{3,2,1,0} get-tuple-element(fusion.446), index=1
  bitcast.2996 = f32[256,2048,64]{2,1,0} bitcast(get-tuple-element.652)
  custom-call.48 = f32[256,2048,2048]{2,1,0} custom-call(bitcast.2996, bitcast.2646), custom_call_target="__cublas$gemm", metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/pv_einsum/BNTS,BSNH->BTNH/dot_general[dimension_numbers=(((2,), (3,)), ((0, 1), (0, 2))) precision=None preferred_element_type=float32]" source_file="/pax/praxis/praxis/layers/base_ops.py" source_line=42}, backend_config={"alpha_real":1,"alpha_imag":0,"beta":0,"dot_dimension_numbers":{"lhs_contracting_dimensions":["2"],"rhs_contracting_dimensions":["1"],"lhs_batch_dimensions":["0"],"rhs_batch_dimensions":["0"]},"precision_config":{"operand_precision":["DEFAULT","DEFAULT"]},"epilogue":"DEFAULT"}
  fusion.340 = f32[2,128,2048]{2,1,0} fusion(get-tuple-element.672, get-tuple-element.671, custom-call.48), kind=kInput, calls=fused_computation.340, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/reduce_sum[axes=(3,)]" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=1487}
  fusion.339 = f32[2,128,2048,2048]{3,2,1,0} fusion(get-tuple-element.674, get-tuple-element.672, fusion.340, get-tuple-element.671, custom-call.48, /*index=5*/get-tuple-element.696), kind=kLoop, calls=fused_computation.339, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._cap_logits/div" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=1384}
  bitcast.3054 = f32[256,2048,2048]{2,1,0} bitcast(fusion.339)
  fusion.338 = f32[2,128,2048,64]{3,2,1,0} fusion(fusion.368), kind=kInput, calls=fused_computation.338, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._shard_blnh/sharding_constraint[sharding=GSPMDSharding({devices=[8,1,1,1]<=[8]}) resource_env=ResourceEnv(Mesh(device_ids=array([[[0],\n        [1],\n        [2],\n        [3],\n        [4],\n        [5],\n        [6],\n        [7]]]), axis_names=(\'replica\', \'data\', \'mdl\')), ()) unconstrained_dims=set()]" source_file="/pax/praxis/praxis/py_utils.py" source_line=486}
  bitcast.3078 = f32[256,2048,64]{2,1,0} bitcast(fusion.338)
  custom-call.50 = f32[256,2048,64]{2,1,0} custom-call(bitcast.3054, bitcast.3078), custom_call_target="__cublas$gemm", metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._atten_logits/qk_einsum/BTNH,BSNH->BNTS/dot_general[dimension_numbers=(((3,), (1,)), ((0, 1), (0, 2))) precision=None preferred_element_type=float32]" source_file="/pax/praxis/praxis/layers/base_ops.py" source_line=42}, backend_config={"alpha_real":1,"alpha_imag":0,"beta":0,"dot_dimension_numbers":{"lhs_contracting_dimensions":["2"],"rhs_contracting_dimensions":["1"],"lhs_batch_dimensions":["0"],"rhs_batch_dimensions":["0"]},"precision_config":{"operand_precision":["DEFAULT","DEFAULT"]},"epilogue":"DEFAULT"}
  fusion.337 = f32[2,128,64,2048]{3,2,1,0} fusion(custom-call.50), kind=kInput, calls=fused_computation.337, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._atten_logits/qk_einsum/BTNH,BSNH->BNTS/dot_general[dimension_numbers=(((3,), (1,)), ((0, 1), (0, 2))) precision=None preferred_element_type=float32]" source_file="/pax/praxis/praxis/layers/base_ops.py" source_line=42}
  custom-call.49 = f32[256,2048,64]{2,1,0} custom-call(bitcast.3054, bitcast.2702), custom_call_target="__cublas$gemm", metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._atten_logits/qk_einsum/BTNH,BSNH->BNTS/dot_general[dimension_numbers=(((2,), (1,)), ((0, 1), (0, 2))) precision=None preferred_element_type=float32]" source_file="/pax/praxis/praxis/layers/base_ops.py" source_line=42}, backend_config={"alpha_real":1,"alpha_imag":0,"beta":0,"dot_dimension_numbers":{"lhs_contracting_dimensions":["1"],"rhs_contracting_dimensions":["1"],"lhs_batch_dimensions":["0"],"rhs_batch_dimensions":["0"]},"precision_config":{"operand_precision":["DEFAULT","DEFAULT"]},"epilogue":"DEFAULT"}
  fusion.464 = (f32[2,2048,3,128,64]{4,3,2,1,0}, f32[3,128,64,2,2048]{4,3,2,1,0}) fusion(custom-call.51, fusion.337, fusion.366, custom-call.49), kind=kLoop, calls=fused_computation.464, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/combined_qkv/einsum/ABD,KDNH->KABNH/transpose[permutation=(0, 3, 4, 1, 2)]" source_file="/pax/praxis/praxis/layers/base_ops.py" source_line=42}
  get-tuple-element.630 = f32[2,2048,3,128,64]{4,3,2,1,0} get-tuple-element(fusion.464), index=0
  bitcast.3118 = f32[4096,24576]{1,0} bitcast(get-tuple-element.630)
  custom-call.52 = f32[4096,8192]{1,0} custom-call(bitcast.3118, bitcast.3120), custom_call_target="__cublas$gemm", metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/combined_qkv/einsum/ABD,KDNH->KABNH/dot_general[dimension_numbers=(((0, 1, 2), (0, 2, 3)), ((), ())) precision=None preferred_element_type=float32]" source_file="/pax/praxis/praxis/layers/base_ops.py" source_line=42}, backend_config={"alpha_real":1,"alpha_imag":0,"beta":0,"dot_dimension_numbers":{"lhs_contracting_dimensions":["1"],"rhs_contracting_dimensions":["0"],"lhs_batch_dimensions":[],"rhs_batch_dimensions":[]},"precision_config":{"operand_precision":["DEFAULT","DEFAULT"]},"epilogue":"DEFAULT"}
  fusion.330 = (f32[2,2048]{1,0}, f32[2,2048,8192]{2,1,0}, f32[2,2048]{1,0}) fusion(fusion.372, fusion.370, custom-call.52, fusion.448, fusion.375), kind=kInput, calls=fused_computation.330, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/layer_norm/reduce_sum[axes=(2,)]" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  get-tuple-element.608 = f32[2,2048]{1,0} get-tuple-element(fusion.330), index=2
  fusion.331 = (f32[2,2048]{1,0}, f32[2,2048,8192]{2,1,0}) fusion(fusion.372, get-tuple-element.608, fusion.448, fusion.375), kind=kInput, calls=fused_computation.331, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/layer_norm/reduce_sum[axes=(2,)]" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=371}
  get-tuple-element.606 = f32[2,2048]{1,0} get-tuple-element(fusion.331), index=0
  get-tuple-element.604 = f32[2,2048]{1,0} get-tuple-element(fusion.330), index=0
  get-tuple-element.605 = f32[2,2048,8192]{2,1,0} get-tuple-element(fusion.330), index=1
  get-tuple-element.607 = f32[2,2048,8192]{2,1,0} get-tuple-element(fusion.331), index=1
  fusion.329 = f32[2,2048,8192]{2,1,0} fusion(get-tuple-element.606, get-tuple-element.604, get-tuple-element.605, fusion.341, get-tuple-element.607), kind=kLoop, calls=fused_computation.329, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/layer_norm/add_any" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=370}
  get-tuple-element.660 = f32[32768]{0} get-tuple-element(fusion.444), index=0
  all-reduce.43 = f32[32768]{0} all-reduce(get-tuple-element.660), channel_id=95, replica_groups={{0}}, to_apply=region_15.791, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/ffn_layer1/bias/reduce_sum[axes=(0, 1)]" source_file="/pax/praxis/praxis/layers/linears.py" source_line=143}
  fusion.328 = f32[8,32768]{1,0} fusion(all-reduce.43), kind=kLoop, calls=fused_computation.328, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  broadcast.1809 = f32[8,1024,32768]{2,1,0} broadcast(constant.1007), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/broadcast_in_dim[shape=(8, 8192, 32768) broadcast_dimensions=()]" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  get-tuple-element.662 = f32[8192]{0} get-tuple-element(fusion.443), index=0
  all-reduce.44 = f32[8192]{0} all-reduce(get-tuple-element.662), channel_id=96, replica_groups={{0}}, to_apply=region_15.791, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/ffn_layer2/bias/reduce_sum[axes=(0, 1)]" source_file="/pax/praxis/praxis/layers/linears.py" source_line=143}
  get-tuple-element.670 = f32[2,2048,8192]{2,1,0} get-tuple-element(fusion.354), index=1
  fusion.325 = (f32[8192]{0}, f32[8192]{0}) fusion(get-tuple-element.670, custom-call.46), kind=kInput, calls=fused_computation.325, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/reduce_sum[axes=(0, 1)]" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=376}
  get-tuple-element.659 = f32[8192]{0} get-tuple-element(fusion.325), index=1
  all-reduce.45 = f32[8192]{0} all-reduce(get-tuple-element.659), channel_id=97, replica_groups={{0}}, to_apply=region_15.791, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/reduce_sum[axes=(0, 1)]" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=378}
  get-tuple-element.658 = f32[8192]{0} get-tuple-element(fusion.325), index=0
  all-reduce.46 = f32[8192]{0} all-reduce(get-tuple-element.658), channel_id=98, replica_groups={{0}}, to_apply=region_15.791, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/reduce_sum[axes=(0, 1)]" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=376}
  get-tuple-element.676 = f32[2,2048,8192]{2,1,0} get-tuple-element(fusion.369), index=1
  fusion.322 = (f32[8192]{0}, f32[8192]{0}) fusion(get-tuple-element.676, custom-call.52), kind=kInput, calls=fused_computation.322, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/layer_norm/reduce_sum[axes=(0, 1)]" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=376}
  get-tuple-element.610 = f32[8192]{0} get-tuple-element(fusion.322), index=1
  all-reduce.47 = f32[8192]{0} all-reduce(get-tuple-element.610), channel_id=99, replica_groups={{0}}, to_apply=region_15.791, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/layer_norm/reduce_sum[axes=(0, 1)]" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=378}
  get-tuple-element.609 = f32[8192]{0} get-tuple-element(fusion.322), index=0
  fusion.320 = f32[256,64]{1,0} fusion(fusion.337, fusion.368), kind=kInput, calls=fused_computation.320
  reduce.185 = f32[64]{0} reduce(fusion.320, constant.1007), dimensions={0}, to_apply=region_15.791, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._scale_query/per_dim_scale/reduce_sum[axes=(0, 1, 2)]" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=404}
  all-reduce.58 = (f32[8192]{0}, f32[64]{0}) all-reduce(get-tuple-element.609, reduce.185), channel_id=100, replica_groups={{0}}, to_apply=region_15.791
  get-tuple-element.745 = f32[8192]{0} get-tuple-element(all-reduce.58), index=0, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/layer_norm/reduce_sum[axes=(0, 1)]" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=376}
  fusion.482 = (f32[8,8192]{1,0}, f32[8,8192]{1,0}, f32[8,8192]{1,0}, f32[8,8192]{1,0}, f32[8,8192]{1,0}) fusion(all-reduce.44, all-reduce.45, all-reduce.46, all-reduce.47, get-tuple-element.745), kind=kLoop, calls=horizontally_fused_computation.4
  get-tuple-element.717 = f32[8,8192]{1,0} get-tuple-element(fusion.482), index=0
  bitcast.8206 = f32[8,8192]{1,0} bitcast(get-tuple-element.717), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  broadcast.2086 = f32[8,32768,1024]{1,2,0} broadcast(constant.1007), dimensions={}
  get-tuple-element.718 = f32[8,8192]{1,0} get-tuple-element(fusion.482), index=1
  bitcast.8207 = f32[8,8192]{1,0} bitcast(get-tuple-element.718), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  get-tuple-element.719 = f32[8,8192]{1,0} get-tuple-element(fusion.482), index=2
  bitcast.8208 = f32[8,8192]{1,0} bitcast(get-tuple-element.719), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  get-tuple-element.720 = f32[8,8192]{1,0} get-tuple-element(fusion.482), index=3
  bitcast.8209 = f32[8,8192]{1,0} bitcast(get-tuple-element.720), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  get-tuple-element.721 = f32[8,8192]{1,0} get-tuple-element(fusion.482), index=4
  bitcast.8210 = f32[8,8192]{1,0} bitcast(get-tuple-element.721), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  broadcast.2089 = f32[8,3,1024,128,64]{4,3,1,2,0} broadcast(constant.1007), dimensions={}
  get-tuple-element.746 = f32[64]{0} get-tuple-element(all-reduce.58), index=1, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._scale_query/per_dim_scale/reduce_sum[axes=(0, 1, 2)]" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=404}
  fusion.319 = f32[8,64]{1,0} fusion(get-tuple-element.746, param.19), kind=kLoop, calls=fused_computation.319, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/dynamic_update_slice" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  broadcast.1817 = f32[8,1024,128,64]{3,2,1,0} broadcast(constant.1007), dimensions={}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/broadcast_in_dim[shape=(8, 8192, 128, 64) broadcast_dimensions=()]" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  get-tuple-element.697 = f32[2,2048,2048]{2,1,0} get-tuple-element(fusion.418), index=1
  bitcast.2648 = f32[2,1,2048,2048]{3,2,0,1} bitcast(get-tuple-element.697)
  fusion.318 = f32[1,1024,3,128,64]{4,3,2,1,0} fusion(param.18), kind=kLoop, calls=fused_computation.318, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/dynamic_slice[slice_sizes=(1, 3, 8192, 128, 64)]" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  bitcast.3323 = f32[3,1024,128,64]{3,2,0,1} bitcast(fusion.318)
  all-gather.40 = f32[3,8192,128,64]{3,2,0,1} all-gather(bitcast.3323), channel_id=102, replica_groups={{0,1,2,3,4,5,6,7}}, dimensions={1}, use_global_device_ids=true, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/combined_qkv/einsum/ABD,KDNH->KABNH/dot_general[dimension_numbers=(((1,), (2,)), ((), ())) precision=None preferred_element_type=float32]" source_file="/pax/praxis/praxis/layers/base_ops.py" source_line=42}
  fusion.317 = f32[1,1024,32768]{2,1,0} fusion(param.13), kind=kInput, calls=fused_computation.317, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/dynamic_slice[slice_sizes=(1, 32768, 8192)]" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  bitcast.3331 = f32[32768,1024]{0,1} bitcast(fusion.317)
  all-gather.41 = f32[32768,8192]{0,1} all-gather(bitcast.3331), channel_id=103, replica_groups={{0,1,2,3,4,5,6,7}}, dimensions={1}, use_global_device_ids=true, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/ffn_layer2/linear/einsum/...y,yz->...z/dot_general[dimension_numbers=(((2,), (1,)), ((), ())) precision=None preferred_element_type=float32]" source_file="/pax/praxis/praxis/layers/base_ops.py" source_line=42}
  constant.1643 = s32[] constant(2)
  constant.1528 = s32[] constant(7)
  bitcast.3339 = f32[8192,4096]{0,1} bitcast(get-tuple-element.669)
  custom-call.53 = f32[8192,32768]{1,0} custom-call(bitcast.3339, bitcast.3341), custom_call_target="__cublas$gemm", metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/ffn_layer1/linear/einsum/...y,yz->...z/transpose[permutation=(1, 0)]" source_file="/pax/praxis/praxis/layers/base_ops.py" source_line=42}, backend_config={"alpha_real":1,"alpha_imag":0,"beta":0,"dot_dimension_numbers":{"lhs_contracting_dimensions":["1"],"rhs_contracting_dimensions":["0"],"lhs_batch_dimensions":[],"rhs_batch_dimensions":[]},"precision_config":{"operand_precision":["DEFAULT","DEFAULT"]},"epilogue":"DEFAULT"}
  get-tuple-element.668 = f32[2,2048,32768]{2,1,0} get-tuple-element(fusion.444), index=2
  bitcast.3353 = f32[32768,4096]{0,1} bitcast(get-tuple-element.668)
  custom-call.54 = f32[32768,8192]{1,0} custom-call(bitcast.3353, bitcast.3355), custom_call_target="__cublas$gemm", metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/ffn_layer2/linear/einsum/...y,yz->...z/transpose[permutation=(1, 0)]" source_file="/pax/praxis/praxis/layers/base_ops.py" source_line=42}, backend_config={"alpha_real":1,"alpha_imag":0,"beta":0,"dot_dimension_numbers":{"lhs_contracting_dimensions":["1"],"rhs_contracting_dimensions":["0"],"lhs_batch_dimensions":[],"rhs_batch_dimensions":[]},"precision_config":{"operand_precision":["DEFAULT","DEFAULT"]},"epilogue":"DEFAULT"}
  get-tuple-element.631 = f32[3,128,64,2,2048]{4,3,2,1,0} get-tuple-element(fusion.464), index=1
  bitcast.3364 = f32[24576,4096]{1,0} bitcast(get-tuple-element.631)
  bitcast.3368 = f32[4096,8192]{1,0} bitcast(get-tuple-element.675)
  custom-call.55 = f32[24576,8192]{1,0} custom-call(bitcast.3364, bitcast.3368), custom_call_target="__cublas$gemm", metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/combined_qkv/einsum/ABD,KDNH->KABNH/dot_general[dimension_numbers=(((3, 4), (0, 1)), ((), ())) precision=None preferred_element_type=float32]" source_file="/pax/praxis/praxis/layers/base_ops.py" source_line=42}, backend_config={"alpha_real":1,"alpha_imag":0,"beta":0,"dot_dimension_numbers":{"lhs_contracting_dimensions":["1"],"rhs_contracting_dimensions":["0"],"lhs_batch_dimensions":[],"rhs_batch_dimensions":[]},"precision_config":{"operand_precision":["DEFAULT","DEFAULT"]},"epilogue":"DEFAULT"}
  bitcast.3372 = f32[3,128,64,8192]{3,2,1,0} bitcast(custom-call.55)
  bitcast.3376 = f32[8192,4096]{0,1} bitcast(fusion.341)
  custom-call.56 = f32[8192,8192]{1,0} custom-call(bitcast.3376, bitcast.3378), custom_call_target="__cublas$gemm", metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/post/einsum/ABNH,DNH->ABD/dot_general[dimension_numbers=(((0, 1), (0, 1)), ((), ())) precision=None preferred_element_type=float32]" source_file="/pax/praxis/praxis/layers/base_ops.py" source_line=42}, backend_config={"alpha_real":1,"alpha_imag":0,"beta":0,"dot_dimension_numbers":{"lhs_contracting_dimensions":["1"],"rhs_contracting_dimensions":["0"],"lhs_batch_dimensions":[],"rhs_batch_dimensions":[]},"precision_config":{"operand_precision":["DEFAULT","DEFAULT"]},"epilogue":"DEFAULT"}
  bitcast.3382 = f32[8192,128,64]{2,1,0} bitcast(custom-call.56)
  tuple.25 = (s32[], f32[2,2048,8192]{2,1,0}, f32[8,32768]{1,0}, f32[8,1024,32768]{2,1,0}, f32[8,8192]{1,0}, /*index=5*/f32[8,32768,1024]{1,2,0}, f32[8,8192]{1,0}, f32[8,8192]{1,0}, f32[8,8192]{1,0}, f32[8,8192]{1,0}, /*index=10*/f32[8,3,1024,128,64]{4,3,1,2,0}, f32[8,64]{1,0}, f32[8,1024,128,64]{3,2,1,0}, f32[8,32768]{1,0}, f32[8,1024,32768]{2,1,0}, /*index=15*/f32[8,32768,1024]{1,2,0}, f32[8,8192]{1,0}, f32[8,8192]{1,0}, f32[8,8192]{1,0}, f32[8,8192]{1,0}, /*index=20*/f32[8,3,1024,128,64]{4,3,1,2,0}, f32[8,64]{1,0}, f32[8,1024,128,64]{3,2,1,0}, f32[8,2,2048,8192]{3,2,1,0}, f32[2,1,2048,2048]{3,2,0,1}, /*index=25*/f32[2,2048]{1,0}, f32[3,8192,128,64]{3,2,0,1}, f32[32768,8192]{0,1}, s32[], s32[], /*index=30*/f32[8192,32768]{1,0}, f32[32768,8192]{1,0}, f32[3,128,64,8192]{3,2,1,0}, f32[8192,128,64]{2,1,0}) tuple(constant.1407, fusion.329, fusion.328, broadcast.1809, bitcast.8206, /*index=5*/broadcast.2086, bitcast.8207, bitcast.8208, bitcast.8209, bitcast.8210, /*index=10*/broadcast.2089, fusion.319, broadcast.1817, param.10, param.11, /*index=15*/bitcast.1964, param.14, param.15, param.16, param.17, /*index=20*/bitcast.1975, param.19, param.20, fusion.375, bitcast.2648, /*index=25*/param.21, all-gather.40, all-gather.41, constant.1643, constant.1528, /*index=30*/custom-call.53, custom-call.54, bitcast.3372, bitcast.3382)
  while.6 = (s32[], f32[2,2048,8192]{2,1,0}, f32[8,32768]{1,0}, f32[8,1024,32768]{2,1,0}, f32[8,8192]{1,0}, /*index=5*/f32[8,32768,1024]{1,2,0}, f32[8,8192]{1,0}, f32[8,8192]{1,0}, f32[8,8192]{1,0}, f32[8,8192]{1,0}, /*index=10*/f32[8,3,1024,128,64]{4,3,1,2,0}, f32[8,64]{1,0}, f32[8,1024,128,64]{3,2,1,0}, f32[8,32768]{1,0}, f32[8,1024,32768]{2,1,0}, /*index=15*/f32[8,32768,1024]{1,2,0}, f32[8,8192]{1,0}, f32[8,8192]{1,0}, f32[8,8192]{1,0}, f32[8,8192]{1,0}, /*index=20*/f32[8,3,1024,128,64]{4,3,1,2,0}, f32[8,64]{1,0}, f32[8,1024,128,64]{3,2,1,0}, f32[8,2,2048,8192]{3,2,1,0}, f32[2,1,2048,2048]{3,2,0,1}, /*index=25*/f32[2,2048]{1,0}, f32[3,8192,128,64]{3,2,0,1}, f32[32768,8192]{0,1}, s32[], s32[], /*index=30*/f32[8192,32768]{1,0}, f32[32768,8192]{1,0}, f32[3,128,64,8192]{3,2,1,0}, f32[8192,128,64]{2,1,0}) while(tuple.25), condition=region_65.1623_spmd.1.clone, body=region_32.1118_spmd.1.clone, backend_config={"known_trip_count":{"n":"6"}}
  get-tuple-element.264 = s32[] get-tuple-element(while.6), index=0
  get-tuple-element.267 = f32[3,8192,128,64]{3,2,0,1} get-tuple-element(while.6), index=26
  bitcast.3963 = f32[24576,8192]{0,1} bitcast(get-tuple-element.267)
  get-tuple-element.270 = f32[8,8192]{1,0} get-tuple-element(while.6), index=18
  get-tuple-element.269 = f32[8,8192]{1,0} get-tuple-element(while.6), index=19
  fusion.310 = f32[1,8192]{1,0} fusion(get-tuple-element.269, get-tuple-element.264), kind=kLoop, calls=fused_computation.310, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/layer_norm/add" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=376}
  get-tuple-element.268 = f32[8,2,2048,8192]{3,2,1,0} get-tuple-element(while.6), index=23
  fusion.442 = f32[2,2048]{1,0} fusion(get-tuple-element.268, get-tuple-element.264), kind=kInput, calls=fused_computation.442, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/layer_norm/reduce_sum[axes=(2,)]" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=370}
  fusion.313 = f32[2,2048]{1,0} fusion(fusion.442, get-tuple-element.268, get-tuple-element.264), kind=kInput, calls=fused_computation.313, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/layer_norm/reduce_sum[axes=(2,)]" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=371}
  fusion.312 = f32[2,2048]{1,0} fusion(fusion.313), kind=kLoop, calls=fused_computation.312, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/layer_norm/add" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  fusion.309 = (f32[2,2048,8192]{2,1,0}, f32[2,2048,8192]{2,1,0}, f32[1,2,2048,8192]{3,2,1,0}) fusion(get-tuple-element.270, fusion.310, get-tuple-element.264, fusion.312, fusion.442, /*index=5*/get-tuple-element.268), kind=kLoop, calls=fused_computation.309, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/layer_norm/add" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=378}
  get-tuple-element.601 = f32[2,2048,8192]{2,1,0} get-tuple-element(fusion.309), index=0
  bitcast.3461 = f32[8192,4096]{0,1} bitcast(get-tuple-element.601)
  custom-call.57 = f32[24576,4096]{1,0} custom-call(bitcast.3963, bitcast.3461), custom_call_target="__cublas$gemm", metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/combined_qkv/einsum/ABD,KDNH->KABNH/dot_general[dimension_numbers=(((1,), (2,)), ((), ())) precision=None preferred_element_type=float32]" source_file="/pax/praxis/praxis/layers/base_ops.py" source_line=42}, backend_config={"alpha_real":1,"alpha_imag":0,"beta":0,"dot_dimension_numbers":{"lhs_contracting_dimensions":["1"],"rhs_contracting_dimensions":["0"],"lhs_batch_dimensions":[],"rhs_batch_dimensions":[]},"precision_config":{"operand_precision":["DEFAULT","DEFAULT"]},"epilogue":"DEFAULT"}
  fusion.308 = f32[3,2,128,64,2048]{4,3,2,1,0} fusion(custom-call.57), kind=kLoop, calls=fused_computation.308, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/combined_qkv/einsum/ABD,KDNH->KABNH/dot_general[dimension_numbers=(((1,), (2,)), ((), ())) precision=None preferred_element_type=float32]" source_file="/pax/praxis/praxis/layers/base_ops.py" source_line=42}
  slice.76 = f32[1,2,128,64,2048]{4,3,2,1,0} slice(fusion.308), slice={[2:3], [0:2], [0:128], [0:64], [0:2048]}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/combined_qkv/slice[start_indices=(2, 0, 0, 0, 0) limit_indices=(3, 16, 2048, 128, 64) strides=(1, 1, 1, 1, 1)]" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=882}
  bitcast.3471 = f32[256,64,2048]{2,1,0} bitcast(slice.76)
  get-tuple-element.271 = f32[2,1,2048,2048]{3,2,0,1} get-tuple-element(while.6), index=24
  fusion.307 = pred[1,2,2048,2048]{3,2,1,0} fusion(get-tuple-element.271), kind=kLoop, calls=fused_computation.307, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/ge" source_file="/pax/praxis/praxis/py_utils.py" source_line=743}
  get-tuple-element.272 = f32[8,64]{1,0} get-tuple-element(while.6), index=21
  fusion.305 = f32[64]{0} fusion(get-tuple-element.272, get-tuple-element.264), kind=kLoop, calls=fused_computation.305, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._scale_query/per_dim_scale/mul" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=403}
  fusion.304 = f32[2,128,2048,64]{3,2,1,0} fusion(fusion.305, fusion.308), kind=kInput, calls=fused_computation.304, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._scale_query/per_dim_scale/mul" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=404}
  bitcast.3531 = f32[256,2048,64]{2,1,0} bitcast(fusion.304)
  slice.78 = f32[1,2,128,64,2048]{4,3,2,1,0} slice(fusion.308), slice={[1:2], [0:2], [0:128], [0:64], [0:2048]}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/combined_qkv/slice[start_indices=(1, 0, 0, 0, 0) limit_indices=(2, 16, 2048, 128, 64) strides=(1, 1, 1, 1, 1)]" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=882}
  bitcast.3536 = f32[256,64,2048]{2,1,0} bitcast(slice.78)
  custom-call.58 = f32[256,2048,2048]{2,1,0} custom-call(bitcast.3531, bitcast.3536), custom_call_target="__cublas$gemm", metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._atten_logits/qk_einsum/BTNH,BSNH->BNTS/dot_general[dimension_numbers=(((3,), (3,)), ((0, 2), (0, 2))) precision=None preferred_element_type=float32]" source_file="/pax/praxis/praxis/layers/base_ops.py" source_line=42}, backend_config={"alpha_real":1,"alpha_imag":0,"beta":0,"dot_dimension_numbers":{"lhs_contracting_dimensions":["2"],"rhs_contracting_dimensions":["1"],"lhs_batch_dimensions":["0"],"rhs_batch_dimensions":["0"]},"precision_config":{"operand_precision":["DEFAULT","DEFAULT"]},"epilogue":"DEFAULT"}
  fusion.468 = (f32[2,128,2048]{2,1,0}, f32[2,128,2048,2048]{3,2,1,0}) fusion(fusion.307, custom-call.58), kind=kInput, calls=fused_computation.468, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/reduce_max[axes=(3,)]" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=1487}
  get-tuple-element.599 = f32[2,128,2048]{2,1,0} get-tuple-element(fusion.468), index=0
  get-tuple-element.600 = f32[2,128,2048,2048]{3,2,1,0} get-tuple-element(fusion.468), index=1
  fusion.474 = (f32[2,128,2048]{2,1,0}, f32[2,128,2048,2048]{3,2,1,0}) fusion(get-tuple-element.599, get-tuple-element.600, fusion.307), kind=kInput, calls=fused_computation.474, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/reduce_sum[axes=(3,)]" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=1487}
  get-tuple-element.598 = f32[2,128,2048,2048]{3,2,1,0} get-tuple-element(fusion.474), index=1
  get-tuple-element.597 = f32[2,128,2048]{2,1,0} get-tuple-element(fusion.474), index=0
  fusion.300 = f32[2,128,2048,2048]{3,2,1,0} fusion(get-tuple-element.598, get-tuple-element.597), kind=kLoop, calls=fused_computation.300, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/div" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=1487}
  bitcast.3569 = f32[256,2048,2048]{2,1,0} bitcast(fusion.300)
  custom-call.59 = f32[256,64,2048]{2,1,0} custom-call(bitcast.3471, bitcast.3569), custom_call_target="__cublas$gemm", metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/pv_einsum/BNTS,BSNH->BTNH/dot_general[dimension_numbers=(((1,), (3,)), ((0, 2), (0, 1))) precision=None preferred_element_type=float32]" source_file="/pax/praxis/praxis/layers/base_ops.py" source_line=42}, backend_config={"alpha_real":1,"alpha_imag":0,"beta":0,"dot_dimension_numbers":{"lhs_contracting_dimensions":["2"],"rhs_contracting_dimensions":["2"],"lhs_batch_dimensions":["0"],"rhs_batch_dimensions":["0"]},"precision_config":{"operand_precision":["DEFAULT","DEFAULT"]},"epilogue":"DEFAULT"}
  fusion.299 = f32[2,2048,128,64]{3,2,1,0} fusion(custom-call.59), kind=kInput, calls=fused_computation.299, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/pv_einsum/BNTS,BSNH->BTNH/transpose[permutation=(0, 3, 1, 2)]" source_file="/pax/praxis/praxis/layers/base_ops.py" source_line=42}
  bitcast.4379 = f32[4096,8192]{1,0} bitcast(fusion.299)
  get-tuple-element.273 = f32[8,1024,128,64]{3,2,1,0} get-tuple-element(while.6), index=22
  fusion.466 = f32[1,1024,128,64]{3,2,1,0} fusion(get-tuple-element.273, get-tuple-element.264), kind=kLoop, calls=fused_computation.466, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/dynamic_slice[slice_sizes=(1, 8192, 128, 64)]" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  bitcast.3585 = f32[1024,128,64]{2,1,0} bitcast(fusion.466)
  all-gather.35 = f32[8192,128,64]{2,1,0} all-gather(bitcast.3585), channel_id=79, replica_groups={{0,1,2,3,4,5,6,7}}, dimensions={0}, use_global_device_ids=true, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/post/einsum/ABNH,DNH->ABD/dot_general[dimension_numbers=(((3, 2), (2, 1)), ((), ())) precision=None preferred_element_type=float32]" source_file="/pax/praxis/praxis/layers/base_ops.py" source_line=42}
  bitcast.3589 = f32[8192,8192]{0,1} bitcast(all-gather.35)
  get-tuple-element.603 = f32[1,2,2048,8192]{3,2,1,0} get-tuple-element(fusion.309), index=2
  bitcast.3593 = f32[4096,8192]{1,0} bitcast(get-tuple-element.603)
  cublas-gemm.11 = f32[4096,8192]{1,0} custom-call(bitcast.4379, bitcast.3589, bitcast.3593), custom_call_target="__cublas$gemm", output_to_operand_aliasing={{}: (2, {})}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/post/einsum/ABNH,DNH->ABD/dot_general[dimension_numbers=(((3, 2), (2, 1)), ((), ())) precision=None preferred_element_type=float32]" source_file="/pax/praxis/praxis/layers/base_ops.py" source_line=42}, backend_config={"alpha_real":1,"alpha_imag":0,"beta":1,"dot_dimension_numbers":{"lhs_contracting_dimensions":["1"],"rhs_contracting_dimensions":["0"],"lhs_batch_dimensions":[],"rhs_batch_dimensions":[]},"precision_config":{"operand_precision":["DEFAULT","DEFAULT"]},"epilogue":"DEFAULT"}
  fusion.441 = f32[2,2048]{1,0} fusion(cublas-gemm.11), kind=kInput, calls=fused_computation.441, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/reduce_sum[axes=(2,)]" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=370}
  fusion.297 = f32[2,2048]{1,0} fusion(fusion.441, cublas-gemm.11), kind=kInput, calls=fused_computation.297, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/reduce_sum[axes=(2,)]" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=371}
  fusion.296 = f32[2,2048]{1,0} fusion(fusion.297), kind=kLoop, calls=fused_computation.296, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/add" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  get-tuple-element.274 = f32[8,8192]{1,0} get-tuple-element(while.6), index=17
  fusion.294 = f32[1,8192]{1,0} fusion(get-tuple-element.274, get-tuple-element.264), kind=kLoop, calls=fused_computation.294, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/add" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=376}
  get-tuple-element.275 = f32[8,8192]{1,0} get-tuple-element(while.6), index=16
  fusion.293 = (f32[2,2048,8192]{2,1,0}, f32[2,2048,8192]{2,1,0}) fusion(get-tuple-element.275, fusion.294, get-tuple-element.264, fusion.296, fusion.441, /*index=5*/cublas-gemm.11), kind=kLoop, calls=fused_computation.293, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/add" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=378}
  get-tuple-element.595 = f32[2,2048,8192]{2,1,0} get-tuple-element(fusion.293), index=0
  bitcast.3659 = f32[4096,8192]{1,0} bitcast(get-tuple-element.595)
  get-tuple-element.276 = f32[8,1024,32768]{2,1,0} get-tuple-element(while.6), index=14
  fusion.467 = f32[1,1024,32768]{2,1,0} fusion(get-tuple-element.276, get-tuple-element.264), kind=kLoop, calls=fused_computation.467, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/dynamic_slice[slice_sizes=(1, 8192, 32768)]" source_file="/usr/local/lib/python3.10/dist-packages/flax/core/axes_scan.py" source_line=149}
  bitcast.3668 = f32[1024,32768]{1,0} bitcast(fusion.467)
  all-gather.36 = f32[8192,32768]{1,0} all-gather(bitcast.3668), channel_id=80, replica_groups={{0,1,2,3,4,5,6,7}}, dimensions={0}, use_global_device_ids=true, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/ffn_layer1/linear/einsum/...y,yz->...z/dot_general[dimension_numbers=(((2,), (0,)), ((), ())) precision=None preferred_element_type=float32]" source_file="/pax/praxis/praxis/layers/base_ops.py" source_line=42}
  custom-call.61 = f32[4096,32768]{1,0} custom-call(bitcast.3659, all-gather.36), custom_call_target="__cublas$gemm", metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/ffn_layer1/linear/einsum/...y,yz->...z/dot_general[dimension_numbers=(((2,), (0,)), ((), ())) precision=None preferred_element_type=float32]" source_file="/pax/praxis/praxis/layers/base_ops.py" source_line=42}, backend_config={"alpha_real":1,"alpha_imag":0,"beta":0,"dot_dimension_numbers":{"lhs_contracting_dimensions":["1"],"rhs_contracting_dimensions":["0"],"lhs_batch_dimensions":[],"rhs_batch_dimensions":[]},"precision_config":{"operand_precision":["DEFAULT","DEFAULT"]},"epilogue":"DEFAULT"}
  get-tuple-element.277 = f32[8,32768]{1,0} get-tuple-element(while.6), index=13
  fusion.289 = f32[2,2048,32768]{2,1,0} fusion(custom-call.61, get-tuple-element.277, get-tuple-element.264), kind=kLoop, calls=fused_computation.289, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/ffn_layer1/activation/tanh" source_file="/pax/praxis/praxis/layers/activations.py" source_line=157}
  get-tuple-element.278 = f32[2,2048]{1,0} get-tuple-element(while.6), index=25, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/broadcast_in_dim[shape=(16, 2048, 1) broadcast_dimensions=(0, 1)]" source_file="/pax/praxis/praxis/layers/transformers.py" source_line=428}
  fusion.291 = f32[2,2048]{1,0} fusion(get-tuple-element.278), kind=kLoop, calls=fused_computation.291, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/sub" source_file="/pax/praxis/praxis/layers/transformers.py" source_line=468}
  get-tuple-element.265 = f32[2,2048,8192]{2,1,0} get-tuple-element(while.6), index=1
  fusion.438 = (f32[8192]{0}, f32[2,2048,8192]{2,1,0}) fusion(get-tuple-element.265, fusion.291), kind=kInput, calls=fused_computation.438, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/ffn_layer2/bias/reduce_sum[axes=(0, 1)]" source_file="/pax/praxis/praxis/layers/linears.py" source_line=143}
  get-tuple-element.593 = f32[2,2048,8192]{2,1,0} get-tuple-element(fusion.438), index=1
  bitcast.4147 = f32[4096,8192]{1,0} bitcast(get-tuple-element.593)
  get-tuple-element.280 = f32[32768,8192]{0,1} get-tuple-element(while.6), index=27
  custom-call.62 = f32[4096,32768]{1,0} custom-call(bitcast.4147, get-tuple-element.280), custom_call_target="__cublas$gemm", metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/ffn_layer2/linear/einsum/...y,yz->...z/dot_general[dimension_numbers=(((2,), (1,)), ((), ())) precision=None preferred_element_type=float32]" source_file="/pax/praxis/praxis/layers/base_ops.py" source_line=42}, backend_config={"alpha_real":1,"alpha_imag":0,"beta":0,"dot_dimension_numbers":{"lhs_contracting_dimensions":["1"],"rhs_contracting_dimensions":["1"],"lhs_batch_dimensions":[],"rhs_batch_dimensions":[]},"precision_config":{"operand_precision":["DEFAULT","DEFAULT"]},"epilogue":"DEFAULT"}
  fusion.437 = (f32[32768]{0}, f32[2,2048,32768]{2,1,0}, f32[2,2048,32768]{2,1,0}) fusion(fusion.289, fusion.291, custom-call.62, custom-call.61, get-tuple-element.277, /*index=5*/get-tuple-element.264), kind=kInput, calls=fused_computation.437, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/ffn_layer1/bias/reduce_sum[axes=(0, 1)]" source_file="/pax/praxis/praxis/layers/linears.py" source_line=143}
  get-tuple-element.591 = f32[2,2048,32768]{2,1,0} get-tuple-element(fusion.437), index=1
  bitcast.4078 = f32[4096,32768]{1,0} bitcast(get-tuple-element.591)
  custom-call.63 = f32[4096,8192]{1,0} custom-call(bitcast.4078, all-gather.36), custom_call_target="__cublas$gemm", metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/ffn_layer1/linear/einsum/...y,yz->...z/dot_general[dimension_numbers=(((2,), (1,)), ((), ())) precision=None preferred_element_type=float32]" source_file="/pax/praxis/praxis/layers/base_ops.py" source_line=42}, backend_config={"alpha_real":1,"alpha_imag":0,"beta":0,"dot_dimension_numbers":{"lhs_contracting_dimensions":["1"],"rhs_contracting_dimensions":["1"],"lhs_batch_dimensions":[],"rhs_batch_dimensions":[]},"precision_config":{"operand_precision":["DEFAULT","DEFAULT"]},"epilogue":"DEFAULT"}
  fusion.281 = (f32[2,2048]{1,0}, f32[2,2048,8192]{2,1,0}, f32[2,2048]{1,0}) fusion(fusion.296, fusion.294, custom-call.63, fusion.441, cublas-gemm.11), kind=kInput, calls=fused_computation.281, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/reduce_sum[axes=(2,)]" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  get-tuple-element.587 = f32[2,2048]{1,0} get-tuple-element(fusion.281), index=2
  fusion.282 = (f32[2,2048]{1,0}, f32[2,2048,8192]{2,1,0}) fusion(fusion.296, get-tuple-element.587, fusion.441, cublas-gemm.11), kind=kInput, calls=fused_computation.282, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/reduce_sum[axes=(2,)]" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=371}
  get-tuple-element.585 = f32[2,2048]{1,0} get-tuple-element(fusion.282), index=0
  get-tuple-element.583 = f32[2,2048]{1,0} get-tuple-element(fusion.281), index=0
  get-tuple-element.584 = f32[2,2048,8192]{2,1,0} get-tuple-element(fusion.281), index=1
  get-tuple-element.586 = f32[2,2048,8192]{2,1,0} get-tuple-element(fusion.282), index=1
  fusion.280 = f32[2,2048,8192]{2,1,0} fusion(get-tuple-element.585, get-tuple-element.583, get-tuple-element.584, get-tuple-element.265, get-tuple-element.586), kind=kLoop, calls=fused_computation.280, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/add_any" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=370}
  bitcast.4377 = f32[8192,4096]{0,1} bitcast(fusion.280)
  custom-call.74 = f32[8192,8192]{1,0} custom-call(bitcast.4377, bitcast.4379), custom_call_target="__cublas$gemm", metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/post/einsum/ABNH,DNH->ABD/dot_general[dimension_numbers=(((0, 1), (0, 1)), ((), ())) precision=None preferred_element_type=float32]" source_file="/pax/praxis/praxis/layers/base_ops.py" source_line=42}, backend_config={"alpha_real":1,"alpha_imag":0,"beta":0,"dot_dimension_numbers":{"lhs_contracting_dimensions":["1"],"rhs_contracting_dimensions":["0"],"lhs_batch_dimensions":[],"rhs_batch_dimensions":[]},"precision_config":{"operand_precision":["DEFAULT","DEFAULT"]},"epilogue":"DEFAULT"}
  bitcast.4383 = f32[8192,128,64]{2,1,0} bitcast(custom-call.74)
  reduce-scatter.14 = f32[1024,128,64]{2,1,0} reduce-scatter(bitcast.4383), channel_id=92, replica_groups={{0}}, dimensions={0}, to_apply=region_15.791
  get-tuple-element.393 = f32[8,1024,128,64]{3,2,1,0} get-tuple-element(while.6), index=12
  get-tuple-element.358 = s32[] get-tuple-element(while.6), index=29
  get-tuple-element.395 = f32[8192,128,64]{2,1,0} get-tuple-element(while.6), index=33
  reduce-scatter.26 = f32[1024,128,64]{2,1,0} reduce-scatter(get-tuple-element.395), channel_id=111, replica_groups={{0}}, dimensions={0}, to_apply=region_15.791
  fusion.233 = f32[8192]{0} fusion(get-tuple-element.264, reduce-scatter.14, get-tuple-element.393, get-tuple-element.358, reduce-scatter.26), kind=kInput, calls=fused_computation.233, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/reduce_sum[axes=(0, 1, 2, 3)]" source_file="/pax/paxml/paxml/learners.py" source_line=47}
  reduce.85 = f32[] reduce(fusion.233, constant.1007), dimensions={0}, to_apply=region_15.791, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/reduce_sum[axes=(0, 1, 2, 3)]" source_file="/pax/paxml/paxml/learners.py" source_line=47}
  bitcast.3828 = f32[4096,8192]{1,0} bitcast(fusion.280)
  bitcast.3832 = f32[8192,8192]{1,0} bitcast(all-gather.35)
  custom-call.64 = f32[4096,8192]{1,0} custom-call(bitcast.3828, bitcast.3832), custom_call_target="__cublas$gemm", metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/post/einsum/ABNH,DNH->ABD/dot_general[dimension_numbers=(((2,), (0,)), ((), ())) precision=None preferred_element_type=float32]" source_file="/pax/praxis/praxis/layers/base_ops.py" source_line=42}, backend_config={"alpha_real":1,"alpha_imag":0,"beta":0,"dot_dimension_numbers":{"lhs_contracting_dimensions":["1"],"rhs_contracting_dimensions":["0"],"lhs_batch_dimensions":[],"rhs_batch_dimensions":[]},"precision_config":{"operand_precision":["DEFAULT","DEFAULT"]},"epilogue":"DEFAULT"}
  fusion.440 = (f32[2,128,2048,64]{3,2,1,0}, f32[2,128,64,2048]{3,2,1,0}) fusion(custom-call.64), kind=kInput, calls=fused_computation.440, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/post/einsum/ABNH,DNH->ABD/dot_general[dimension_numbers=(((2,), (0,)), ((), ())) precision=None preferred_element_type=float32]" source_file="/pax/praxis/praxis/layers/base_ops.py" source_line=42}
  get-tuple-element.581 = f32[2,128,2048,64]{3,2,1,0} get-tuple-element(fusion.440), index=0
  bitcast.3839 = f32[256,2048,64]{2,1,0} bitcast(get-tuple-element.581)
  custom-call.65 = f32[256,2048,2048]{2,1,0} custom-call(bitcast.3839, bitcast.3471), custom_call_target="__cublas$gemm", metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/pv_einsum/BNTS,BSNH->BTNH/dot_general[dimension_numbers=(((2,), (3,)), ((0, 1), (0, 2))) precision=None preferred_element_type=float32]" source_file="/pax/praxis/praxis/layers/base_ops.py" source_line=42}, backend_config={"alpha_real":1,"alpha_imag":0,"beta":0,"dot_dimension_numbers":{"lhs_contracting_dimensions":["2"],"rhs_contracting_dimensions":["1"],"lhs_batch_dimensions":["0"],"rhs_batch_dimensions":["0"]},"precision_config":{"operand_precision":["DEFAULT","DEFAULT"]},"epilogue":"DEFAULT"}
  fusion.279 = f32[2,128,2048]{2,1,0} fusion(get-tuple-element.598, get-tuple-element.597, custom-call.65), kind=kInput, calls=fused_computation.279, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/reduce_sum[axes=(3,)]" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=1487}
  fusion.278 = f32[2,128,2048,2048]{3,2,1,0} fusion(get-tuple-element.600, get-tuple-element.598, fusion.279, get-tuple-element.597, custom-call.65, /*index=5*/fusion.307), kind=kLoop, calls=fused_computation.278, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._cap_logits/div" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=1384}
  bitcast.3897 = f32[256,2048,2048]{2,1,0} bitcast(fusion.278)
  fusion.277 = f32[2,128,2048,64]{3,2,1,0} fusion(fusion.308), kind=kInput, calls=fused_computation.277, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._shard_blnh/sharding_constraint[sharding=GSPMDSharding({devices=[8,1,1,1]<=[8]}) resource_env=ResourceEnv(Mesh(device_ids=array([[[0],\n        [1],\n        [2],\n        [3],\n        [4],\n        [5],\n        [6],\n        [7]]]), axis_names=(\'replica\', \'data\', \'mdl\')), ()) unconstrained_dims=set()]" source_file="/pax/praxis/praxis/py_utils.py" source_line=486}
  bitcast.3921 = f32[256,2048,64]{2,1,0} bitcast(fusion.277)
  custom-call.67 = f32[256,2048,64]{2,1,0} custom-call(bitcast.3897, bitcast.3921), custom_call_target="__cublas$gemm", metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._atten_logits/qk_einsum/BTNH,BSNH->BNTS/dot_general[dimension_numbers=(((3,), (1,)), ((0, 1), (0, 2))) precision=None preferred_element_type=float32]" source_file="/pax/praxis/praxis/layers/base_ops.py" source_line=42}, backend_config={"alpha_real":1,"alpha_imag":0,"beta":0,"dot_dimension_numbers":{"lhs_contracting_dimensions":["2"],"rhs_contracting_dimensions":["1"],"lhs_batch_dimensions":["0"],"rhs_batch_dimensions":["0"]},"precision_config":{"operand_precision":["DEFAULT","DEFAULT"]},"epilogue":"DEFAULT"}
  fusion.276 = f32[2,128,64,2048]{3,2,1,0} fusion(custom-call.67), kind=kInput, calls=fused_computation.276, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._atten_logits/qk_einsum/BTNH,BSNH->BNTS/dot_general[dimension_numbers=(((3,), (1,)), ((0, 1), (0, 2))) precision=None preferred_element_type=float32]" source_file="/pax/praxis/praxis/layers/base_ops.py" source_line=42}
  fusion.238 = f32[256,64]{1,0} fusion(fusion.276, fusion.308), kind=kInput, calls=fused_computation.238
  reduce.165 = f32[64]{0} reduce(fusion.238, constant.1007), dimensions={0}, to_apply=region_15.791, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._scale_query/per_dim_scale/reduce_sum[axes=(0, 1, 2)]" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=404}
  get-tuple-element.582 = f32[2,128,64,2048]{3,2,1,0} get-tuple-element(fusion.440), index=1
  bitcast.3944 = f32[256,64,2048]{2,1,0} bitcast(get-tuple-element.582)
  custom-call.68 = f32[256,64,2048]{2,1,0} custom-call(bitcast.3944, bitcast.3569), custom_call_target="__cublas$gemm", metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/pv_einsum/BNTS,BSNH->BTNH/dot_general[dimension_numbers=(((3,), (2,)), ((0, 1), (0, 1))) precision=None preferred_element_type=float32]" source_file="/pax/praxis/praxis/layers/base_ops.py" source_line=42}, backend_config={"alpha_real":1,"alpha_imag":0,"beta":0,"dot_dimension_numbers":{"lhs_contracting_dimensions":["2"],"rhs_contracting_dimensions":["1"],"lhs_batch_dimensions":["0"],"rhs_batch_dimensions":["0"]},"precision_config":{"operand_precision":["DEFAULT","DEFAULT"]},"epilogue":"DEFAULT"}
  custom-call.66 = f32[256,2048,64]{2,1,0} custom-call(bitcast.3897, bitcast.3531), custom_call_target="__cublas$gemm", metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._atten_logits/qk_einsum/BTNH,BSNH->BNTS/dot_general[dimension_numbers=(((2,), (1,)), ((0, 1), (0, 2))) precision=None preferred_element_type=float32]" source_file="/pax/praxis/praxis/layers/base_ops.py" source_line=42}, backend_config={"alpha_real":1,"alpha_imag":0,"beta":0,"dot_dimension_numbers":{"lhs_contracting_dimensions":["1"],"rhs_contracting_dimensions":["1"],"lhs_batch_dimensions":["0"],"rhs_batch_dimensions":["0"]},"precision_config":{"operand_precision":["DEFAULT","DEFAULT"]},"epilogue":"DEFAULT"}
  fusion.470 = (f32[2,2048,3,128,64]{4,3,2,1,0}, f32[3,128,64,2,2048]{4,3,2,1,0}) fusion(custom-call.68, fusion.276, fusion.305, custom-call.66), kind=kLoop, calls=fused_computation.470, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/combined_qkv/einsum/ABD,KDNH->KABNH/transpose[permutation=(0, 3, 4, 1, 2)]" source_file="/pax/praxis/praxis/layers/base_ops.py" source_line=42}
  get-tuple-element.580 = f32[3,128,64,2,2048]{4,3,2,1,0} get-tuple-element(fusion.470), index=1
  bitcast.4287 = f32[24576,4096]{1,0} bitcast(get-tuple-element.580)
  bitcast.4291 = f32[4096,8192]{1,0} bitcast(get-tuple-element.601)
  custom-call.73 = f32[24576,8192]{0,1} custom-call(bitcast.4287, bitcast.4291), custom_call_target="__cublas$gemm", metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/combined_qkv/einsum/ABD,KDNH->KABNH/dot_general[dimension_numbers=(((3, 4), (0, 1)), ((), ())) precision=None preferred_element_type=float32]" source_file="/pax/praxis/praxis/layers/base_ops.py" source_line=42}, backend_config={"alpha_real":1,"alpha_imag":0,"beta":0,"dot_dimension_numbers":{"lhs_contracting_dimensions":["1"],"rhs_contracting_dimensions":["0"],"lhs_batch_dimensions":[],"rhs_batch_dimensions":[]},"precision_config":{"operand_precision":["DEFAULT","DEFAULT"]},"epilogue":"DEFAULT"}
  bitcast.4295 = f32[3,128,64,8192]{2,1,0,3} bitcast(custom-call.73)
  reduce-scatter.13 = f32[3,128,64,1024]{2,1,0,3} reduce-scatter(bitcast.4295), channel_id=90, replica_groups={{0}}, dimensions={3}, to_apply=region_15.791
  get-tuple-element.369 = f32[8,3,1024,128,64]{4,3,1,2,0} get-tuple-element(while.6), index=10
  fusion.242 = f32[8,3,1024,128,64]{4,3,2,1,0} fusion(get-tuple-element.369), kind=kLoop, calls=fused_computation.242
  get-tuple-element.390 = f32[3,128,64,8192]{3,2,1,0} get-tuple-element(while.6), index=32
  transpose.234 = f32[8192,3,128,64]{3,2,1,0} transpose(get-tuple-element.390), dimensions={3,0,1,2}
  bitcast.4271 = f32[3,128,64,8192]{2,1,0,3} bitcast(transpose.234)
  reduce-scatter.24 = f32[3,128,64,1024]{2,1,0,3} reduce-scatter(bitcast.4271), channel_id=109, replica_groups={{0}}, dimensions={3}, to_apply=region_15.791
  fusion.239 = f32[8192,128]{1,0} fusion(get-tuple-element.264, reduce-scatter.13, fusion.242, get-tuple-element.358, reduce-scatter.24), kind=kInput, calls=fused_computation.239, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/reduce_sum[axes=(0, 1, 2, 3, 4)]" source_file="/pax/paxml/paxml/learners.py" source_line=47}
  reduce.281 = f32[8192]{0} reduce(fusion.239, constant.1007), dimensions={1}, to_apply=region_15.791, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/reduce_sum[axes=(0, 1, 2, 3, 4)]" source_file="/pax/paxml/paxml/learners.py" source_line=47}
  reduce.83 = f32[] reduce(reduce.281, constant.1007), dimensions={0}, to_apply=region_15.791, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/reduce_sum[axes=(0, 1, 2, 3, 4)]" source_file="/pax/paxml/paxml/learners.py" source_line=47}
  get-tuple-element.602 = f32[2,2048,8192]{2,1,0} get-tuple-element(fusion.309), index=1
  get-tuple-element.579 = f32[2,2048,3,128,64]{4,3,2,1,0} get-tuple-element(fusion.470), index=0
  bitcast.3961 = f32[4096,24576]{1,0} bitcast(get-tuple-element.579)
  custom-call.69 = f32[4096,8192]{1,0} custom-call(bitcast.3961, bitcast.3963), custom_call_target="__cublas$gemm", metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/combined_qkv/einsum/ABD,KDNH->KABNH/dot_general[dimension_numbers=(((0, 1, 2), (0, 2, 3)), ((), ())) precision=None preferred_element_type=float32]" source_file="/pax/praxis/praxis/layers/base_ops.py" source_line=42}, backend_config={"alpha_real":1,"alpha_imag":0,"beta":0,"dot_dimension_numbers":{"lhs_contracting_dimensions":["1"],"rhs_contracting_dimensions":["0"],"lhs_batch_dimensions":[],"rhs_batch_dimensions":[]},"precision_config":{"operand_precision":["DEFAULT","DEFAULT"]},"epilogue":"DEFAULT"}
  fusion.245 = (f32[8192]{0}, f32[8192]{0}) fusion(get-tuple-element.602, custom-call.69), kind=kInput, calls=fused_computation.245, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/layer_norm/reduce_sum[axes=(0, 1)]" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=376}
  get-tuple-element.577 = f32[8192]{0} get-tuple-element(fusion.245), index=0
  all-reduce.59 = (f32[], f32[64]{0}, f32[], f32[8192]{0}) all-reduce(reduce.85, reduce.165, reduce.83, get-tuple-element.577), channel_id=32, replica_groups={{0}}, to_apply=region_15.791
  get-tuple-element.747 = f32[] get-tuple-element(all-reduce.59), index=0, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/reduce_sum[axes=(0, 1, 2, 3)]" source_file="/pax/paxml/paxml/learners.py" source_line=47}
  get-tuple-element.281 = f32[8,32768]{1,0} get-tuple-element(while.6), index=2
  get-tuple-element.590 = f32[32768]{0} get-tuple-element(fusion.437), index=0
  all-reduce.36 = f32[32768]{0} all-reduce(get-tuple-element.590), channel_id=82, replica_groups={{0}}, to_apply=region_15.791, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/ffn_layer1/bias/reduce_sum[axes=(0, 1)]" source_file="/pax/praxis/praxis/layers/linears.py" source_line=143}
  fusion.265 = f32[512]{0} fusion(get-tuple-element.281, get-tuple-element.264, all-reduce.36), kind=kInput, calls=fused_computation.265, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/reduce_sum[axes=(0, 1)]" source_file="/pax/paxml/paxml/learners.py" source_line=47}
  get-tuple-element.290 = f32[8,64]{1,0} get-tuple-element(while.6), index=11
  get-tuple-element.748 = f32[64]{0} get-tuple-element(all-reduce.59), index=1, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/self_attention/self_attention._dot_atten/self_attention._scale_query/per_dim_scale/reduce_sum[axes=(0, 1, 2)]" source_file="/pax/praxis/praxis/layers/attentions.py" source_line=404}
  fusion.489 = (f32[], f32[]) fusion(fusion.265, constant.1007, get-tuple-element.290, get-tuple-element.272, get-tuple-element.264, /*index=5*/get-tuple-element.748), kind=kInput, calls=fused_computation.484, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/reduce_sum[axes=(0, 1)]" source_file="/pax/paxml/paxml/learners.py" source_line=47}
  get-tuple-element.728 = f32[] get-tuple-element(fusion.489), index=1
  get-tuple-element.749 = f32[] get-tuple-element(all-reduce.59), index=2, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/reduce_sum[axes=(0, 1, 2, 3, 4)]" source_file="/pax/paxml/paxml/learners.py" source_line=47}
  get-tuple-element.288 = f32[8,8192]{1,0} get-tuple-element(while.6), index=9
  get-tuple-element.750 = f32[8192]{0} get-tuple-element(all-reduce.59), index=3, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/layer_norm/reduce_sum[axes=(0, 1)]" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=376}
  get-tuple-element.287 = f32[8,8192]{1,0} get-tuple-element(while.6), index=8
  get-tuple-element.578 = f32[8192]{0} get-tuple-element(fusion.245), index=1
  all-reduce.40 = f32[8192]{0} all-reduce(get-tuple-element.578), channel_id=88, replica_groups={{0}}, to_apply=region_15.791, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/layer_norm/reduce_sum[axes=(0, 1)]" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=378}
  get-tuple-element.286 = f32[8,8192]{1,0} get-tuple-element(while.6), index=7
  get-tuple-element.596 = f32[2,2048,8192]{2,1,0} get-tuple-element(fusion.293), index=1
  fusion.250 = (f32[8192]{0}, f32[8192]{0}) fusion(get-tuple-element.596, custom-call.63), kind=kInput, calls=fused_computation.250, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/reduce_sum[axes=(0, 1)]" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=376}
  get-tuple-element.588 = f32[8192]{0} get-tuple-element(fusion.250), index=0
  all-reduce.39 = f32[8192]{0} all-reduce(get-tuple-element.588), channel_id=87, replica_groups={{0}}, to_apply=region_15.791, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/reduce_sum[axes=(0, 1)]" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=376}
  get-tuple-element.285 = f32[8,8192]{1,0} get-tuple-element(while.6), index=6
  get-tuple-element.589 = f32[8192]{0} get-tuple-element(fusion.250), index=1
  all-reduce.38 = f32[8192]{0} all-reduce(get-tuple-element.589), channel_id=86, replica_groups={{0}}, to_apply=region_15.791, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/layer_norm/reduce_sum[axes=(0, 1)]" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=378}
  get-tuple-element.283 = f32[8,8192]{1,0} get-tuple-element(while.6), index=4
  get-tuple-element.592 = f32[8192]{0} get-tuple-element(fusion.438), index=0
  get-tuple-element.594 = f32[2,2048,32768]{2,1,0} get-tuple-element(fusion.437), index=2
  bitcast.4145 = f32[32768,4096]{0,1} bitcast(get-tuple-element.594)
  custom-call.72 = f32[32768,8192]{0,1} custom-call(bitcast.4145, bitcast.4147), custom_call_target="__cublas$gemm", metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/ffn_layer2/linear/einsum/...y,yz->...z/transpose[permutation=(1, 0)]" source_file="/pax/praxis/praxis/layers/base_ops.py" source_line=42}, backend_config={"alpha_real":1,"alpha_imag":0,"beta":0,"dot_dimension_numbers":{"lhs_contracting_dimensions":["1"],"rhs_contracting_dimensions":["0"],"lhs_batch_dimensions":[],"rhs_batch_dimensions":[]},"precision_config":{"operand_precision":["DEFAULT","DEFAULT"]},"epilogue":"DEFAULT"}
  reduce-scatter.12 = f32[32768,1024]{0,1} reduce-scatter(custom-call.72), channel_id=85, replica_groups={{0}}, dimensions={1}, to_apply=region_15.791
  get-tuple-element.364 = f32[8,32768,1024]{1,2,0} get-tuple-element(while.6), index=5
  fusion.258 = f32[8,32768,1024]{2,1,0} fusion(get-tuple-element.364), kind=kInput, calls=fused_computation.258
  get-tuple-element.366 = f32[32768,8192]{1,0} get-tuple-element(while.6), index=31
  transpose.230 = f32[8192,32768]{1,0} transpose(get-tuple-element.366), dimensions={1,0}
  bitcast.4126 = f32[32768,8192]{0,1} bitcast(transpose.230)
  reduce-scatter.22 = f32[32768,1024]{0,1} reduce-scatter(bitcast.4126), channel_id=107, replica_groups={{0}}, dimensions={1}, to_apply=region_15.791
  fusion.254 = f32[16384,128]{1,0} fusion(get-tuple-element.264, reduce-scatter.12, fusion.258, get-tuple-element.358, reduce-scatter.22), kind=kInput, calls=fused_computation.254, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/reduce_sum[axes=(0, 1, 2)]" source_file="/pax/paxml/paxml/learners.py" source_line=47}
  reduce.271 = f32[16384]{0} reduce(fusion.254, constant.1007), dimensions={1}, to_apply=region_15.791, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/reduce_sum[axes=(0, 1, 2)]" source_file="/pax/paxml/paxml/learners.py" source_line=47}
  fusion.253 = f32[128]{0} fusion(reduce.271), kind=kInput, calls=fused_computation.253, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/reduce_sum[axes=(0, 1, 2)]" source_file="/pax/paxml/paxml/learners.py" source_line=47}
  reduce.78 = f32[] reduce(fusion.253, constant.1007), dimensions={0}, to_apply=region_15.791, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/reduce_sum[axes=(0, 1, 2)]" source_file="/pax/paxml/paxml/learners.py" source_line=47}
  get-tuple-element.359 = f32[8,1024,32768]{2,1,0} get-tuple-element(while.6), index=3
  get-tuple-element.361 = f32[8192,32768]{1,0} get-tuple-element(while.6), index=30
  reduce-scatter.20 = f32[1024,32768]{1,0} reduce-scatter(get-tuple-element.361), channel_id=105, replica_groups={{0}}, dimensions={0}, to_apply=region_15.791
  fusion.264 = f32[8,1024,32768]{2,1,0} fusion(get-tuple-element.359, get-tuple-element.358, reduce-scatter.20), kind=kLoop, calls=fused_computation.264
  bitcast.4076 = f32[8192,4096]{0,1} bitcast(get-tuple-element.595)
  custom-call.71 = f32[8192,32768]{1,0} custom-call(bitcast.4076, bitcast.4078), custom_call_target="__cublas$gemm", metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/ffn_layer1/linear/einsum/...y,yz->...z/transpose[permutation=(1, 0)]" source_file="/pax/praxis/praxis/layers/base_ops.py" source_line=42}, backend_config={"alpha_real":1,"alpha_imag":0,"beta":0,"dot_dimension_numbers":{"lhs_contracting_dimensions":["1"],"rhs_contracting_dimensions":["0"],"lhs_batch_dimensions":[],"rhs_batch_dimensions":[]},"precision_config":{"operand_precision":["DEFAULT","DEFAULT"]},"epilogue":"DEFAULT"}
  reduce-scatter.11 = f32[1024,32768]{1,0} reduce-scatter(custom-call.71), channel_id=83, replica_groups={{0}}, dimensions={0}, to_apply=region_15.791
  fusion.262 = f32[16384,128]{1,0} fusion(fusion.264, get-tuple-element.264, reduce-scatter.11), kind=kInput, calls=fused_computation.262, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/reduce_sum[axes=(0, 1, 2)]" source_file="/pax/paxml/paxml/learners.py" source_line=47}
  reduce.267 = f32[16384]{0} reduce(fusion.262, constant.1007), dimensions={1}, to_apply=region_15.791, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/reduce_sum[axes=(0, 1, 2)]" source_file="/pax/paxml/paxml/learners.py" source_line=47}
  fusion.261 = f32[128]{0} fusion(reduce.267), kind=kInput, calls=fused_computation.261, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/reduce_sum[axes=(0, 1, 2)]" source_file="/pax/paxml/paxml/learners.py" source_line=47}
  reduce.76 = f32[] reduce(fusion.261, constant.1007), dimensions={0}, to_apply=region_15.791, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/reduce_sum[axes=(0, 1, 2)]" source_file="/pax/paxml/paxml/learners.py" source_line=47}
  bitcast.2502 = f32[8192,4096]{0,1} bitcast(get-tuple-element.685)
  fusion.269 = (f32[2,2048]{1,0}, f32[2,2048,8192]{2,1,0}, f32[2,2048]{1,0}) fusion(fusion.312, fusion.310, custom-call.69, fusion.442, get-tuple-element.268, /*index=5*/get-tuple-element.264), kind=kInput, calls=fused_computation.269, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/layer_norm/reduce_sum[axes=(2,)]" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=372}
  get-tuple-element.576 = f32[2,2048]{1,0} get-tuple-element(fusion.269), index=2
  fusion.270 = (f32[2,2048]{1,0}, f32[2,2048,8192]{2,1,0}) fusion(fusion.312, get-tuple-element.576, fusion.442, get-tuple-element.268, get-tuple-element.264), kind=kInput, calls=fused_computation.270, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/layer_norm/reduce_sum[axes=(2,)]" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=371}
  get-tuple-element.574 = f32[2,2048]{1,0} get-tuple-element(fusion.270), index=0
  get-tuple-element.572 = f32[2,2048]{1,0} get-tuple-element(fusion.269), index=0
  get-tuple-element.573 = f32[2,2048,8192]{2,1,0} get-tuple-element(fusion.269), index=1
  get-tuple-element.575 = f32[2,2048,8192]{2,1,0} get-tuple-element(fusion.270), index=1
  fusion.268 = f32[2,2048,8192]{2,1,0} fusion(get-tuple-element.574, get-tuple-element.572, get-tuple-element.573, fusion.280, get-tuple-element.575), kind=kLoop, calls=fused_computation.268, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/lm._prepare_input/softmax.emb_lookup/mul" source_file="/pax/praxis/praxis/layers/embedding_softmax.py" source_line=399}
  bitcast.4023 = f32[8192,4096]{0,1} bitcast(fusion.268)
  custom-call.70 = f32[8192,32000]{1,0} custom-call(bitcast.4023, fusion.423), custom_call_target="__cublas$gemm", metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/lm._prepare_input/softmax.emb_lookup/einsum/...y,yz->...z/dot_general[dimension_numbers=(((0, 1), (0, 1)), ((), ())) precision=None preferred_element_type=float32]" source_file="/pax/praxis/praxis/layers/base_ops.py" source_line=42}, backend_config={"alpha_real":1,"alpha_imag":0,"beta":0,"dot_dimension_numbers":{"lhs_contracting_dimensions":["1"],"rhs_contracting_dimensions":["0"],"lhs_batch_dimensions":[],"rhs_batch_dimensions":[]},"precision_config":{"operand_precision":["DEFAULT","DEFAULT"]},"epilogue":"DEFAULT"}
  cublas-gemm.13 = f32[8192,32000]{1,0} custom-call(bitcast.2502, bitcast.2504, custom-call.70), custom_call_target="__cublas$gemm", output_to_operand_aliasing={{}: (2, {})}, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/lm.compute_loss/softmax/softmax.get_logits/logits_ffn/linear/einsum/...y,yz->...z/transpose[permutation=(1, 0)]" source_file="/pax/praxis/praxis/layers/base_ops.py" source_line=42}, backend_config={"alpha_real":1,"alpha_imag":0,"beta":1,"dot_dimension_numbers":{"lhs_contracting_dimensions":["1"],"rhs_contracting_dimensions":["0"],"lhs_batch_dimensions":[],"rhs_batch_dimensions":[]},"precision_config":{"operand_precision":["DEFAULT","DEFAULT"]},"epilogue":"DEFAULT"}
  reduce-scatter.6 = f32[1024,32000]{1,0} reduce-scatter(cublas-gemm.13), channel_id=48, replica_groups={{0}}, dimensions={0}, to_apply=region_15.791
  fusion.267 = f32[4096]{0} fusion(reduce-scatter.6), kind=kInput, calls=fused_computation.267, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/reduce_sum[axes=(0, 1)]" source_file="/pax/paxml/paxml/learners.py" source_line=47}
  reduce.74 = f32[] reduce(fusion.267, constant.1007), dimensions={0}, to_apply=region_15.791, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/reduce_sum[axes=(0, 1)]" source_file="/pax/paxml/paxml/learners.py" source_line=47}
  all-reduce.60 = (f32[8192]{0}, f32[], f32[], f32[]) all-reduce(get-tuple-element.592, reduce.78, reduce.76, reduce.74), channel_id=84, replica_groups={{0}}, to_apply=region_15.791
  get-tuple-element.751 = f32[8192]{0} get-tuple-element(all-reduce.60), index=0, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/transformer/repeat/repeat.call_with_custom_method/while/body/remat/sub.body_fn/sub/x_layers_0/ff_layer/ffn_layer2/bias/reduce_sum[axes=(0, 1)]" source_file="/pax/praxis/praxis/layers/linears.py" source_line=143}
  fusion.243 = (f32[256]{0}, f32[256]{0}, f32[256]{0}, f32[256]{0}, f32[256]{0}) fusion(get-tuple-element.288, get-tuple-element.264, get-tuple-element.750, get-tuple-element.287, all-reduce.40, /*index=5*/get-tuple-element.286, all-reduce.39, get-tuple-element.285, all-reduce.38, get-tuple-element.283, /*index=10*/get-tuple-element.751), kind=kInput, calls=fused_computation.243, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/reduce_sum[axes=(0, 1)]" source_file="/pax/paxml/paxml/learners.py" source_line=47}
  get-tuple-element.733 = f32[256]{0} get-tuple-element(fusion.243), index=0
  get-tuple-element.734 = f32[256]{0} get-tuple-element(fusion.243), index=1
  get-tuple-element.738 = f32[256]{0} get-tuple-element(fusion.243), index=2
  get-tuple-element.739 = f32[256]{0} get-tuple-element(fusion.243), index=3
  get-tuple-element.740 = f32[256]{0} get-tuple-element(fusion.243), index=4
  fusion.484 = (f32[], f32[], f32[], f32[], f32[]) fusion(get-tuple-element.733, constant.1007, get-tuple-element.734, get-tuple-element.738, get-tuple-element.739, /*index=5*/get-tuple-element.740), kind=kInput, calls=fused_computation.479, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/reduce_sum[axes=(0, 1)]" source_file="/pax/paxml/paxml/learners.py" source_line=47}
  get-tuple-element.722 = f32[] get-tuple-element(fusion.484), index=0
  get-tuple-element.723 = f32[] get-tuple-element(fusion.484), index=1
  get-tuple-element.724 = f32[] get-tuple-element(fusion.484), index=2
  get-tuple-element.725 = f32[] get-tuple-element(fusion.484), index=3
  get-tuple-element.752 = f32[] get-tuple-element(all-reduce.60), index=1, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/reduce_sum[axes=(0, 1, 2)]" source_file="/pax/paxml/paxml/learners.py" source_line=47}
  get-tuple-element.726 = f32[] get-tuple-element(fusion.484), index=4
  get-tuple-element.753 = f32[] get-tuple-element(all-reduce.60), index=2, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/reduce_sum[axes=(0, 1, 2)]" source_file="/pax/paxml/paxml/learners.py" source_line=47}
  get-tuple-element.727 = f32[] get-tuple-element(fusion.489), index=0
  get-tuple-element.754 = f32[] get-tuple-element(all-reduce.60), index=3, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/reduce_sum[axes=(0, 1)]" source_file="/pax/paxml/paxml/learners.py" source_line=47}
  get-tuple-element.681 = f32[32000]{0} get-tuple-element(fusion.436), index=0
  all-reduce.14 = f32[32000]{0} all-reduce(get-tuple-element.681), channel_id=10, replica_groups={{0}}, to_apply=region_15.791, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/lm.compute_loss/softmax/softmax.get_logits/logits_ffn/bias/reduce_sum[axes=(0, 1)]" source_file="/pax/praxis/praxis/layers/linears.py" source_line=143}
  fusion.384 = f32[128]{0} fusion(all-reduce.14), kind=kInput, calls=fused_computation.384, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/reduce_sum[axes=(0,)]" source_file="/pax/paxml/paxml/learners.py" source_line=47}
  fusion.483 = f32[] fusion(fusion.384, constant.1007), kind=kInput, calls=fused_computation.478, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/reduce_sum[axes=(0,)]" source_file="/pax/paxml/paxml/learners.py" source_line=47}
  get-tuple-element.680 = f32[8192]{0} get-tuple-element(fusion.386), index=1
  all-reduce.12 = f32[8192]{0} all-reduce(get-tuple-element.680), channel_id=8, replica_groups={{0}}, to_apply=region_15.791, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/transpose(jvp(xformer_lm.apply))/xformer_lm/xformer_lm.compute_predictions/lm/final_ln/reduce_sum[axes=(0, 1)]" source_file="/pax/praxis/praxis/layers/normalizations.py" source_line=378}
  fusion.387 = (f32[], f32[]) fusion(all-reduce.12, all-reduce.13), kind=kInput, calls=fused_computation.387, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/reduce_sum[axes=(0,)]" source_file="/pax/paxml/paxml/learners.py" source_line=47}
  get-tuple-element.729 = f32[] get-tuple-element(fusion.387), index=0
  get-tuple-element.730 = f32[] get-tuple-element(fusion.387), index=1
  fusion.229 = (f32[], f32[]) fusion(get-tuple-element.747, get-tuple-element.728, get-tuple-element.749, get-tuple-element.722, get-tuple-element.723, /*index=5*/get-tuple-element.724, get-tuple-element.725, get-tuple-element.752, get-tuple-element.726, get-tuple-element.753, /*index=10*/get-tuple-element.727, get-tuple-element.754, fusion.483, get-tuple-element.729, get-tuple-element.730), kind=kLoop, calls=fused_computation.229, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/min" source_file="/pax/paxml/paxml/learners.py" source_line=262}
  get-tuple-element.570 = f32[] get-tuple-element(fusion.229), index=0
  param.28 = f32[8192]{0} parameter(24), sharding={replicated}
  fusion.226 = f32[] fusion(param.24), kind=kLoop, calls=fused_computation.226, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/div" source_file="/pax/praxis/praxis/optimizers.py" source_line=331}
  param.26 = f32[8192]{0} parameter(23), sharding={replicated}
  param.25 = f32[8192]{0} parameter(19), sharding={replicated}
  fusion.217 = (f32[], f32[]) fusion(param.27, fusion.230, all-reduce.13, get-tuple-element.570, param.28, /*index=5*/fusion.226, param.26, param.25, all-reduce.12), kind=kInput, calls=fused_computation.217, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/reduce_sum[axes=(0,)]" source_file="/pax/praxis/praxis/optimizers.py" source_line=2066}
  get-tuple-element.731 = f32[] get-tuple-element(fusion.217), index=0
  fusion.231 = f32[] fusion(param.24), kind=kLoop, calls=fused_computation.231, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/mul" source_file="/pax/praxis/praxis/optimizers.py" source_line=693}
  get-tuple-element.571 = f32[] get-tuple-element(fusion.229), index=1
  get-tuple-element.732 = f32[] get-tuple-element(fusion.217), index=1
  fusion.481 = (f32[8192]{0}, f32[8192]{0}, f32[8192]{0}, f32[8192]{0}, f32[8192]{0}, /*index=5*/f32[8192]{0}) fusion(param.22, get-tuple-element.731, fusion.231, get-tuple-element.571, param.27, /*index=5*/fusion.230, all-reduce.13, get-tuple-element.570, param.28, fusion.226, /*index=10*/param.5, get-tuple-element.732, param.25, all-reduce.12, param.26), kind=kLoop, calls=horizontally_fused_computation.3
  get-tuple-element.714 = f32[8192]{0} get-tuple-element(fusion.481), index=3
  get-tuple-element.715 = f32[8192]{0} get-tuple-element(fusion.481), index=4
  get-tuple-element.716 = f32[8192]{0} get-tuple-element(fusion.481), index=5
  tuple.153 = (f32[8192]{0}, f32[8192]{0}, f32[8192]{0}) tuple(get-tuple-element.714, get-tuple-element.715, get-tuple-element.716), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/add" source_file="/pax/paxml/paxml/learners.py" source_line=408}
  get-tuple-element.568 = f32[8192]{0} get-tuple-element(tuple.153), index=0
  get-tuple-element.711 = f32[8192]{0} get-tuple-element(fusion.481), index=0
  get-tuple-element.712 = f32[8192]{0} get-tuple-element(fusion.481), index=1
  get-tuple-element.713 = f32[8192]{0} get-tuple-element(fusion.481), index=2
  tuple.152 = (f32[8192]{0}, f32[8192]{0}, f32[8192]{0}) tuple(get-tuple-element.711, get-tuple-element.712, get-tuple-element.713), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/add" source_file="/pax/paxml/paxml/learners.py" source_line=408}
  get-tuple-element.565 = f32[8192]{0} get-tuple-element(tuple.152), index=0
  param.29 = f32[32000]{0} parameter(21), sharding={replicated}
  param.30 = f32[32000]{0} parameter(25), sharding={replicated}
  fusion.211 = f32[128]{0} fusion(param.29, fusion.230, all-reduce.14, get-tuple-element.570, param.30, /*index=5*/fusion.226), kind=kInput, calls=fused_computation.211, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/reduce_sum[axes=(0,)]" source_file="/pax/praxis/praxis/optimizers.py" source_line=2066}
  reduce.88 = f32[] reduce(fusion.211, constant.1007), dimensions={0}, to_apply=region_15.791, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/reduce_sum[axes=(0,)]" source_file="/pax/praxis/praxis/optimizers.py" source_line=2066}
  fusion.210 = (f32[32000]{0}, f32[32000]{0}, f32[32000]{0}) fusion(param.23, reduce.88, fusion.231, get-tuple-element.571, param.29, /*index=5*/fusion.230, all-reduce.14, get-tuple-element.570, param.30, fusion.226), kind=kLoop, calls=fused_computation.210, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/add" source_file="/pax/paxml/paxml/learners.py" source_line=408}
  get-tuple-element.562 = f32[32000]{0} get-tuple-element(fusion.210), index=0
  param.31 = f32[1024,32000]{1,0} parameter(22), sharding={devices=[8,1]<=[8]}
  param.32 = f32[1024,32000]{1,0} parameter(26), sharding={devices=[8,1]<=[8]}
  fusion.205 = (f32[4096]{0}, f32[1024,32000]{1,0}, f32[1024,32000]{1,0}, f32[1024,32000]{1,0}) fusion(param.31, fusion.230, reduce-scatter.6, get-tuple-element.570, get-tuple-element.571, /*index=5*/param.32, fusion.226), kind=kInput, calls=fused_computation.205, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/reduce_sum[axes=(0,)]" source_file="/pax/praxis/praxis/optimizers.py" source_line=2063}
  get-tuple-element.560 = f32[1024,32000]{1,0} get-tuple-element(fusion.205), index=2
  get-tuple-element.558 = f32[4096]{0} get-tuple-element(fusion.205), index=0
  reduce.89 = f32[] reduce(get-tuple-element.558, constant.1007), dimensions={0}, to_apply=region_15.791, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/reduce_sum[axes=(0,)]" source_file="/pax/praxis/praxis/optimizers.py" source_line=2063}
  param.36 = f32[8,1024,32768]{2,1,0} parameter(32), sharding={devices=[1,8,1]<=[8]}
  param.33 = s32[8]{0} parameter(30), sharding={replicated}
  fusion.200 = (f32[8]{0}, f32[8]{0}, f32[8]{0}, f32[8]{0}, s32[8]{0}, /*index=5*/f32[8]{0}) fusion(param.33, get-tuple-element.571), kind=kLoop, calls=fused_computation.200, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/sub" source_file="/pax/praxis/praxis/optimizers.py" source_line=339}
  get-tuple-element.553 = f32[8]{0} get-tuple-element(fusion.200), index=1
  get-tuple-element.552 = f32[8]{0} get-tuple-element(fusion.200), index=0
  param.37 = f32[8,1024,32768]{2,1,0} parameter(43), sharding={devices=[1,8,1]<=[8]}
  get-tuple-element.555 = f32[8]{0} get-tuple-element(fusion.200), index=3
  get-tuple-element.554 = f32[8]{0} get-tuple-element(fusion.200), index=2
  param.41 = f32[8,32768,1024]{2,1,0} parameter(45), sharding={devices=[1,1,8]<=[8]}
  fusion.187 = (f32[8,4096]{1,0}, f32[8,1024,32768]{2,1,0}, f32[8,1024,32768]{2,1,0}, f32[8,1024,32768]{2,1,0}, f32[8,32768,1024]{2,1,0}, /*index=5*/f32[8,32768,1024]{2,1,0}) fusion(param.36, get-tuple-element.553, get-tuple-element.570, fusion.264, get-tuple-element.264, /*index=5*/reduce-scatter.11, get-tuple-element.552, get-tuple-element.571, param.37, get-tuple-element.555, /*index=10*/get-tuple-element.554, param.41, reduce-scatter.12, fusion.258, get-tuple-element.358, /*index=15*/reduce-scatter.22), kind=kInput, calls=fused_computation.187, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/reduce_sum[axes=(1,)]" source_file="/pax/praxis/praxis/optimizers.py" source_line=2063}
  get-tuple-element.522 = f32[8,4096]{1,0} get-tuple-element(fusion.187), index=0
  reduce.91 = f32[8]{0} reduce(get-tuple-element.522, constant.1007), dimensions={1}, to_apply=region_15.791, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/reduce_sum[axes=(1,)]" source_file="/pax/praxis/praxis/optimizers.py" source_line=2063}
  get-tuple-element.540 = f32[8,32768,1024]{2,1,0} get-tuple-element(fusion.187), index=4
  param.40 = f32[8,32768,1024]{2,1,0} parameter(34), sharding={devices=[1,1,8]<=[8]}
  fusion.175 = (f32[8,4096]{1,0}, f32[8,32768,1024]{2,1,0}) fusion(get-tuple-element.540, param.40, get-tuple-element.553, get-tuple-element.570, get-tuple-element.264, /*index=5*/reduce-scatter.12, get-tuple-element.552, get-tuple-element.571, fusion.258, get-tuple-element.358, /*index=10*/reduce-scatter.22), kind=kInput, calls=fused_computation.175, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/reduce_sum[axes=(1,)]" source_file="/pax/praxis/praxis/optimizers.py" source_line=2063}
  get-tuple-element.515 = f32[8,4096]{1,0} get-tuple-element(fusion.175), index=0
  reduce.93 = f32[8]{0} reduce(get-tuple-element.515, constant.1007), dimensions={1}, to_apply=region_15.791, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/reduce_sum[axes=(1,)]" source_file="/pax/praxis/praxis/optimizers.py" source_line=2063}
  param.51 = f32[8,3,1024,128,64]{4,3,2,1,0} parameter(50), sharding={devices=[1,1,8,1,1]<=[8]}
  fusion.146 = (f32[8,3,1024,128,64]{4,3,2,1,0}, f32[8,3,1024,128,64]{4,3,2,1,0}) fusion(param.51, get-tuple-element.555, get-tuple-element.570, get-tuple-element.264, reduce-scatter.13, /*index=5*/get-tuple-element.554, get-tuple-element.571, fusion.242, get-tuple-element.358, reduce-scatter.24), kind=kLoop, calls=fused_computation.146, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/add" source_file="/pax/praxis/praxis/optimizers.py" source_line=684}
  get-tuple-element.501 = f32[8,3,1024,128,64]{4,3,2,1,0} get-tuple-element(fusion.146), index=0
  param.50 = f32[8,3,1024,128,64]{4,3,2,1,0} parameter(39), sharding={devices=[1,1,8,1,1]<=[8]}
  fusion.145 = (f32[8,4096]{1,0}, f32[8,3,1024,128,64]{4,3,2,1,0}) fusion(get-tuple-element.501, param.50, get-tuple-element.553, get-tuple-element.570, get-tuple-element.264, /*index=5*/reduce-scatter.13, get-tuple-element.552, get-tuple-element.571, fusion.242, get-tuple-element.358, /*index=10*/reduce-scatter.24), kind=kInput, calls=fused_computation.145, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/reduce_sum[axes=(1, 2, 3)]" source_file="/pax/praxis/praxis/optimizers.py" source_line=2063}
  get-tuple-element.499 = f32[8,4096]{1,0} get-tuple-element(fusion.145), index=0
  reduce.98 = f32[8]{0} reduce(get-tuple-element.499, constant.1007), dimensions={1}, to_apply=region_15.791, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/reduce_sum[axes=(1, 2, 3)]" source_file="/pax/praxis/praxis/optimizers.py" source_line=2063}
  param.54 = f32[8,1024,128,64]{3,2,1,0} parameter(41), sharding={devices=[1,8,1,1]<=[8]}
  param.55 = f32[8,1024,128,64]{3,2,1,0} parameter(52), sharding={devices=[1,8,1,1]<=[8]}
  fusion.133 = (f32[8,2048]{1,0}, f32[8,1024,128,64]{3,2,1,0}, f32[8,1024,128,64]{3,2,1,0}, f32[8,1024,128,64]{3,2,1,0}) fusion(param.54, get-tuple-element.553, get-tuple-element.570, get-tuple-element.264, reduce-scatter.14, /*index=5*/get-tuple-element.552, get-tuple-element.571, param.55, get-tuple-element.555, get-tuple-element.554, /*index=10*/get-tuple-element.393, get-tuple-element.358, reduce-scatter.26), kind=kInput, calls=fused_computation.133, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/reduce_sum[axes=(1, 2, 3)]" source_file="/pax/praxis/praxis/optimizers.py" source_line=2066}
  get-tuple-element.492 = f32[8,2048]{1,0} get-tuple-element(fusion.133), index=0
  reduce.100 = f32[8]{0} reduce(get-tuple-element.492, constant.1007), dimensions={1}, to_apply=region_15.791, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/reduce_sum[axes=(1, 2, 3)]" source_file="/pax/praxis/praxis/optimizers.py" source_line=2066}
  get-tuple-element.698 = f32[2,2048,128]{2,1,0} get-tuple-element(fusion.93), index=0
  reduce.101 = f32[2,2048]{1,0} reduce(get-tuple-element.698, constant.1007), dimensions={2}, to_apply=region_15.791, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/lm.compute_loss/softmax/reduce_sum[axes=(2,)]" source_file="/pax/praxis/praxis/layers/embedding_softmax.py" source_line=317}
  get-tuple-element.120 = s32[2,2048]{1,0} get-tuple-element(reduce.63), index=1, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/lm.compute_loss/softmax/reduce[computation=<function _compute_argminmax.<locals>.reducer_fn at 0x7f7f7dce49d0> consts=() dimensions=(2,)]" source_file="/pax/praxis/praxis/layers/embedding_softmax.py" source_line=323}
  fusion.91 = (f32[], f32[]) fusion(param.7, reduce.101, param.6, get-tuple-element.120), kind=kInput, calls=fused_computation.91, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/lm.compute_loss/softmax/reduce_sum[axes=(0, 1, 2)]" source_file="/pax/praxis/praxis/layers/embedding_softmax.py" source_line=327}
  get-tuple-element.701 = f32[] get-tuple-element(fusion.91), index=1
  get-tuple-element.700 = f32[] get-tuple-element(fusion.91), index=0
  all-reduce.61 = (f32[], f32[8]{0}, f32[8]{0}, f32[8]{0}, f32[8]{0}, /*index=5*/f32[], f32[]) all-reduce(reduce.89, reduce.91, reduce.93, reduce.98, reduce.100, /*index=5*/get-tuple-element.701, get-tuple-element.700), channel_id=33, replica_groups={{0}}, to_apply=region_15.791
  get-tuple-element.755 = f32[] get-tuple-element(all-reduce.61), index=0, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/reduce_sum[axes=(0,)]" source_file="/pax/praxis/praxis/optimizers.py" source_line=2063}
  fusion.204 = f32[1024,32000]{1,0} fusion(param.9, get-tuple-element.560, get-tuple-element.755, fusion.231, get-tuple-element.571, /*index=5*/param.31, fusion.230, reduce-scatter.6, get-tuple-element.570), kind=kLoop, calls=fused_computation.204, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/add" source_file="/pax/paxml/paxml/learners.py" source_line=408}
  param.34 = f32[8,32768]{1,0} parameter(31), sharding={replicated}
  param.35 = f32[8,32768]{1,0} parameter(42), sharding={replicated}
  fusion.193 = f32[8,128]{1,0} fusion(param.34, get-tuple-element.553, get-tuple-element.570, get-tuple-element.281, get-tuple-element.264, /*index=5*/all-reduce.36, get-tuple-element.552, param.35, get-tuple-element.555, get-tuple-element.554), kind=kInput, calls=fused_computation.193, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/reduce_sum[axes=(1,)]" source_file="/pax/praxis/praxis/optimizers.py" source_line=2066}
  reduce.90 = f32[8]{0} reduce(fusion.193, constant.1007), dimensions={1}, to_apply=region_15.791, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/reduce_sum[axes=(1,)]" source_file="/pax/praxis/praxis/optimizers.py" source_line=2066}
  get-tuple-element.557 = f32[8]{0} get-tuple-element(fusion.200), index=5
  fusion.192 = (f32[8,32768]{1,0}, f32[8,32768]{1,0}, f32[8,32768]{1,0}) fusion(param.10, reduce.90, get-tuple-element.557, get-tuple-element.571, param.34, /*index=5*/get-tuple-element.553, get-tuple-element.570, get-tuple-element.281, get-tuple-element.264, all-reduce.36, /*index=10*/get-tuple-element.552, param.35, get-tuple-element.555, get-tuple-element.554), kind=kLoop, calls=fused_computation.192, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/add" source_file="/pax/paxml/paxml/learners.py" source_line=408}
  get-tuple-element.542 = f32[8,32768]{1,0} get-tuple-element(fusion.192), index=0
  get-tuple-element.524 = f32[8,1024,32768]{2,1,0} get-tuple-element(fusion.187), index=2
  get-tuple-element.756 = f32[8]{0} get-tuple-element(all-reduce.61), index=1, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/reduce_sum[axes=(1,)]" source_file="/pax/praxis/praxis/optimizers.py" source_line=2063}
  get-tuple-element.757 = f32[8]{0} get-tuple-element(all-reduce.61), index=2, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/reduce_sum[axes=(1,)]" source_file="/pax/praxis/praxis/optimizers.py" source_line=2063}
  fusion.186 = (f32[8,1024,32768]{2,1,0}, f32[8,32768,1024]{2,1,0}) fusion(param.11, get-tuple-element.524, get-tuple-element.756, get-tuple-element.557, get-tuple-element.571, /*index=5*/param.36, get-tuple-element.553, get-tuple-element.570, fusion.264, get-tuple-element.264, /*index=10*/reduce-scatter.11, get-tuple-element.552, param.13, get-tuple-element.540, get-tuple-element.757, /*index=15*/param.40, reduce-scatter.12, fusion.258, get-tuple-element.358, reduce-scatter.22), kind=kLoop, calls=fused_computation.186, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/add" source_file="/pax/paxml/paxml/learners.py" source_line=408}
  get-tuple-element.538 = f32[8,1024,32768]{2,1,0} get-tuple-element(fusion.186), index=0
  param.42 = f32[8,8192]{1,0} parameter(35), sharding={replicated}
  param.43 = f32[8,8192]{1,0} parameter(46), sharding={replicated}
  param.47 = f32[8,8192]{1,0} parameter(48), sharding={replicated}
  param.46 = f32[8,8192]{1,0} parameter(37), sharding={replicated}
  param.49 = f32[8,8192]{1,0} parameter(49), sharding={replicated}
  param.48 = f32[8,8192]{1,0} parameter(38), sharding={replicated}
  param.39 = f32[8,8192]{1,0} parameter(44), sharding={replicated}
  param.38 = f32[8,8192]{1,0} parameter(33), sharding={replicated}
  param.45 = f32[8,8192]{1,0} parameter(47), sharding={replicated}
  param.44 = f32[8,8192]{1,0} parameter(36), sharding={replicated}
  fusion.169 = (f32[8]{0}, f32[8]{0}, f32[8]{0}, f32[8]{0}, f32[8]{0}) fusion(param.42, get-tuple-element.553, get-tuple-element.570, get-tuple-element.285, get-tuple-element.264, /*index=5*/all-reduce.38, get-tuple-element.552, param.43, get-tuple-element.555, get-tuple-element.554, /*index=10*/param.47, param.46, get-tuple-element.287, all-reduce.40, param.49, /*index=15*/param.48, get-tuple-element.288, get-tuple-element.750, param.39, param.38, /*index=20*/get-tuple-element.283, get-tuple-element.751, param.45, param.44, get-tuple-element.286, /*index=25*/all-reduce.39), kind=kInput, calls=fused_computation.169, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/reduce_sum[axes=(1,)]" source_file="/pax/praxis/praxis/optimizers.py" source_line=2066}
  get-tuple-element.547 = f32[8]{0} get-tuple-element(fusion.169), index=3
  get-tuple-element.546 = f32[8]{0} get-tuple-element(fusion.169), index=2
  get-tuple-element.545 = f32[8]{0} get-tuple-element(fusion.169), index=1
  get-tuple-element.548 = f32[8]{0} get-tuple-element(fusion.169), index=4
  get-tuple-element.544 = f32[8]{0} get-tuple-element(fusion.169), index=0
  fusion.180 = (f32[8,8192]{1,0}, f32[8,8192]{1,0}, f32[8,8192]{1,0}, f32[8,8192]{1,0}, f32[8,8192]{1,0}, /*index=5*/f32[8,8192]{1,0}, f32[8,8192]{1,0}, f32[8,8192]{1,0}, f32[8,8192]{1,0}, f32[8,8192]{1,0}, /*index=10*/f32[8,8192]{1,0}, f32[8,8192]{1,0}, f32[8,8192]{1,0}, f32[8,8192]{1,0}, f32[8,8192]{1,0}) fusion(param.12, get-tuple-element.547, get-tuple-element.557, get-tuple-element.571, param.38, /*index=5*/get-tuple-element.553, get-tuple-element.570, get-tuple-element.283, get-tuple-element.264, get-tuple-element.751, /*index=10*/get-tuple-element.552, param.39, get-tuple-element.555, get-tuple-element.554, param.48, /*index=15*/get-tuple-element.288, get-tuple-element.750, param.49, param.17, get-tuple-element.546, /*index=20*/param.46, get-tuple-element.287, all-reduce.40, param.47, param.16, /*index=25*/get-tuple-element.545, param.44, get-tuple-element.286, all-reduce.39, param.45, /*index=30*/param.15, get-tuple-element.548, param.42, get-tuple-element.285, all-reduce.38, /*index=35*/param.43, param.14, get-tuple-element.544), kind=kLoop, calls=fused_computation.180, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/add" source_file="/pax/paxml/paxml/learners.py" source_line=408}
  get-tuple-element.519 = f32[8,8192]{1,0} get-tuple-element(fusion.180), index=0
  get-tuple-element.539 = f32[8,32768,1024]{2,1,0} get-tuple-element(fusion.186), index=1
  get-tuple-element.535 = f32[8,8192]{1,0} get-tuple-element(fusion.180), index=12
  get-tuple-element.532 = f32[8,8192]{1,0} get-tuple-element(fusion.180), index=9
  get-tuple-element.529 = f32[8,8192]{1,0} get-tuple-element(fusion.180), index=6
  get-tuple-element.526 = f32[8,8192]{1,0} get-tuple-element(fusion.180), index=3
  get-tuple-element.758 = f32[8]{0} get-tuple-element(all-reduce.61), index=3, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/reduce_sum[axes=(1, 2, 3)]" source_file="/pax/praxis/praxis/optimizers.py" source_line=2063}
  fusion.144 = f32[8,3,1024,128,64]{4,3,2,1,0} fusion(param.18, get-tuple-element.501, get-tuple-element.758, get-tuple-element.557, get-tuple-element.571, /*index=5*/param.50, get-tuple-element.553, get-tuple-element.570, get-tuple-element.264, reduce-scatter.13, /*index=10*/get-tuple-element.552, fusion.242, get-tuple-element.358, reduce-scatter.24), kind=kLoop, calls=fused_computation.144, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/add" source_file="/pax/paxml/paxml/learners.py" source_line=408}
  param.52 = f32[8,64]{1,0} parameter(40), sharding={replicated}
  param.53 = f32[8,64]{1,0} parameter(51), sharding={replicated}
  fusion.139 = f32[8]{0} fusion(param.52, get-tuple-element.553, get-tuple-element.570, get-tuple-element.290, get-tuple-element.272, /*index=5*/get-tuple-element.264, get-tuple-element.748, get-tuple-element.552, param.53, get-tuple-element.555, /*index=10*/get-tuple-element.554), kind=kInput, calls=fused_computation.139, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/reduce_sum[axes=(1,)]" source_file="/pax/praxis/praxis/optimizers.py" source_line=2066}
  fusion.138 = (f32[8,64]{1,0}, f32[8,64]{1,0}, f32[8,64]{1,0}) fusion(param.19, fusion.139, get-tuple-element.557, get-tuple-element.571, param.52, /*index=5*/get-tuple-element.553, get-tuple-element.570, get-tuple-element.290, get-tuple-element.272, get-tuple-element.264, /*index=10*/get-tuple-element.748, get-tuple-element.552, param.53, get-tuple-element.555, get-tuple-element.554), kind=kLoop, calls=fused_computation.138, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/add" source_file="/pax/paxml/paxml/learners.py" source_line=408}
  get-tuple-element.496 = f32[8,64]{1,0} get-tuple-element(fusion.138), index=0
  get-tuple-element.494 = f32[8,1024,128,64]{3,2,1,0} get-tuple-element(fusion.133), index=2
  get-tuple-element.759 = f32[8]{0} get-tuple-element(all-reduce.61), index=4, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/reduce_sum[axes=(1, 2, 3)]" source_file="/pax/praxis/praxis/optimizers.py" source_line=2066}
  fusion.132 = f32[8,1024,128,64]{3,2,1,0} fusion(param.20, get-tuple-element.494, get-tuple-element.759, get-tuple-element.557, get-tuple-element.571, /*index=5*/param.54, get-tuple-element.553, get-tuple-element.570, get-tuple-element.264, reduce-scatter.14, /*index=10*/get-tuple-element.552, get-tuple-element.393, get-tuple-element.358, reduce-scatter.26), kind=kLoop, calls=fused_computation.132, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/add" source_file="/pax/paxml/paxml/learners.py" source_line=408}
  param.58 = s32[] parameter(27), sharding={replicated}
  param.56 = s32[] parameter(16), sharding={replicated}
  param.57 = s32[] parameter(17), sharding={replicated}
  fusion.478 = (s32[], s32[], s32[], s32[]) fusion(param.58, get-tuple-element.571, param.24, param.56, param.57), kind=kLoop, calls=horizontally_fused_computation
  get-tuple-element.704 = s32[] get-tuple-element(fusion.478), index=2
  bitcast.8197 = s32[] bitcast(get-tuple-element.704), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(_where)/select_n" source_file="/pax/paxml/paxml/learners.py" source_line=349}
  get-tuple-element.705 = s32[] get-tuple-element(fusion.478), index=3
  bitcast.8198 = s32[] bitcast(get-tuple-element.705), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(_where)/select_n" source_file="/pax/paxml/paxml/learners.py" source_line=349}
  get-tuple-element.703 = s32[] get-tuple-element(fusion.478), index=1
  bitcast.8196 = s32[] bitcast(get-tuple-element.703), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(_where)/select_n" source_file="/pax/paxml/paxml/learners.py" source_line=349}
  get-tuple-element.677 = f32[8192]{0} get-tuple-element(tuple.153), index=2
  get-tuple-element.567 = f32[8192]{0} get-tuple-element(tuple.152), index=2
  get-tuple-element.564 = f32[32000]{0} get-tuple-element(fusion.210), index=2
  get-tuple-element.559 = f32[1024,32000]{1,0} get-tuple-element(fusion.205), index=1
  get-tuple-element.569 = f32[8192]{0} get-tuple-element(tuple.153), index=1
  get-tuple-element.566 = f32[8192]{0} get-tuple-element(tuple.152), index=1
  get-tuple-element.563 = f32[32000]{0} get-tuple-element(fusion.210), index=1
  get-tuple-element.561 = f32[1024,32000]{1,0} get-tuple-element(fusion.205), index=3
  get-tuple-element.702 = s32[] get-tuple-element(fusion.478), index=0
  bitcast.8195 = s32[] bitcast(get-tuple-element.702), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(_where)/select_n" source_file="/pax/paxml/paxml/learners.py" source_line=349}
  param.61 = s32[8]{0} parameter(53), sharding={replicated}
  param.60 = s32[8]{0} parameter(29), sharding={replicated}
  param.59 = s32[8]{0} parameter(28), sharding={replicated}
  fusion.479 = (s32[8]{0}, s32[8]{0}, s32[8]{0}) fusion(param.61, get-tuple-element.571, param.60, param.59), kind=kLoop, calls=horizontally_fused_computation.1
  get-tuple-element.708 = s32[8]{0} get-tuple-element(fusion.479), index=2, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(_where)/select_n" source_file="/pax/paxml/paxml/learners.py" source_line=349}
  get-tuple-element.707 = s32[8]{0} get-tuple-element(fusion.479), index=1, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(_where)/select_n" source_file="/pax/paxml/paxml/learners.py" source_line=349}
  get-tuple-element.556 = s32[8]{0} get-tuple-element(fusion.200), index=4
  get-tuple-element.551 = f32[8,32768]{1,0} get-tuple-element(fusion.192), index=2
  get-tuple-element.523 = f32[8,1024,32768]{2,1,0} get-tuple-element(fusion.187), index=1
  get-tuple-element.521 = f32[8,8192]{1,0} get-tuple-element(fusion.180), index=2
  get-tuple-element.516 = f32[8,32768,1024]{2,1,0} get-tuple-element(fusion.175), index=1
  get-tuple-element.537 = f32[8,8192]{1,0} get-tuple-element(fusion.180), index=14
  get-tuple-element.534 = f32[8,8192]{1,0} get-tuple-element(fusion.180), index=11
  get-tuple-element.531 = f32[8,8192]{1,0} get-tuple-element(fusion.180), index=8
  get-tuple-element.528 = f32[8,8192]{1,0} get-tuple-element(fusion.180), index=5
  get-tuple-element.500 = f32[8,3,1024,128,64]{4,3,2,1,0} get-tuple-element(fusion.145), index=1
  get-tuple-element.498 = f32[8,64]{1,0} get-tuple-element(fusion.138), index=2
  get-tuple-element.493 = f32[8,1024,128,64]{3,2,1,0} get-tuple-element(fusion.133), index=1
  get-tuple-element.543 = f32[8,32768]{1,0} get-tuple-element(fusion.192), index=1
  get-tuple-element.525 = f32[8,1024,32768]{2,1,0} get-tuple-element(fusion.187), index=3
  get-tuple-element.520 = f32[8,8192]{1,0} get-tuple-element(fusion.180), index=1
  get-tuple-element.541 = f32[8,32768,1024]{2,1,0} get-tuple-element(fusion.187), index=5
  get-tuple-element.536 = f32[8,8192]{1,0} get-tuple-element(fusion.180), index=13
  get-tuple-element.533 = f32[8,8192]{1,0} get-tuple-element(fusion.180), index=10
  get-tuple-element.530 = f32[8,8192]{1,0} get-tuple-element(fusion.180), index=7
  get-tuple-element.527 = f32[8,8192]{1,0} get-tuple-element(fusion.180), index=4
  get-tuple-element.502 = f32[8,3,1024,128,64]{4,3,2,1,0} get-tuple-element(fusion.146), index=1
  get-tuple-element.497 = f32[8,64]{1,0} get-tuple-element(fusion.138), index=1
  get-tuple-element.495 = f32[8,1024,128,64]{3,2,1,0} get-tuple-element(fusion.133), index=3
  get-tuple-element.706 = s32[8]{0} get-tuple-element(fusion.479), index=0, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jit(_where)/select_n" source_file="/pax/paxml/paxml/learners.py" source_line=349}
  get-tuple-element.760 = f32[] get-tuple-element(all-reduce.61), index=5, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_loss/reduce_sum[axes=(0, 1)]" source_file="/pax/praxis/praxis/layers/models.py" source_line=129}
  get-tuple-element.761 = f32[] get-tuple-element(all-reduce.61), index=6, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/lm.compute_loss/softmax/reduce_sum[axes=(0, 1, 2)]" source_file="/pax/praxis/praxis/layers/embedding_softmax.py" source_line=327}
  fusion.480 = (f32[], f32[]) fusion(get-tuple-element.760, all-reduce.11, get-tuple-element.761), kind=kLoop, calls=horizontally_fused_computation.2
  get-tuple-element.710 = f32[] get-tuple-element(fusion.480), index=1
  bitcast.8200 = f32[] bitcast(get-tuple-element.710), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_predictions/lm/lm.compute_loss/softmax/div" source_file="/pax/praxis/praxis/layers/embedding_softmax.py" source_line=349}
  constant.1006 = f32[] constant(1)
  get-tuple-element.709 = f32[] get-tuple-element(fusion.480), index=0
  bitcast.8199 = f32[] bitcast(get-tuple-element.709), metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_loss/div" source_file="/pax/praxis/praxis/layers/models.py" source_line=129}
  fusion.88 = f32[2]{0} fusion(param.7, reduce.101), kind=kInput, calls=fused_computation.88, metadata={op_name="pjit(_wrapped_step_fn)/jit(main)/jvp(xformer_lm.apply)/xformer_lm/xformer_lm.compute_loss/neg" source_file="/pax/praxis/praxis/layers/models.py" source_line=170}
  all-gather.46 = (s32[16,2048]{1,0}, f32[16]{0}) all-gather(param.6, fusion.88), channel_id=40, replica_groups={{0,1,2,3,4,5,6,7}}, dimensions={0}, use_global_device_ids=true
  get-tuple-element.741 = s32[16,2048]{1,0} get-tuple-element(all-gather.46), index=0
  get-tuple-element.742 = f32[16]{0} get-tuple-element(all-gather.46), index=1
  ROOT tuple.11 = (u32[], f32[8192]{0}, f32[8192]{0}, f32[32000]{0}, f32[1024,32000]{1,0}, /*index=5*/f32[8,32768]{1,0}, f32[8,1024,32768]{2,1,0}, f32[8,8192]{1,0}, f32[8,32768,1024]{2,1,0}, f32[8,8192]{1,0}, /*index=10*/f32[8,8192]{1,0}, f32[8,8192]{1,0}, f32[8,8192]{1,0}, f32[8,3,1024,128,64]{4,3,2,1,0}, f32[8,64]{1,0}, /*index=15*/f32[8,1024,128,64]{3,2,1,0}, s32[], s32[], s32[], f32[8192]{0}, /*index=20*/f32[8192]{0}, f32[32000]{0}, f32[1024,32000]{1,0}, f32[8192]{0}, f32[8192]{0}, /*index=25*/f32[32000]{0}, f32[1024,32000]{1,0}, s32[], s32[8]{0}, s32[8]{0}, /*index=30*/s32[8]{0}, f32[8,32768]{1,0}, f32[8,1024,32768]{2,1,0}, f32[8,8192]{1,0}, f32[8,32768,1024]{2,1,0}, /*index=35*/f32[8,8192]{1,0}, f32[8,8192]{1,0}, f32[8,8192]{1,0}, f32[8,8192]{1,0}, f32[8,3,1024,128,64]{4,3,2,1,0}, /*index=40*/f32[8,64]{1,0}, f32[8,1024,128,64]{3,2,1,0}, f32[8,32768]{1,0}, f32[8,1024,32768]{2,1,0}, f32[8,8192]{1,0}, /*index=45*/f32[8,32768,1024]{2,1,0}, f32[8,8192]{1,0}, f32[8,8192]{1,0}, f32[8,8192]{1,0}, f32[8,8192]{1,0}, /*index=50*/f32[8,3,1024,128,64]{4,3,2,1,0}, f32[8,64]{1,0}, f32[8,1024,128,64]{3,2,1,0}, s32[8]{0}, f32[], /*index=55*/f32[], f32[], f32[], f32[], f32[], /*index=60*/f32[], f32[], f32[], f32[], f32[], /*index=65*/f32[], f32[], s32[16,2048]{1,0}, f32[16]{0}) tuple(add.649, get-tuple-element.568, get-tuple-element.565, get-tuple-element.562, fusion.204, /*index=5*/get-tuple-element.542, get-tuple-element.538, get-tuple-element.519, get-tuple-element.539, get-tuple-element.535, /*index=10*/get-tuple-element.532, get-tuple-element.529, get-tuple-element.526, fusion.144, get-tuple-element.496, /*index=15*/fusion.132, bitcast.8197, bitcast.8198, bitcast.8196, get-tuple-element.677, /*index=20*/get-tuple-element.567, get-tuple-element.564, get-tuple-element.559, get-tuple-element.569, get-tuple-element.566, /*index=25*/get-tuple-element.563, get-tuple-element.561, bitcast.8195, get-tuple-element.708, get-tuple-element.707, /*index=30*/get-tuple-element.556, get-tuple-element.551, get-tuple-element.523, get-tuple-element.521, get-tuple-element.516, /*index=35*/get-tuple-element.537, get-tuple-element.534, get-tuple-element.531, get-tuple-element.528, get-tuple-element.500, /*index=40*/get-tuple-element.498, get-tuple-element.493, get-tuple-element.543, get-tuple-element.525, get-tuple-element.520, /*index=45*/get-tuple-element.541, get-tuple-element.536, get-tuple-element.533, get-tuple-element.530, get-tuple-element.527, /*index=50*/get-tuple-element.502, get-tuple-element.497, get-tuple-element.495, get-tuple-element.706, bitcast.8200, /*index=55*/constant.1007, constant.1006, bitcast.8200, all-reduce.11, bitcast.8199, /*index=60*/all-reduce.11, bitcast.8200, all-reduce.11, all-reduce.11, constant.1006, /*index=65*/bitcast.8200, all-reduce.11, get-tuple-element.741, get-tuple-element.742)
} // main.4503_spmd

)";

  TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<xla::HloModule> module,
                          ParseAndReturnVerifiedModule(kModuleString));
  CopyInsertion copy_insertion(GpuCompiler::FusionCanShareBufferHint,
                               /*use_region_based_live_range_analysis=*/-1);
  LoopScheduleLinearizer loop_linear(GpuCompiler::FusionCanShareBufferHint);
  AliasPassthroughParams alias_pass;
  TestDoubleBuffer test_double;
  WhileLoopTripCountAnnotator annotator;
  HloDCE dce;
  AlgebraicSimplifierOptions options;
  options.set_supports_non_canonical_dots(false);
  options.set_is_layout_sensitive(false);
  options.set_enable_conv_operand_swap(false);
  options.set_enable_unconditional_reduce_of_concat_replacement(false);
  AlgebraicSimplifier alg_simp(options);


  ASSERT_IS_OK(test_double.Run(module.get()).status());
  ASSERT_IS_OK(dce.Run(module.get()).status());
  ASSERT_IS_OK(annotator.Run(module.get()).status());
  ASSERT_IS_OK(alias_pass.Run(module.get()).status());

  ASSERT_IS_OK(loop_linear.Run(module.get()).status());

  ASSERT_IS_OK(copy_insertion.Run(module.get()).status());

  // We expect that for the while loop, no further copy needs to be added to the
  // module.
  HloInstruction* while_instruction = nullptr;
  for(auto instr : module->entry_computation()->instructions()) {
    if(instr->opcode() == HloOpcode::kWhile) {
      while_instruction = instr;
    }
  }
  EXPECT_TRUE(while_instruction != nullptr);
  EXPECT_EQ(CountCopies(*(while_instruction->while_body())), 0);
}

}  // namespace
}  // namespace gpu
}  // namespace xla
