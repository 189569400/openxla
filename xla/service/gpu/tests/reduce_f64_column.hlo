// RUN: hlo-opt %s --platform=gpu --stage=llvm-before-optimizations --xla_gpu_target_config_filename=%S/../../../tools/hlo_opt/gpu_specs/%{GPU}.txtpb | FileCheck %s --check-prefixes=CHECK,CHECK-%{PTX}

HloModule m, is_scheduled=true

add {
  a = f64[] parameter(0)
  b = f64[] parameter(1)
  ROOT out = f64[] add(a, b)
}

fused_computation {
  p1 = f64[1024,1024]{1,0} parameter(0)
  p2 = f64[1024,1024]{1,0} parameter(1)
  s = pred[1024,1024]{1,0} parameter(2)
  p = f64[1024,1024]{1,0} select(s, p1, p2)
  z = f64[] constant(0)
  ROOT out = f64[1024]{0} reduce(p, z), to_apply=add, dimensions={0}
}

ENTRY e {
  p1 = f64[1024,1024]{1,0} parameter(0)
  p2 = f64[1024,1024]{1,0} parameter(1)
  s = pred[1024,1024]{1,0} parameter(2)
  ROOT f = f64[1024]{0} fusion(p1, p2, s), kind=kInput, calls=fused_computation
}

// CHECK: @shared_cache = private addrspace(3) global [32 x [33 x double]]

// CHECK-LABEL: entry:
// CHECK:         %[[VAL_0:.*]] = alloca double, align 8
// CHECK:         %[[VAL_1:.*]] = alloca double, align 8
// CHECK:         %[[VAL_2:.*]] = alloca double, align 8
// CHECK:         %[[VAL_3:.*]] = alloca double, align 8
// CHECK:         %[[VAL_4:.*]] = alloca double, align 8
// CHECK:         %[[VAL_5:.*]] = alloca double, align 8
// CHECK:         %[[VAL_6:.*]] = alloca double, align 8
// CHECK:         %[[VAL_7:.*]] = alloca double, align 8
// CHECK:         %[[VAL_8:.*]] = alloca double, align 8
// CHECK:         %[[VAL_9:.*]] = alloca double, align 8
// CHECK:         %[[VAL_10:.*]] = alloca double, align 8
// CHECK:         %[[VAL_11:.*]] = alloca i32, align 4
// CHECK:         %[[VAL_12:.*]] = alloca i32, align 4
// CHECK:         %[[VAL_13:.*]] = alloca double, align 8
// CHECK:         %[[VAL_14:.*]] = alloca double, align 8
// CHECK-PTX:     %[[VAL_15:.*]] = call i32 @llvm.nvvm.read.ptx.sreg.ctaid.y(), !range !2
// CHECK-GCN:     %[[VAL_15:.*]] = call i32 @llvm.amdgcn.workgroup.id.y
// CHECK:         %[[VAL_16:.*]] = icmp eq i32 %[[VAL_15]], 0
// CHECK:         br i1 %[[VAL_16]], label %[[VAL_17:.*]], label %[[VAL_18:.*]]
// CHECK:       reduce-group-0-after:                             ; preds = %[[VAL_19:.*]], %[[VAL_20:.*]]
// CHECK:         ret void
// CHECK:       reduce-group-0-true:                              ; preds = %[[VAL_20]]
// CHECK:         %[[VAL_21:.*]] = load double, ptr @0, align 8
// CHECK:         %[[VAL_22:.*]] = getelementptr inbounds double, ptr %[[VAL_13]], i32 0
// CHECK:         store double %[[VAL_21]], ptr{{.*}}%[[VAL_22]], align 8
// CHECK-PTX:     %thread.id.x = call i32 @llvm.nvvm.read.ptx.sreg.tid.x(), !range !3
// CHECK-GCN:     %thread.id.x = call i32 @llvm.amdgcn.workitem.id.x
// CHECK-PTX:     %block.id.x = call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x(), !range !4
// CHECK-GCN:     %block.id.x = call i32 @llvm.amdgcn.workgroup.id.x
// CHECK:         %[[VAL_23:.*]] = udiv i32 %thread.id.x, 32
// CHECK:         %thread.id.1 = urem i32 %[[VAL_23]], 32
// CHECK:         %thread.id.2 = urem i32 %thread.id.x, 32
// CHECK:         %lane_id = urem i32 %thread.id.x, 32
// CHECK:         %[[VAL_24:.*]] = udiv i32 %block.id.x, 1
// CHECK:         %[[VAL_25:.*]] = urem i32 %[[VAL_24]], 1
// CHECK:         %[[VAL_26:.*]] = udiv i32 %block.id.x, 1
// CHECK:         %[[VAL_27:.*]] = urem i32 %[[VAL_26]], 32
// CHECK:         %[[VAL_28:.*]] = udiv i32 %block.id.x, 32
// CHECK:         %[[VAL_29:.*]] = urem i32 %[[VAL_28]], 1
// CHECK:         %[[VAL_30:.*]] = udiv i32 %block.id.x, 32
// CHECK:         %[[VAL_31:.*]] = icmp eq i32 %[[VAL_29]], 0
// CHECK:         %tile_bound.1 = select i1 %[[VAL_31]], i32 1024, i32 4096
// CHECK:         %tile_origin.0 = mul i32 %[[VAL_30]], 1
// CHECK:         %tile_origin.1 = mul i32 %[[VAL_29]], 4096
// CHECK:         %tile_origin.2 = mul i32 %[[VAL_27]], 32
// CHECK:         %tile_origin.3 = mul i32 %[[VAL_25]], 1
// CHECK:         store i32 %thread.id.1, ptr{{.*}}%[[VAL_12]], align 4
// CHECK:         br label %[[VAL_32:.*]]
// CHECK:       loop1.loop_header:                                ; preds = %[[VAL_33:.*]], %[[VAL_17]]
// CHECK:         %[[VAL_34:.*]] = load i32, ptr{{.*}}%[[VAL_12]], align 4
// CHECK:         %[[VAL_35:.*]] = icmp uge i32 %[[VAL_34]], %tile_bound.1
// CHECK:         br i1 %[[VAL_35]], label %[[VAL_36:.*]], label %[[VAL_37:.*]]
// CHECK:       loop1.loop_body:                                  ; preds = %[[VAL_32]]
// CHECK:         %[[VAL_38:.*]] = add nuw nsw i32 %[[VAL_34]], 32
// CHECK:         store i32 %[[VAL_38]], ptr{{.*}}%[[VAL_12]], align 4
// CHECK:         %[[VAL_39:.*]] = icmp eq i32 %[[VAL_34]], %thread.id.1
// CHECK:         store i32 0, ptr{{.*}}%[[VAL_11]], align 4
// CHECK:         br label %[[VAL_40:.*]]
// CHECK:       loop2.loop_header:                                ; preds = %[[VAL_41:.*]], %[[VAL_37]]
// CHECK:         %[[VAL_42:.*]] = load i32, ptr{{.*}}%[[VAL_11]], align 4
// CHECK:         %[[VAL_43:.*]] = icmp uge i32 %[[VAL_42]], 32
// CHECK:         br i1 %[[VAL_43]], label %[[VAL_33]], label %[[VAL_44:.*]]
// CHECK:       loop2.loop_body:                                  ; preds = %[[VAL_40]]
// CHECK:         %[[VAL_45:.*]] = add nuw nsw i32 %[[VAL_42]], 32
// CHECK:         store i32 %[[VAL_45]], ptr{{.*}}%[[VAL_11]], align 4
// CHECK:         %[[VAL_46:.*]] = icmp eq i32 %[[VAL_42]], 0
// CHECK:         %[[VAL_47:.*]] = add i32 %[[VAL_42]], %thread.id.2
// CHECK:         %[[VAL_48:.*]] = icmp ult i32 %[[VAL_47]], 32
// CHECK:         br i1 %[[VAL_48]], label %[[VAL_49:.*]], label %[[VAL_41]]
// CHECK:       x_in_tile-after:                                  ; preds = %[[VAL_49]], %[[VAL_44]]
// CHECK:         br label %[[VAL_40]], !llvm.loop !{{[0-9]}}
// CHECK:       loop2.loop_exit:                                  ; preds = %[[VAL_40]]
// CHECK:         br label %[[VAL_32]], !llvm.loop !{{[0-9]}}
// CHECK:       loop1.loop_exit:                                  ; preds = %[[VAL_32]]
// CHECK:         %[[VAL_50:.*]] = icmp ult i32 %thread.id.1, 32
// CHECK:         %[[VAL_51:.*]] = icmp ult i32 %thread.id.2, %tile_bound.1
// CHECK:         %[[VAL_52:.*]] = and i1 %[[VAL_50]], %[[VAL_51]]
// CHECK:         %[[VAL_53:.*]] = getelementptr inbounds double, ptr %[[VAL_13]], i32 0
// CHECK:         %[[VAL_54:.*]] = load double, ptr{{.*}}%[[VAL_53]], align 8
// CHECK:         %[[VAL_55:.*]] = getelementptr inbounds [32 x [33 x double]], ptr addrspace(3) @shared_cache, i32 0, i32 %thread.id.2, i32 %thread.id.1
// CHECK:         %[[VAL_56:.*]] = addrspacecast ptr addrspace(3) %[[VAL_55]] to ptr
// CHECK:         store double %[[VAL_54]], ptr{{.*}}%[[VAL_56]], align 8
// CHECK-PTX:     call void @llvm.nvvm.barrier0()
// CHECK-GCN:     call void @llvm.amdgcn.s.barrier()
// CHECK:         %[[VAL_57:.*]] = getelementptr inbounds [32 x [33 x double]], ptr addrspace(3) @shared_cache, i32 0, i32 %thread.id.1, i32 %thread.id.2
// CHECK:         %[[VAL_58:.*]] = addrspacecast ptr addrspace(3) %[[VAL_57]] to ptr
// CHECK:         %[[VAL_59:.*]] = load double, ptr{{.*}}%[[VAL_58]], align 8
// CHECK:         %[[VAL_60:.*]] = bitcast double %[[VAL_59]] to i64
// CHECK:         %[[VAL_61:.*]] = bitcast i64 %[[VAL_60]] to <2 x i32>
// CHECK:         %[[VAL_62:.*]] = extractelement <2 x i32> %[[VAL_61]], i64 0
// CHECK-PTX:     %[[VAL_63:.*]] = call i32 @llvm.nvvm.shfl.sync.down.i32(i32 -1, i32 %[[VAL_62]], i32 16, i32 31)
// CHECK-GCN:     %[[VAL_63:.*]] = call i32 @__ockl_readuplane_i32(i32 %[[VAL_62]], i32 16)
// CHECK:         %[[VAL_64:.*]] = insertelement <2 x i32> %[[VAL_61]], i32 %[[VAL_63]], i64 0
// CHECK:         %[[VAL_65:.*]] = extractelement <2 x i32> %[[VAL_64]], i64 1
// CHECK-PTX:     %[[VAL_66:.*]] = call i32 @llvm.nvvm.shfl.sync.down.i32(i32 -1, i32 %[[VAL_65]], i32 16, i32 31)
// CHECK-GCN:     %[[VAL_66:.*]] = call i32 @__ockl_readuplane_i32(i32 %[[VAL_65]], i32 16)
// CHECK:         %[[VAL_67:.*]] = insertelement <2 x i32> %[[VAL_64]], i32 %[[VAL_66]], i64 1
// CHECK:         %[[VAL_68:.*]] = bitcast <2 x i32> %[[VAL_67]] to i64
// CHECK:         %[[VAL_69:.*]] = bitcast i64 %[[VAL_68]] to double
// CHECK:         store double %[[VAL_69]], ptr{{.*}}%[[VAL_9]], align 8
// CHECK-PTX:     call void @[[ADD:add.*]](ptr %[[VAL_58]], ptr %[[VAL_9]], ptr %[[VAL_8]])
// CHECK-GCN:     %[[VAL_9_1:.*]] = addrspacecast ptr{{.*}}%[[VAL_9]] to ptr
// CHECK-GCN:     %[[VAL_8_1:.*]] = addrspacecast ptr{{.*}}%[[VAL_8]] to ptr
// CHECK-GCN:     call void @[[ADD:add.*]](ptr %[[VAL_58]], ptr %[[VAL_9_1]], ptr %[[VAL_8_1]])
// CHECK:         %[[VAL_70:.*]] = load double, ptr{{.*}}%[[VAL_8]], align 8
// CHECK:         store double %[[VAL_70]], ptr{{.*}}%[[VAL_58]], align 8
// CHECK:         %[[VAL_71:.*]] = load double, ptr{{.*}}%[[VAL_58]], align 8
// CHECK:         %[[VAL_72:.*]] = bitcast double %[[VAL_71]] to i64
// CHECK:         %[[VAL_73:.*]] = bitcast i64 %[[VAL_72]] to <2 x i32>
// CHECK:         %[[VAL_74:.*]] = extractelement <2 x i32> %[[VAL_73]], i64 0
// CHECK-PTX:     %[[VAL_75:.*]] = call i32 @llvm.nvvm.shfl.sync.down.i32(i32 -1, i32 %[[VAL_74]], i32 8, i32 31)
// CHECK-GCN:     %[[VAL_75:.*]] = call i32 @__ockl_readuplane_i32(i32 %[[VAL_74]], i32 8)
// CHECK:         %[[VAL_76:.*]] = insertelement <2 x i32> %[[VAL_73]], i32 %[[VAL_75]], i64 0
// CHECK:         %[[VAL_77:.*]] = extractelement <2 x i32> %[[VAL_76]], i64 1
// CHECK-PTX:     %[[VAL_78:.*]] = call i32 @llvm.nvvm.shfl.sync.down.i32(i32 -1, i32 %[[VAL_77]], i32 8, i32 31)
// CHECK-GCN:     %[[VAL_78:.*]] = call i32 @__ockl_readuplane_i32(i32 %[[VAL_77]], i32 8)
// CHECK:         %[[VAL_79:.*]] = insertelement <2 x i32> %[[VAL_76]], i32 %[[VAL_78]], i64 1
// CHECK:         %[[VAL_80:.*]] = bitcast <2 x i32> %[[VAL_79]] to i64
// CHECK:         %[[VAL_81:.*]] = bitcast i64 %[[VAL_80]] to double
// CHECK:         store double %[[VAL_81]], ptr{{.*}}%[[VAL_7]], align 8
// CHECK-PTX:     call void @[[ADD]](ptr %[[VAL_58]], ptr %[[VAL_7]], ptr %[[VAL_6]])
// CHECK-GCN:     %[[VAL_7_1:.*]] = addrspacecast ptr{{.*}}%[[VAL_7]] to ptr
// CHECK-GCN:     %[[VAL_6_1:.*]] = addrspacecast ptr{{.*}}%[[VAL_6]] to ptr
// CHECK-GCN:     call void @[[ADD]](ptr %[[VAL_58]], ptr %[[VAL_7_1]], ptr %[[VAL_6_1]])
// CHECK:         %[[VAL_82:.*]] = load double, ptr{{.*}}%[[VAL_6]], align 8
// CHECK:         store double %[[VAL_82]], ptr{{.*}}%[[VAL_58]], align 8
// CHECK:         %[[VAL_83:.*]] = load double, ptr{{.*}}%[[VAL_58]], align 8
// CHECK:         %[[VAL_84:.*]] = bitcast double %[[VAL_83]] to i64
// CHECK:         %[[VAL_85:.*]] = bitcast i64 %[[VAL_84]] to <2 x i32>
// CHECK:         %[[VAL_86:.*]] = extractelement <2 x i32> %[[VAL_85]], i64 0
// CHECK-PTX:     %[[VAL_87:.*]] = call i32 @llvm.nvvm.shfl.sync.down.i32(i32 -1, i32 %[[VAL_86]], i32 4, i32 31)
// CHECK-GCN:     %[[VAL_87:.*]] = call i32 @__ockl_readuplane_i32(i32 %[[VAL_86]], i32 4)
// CHECK:         %[[VAL_88:.*]] = insertelement <2 x i32> %[[VAL_85]], i32 %[[VAL_87]], i64 0
// CHECK:         %[[VAL_89:.*]] = extractelement <2 x i32> %[[VAL_88]], i64 1
// CHECK-PTX:     %[[VAL_90:.*]] = call i32 @llvm.nvvm.shfl.sync.down.i32(i32 -1, i32 %[[VAL_89]], i32 4, i32 31)
// CHECK-GCN:     %[[VAL_90:.*]] = call i32 @__ockl_readuplane_i32(i32 %[[VAL_89]], i32 4)
// CHECK:         %[[VAL_91:.*]] = insertelement <2 x i32> %[[VAL_88]], i32 %[[VAL_90]], i64 1
// CHECK:         %[[VAL_92:.*]] = bitcast <2 x i32> %[[VAL_91]] to i64
// CHECK:         %[[VAL_93:.*]] = bitcast i64 %[[VAL_92]] to double
// CHECK:         store double %[[VAL_93]], ptr{{.*}}%[[VAL_5]], align 8
// CHECK-PTX:     call void @[[ADD]](ptr %[[VAL_58]], ptr %[[VAL_5]], ptr %[[VAL_4]])
// CHECK-GCN:     %[[VAL_5_1:.*]] = addrspacecast ptr{{.*}}%[[VAL_5]] to ptr
// CHECK-GCN:     %[[VAL_4_1:.*]] = addrspacecast ptr{{.*}}%[[VAL_4]] to ptr
// CHECK-GCN:     call void @[[ADD]](ptr %[[VAL_58]], ptr %[[VAL_5_1]], ptr %[[VAL_4_1]])
// CHECK:         %[[VAL_94:.*]] = load double, ptr{{.*}}%[[VAL_4]], align 8
// CHECK:         store double %[[VAL_94]], ptr{{.*}}%[[VAL_58]], align 8
// CHECK:         %[[VAL_95:.*]] = load double, ptr{{.*}}%[[VAL_58]], align 8
// CHECK:         %[[VAL_96:.*]] = bitcast double %[[VAL_95]] to i64
// CHECK:         %[[VAL_97:.*]] = bitcast i64 %[[VAL_96]] to <2 x i32>
// CHECK:         %[[VAL_98:.*]] = extractelement <2 x i32> %[[VAL_97]], i64 0
// CHECK-PTX:     %[[VAL_99:.*]] = call i32 @llvm.nvvm.shfl.sync.down.i32(i32 -1, i32 %[[VAL_98]], i32 2, i32 31)
// CHECK-GCN:     %[[VAL_99:.*]] = call i32 @__ockl_readuplane_i32(i32 %[[VAL_98]], i32 2)
// CHECK:         %[[VAL_100:.*]] = insertelement <2 x i32> %[[VAL_97]], i32 %[[VAL_99]], i64 0
// CHECK:         %[[VAL_101:.*]] = extractelement <2 x i32> %[[VAL_100]], i64 1
// CHECK-PTX:     %[[VAL_102:.*]] = call i32 @llvm.nvvm.shfl.sync.down.i32(i32 -1, i32 %[[VAL_101]], i32 2, i32 31)
// CHECK-GCN:     %[[VAL_102:.*]] = call i32 @__ockl_readuplane_i32(i32 %[[VAL_101]], i32 2)
// CHECK:         %[[VAL_103:.*]] = insertelement <2 x i32> %[[VAL_100]], i32 %[[VAL_102]], i64 1
// CHECK:         %[[VAL_104:.*]] = bitcast <2 x i32> %[[VAL_103]] to i64
// CHECK:         %[[VAL_105:.*]] = bitcast i64 %[[VAL_104]] to double
// CHECK:         store double %[[VAL_105]], ptr{{.*}}%[[VAL_3]], align 8
// CHECK-PTX:     call void @[[ADD]](ptr %[[VAL_58]], ptr %[[VAL_3]], ptr %[[VAL_2]])
// CHECK-GCN:     %[[VAL_3_1:.*]] = addrspacecast ptr{{.*}}%[[VAL_3]] to ptr
// CHECK-GCN:     %[[VAL_2_1:.*]] = addrspacecast ptr{{.*}}%[[VAL_2]] to ptr
// CHECK-GCN:     call void @[[ADD]](ptr %[[VAL_58]], ptr %[[VAL_3_1]], ptr %[[VAL_2_1]])
// CHECK:         %[[VAL_106:.*]] = load double, ptr{{.*}}%[[VAL_2]], align 8
// CHECK:         store double %[[VAL_106]], ptr{{.*}}%[[VAL_58]], align 8
// CHECK:         %[[VAL_107:.*]] = load double, ptr{{.*}}%[[VAL_58]], align 8
// CHECK:         %[[VAL_108:.*]] = bitcast double %[[VAL_107]] to i64
// CHECK:         %[[VAL_109:.*]] = bitcast i64 %[[VAL_108]] to <2 x i32>
// CHECK:         %[[VAL_110:.*]] = extractelement <2 x i32> %[[VAL_109]], i64 0
// CHECK-PTX:     %[[VAL_111:.*]] = call i32 @llvm.nvvm.shfl.sync.down.i32(i32 -1, i32 %[[VAL_110]], i32 1, i32 31)
// CHECK-GCN:     %[[VAL_111:.*]] = call i32 @__ockl_readuplane_i32(i32 %[[VAL_110]], i32 1)
// CHECK:         %[[VAL_112:.*]] = insertelement <2 x i32> %[[VAL_109]], i32 %[[VAL_111]], i64 0
// CHECK:         %[[VAL_113:.*]] = extractelement <2 x i32> %[[VAL_112]], i64 1
// CHECK-PTX:     %[[VAL_114:.*]] = call i32 @llvm.nvvm.shfl.sync.down.i32(i32 -1, i32 %[[VAL_113]], i32 1, i32 31)
// CHECK-GCN:     %[[VAL_114:.*]] = call i32 @__ockl_readuplane_i32(i32 %[[VAL_113]], i32 1)
// CHECK:         %[[VAL_115:.*]] = insertelement <2 x i32> %[[VAL_112]], i32 %[[VAL_114]], i64 1
// CHECK:         %[[VAL_116:.*]] = bitcast <2 x i32> %[[VAL_115]] to i64
// CHECK:         %[[VAL_117:.*]] = bitcast i64 %[[VAL_116]] to double
// CHECK:         store double %[[VAL_117]], ptr{{.*}}%[[VAL_1]], align 8
// CHECK-PTX:     call void @[[ADD]](ptr %[[VAL_58]], ptr %[[VAL_1]], ptr %[[VAL_0]])
// CHECK-GCN:     %[[VAL_1_1:.*]] = addrspacecast ptr{{.*}}%[[VAL_1]] to ptr
// CHECK-GCN:     %[[VAL_0_1:.*]] = addrspacecast ptr{{.*}}%[[VAL_0]] to ptr
// CHECK-GCN:     call void @[[ADD]](ptr %[[VAL_58]], ptr %[[VAL_1_1]], ptr %[[VAL_0_1]])
// CHECK:         %[[VAL_118:.*]] = load double, ptr{{.*}}%[[VAL_0]], align 8
// CHECK:         store double %[[VAL_118]], ptr{{.*}}%[[VAL_58]], align 8
// CHECK:         %[[VAL_119:.*]] = mul i32 %thread.id.1, 1
// CHECK:         %[[VAL_120:.*]] = add i32 %[[VAL_119]], 0
// CHECK:         %[[VAL_121:.*]] = icmp eq i32 %lane_id, 0
// CHECK:         %[[VAL_122:.*]] = and i1 %[[VAL_52]], %[[VAL_121]]
// CHECK:         br i1 %[[VAL_122]], label %[[VAL_123:.*]], label %[[VAL_19]]
// CHECK:       reduction_write_output-after:                     ; preds = %[[VAL_123]], %[[VAL_36]]
// CHECK:         br label %[[VAL_18]]
// CHECK:       x_in_tile-true:                                   ; preds = %[[VAL_44]]
// CHECK:         %[[VAL_124:.*]] = add i32 %tile_origin.0, 0
// CHECK:         %[[VAL_125:.*]] = add i32 %tile_origin.1, %[[VAL_34]]
// CHECK:         %[[VAL_126:.*]] = add i32 %tile_origin.2, %[[VAL_47]]
// CHECK:         %[[VAL_127:.*]] = add i32 %tile_origin.3, 0
// CHECK:         %[[VAL_128:.*]] = getelementptr inbounds double, ptr %[[VAL_14]], i32 %[[VAL_127]]
// CHECK:         %[[VAL_129:.*]] = getelementptr inbounds double, ptr %[[VAL_13]], i32 %[[VAL_127]]
// CHECK:         %[[VAL_130:.*]] = getelementptr inbounds [1024 x [1024 x i8]], ptr{{.*}}%[[VAL_131:.*]], i32 0, i32 %[[VAL_125]], i32 %[[VAL_126]]
// CHECK:         %[[VAL_131:.*]] = load i8, ptr{{.*}}%[[VAL_130]], align 1, !invariant.load !{{[0-9]}}
// CHECK:         %[[VAL_132:.*]] = getelementptr inbounds [1024 x [1024 x double]], ptr{{.*}}%[[VAL_133:.*]], i32 0, i32 %[[VAL_125]], i32 %[[VAL_126]]
// CHECK:         %[[VAL_133:.*]] = load double, ptr{{.*}}%[[VAL_132]], align 8, !invariant.load !{{[0-9]}}
// CHECK:         %[[VAL_135:.*]] = getelementptr inbounds [1024 x [1024 x double]], ptr{{.*}}%[[VAL_136:.*]], i32 0, i32 %[[VAL_125]], i32 %[[VAL_126]]
// CHECK:         %[[VAL_137:.*]] = load double, ptr{{.*}}%[[VAL_135]], align 8, !invariant.load !{{[0-9]}}
// CHECK:         %[[VAL_138:.*]] = trunc i8 %[[VAL_131]] to i1
// CHECK:         %[[VAL_139:.*]] = select i1 %[[VAL_138]], double %[[VAL_133]], double %[[VAL_137]]
// CHECK:         store double %[[VAL_139]], ptr{{.*}}%[[VAL_128]], align 8
// CHECK-PTX:     call void @[[ADD]](ptr %[[VAL_129]], ptr %[[VAL_128]], ptr %[[VAL_10]])
// CHECK-GCN:     %[[VAL_129_1:.*]] = addrspacecast ptr{{.*}}%[[VAL_129]] to ptr
// CHECK-GCN:     %[[VAL_128_1:.*]] = addrspacecast ptr{{.*}}%[[VAL_128]] to ptr
// CHECK-GCN:     %[[VAL_10_1:.*]] = addrspacecast ptr{{.*}}%[[VAL_10]] to ptr
// CHECK-GCN:     call void @[[ADD]](ptr %[[VAL_129_1]], ptr %[[VAL_128_1]], ptr %[[VAL_10_1]])
// CHECK:         %[[VAL_140:.*]] = load double, ptr{{.*}}%[[VAL_10]], align 8
// CHECK:         store double %[[VAL_140]], ptr{{.*}}%[[VAL_129]], align 8
// CHECK:         br label %[[VAL_41]]
// CHECK:       reduction_write_output-true:                      ; preds = %[[VAL_36]]
// CHECK:         %[[VAL_141:.*]] = add i32 %tile_origin.2, %[[VAL_120]]
// CHECK:         %[[VAL_142:.*]] = getelementptr inbounds [1024 x double], ptr{{.*}}%[[VAL_143:.*]], i32 0, i32 %[[VAL_141]]
// CHECK:         %[[VAL_144:.*]] = load double, ptr{{.*}}%[[VAL_58]], align 8
// CHECK:         store double %[[VAL_144]], ptr{{.*}}%[[VAL_142]], align 8
// CHECK:         br label %[[VAL_19]]
// CHECK:       entry:
// CHECK:         %[[VAL_142:.*]] = alloca double, align 8
// CHECK:         %[[VAL_143:.*]] = load double, ptr{{.*}}%[[VAL_144:.*]], align 8
// CHECK:         %[[VAL_145:.*]] = load double, ptr{{.*}}%[[VAL_146:.*]], align 8
// CHECK:         %[[VAL_147:.*]] = fadd double %[[VAL_143]], %[[VAL_145]]
// CHECK:         store double %[[VAL_147]], ptr{{.*}}%[[VAL_142]], align 8
// CHECK:         %[[VAL_148:.*]] = load double, ptr{{.*}}%[[VAL_142]], align 8
// CHECK:         store double %[[VAL_148]], ptr{{.*}}%[[VAL_149:.*]], align 8
// CHECK:         ret void

// CHECK-PTX: !3 = !{i32 0, i32 1024}
// CHECK-PTX: !4 = !{i32 0, i32 32}
