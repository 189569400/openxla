// RUN: hlo-opt %s --platform=gpu --stage=llvm-before-optimizations --xla_gpu_target_config_filename=%S/../../../tools/hlo_opt/gpu_specs/%{GPU}.txtpb | FileCheck %s --check-prefixes=CHECK,CHECK-%{PTX}

HloModule reduce_with_layout_change, is_scheduled=true

reduction0 {
  x0 = f32[] parameter(0)
  y0 = f32[] parameter(1)
  ROOT add0 = f32[] add(x0, y0)
}

fused_computation {
  arg0 = f32[12,3,32,16,32,4,3,12] parameter(0)
  constant0 = f32[] constant(0)
  ROOT reduce0 = f32[16,32,4,3,12]{1,3,2,0,4} reduce(arg0, constant0), dimensions={0,1,2}, to_apply=reduction0
}

ENTRY kernel_entry {
  arg0 = f32[12,3,32,16,32,4,3,12] parameter(0)
  ROOT fusion = f32[16,32,4,3,12]{1,3,2,0,4} fusion(arg0), kind=kInput, calls=fused_computation
}

// CHECK-LABEL: entry:
// CHECK:         %[[VAL_0:.*]] = alloca float, align 4
// CHECK:         %[[VAL_1:.*]] = alloca float, align 4
// CHECK:         %[[VAL_2:.*]] = alloca float, align 4
// CHECK:         %[[VAL_3:.*]] = alloca float, align 4
// CHECK:         %[[VAL_4:.*]] = alloca float, align 4
// CHECK:         %[[VAL_5:.*]] = alloca float, align 4
// CHECK:         %[[VAL_6:.*]] = alloca float, align 4
// CHECK:         %[[VAL_7:.*]] = alloca float, align 4
// CHECK:         %[[VAL_8:.*]] = alloca float, align 4
// CHECK:         %[[VAL_9:.*]] = alloca float, align 4
// CHECK:         %[[VAL_10:.*]] = alloca float, align 4
// CHECK:         %[[VAL_11:.*]] = alloca float, align 4
// CHECK:         %[[VAL_12:.*]] = alloca float, align 4
// CHECK:         %[[VAL_13:.*]] = alloca float, align 4
// CHECK:         %[[VAL_14:.*]] = alloca float, align 4
// CHECK:         %[[VAL_15:.*]] = alloca float, align 4
// CHECK:         %[[VAL_16:.*]] = alloca float, align 4
// CHECK:         %[[VAL_17:.*]] = alloca float, align 4
// CHECK:         %[[VAL_18:.*]] = alloca float, align 4
// CHECK:         %[[VAL_19:.*]] = alloca float, align 4
// CHECK:         %[[VAL_20:.*]] = alloca float, align 4
// CHECK:         %[[VAL_21:.*]] = alloca i32, align 4
// CHECK:         %[[VAL_22:.*]] = alloca i32, align 4
// CHECK:         %[[VAL_23:.*]] = alloca i32, align 4
// CHECK:         %[[VAL_24:.*]] = alloca float, i32 2, align 4
// CHECK:         %[[VAL_25:.*]] = alloca float, i32 2, align 4
// CHECK-PTX:     %[[VAL_26:.*]] = call i32 @llvm.nvvm.read.ptx.sreg.ctaid.y(), !range !2
// CHECK-GCN:     %[[VAL_26:.*]] = call i32 @llvm.amdgcn.workgroup.id.y
// CHECK:         %[[VAL_27:.*]] = icmp eq i32 %[[VAL_26]], 0
// CHECK:         br i1 %[[VAL_27]], label %[[VAL_28:.*]], label %[[VAL_29:.*]]
// CHECK:       reduce-group-0-after:                             ; preds = %[[VAL_30:.*]], %[[VAL_31:.*]]
// CHECK:         ret void
// CHECK:       reduce-group-0-true:                              ; preds = %[[VAL_31]]
// CHECK:         %[[VAL_32:.*]] = load float, ptr @0, align 4
// CHECK:         %[[VAL_33:.*]] = getelementptr inbounds float, ptr %[[VAL_24]], i32 0
// CHECK:         store float %[[VAL_32]], ptr %[[VAL_33]], align 4
// CHECK:         %[[VAL_34:.*]] = getelementptr inbounds float, ptr %[[VAL_24]], i32 1
// CHECK:         store float %[[VAL_32]], ptr %[[VAL_34]], align 4
// CHECK-PTX:     %thread.id.x = call i32 @llvm.nvvm.read.ptx.sreg.tid.x(), !range !3
// CHECK-GCN:     %thread.id.x = call i32 @llvm.amdgcn.workitem.id.x
// CHECK-PTX:     %block.id.x = call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x(), !range !4
// CHECK-GCN:     %block.id.x = call i32 @llvm.amdgcn.workgroup.id.x
// CHECK:         %[[VAL_35:.*]] = udiv i32 %thread.id.x, 32
// CHECK:         %thread.id.1 = urem i32 %[[VAL_35]], 32
// CHECK:         %thread.id.2 = urem i32 %thread.id.x, 32
// CHECK:         %lane_id = urem i32 %thread.id.x, 32
// CHECK:         %[[VAL_36:.*]] = udiv i32 %block.id.x, 1
// CHECK:         %[[VAL_37:.*]] = urem i32 %[[VAL_36]], 1
// CHECK:         %[[VAL_38:.*]] = udiv i32 %block.id.x, 1
// CHECK:         %[[VAL_39:.*]] = urem i32 %[[VAL_38]], 1152
// CHECK:         %[[VAL_40:.*]] = udiv i32 %block.id.x, 1152
// CHECK:         %[[VAL_41:.*]] = urem i32 %[[VAL_40]], 1
// CHECK:         %[[VAL_42:.*]] = udiv i32 %block.id.x, 1152
// CHECK:         %tile_origin.0 = mul i32 %[[VAL_42]], 1
// CHECK:         %tile_origin.1 = mul i32 %[[VAL_41]], 1152
// CHECK:         %tile_origin.2 = mul i32 %[[VAL_39]], 32
// CHECK:         %tile_origin.3 = mul i32 %[[VAL_37]], 2
// CHECK:         store i32 %thread.id.1, ptr %[[VAL_23]], align 4
// CHECK:         br label %[[VAL_44:.*]]
// CHECK:       loop1.loop_header:                                ; preds = %[[VAL_45:.*]], %[[VAL_28]]
// CHECK:         %[[VAL_46:.*]] = load i32, ptr %[[VAL_23]], align 4
// CHECK:         %[[VAL_47:.*]] = icmp uge i32 %[[VAL_46]], 1152
// CHECK:         br i1 %[[VAL_47]], label %[[VAL_48:.*]], label %[[VAL_49:.*]]
// CHECK:       loop1.loop_body:                                  ; preds = %[[VAL_44]]
// CHECK:         %[[VAL_50:.*]] = add nuw nsw i32 %[[VAL_46]], 32
// CHECK:         store i32 %[[VAL_50]], ptr %[[VAL_23]], align 4
// CHECK:         store i32 0, ptr %[[VAL_22]], align 4
// CHECK:         br label %[[VAL_52:.*]]
// CHECK:       loop2.loop_header:                                ; preds = %[[VAL_53:.*]], %[[VAL_49]]
// CHECK:         %[[VAL_54:.*]] = load i32, ptr %[[VAL_22]], align 4
// CHECK:         %[[VAL_55:.*]] = icmp uge i32 %[[VAL_54]], 32
// CHECK:         br i1 %[[VAL_55]], label %[[VAL_45]], label %[[VAL_56:.*]]
// CHECK:       loop2.loop_body:                                  ; preds = %[[VAL_52]]
// CHECK:         %[[VAL_57:.*]] = add nuw nsw i32 %[[VAL_54]], 32
// CHECK:         store i32 %[[VAL_57]], ptr %[[VAL_22]], align 4
// CHECK:         %[[VAL_59:.*]] = add i32 %[[VAL_54]], %thread.id.2
// CHECK:         %[[VAL_60:.*]] = icmp ult i32 %[[VAL_59]], 32
// CHECK:         br i1 %[[VAL_60]], label %[[VAL_61:.*]], label %[[VAL_53]]
// CHECK:       x_in_tile-after:                                  ; preds = %[[VAL_62:.*]], %[[VAL_56]]
// CHECK:         br label %[[VAL_52]], !llvm.loop !5
// CHECK:       loop2.loop_exit:                                  ; preds = %[[VAL_52]]
// CHECK:         br label %[[VAL_44]], !llvm.loop !8
// CHECK:       loop1.loop_exit:                                  ; preds = %[[VAL_44]]
// CHECK:         %[[VAL_63:.*]] = icmp ult i32 %thread.id.1, 32
// CHECK:         %[[VAL_64:.*]] = icmp ult i32 %thread.id.2, 1152
// CHECK:         %[[VAL_65:.*]] = and i1 %[[VAL_63]], %[[VAL_64]]
// CHECK:         %[[VAL_66:.*]] = mul i32 %tile_origin.2, 2
// CHECK:         %[[VAL_67:.*]] = getelementptr inbounds float, ptr %[[VAL_24]], i32 0
// CHECK:         %[[VAL_68:.*]] = load float, ptr %[[VAL_67]], align 4
// CHECK:         %[[VAL_69:.*]] = getelementptr inbounds [32 x [33 x float]], ptr addrspace(3) @shared_cache, i32 0, i32 %thread.id.2, i32 %thread.id.1
// CHECK:         %[[VAL_70:.*]] = addrspacecast ptr addrspace(3) %[[VAL_69]] to ptr
// CHECK:         store float %[[VAL_68]], ptr %[[VAL_70]], align 4
// CHECK:         call void @llvm.nvvm.barrier0()
// CHECK:         %[[VAL_71:.*]] = getelementptr inbounds [32 x [33 x float]], ptr addrspace(3) @shared_cache, i32 0, i32 %thread.id.1, i32 %thread.id.2
// CHECK:         %[[VAL_72:.*]] = addrspacecast ptr addrspace(3) %[[VAL_71]] to ptr
// CHECK:         %[[VAL_73:.*]] = load float, ptr %[[VAL_72]], align 4
// CHECK:         %[[VAL_74:.*]] = call float @llvm.nvvm.shfl.sync.down.f32(i32 -1, float %[[VAL_73]], i32 16, i32 31)
// CHECK:         store float %[[VAL_74]], ptr %[[VAL_19]], align 4
// CHECK:         call void @[[REDUCTION0:reduction0.*]](ptr %[[VAL_72]], ptr %[[VAL_19]], ptr %[[VAL_18]])
// CHECK:         %[[VAL_75:.*]] = load float, ptr %[[VAL_18]], align 4
// CHECK:         store float %[[VAL_75]], ptr %[[VAL_72]], align 4
// CHECK:         %[[VAL_76:.*]] = load float, ptr %[[VAL_72]], align 4
// CHECK:         %[[VAL_77:.*]] = call float @llvm.nvvm.shfl.sync.down.f32(i32 -1, float %[[VAL_76]], i32 8, i32 31)
// CHECK:         store float %[[VAL_77]], ptr %[[VAL_17]], align 4
// CHECK:         call void @[[REDUCTION0]](ptr %[[VAL_72]], ptr %[[VAL_17]], ptr %[[VAL_16]])
// CHECK:         %[[VAL_78:.*]] = load float, ptr %[[VAL_16]], align 4
// CHECK:         store float %[[VAL_78]], ptr %[[VAL_72]], align 4
// CHECK:         %[[VAL_79:.*]] = load float, ptr %[[VAL_72]], align 4
// CHECK:         %[[VAL_80:.*]] = call float @llvm.nvvm.shfl.sync.down.f32(i32 -1, float %[[VAL_79]], i32 4, i32 31)
// CHECK:         store float %[[VAL_80]], ptr %[[VAL_15]], align 4
// CHECK:         call void @[[REDUCTION0]](ptr %[[VAL_72]], ptr %[[VAL_15]], ptr %[[VAL_14]])
// CHECK:         %[[VAL_81:.*]] = load float, ptr %[[VAL_14]], align 4
// CHECK:         store float %[[VAL_81]], ptr %[[VAL_72]], align 4
// CHECK:         %[[VAL_82:.*]] = load float, ptr %[[VAL_72]], align 4
// CHECK:         %[[VAL_83:.*]] = call float @llvm.nvvm.shfl.sync.down.f32(i32 -1, float %[[VAL_82]], i32 2, i32 31)
// CHECK:         store float %[[VAL_83]], ptr %[[VAL_13]], align 4
// CHECK:         call void @[[REDUCTION0]](ptr %[[VAL_72]], ptr %[[VAL_13]], ptr %[[VAL_12]])
// CHECK:         %[[VAL_84:.*]] = load float, ptr %[[VAL_12]], align 4
// CHECK:         store float %[[VAL_84]], ptr %[[VAL_72]], align 4
// CHECK:         %[[VAL_85:.*]] = load float, ptr %[[VAL_72]], align 4
// CHECK:         %[[VAL_86:.*]] = call float @llvm.nvvm.shfl.sync.down.f32(i32 -1, float %[[VAL_85]], i32 1, i32 31)
// CHECK:         store float %[[VAL_86]], ptr %[[VAL_11]], align 4
// CHECK:         call void @[[REDUCTION0]](ptr %[[VAL_72]], ptr %[[VAL_11]], ptr %[[VAL_10]])
// CHECK:         %[[VAL_87:.*]] = load float, ptr %[[VAL_10]], align 4
// CHECK:         store float %[[VAL_87]], ptr %[[VAL_72]], align 4
// CHECK:         %[[VAL_88:.*]] = mul i32 %thread.id.1, 2
// CHECK:         %[[VAL_89:.*]] = add i32 %[[VAL_88]], 0
// CHECK:         %[[VAL_90:.*]] = icmp eq i32 %lane_id, 0
// CHECK:         %[[VAL_91:.*]] = and i1 %[[VAL_65]], %[[VAL_90]]
// CHECK:         br i1 %[[VAL_91]], label %[[VAL_92:.*]], label %[[VAL_93:.*]]
// CHECK:       reduction_write_output-after:                     ; preds = %[[VAL_92]], %[[VAL_48]]
// CHECK:         call void @llvm.nvvm.barrier0()
// CHECK:         %[[VAL_94:.*]] = getelementptr inbounds float, ptr %[[VAL_24]], i32 1
// CHECK:         %[[VAL_95:.*]] = load float, ptr %[[VAL_94]], align 4
// CHECK:         %[[VAL_96:.*]] = getelementptr inbounds [32 x [33 x float]], ptr addrspace(3) @shared_cache, i32 0, i32 %thread.id.2, i32 %thread.id.1
// CHECK:         %[[VAL_97:.*]] = addrspacecast ptr addrspace(3) %[[VAL_96]] to ptr
// CHECK:         store float %[[VAL_95]], ptr %[[VAL_97]], align 4
// CHECK:         call void @llvm.nvvm.barrier0()
// CHECK:         %[[VAL_98:.*]] = getelementptr inbounds [32 x [33 x float]], ptr addrspace(3) @shared_cache, i32 0, i32 %thread.id.1, i32 %thread.id.2
// CHECK:         %[[VAL_99:.*]] = addrspacecast ptr addrspace(3) %[[VAL_98]] to ptr
// CHECK:         %[[VAL_100:.*]] = load float, ptr %[[VAL_99]], align 4
// CHECK:         %[[VAL_101:.*]] = call float @llvm.nvvm.shfl.sync.down.f32(i32 -1, float %[[VAL_100]], i32 16, i32 31)
// CHECK:         store float %[[VAL_101]], ptr %[[VAL_9]], align 4
// CHECK:         call void @[[REDUCTION0]](ptr %[[VAL_99]], ptr %[[VAL_9]], ptr %[[VAL_8]])
// CHECK:         %[[VAL_102:.*]] = load float, ptr %[[VAL_8]], align 4
// CHECK:         store float %[[VAL_102]], ptr %[[VAL_99]], align 4
// CHECK:         %[[VAL_103:.*]] = load float, ptr %[[VAL_99]], align 4
// CHECK:         %[[VAL_104:.*]] = call float @llvm.nvvm.shfl.sync.down.f32(i32 -1, float %[[VAL_103]], i32 8, i32 31)
// CHECK:         store float %[[VAL_104]], ptr %[[VAL_7]], align 4
// CHECK:         call void @[[REDUCTION0]](ptr %[[VAL_99]], ptr %[[VAL_7]], ptr %[[VAL_6]])
// CHECK:         %[[VAL_105:.*]] = load float, ptr %[[VAL_6]], align 4
// CHECK:         store float %[[VAL_105]], ptr %[[VAL_99]], align 4
// CHECK:         %[[VAL_106:.*]] = load float, ptr %[[VAL_99]], align 4
// CHECK:         %[[VAL_107:.*]] = call float @llvm.nvvm.shfl.sync.down.f32(i32 -1, float %[[VAL_106]], i32 4, i32 31)
// CHECK:         store float %[[VAL_107]], ptr %[[VAL_5]], align 4
// CHECK:         call void @[[REDUCTION0]](ptr %[[VAL_99]], ptr %[[VAL_5]], ptr %[[VAL_4]])
// CHECK:         %[[VAL_108:.*]] = load float, ptr %[[VAL_4]], align 4
// CHECK:         store float %[[VAL_108]], ptr %[[VAL_99]], align 4
// CHECK:         %[[VAL_109:.*]] = load float, ptr %[[VAL_99]], align 4
// CHECK:         %[[VAL_110:.*]] = call float @llvm.nvvm.shfl.sync.down.f32(i32 -1, float %[[VAL_109]], i32 2, i32 31)
// CHECK:         store float %[[VAL_110]], ptr %[[VAL_3]], align 4
// CHECK:         call void @[[REDUCTION0]](ptr %[[VAL_99]], ptr %[[VAL_3]], ptr %[[VAL_2]])
// CHECK:         %[[VAL_111:.*]] = load float, ptr %[[VAL_2]], align 4
// CHECK:         store float %[[VAL_111]], ptr %[[VAL_99]], align 4
// CHECK:         %[[VAL_112:.*]] = load float, ptr %[[VAL_99]], align 4
// CHECK:         %[[VAL_113:.*]] = call float @llvm.nvvm.shfl.sync.down.f32(i32 -1, float %[[VAL_112]], i32 1, i32 31)
// CHECK:         store float %[[VAL_113]], ptr %[[VAL_1]], align 4
// CHECK:         call void @[[REDUCTION0]](ptr %[[VAL_99]], ptr %[[VAL_1]], ptr %[[VAL_0]])
// CHECK:         %[[VAL_114:.*]] = load float, ptr %[[VAL_0]], align 4
// CHECK:         store float %[[VAL_114]], ptr %[[VAL_99]], align 4
// CHECK:         %[[VAL_115:.*]] = mul i32 %thread.id.1, 2
// CHECK:         %[[VAL_116:.*]] = add i32 %[[VAL_115]], 1
// CHECK:         %[[VAL_117:.*]] = icmp eq i32 %lane_id, 0
// CHECK:         %[[VAL_118:.*]] = and i1 %[[VAL_65]], %[[VAL_117]]
// CHECK:         br i1 %[[VAL_118]], label %[[VAL_119:.*]], label %[[VAL_30]]
// CHECK:       reduction_write_output-after35:                   ; preds = %[[VAL_119]], %[[VAL_93]]
// CHECK:         br label %[[VAL_29]]
// CHECK:       x_in_tile-true:                                   ; preds = %[[VAL_56]]
// CHECK:         store i32 0, ptr %[[VAL_21]], align 4
// CHECK:         br label %[[VAL_120:.*]]
// CHECK:       loop3.loop_header:                                ; preds = %[[VAL_121:.*]], %[[VAL_61]]
// CHECK:         %[[VAL_122:.*]] = load i32, ptr %[[VAL_21]], align 4
// CHECK:         %[[VAL_123:.*]] = icmp uge i32 %[[VAL_122]], 2
// CHECK:         br i1 %[[VAL_123]], label %[[VAL_62]], label %[[VAL_124:.*]]
// CHECK:       loop3.loop_body:                                ; preds = %[[VAL_120]]
// CHECK:         %[[VAL_125:.*]] = add nuw nsw i32 %[[VAL_122]], 1
// CHECK:         store i32 %[[VAL_125]], ptr %[[VAL_21]], align 4
// CHECK:         %[[VAL_127:.*]] = add i32 %tile_origin.0, 0
// CHECK:         %[[VAL_128:.*]] = add i32 %tile_origin.1, %[[VAL_46]]
// CHECK:         %[[VAL_129:.*]] = add i32 %tile_origin.2, %[[VAL_59]]
// CHECK:         %[[VAL_130:.*]] = add i32 %tile_origin.3, %[[VAL_122]]
// CHECK:         %[[VAL_131:.*]] = getelementptr inbounds float, ptr %reduction_input_address, i32 %[[VAL_130]]
// CHECK:         %[[VAL_132:.*]] = getelementptr inbounds float, ptr %partial_reduction_result, i32 %[[VAL_130]]
// CHECK:         %[[VAL_133:.*]] = mul nuw nsw i32 %[[VAL_130]], 1
// CHECK:         %[[VAL_134:.*]] = add nuw nsw i32 0, %[[VAL_133]]
// CHECK:         %[[VAL_135:.*]] = mul nuw nsw i32 %[[VAL_129]], 2
// CHECK:         %[[VAL_136:.*]] = add nuw nsw i32 %[[VAL_134]], %[[VAL_135]]
// CHECK:         %[[VAL_137:.*]] = urem i32 %[[VAL_136]], 12
// CHECK:         %[[VAL_138:.*]] = udiv i32 %[[VAL_136]], 12
// CHECK:         %[[VAL_139:.*]] = urem i32 %[[VAL_138]], 3
// CHECK:         %[[VAL_140:.*]] = udiv i32 %[[VAL_138]], 3
// CHECK:         %[[VAL_141:.*]] = urem i32 %[[VAL_140]], 4
// CHECK:         %[[VAL_142:.*]] = udiv i32 %[[VAL_140]], 4
// CHECK:         %[[VAL_143:.*]] = urem i32 %[[VAL_142]], 32
// CHECK:         %[[VAL_144:.*]] = udiv i32 %[[VAL_142]], 32
// CHECK:         %[[VAL_145:.*]] = udiv i32 %[[VAL_144]], 16
// CHECK:         %[[VAL_146:.*]] = mul nuw nsw i32 %[[VAL_128]], 1
// CHECK:         %[[VAL_147:.*]] = add nuw nsw i32 0, %[[VAL_146]]
// CHECK:         %[[VAL_148:.*]] = urem i32 %[[VAL_147]], 32
// CHECK:         %[[VAL_149:.*]] = udiv i32 %[[VAL_147]], 32
// CHECK:         %[[VAL_150:.*]] = urem i32 %[[VAL_149]], 3
// CHECK:         %[[VAL_151:.*]] = udiv i32 %[[VAL_149]], 3
// CHECK:         %[[VAL_152:.*]] = udiv i32 %[[VAL_151]], 12
// CHECK:         %[[VAL_153:.*]] = mul nuw nsw i32 %[[VAL_127]], 1
// CHECK:         %[[VAL_154:.*]] = add nuw nsw i32 0, %[[VAL_153]]
// CHECK:         %[[VAL_155:.*]] = getelementptr inbounds [12 x [3 x [32 x [16 x [32 x [4 x [3 x [12 x float]]]]]]]], ptr %[[VAL_156:.*]], i32 0, i32 %[[VAL_151]], i32 %[[VAL_150]], i32 %[[VAL_148]], i32 %[[VAL_144]], i32 %[[VAL_143]], i32 %[[VAL_141]], i32 %[[VAL_139]], i32 %[[VAL_137]]
// CHECK:         %[[VAL_157:.*]] = load float, ptr %[[VAL_155]], align 4, !invariant.load !9
// CHECK:         store float %[[VAL_157]], ptr %[[VAL_131]], align 4
// CHECK:         call void @[[REDUCTION0]](ptr %[[VAL_132]], ptr %[[VAL_131]], ptr %[[VAL_20]])
// CHECK:         %[[VAL_158:.*]] = load float, ptr %[[VAL_20]], align 4
// CHECK:         store float %[[VAL_158]], ptr %[[VAL_132]], align 4
// CHECK:         br label %[[VAL_120]], !llvm.loop !10
// CHECK:       loop3.loop_exit:                                  ; preds = %[[VAL_120]]
// CHECK:         br label %[[VAL_53]]
// CHECK:       reduction_write_output-true:                      ; preds = %[[VAL_48]]
// CHECK:         %[[VAL_159:.*]] = add i32 %[[VAL_66]], %[[VAL_89]]
// CHECK:         %[[VAL_160:.*]] = mul nuw nsw i32 %[[VAL_159]], 1
// CHECK:         %[[VAL_161:.*]] = add nuw nsw i32 0, %[[VAL_160]]
// CHECK:         %[[VAL_162:.*]] = urem i32 %[[VAL_161]], 12
// CHECK:         %[[VAL_163:.*]] = udiv i32 %[[VAL_161]], 12
// CHECK:         %[[VAL_164:.*]] = urem i32 %[[VAL_163]], 3
// CHECK:         %[[VAL_165:.*]] = udiv i32 %[[VAL_163]], 3
// CHECK:         %[[VAL_166:.*]] = urem i32 %[[VAL_165]], 4
// CHECK:         %[[VAL_167:.*]] = udiv i32 %[[VAL_165]], 4
// CHECK:         %[[VAL_168:.*]] = urem i32 %[[VAL_167]], 32
// CHECK:         %[[VAL_169:.*]] = udiv i32 %[[VAL_167]], 32
// CHECK:         %[[VAL_170:.*]] = udiv i32 %[[VAL_169]], 16
// CHECK:         %[[VAL_171:.*]] = mul nuw nsw i32 %tile_origin.0, 1
// CHECK:         %[[VAL_172:.*]] = add nuw nsw i32 0, %[[VAL_171]]
// CHECK:         %[[VAL_173:.*]] = getelementptr inbounds [12 x [16 x [4 x [3 x [32 x float]]]]], ptr %[[VAL_174:.*]], i32 0, i32 %[[VAL_162]], i32 %[[VAL_169]], i32 %[[VAL_166]], i32 %[[VAL_164]], i32 %[[VAL_168]]
// CHECK:         %[[VAL_175:.*]] = load float, ptr %[[VAL_72]], align 4
// CHECK:         store float %[[VAL_175]], ptr %[[VAL_173]], align 4
// CHECK:         br label %[[VAL_93]]
// CHECK:       reduction_write_output-true34:                      ; preds = %[[VAL_93]]
// CHECK:         %[[VAL_176:.*]] = add i32 %[[VAL_66]], %[[VAL_116]]
// CHECK:         %[[VAL_177:.*]] = mul nuw nsw i32 %[[VAL_176]], 1
// CHECK:         %[[VAL_178:.*]] = add nuw nsw i32 0, %[[VAL_177]]
// CHECK:         %[[VAL_179:.*]] = urem i32 %[[VAL_178]], 12
// CHECK:         %[[VAL_180:.*]] = udiv i32 %[[VAL_178]], 12
// CHECK:         %[[VAL_181:.*]] = urem i32 %[[VAL_180]], 3
// CHECK:         %[[VAL_182:.*]] = udiv i32 %[[VAL_180]], 3
// CHECK:         %[[VAL_183:.*]] = urem i32 %[[VAL_182]], 4
// CHECK:         %[[VAL_184:.*]] = udiv i32 %[[VAL_182]], 4
// CHECK:         %[[VAL_185:.*]] = urem i32 %[[VAL_184]], 32
// CHECK:         %[[VAL_186:.*]] = udiv i32 %[[VAL_184]], 32
// CHECK:         %[[VAL_187:.*]] = udiv i32 %[[VAL_186]], 16
// CHECK:         %[[VAL_188:.*]] = mul nuw nsw i32 %tile_origin.0, 1
// CHECK:         %[[VAL_189:.*]] = add nuw nsw i32 0, %[[VAL_188]]
// CHECK:         %[[VAL_190:.*]] = getelementptr inbounds [12 x [16 x [4 x [3 x [32 x float]]]]], ptr %[[VAL_191:.*]], i32 0, i32 %[[VAL_179]], i32 %[[VAL_186]], i32 %[[VAL_183]], i32 %[[VAL_181]], i32 %[[VAL_185]]
// CHECK:         %[[VAL_192:.*]] = load float, ptr %[[VAL_99]], align 4
// CHECK:         store float %[[VAL_192]], ptr %[[VAL_190]], align 4
// CHECK:         br label %[[VAL_30]]
// CHECK:       entry:
// CHECK:         %[[VAL_117:.*]] = alloca float, align 4
// CHECK:         %[[VAL_118:.*]] = load float, ptr %[[VAL_119:.*]], align 4
// CHECK:         %[[VAL_120:.*]] = load float, ptr %[[VAL_121:.*]], align 4
// CHECK:         %[[VAL_122:.*]] = fadd float %[[VAL_118]], %[[VAL_120]]
// CHECK:         store float %[[VAL_122]], ptr %[[VAL_117]], align 4
// CHECK:         %[[VAL_123:.*]] = load float, ptr %[[VAL_117]], align 4
// CHECK:         store float %[[VAL_123]], ptr %[[VAL_124:.*]], align 4
// CHECK:         ret void
