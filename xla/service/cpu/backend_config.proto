syntax = "proto3";

package xla.cpu;

// Backend config for XLA:CPU.
message BackendConfig {
  // Number of partitions per outer dimension (in order, starting with
  // outer-most dimension first). Used by the parallel cpu backend to partition
  // HLOs into parallel tasks.
  repeated int64 outer_dimension_partitions = 1;
  oneof backend_config_oneof {
    // Configuration to be used by oneDNN matmul
    OneDnnMatMulConfig onednn_matmul_config = 2;
    // Configuration to be used by oneDNN layer norm
    OneDnnNormConfig onednn_layer_norm_config = 3;
    // Configuration to be used by oneDNN convolution
    OneDnnConvolutionConfig onednn_conv_config = 4;
  }
}

message DataLayoutProto {
  // The batch dimension of the tensor
  uint64 batch_dim = 1;
  // The feature dimension of the tensor
  uint64 feature_dim = 2;
  // The spatial dimensions of the tensor
  repeated uint64 spatial_dims = 3; 
}

message FilterLayoutProto {
  // The input feature dimension of the tensor
  uint64 input_feature_dim = 1;
  // The output feature dimension of the tensor
  uint64 output_feature_dim = 2;
  // The spatial dimensions of the tensor
  repeated uint64 spatial_dims = 3;
  // Shape of the tensor
  repeated uint64 shape = 4; 
}

message FactorLayoutProto {
  // The dimensions of the tensor
  repeated uint64 dimensions = 1;
  // Shape of the tensor
  repeated uint64 shape = 2;  
}

message OneDnnFusionConfig {
  // These enum needs to be mapped to oneDNN enum for post_op algorithm.
  // TODO(intel-tf): Add kinds supported by oneDNN.
  enum FusionKind {
    UNDEFINED = 0;
    BIAS = 1;
    RELU = 2;
    TANH = 3;
    GELU_ERF = 4;
    GELU_TANH = 5;
    BINARY_ADD = 6;
    LINEAR = 7;
  }
  repeated FusionKind ops = 1;
  // To avoid protobuf failures for specific decimal values,
  // the original float value alpha is type-casted to int32.
  int32 alpha_typecast = 2;
}

message TensorLayoutProto {
  uint64 dims = 1;
  oneof layout {
    DataLayoutProto data = 3;
    FilterLayoutProto filter = 4;
    FactorLayoutProto tensor = 5;
  }
}

message OneDnnMatMulConfig {
  bool transpose_a = 1;
  bool transpose_b = 2;
  
  OneDnnFusionConfig fusions = 3;
  bool bias_broadcast = 4;
  bool weights_prepacked = 6;
  bool user_scratchpad = 7;
}

message WindowProto {
  repeated uint64 size = 1;
  repeated uint64 pad_left = 2;
  repeated uint64 pad_right = 3;
  repeated uint64 strides = 4;
  repeated uint64 window_dilations = 5;
}

message OneDnnNormConfig {
  enum ScaleAndShift {
    UNDEFINED = 0;
    SCALE = 1;
    SHIFT = 2;
    SCALE_AND_SHIFT = 3;
  }
  ScaleAndShift rescale = 1;
  int32 epsilon_typecast = 2;
  OneDnnFusionConfig fusions = 3;
}

message OneDnnConvolutionConfig {
  uint64 dims = 1;
  TensorLayoutProto input = 2;
  TensorLayoutProto kernel = 3;
  TensorLayoutProto output = 4;
  WindowProto window = 5;
  
  OneDnnFusionConfig fusions = 6;
  uint64 feature_groups = 7;
}
