# OpenXLA, a community-driven and modular open-source compiler (actively migrating from [tensorflow/xla](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/compiler/xla)).

OpenXLA is a community-driven and modular open source compiler. It will enable
efficient lowering, optimization and deployment of ML models from most major
frameworks to any hardware backend notably CPUs, GPUs, and ML ASICs.

It is currently in the process of being created from the code currently inside
[tensorflow](https://github.com/tensorflow/tensorflow/tree/e2009cbe954b5c7644eecd77243cd4dfee14ff8d/tensorflow/compiler/xla),
under the
[OpenXLA SIG governance](https://github.com/tensorflow/community/pull/419/).

### Contacts

*   For technical questions, contact Mehdi Amini - aminim at google
*   For administrative questions, contact Thea Lamkin - thealamkin at google
 
### Resources
*   GitHub
    ([current](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/compiler/xla))
*   Discord TBA
*   Community proposals TBA
*   Community meetings TBA

### Code of Conduct

While under TensorFlow governance, all community spaces for SIG OpenXLA are
subject to the
[TensorFlow Code of Conduct](https://github.com/tensorflow/tensorflow/blob/master/CODE_OF_CONDUCT.md).
